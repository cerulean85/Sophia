# 3번
**정답: A. Add the aws PrincipalOrgID global condition key with a reference to the organization ID to the S3 bucket policy.**

**해설:**
- **aws:PrincipalOrgID 글로벌 조건 키:**
  - **조직 내 접근 제한:** `aws:PrincipalOrgID` 글로벌 조건 키를 사용하면 특정 AWS Organizations ID에 속한 계정만 S3 버킷에 접근할 수 있도록 제한할 수 있습니다. 이는 조직 내의 모든 계정을 포함하므로, 각 계정의 사용자들이 접근할 수 있습니다.
  - **운영 오버헤드 최소화:** 이 방법은 S3 버킷 정책에 단일 조건을 추가하는 것만으로 구현할 수 있어, 운영 오버헤드가 최소화됩니다. 추가적인 관리 작업이 필요하지 않습니다.

**다른 보기가 정답이 될 수 없는 이유:**
- **B. aws:PrincipalOrgPaths 글로벌 조건 키:** `aws:PrincipalOrgPaths`는 조직 경로를 기반으로 접근을 제어할 수 있지만, 각 부서별로 조직 단위를 생성하고 관리해야 하므로 운영 오버헤드가 증가할 수 있습니다.
- **C. AWS CloudTrail 모니터링:** CloudTrail을 사용하여 계정 생성 및 조직 변경 이벤트를 모니터링하고 S3 버킷 정책을 업데이트하는 것은 복잡하고 운영 오버헤드가 큽니다. 실시간으로 정책을 업데이트하는 것도 어려울 수 있습니다.
- **D. aws:PrincipalTag 글로벌 조건 키:** 각 사용자에게 태그를 추가하고 이를 기반으로 접근을 제어하는 것은 많은 관리 작업이 필요합니다. 특히, 새로운 사용자가 추가될 때마다 태그를 관리해야 하므로 운영 오버헤드가 큽니다.

**출제 의도:**
이 문제는 AWS Organizations를 사용하여 여러 AWS 계정을 관리할 때, 특정 S3 버킷에 대한 접근을 조직 내의 계정으로 제한하는 방법을 평가합니다. 특히, 운영 오버헤드를 최소화하면서 접근 제어를 구현하는 방법을 이해하는 것이 목적입니다.

**공부해야 하는 부분:**
1. **AWS Organizations:**
   - AWS Organizations의 기본 개념과 사용 사례
   - 조직 ID와 조직 단위(OU)의 역할

2. **S3 버킷 정책:**
   - S3 버킷 정책의 기본 개념과 사용 사례
   - 글로벌 조건 키(`aws:PrincipalOrgID`, `aws:PrincipalOrgPaths`, `aws:PrincipalTag`)를 사용하여 접근을 제어하는 방법

3. **AWS CloudTrail:**
   - CloudTrail의 기본 개념과 사용 사례
   - CloudTrail을 사용하여 조직 이벤트를 모니터링하는 방법

이 부분들을 공부하면, AWS에서 조직 내의 계정으로 접근을 제한하는 방법을 더 잘 이해할 수 있습니다.

# 16번

## 정답
- B. Create an analysis in Amazon QuickSight. Connect all the data sources and create new datasets. Publish dashboards to visualize the data. Share the dashboards with the appropriate users and groups.**

**해설:**
- **Amazon QuickSight:**
  - **데이터 시각화:** QuickSight는 다양한 데이터 소스를 연결하여 대시보드를 생성하고 데이터를 시각화할 수 있는 서비스입니다. Amazon S3와 Amazon RDS for PostgreSQL을 포함한 여러 데이터 소스를 연결할 수 있습니다.
  - **사용자 및 그룹 공유:** QuickSight는 대시보드를 특정 사용자 및 그룹과 공유할 수 있는 기능을 제공합니다. 이를 통해 관리 팀에게는 전체 접근 권한을 부여하고, 나머지 직원들에게는 제한된 접근 권한을 부여할 수 있습니다.
  - **IAM 통합:** QuickSight는 AWS IAM과 통합되어, 사용자 및 그룹 기반의 접근 제어를 쉽게 설정할 수 있습니다.

**다른 보기가 정답이 될 수 없는 이유:**
- **A. IAM 역할 공유:** IAM 역할을 사용하여 대시보드를 공유하는 것은 가능하지만, QuickSight의 사용자 및 그룹 기반 공유 기능이 더 적합합니다. 사용자 및 그룹을 통해 더 세밀한 접근 제어를 설정할 수 있습니다.
- **C. AWS Glue 및 S3:** Glue를 사용하여 데이터를 처리하고 S3에 보고서를 게시하는 것은 가능하지만, 데이터 시각화 및 대시보드 생성 기능이 부족합니다. 또한, S3 버킷 정책을 사용하여 접근을 제한하는 것은 관리 오버헤드가 큽니다.
- **D. AWS Glue 및 Athena:** Glue와 Athena를 사용하여 데이터를 처리하고 보고서를 생성하는 것은 가능하지만, 데이터 시각화 및 대시보드 생성 기능이 부족합니다. 또한, S3 버킷 정책을 사용하여 접근을 제한하는 것은 관리 오버헤드가 큽니다.

**출제 의도:**
이 문제는 AWS에서 데이터 시각화 및 보고 솔루션을 구현하는 방법을 평가합니다. 특히, Amazon QuickSight를 사용하여 다양한 데이터 소스를 연결하고, 대시보드를 생성하며, 사용자 및 그룹 기반의 접근 제어를 설정하는 방법을 이해하는 것이 목적입니다.

**공부해야 하는 부분:**
1. **Amazon QuickSight:**
   - QuickSight의 기본 개념과 사용 사례
   - QuickSight를 사용하여 데이터 소스를 연결하고 대시보드를 생성하는 방법
   - QuickSight에서 사용자 및 그룹과 대시보드를 공유하는 방법

2. **AWS Glue:**
   - Glue의 기본 개념과 사용 사례
   - Glue를 사용하여 데이터를 처리하고 ETL 작업을 수행하는 방법

3. **Amazon Athena:**
   - Athena의 기본 개념과 사용 사례
   - Athena를 사용하여 데이터를 쿼리하고 보고서를 생성하는 방법

4. **Amazon S3:**
   - S3의 기본 개념과 사용 사례
   - S3 버킷 정책을 사용하여 접근을 제어하는 방법

이 부분들을 공부하면, AWS에서 데이터 시각화 및 보고 솔루션을 효율적으로 구현하는 방법을 더 잘 이해할 수 있습니다.

# 18번
**정답: A. Create an Amazon Simple Queue Service (Amazon SQS) queue. Configure the S3 bucket to send a notification to the SQS queue when an image is uploaded to the S3 bucket.**
**정답: B. Configure the Lambda function to use the Amazon Simple Queue Service (Amazon SQS) queue as the invocation source. When the SQS message is successfully processed, delete the message in the queue.**

**해설:**
- **Amazon SQS와 Lambda 통합:**
  - **내구성 및 무상태 컴포넌트:** SQS는 내구성 있는 메시지 큐잉 서비스로, 메시지를 안전하게 저장하고 전달할 수 있습니다. Lambda 함수는 무상태 컴퓨팅 서비스로, SQS 큐에서 메시지를 읽어와 이미지를 처리할 수 있습니다.
  - **자동 처리:** S3 버킷에 이미지가 업로드되면 SQS 큐에 알림을 보내고, Lambda 함수가 SQS 큐에서 메시지를 읽어와 이미지를 처리하고 압축된 이미지를 다른 S3 버킷에 저장할 수 있습니다.

**다른 보기가 정답이 될 수 없는 이유:**
- **C. Lambda 함수가 S3 버킷을 모니터링:** Lambda 함수가 직접 S3 버킷을 모니터링하는 것은 가능하지만, 파일 이름을 메모리에 저장하고 추적하는 것은 내구성이 부족하고, 무상태 컴포넌트의 장점을 활용하지 못합니다.
- **D. EC2 인스턴스 사용:** EC2 인스턴스를 사용하여 SQS 큐를 모니터링하고 Lambda 함수를 호출하는 것은 불필요하게 복잡하며, 무상태 컴포넌트의 장점을 활용하지 못합니다.
- **E. EventBridge와 SNS 사용:** EventBridge와 SNS를 사용하여 알림을 보내는 것은 가능하지만, 이는 이미지 처리를 자동화하는 데 적합하지 않습니다. 이메일 알림은 추가적인 수동 작업이 필요할 수 있습니다.

**출제 의도:**
이 문제는 AWS에서 내구성 있고 무상태 컴포넌트를 사용하여 이미지를 자동으로 처리하는 솔루션을 설계하는 방법을 평가합니다. 특히, SQS와 Lambda를 사용하여 이미지를 처리하고 압축하는 방법을 이해하는 것이 목적입니다.

**공부해야 하는 부분:**
1. **Amazon SQS:**
   - SQS의 기본 개념과 사용 사례
   - SQS를 사용하여 메시지를 큐잉하고 전달하는 방법

2. **AWS Lambda:**
   - Lambda의 기본 개념과 사용 사례
   - Lambda를 사용하여 SQS 메시지를 처리하는 방법

3. **Amazon S3:**
   - S3의 기본 개념과 사용 사례
   - S3 이벤트 알림을 설정하여 SQS 큐로 알림을 보내는 방법

이 부분들을 공부하면, AWS에서 내구성 있고 무상태 컴포넌트를 사용하여 이미지를 자동으로 처리하는 방법을 더 잘 이해할 수 있습니다.

# 19번
**정답: D. Deploy a Gateway Load Balancer in the inspection VPC. Create a Gateway Load Balancer endpoint to receive the incoming packets and forward the packets to the appliance.**

**해설:**
- **Gateway Load Balancer:**
  - **트래픽 검사:** Gateway Load Balancer는 트래픽을 가로채고, 가상 어플라이언스(예: 방화벽)로 전달하여 트래픽을 검사할 수 있도록 설계되었습니다. 이는 트래픽을 검사하는 데 최적화된 솔루션입니다.
  - **운영 오버헤드 최소화:** Gateway Load Balancer는 자동으로 확장되고, 고가용성을 제공하며, 관리 오버헤드가 적습니다. 또한, Gateway Load Balancer 엔드포인트를 사용하여 VPC 간에 트래픽을 쉽게 전달할 수 있습니다.
  - **통합:** Gateway Load Balancer는 AWS Marketplace에서 제공되는 가상 어플라이언스와 쉽게 통합할 수 있습니다.

**다른 보기가 정답이 될 수 없는 이유:**
- **A. Network Load Balancer:** Network Load Balancer는 트래픽을 분산시키는 데 사용되지만, 트래픽을 검사하는 데 최적화되지 않았습니다. 또한, 트래픽을 가상 어플라이언스로 전달하는 기능이 부족합니다.
- **B. Application Load Balancer:** Application Load Balancer는 HTTP/HTTPS 트래픽을 분산시키는 데 사용되며, 트래픽을 검사하는 데 최적화되지 않았습니다. 또한, 트래픽을 가상 어플라이언스로 전달하는 기능이 부족합니다.
- **C. Transit Gateway:** Transit Gateway는 VPC 간의 트래픽을 라우팅하는 데 사용되지만, 트래픽을 검사하는 데 최적화되지 않았습니다. 또한, 관리 오버헤드가 높을 수 있습니다.

**출제 의도:**
이 문제는 AWS에서 트래픽을 검사하고, 운영 오버헤드를 최소화하는 방법을 평가합니다. 특히, Gateway Load Balancer를 사용하여 트래픽을 가상 어플라이언스로 전달하고 검사하는 방법을 이해하는 것이 목적입니다.

**공부해야 하는 부분:**
1. **Gateway Load Balancer:**
   - Gateway Load Balancer의 기본 개념과 사용 사례
   - Gateway Load Balancer를 사용하여 트래픽을 가상 어플라이언스로 전달하고 검사하는 방법

2. **Network Load Balancer:**
   - Network Load Balancer의 기본 개념과 사용 사례
   - Network Load Balancer를 사용하여 트래픽을 분산시키는 방법

3. **Application Load Balancer:**
   - Application Load Balancer의 기본 개념과 사용 사례
   - Application Load Balancer를 사용하여 HTTP/HTTPS 트래픽을 분산시키는 방법

4. **Transit Gateway:**
   - Transit Gateway의 기본 개념과 사용 사례
   - Transit Gateway를 사용하여 VPC 간의 트래픽을 라우팅하는 방법

이 부분들을 공부하면, AWS에서 트래픽을 검사하고 운영 오버헤드를 최소화하는 방법을 더 잘 이해할 수 있습니다.


# 20번
**정답: D. Take EBS snapshots of the production EBS volumes. Turn on the EBS fast snapshot restore feature on the EBS snapshots. Restore the snapshots into new EBS volumes. Attach the new EBS volumes to EC2 instances in the test environment.**

**해설:**
- **EBS Fast Snapshot Restore:**
  - **빠른 복원:** EBS Fast Snapshot Restore(FSR) 기능을 사용하면 스냅샷에서 EBS 볼륨을 빠르게 복원할 수 있습니다. 이는 복원 시간을 최소화하여 테스트 환경을 신속하게 설정할 수 있습니다.
  - **일관된 성능:** FSR을 사용하면 복원된 볼륨이 즉시 사용 가능하며, 일관된 높은 I/O 성능을 제공합니다. 이는 테스트 환경에서 소프트웨어가 요구하는 성능을 충족할 수 있습니다.
  - **독립된 데이터:** 스냅샷을 사용하여 새로운 EBS 볼륨을 생성하므로, 테스트 환경에서의 데이터 수정이 프로덕션 환경에 영향을 미치지 않습니다.

**다른 보기가 정답이 될 수 없는 이유:**
- **A. EC2 인스턴스 스토어 볼륨:** 인스턴스 스토어 볼륨은 일시적 스토리지로, 인스턴스가 중지되거나 종료되면 데이터가 손실됩니다. 또한, 스냅샷을 인스턴스 스토어 볼륨으로 복원하는 것은 적절하지 않습니다.
- **B. EBS Multi-Attach:** EBS Multi-Attach 기능은 여러 인스턴스에서 동일한 EBS 볼륨을 동시에 연결할 수 있지만, 이는 데이터 일관성 문제를 일으킬 수 있으며, 프로덕션 데이터에 영향을 미칠 수 있습니다.
- **C. 새로운 EBS 볼륨 초기화:** 새로운 EBS 볼륨을 생성하고 초기화한 후 스냅샷에서 복원하는 것은 시간이 많이 걸릴 수 있습니다. FSR을 사용하면 이 과정을 크게 단축할 수 있습니다.

**출제 의도:**
이 문제는 AWS에서 프로덕션 데이터를 테스트 환경으로 신속하게 복제하는 방법을 평가합니다. 특히, EBS Fast Snapshot Restore 기능을 사용하여 복원 시간을 최소화하고 일관된 성능을 제공하는 방법을 이해하는 것이 목적입니다.

**공부해야 하는 부분:**
1. **Amazon EBS Snapshots:**
   - EBS 스냅샷의 기본 개념과 사용 사례
   - EBS 스냅샷을 사용하여 볼륨을 복원하는 방법

2. **EBS Fast Snapshot Restore (FSR):**
   - FSR의 기본 개념과 사용 사례
   - FSR을 사용하여 스냅샷에서 볼륨을 빠르게 복원하는 방법

3. **EBS Multi-Attach:**
   - Multi-Attach의 기본 개념과 사용 사례
   - Multi-Attach를 사용하여 여러 인스턴스에서 동일한 볼륨을 연결하는 방법과 한계

4. **EC2 Instance Store:**
   - 인스턴스 스토어의 기본 개념과 사용 사례
   - 인스턴스 스토어를 사용하여 데이터를 저장하는 방법과 한계

이 부분들을 공부하면, AWS에서 프로덕션 데이터를 테스트 환경으로 신속하게 복제하는 방법을 더 잘 이해할 수 있습니다.



# 25번
**정답: D. Set up two Lambda functions. Configure one function to receive the information. Configure the other function to load the information into the database. Integrate the Lambda functions by using an Amazon Simple Queue Service (Amazon SQS) queue.**

**해설:**
- **AWS Lambda와 SQS 통합:**
  - **비동기 처리:** SQS를 사용하면 데이터를 비동기적으로 처리할 수 있습니다. 첫 번째 Lambda 함수가 데이터를 수신하고 SQS 큐에 메시지를 넣으면, 두 번째 Lambda 함수가 큐에서 메시지를 읽어와 데이터를 데이터베이스에 로드합니다. 이는 시스템의 확장성을 높이고, 데이터 처리량이 증가할 때도 안정적으로 작동할 수 있습니다.
  - **확장성:** SQS는 자동으로 확장되어 높은 트래픽을 처리할 수 있습니다. Lambda 함수도 자동으로 확장되어 SQS 큐에서 메시지를 처리할 수 있습니다.
  - **구성 노력 최소화:** SQS와 Lambda를 사용하면 서버를 관리할 필요 없이 자동으로 확장되는 서버리스 아키텍처를 구현할 수 있습니다. 이는 구성 노력을 최소화합니다.

**다른 보기가 정답이 될 수 없는 이유:**
- **A. Apache Tomcat과 EC2:** Lambda 함수를 EC2 인스턴스에서 실행되는 Tomcat 코드로 리팩토링하는 것은 운영 오버헤드가 크고, 서버 관리를 필요로 합니다. 이는 구성 노력을 증가시킵니다.
- **B. DynamoDB와 DAX:** Aurora PostgreSQL에서 DynamoDB로 플랫폼을 변경하는 것은 데이터베이스 구조와 API 호출 방식을 완전히 변경해야 하므로, 이는 큰 리팩토링 작업이 필요합니다. 또한, DynamoDB는 관계형 데이터베이스가 아니므로, 기존 데이터베이스 구조와 호환되지 않을 수 있습니다.
- **C. Lambda와 SNS 통합:** SNS는 주로 메시지 브로커 역할을 하며, SQS와 달리 메시지를 큐에 저장하지 않습니다. 이는 비동기 데이터 처리를 구현하는 데 적합하지 않습니다.

**출제 의도:**
이 문제는 AWS에서 높은 데이터 처리량을 효율적으로 처리하고, 구성 노력을 최소화하는 방법을 평가합니다. 특히, Lambda와 SQS를 사용하여 비동기 데이터 처리를 구현하는 방법을 이해하는 것이 목적입니다.

**공부해야 하는 부분:**
1. **AWS Lambda:**
   - Lambda의 기본 개념과 사용 사례
   - Lambda를 사용하여 서버리스 아키텍처를 구현하는 방법

2. **Amazon SQS:**
   - SQS의 기본 개념과 사용 사례
   - SQS를 사용하여 비동기 데이터 처리를 구현하는 방법

3. **Amazon SNS:**
   - SNS의 기본 개념과 사용 사례
   - SNS를 사용하여 메시지를 브로커하는 방법

4. **Amazon Aurora 및 DynamoDB:**
   - Aurora와 DynamoDB의 기본 개념과 사용 사례
   - 각 데이터베이스의 장단점과 사용 사례

이 부분들을 공부하면, AWS에서 높은 데이터 처리량을 효율적으로 처리하고, 구성 노력을 최소화하는 방법을 더 잘 이해할 수 있습니다.

# 30번
**정답: A. Stop the DB instance when tests are completed. Restart the DB instance when required.**

**해설:**
- **RDS 인스턴스 중지 및 시작:**
  - **비용 절감:** RDS 인스턴스를 중지하면 스토리지 비용만 발생하고, 인스턴스 사용 비용은 발생하지 않습니다. 이는 테스트가 끝난 후 인스턴스를 중지하고, 필요할 때 다시 시작함으로써 비용을 절감할 수 있습니다.
  - **구성 유지:** 인스턴스를 중지하고 다시 시작해도 기존의 컴퓨팅 및 메모리 속성은 유지됩니다. 이는 테스트 요구 사항을 충족하면서 비용을 절감할 수 있는 방법입니다.

**다른 보기가 정답이 될 수 없는 이유:**
- **B. Auto Scaling 정책 사용:** RDS 인스턴스는 Auto Scaling을 지원하지 않습니다. 또한, Auto Scaling은 주로 EC2 인스턴스에 적용됩니다.
- **C. 스냅샷 생성 및 인스턴스 종료:** 스냅샷을 생성하고 인스턴스를 종료한 후 다시 복원하는 것은 시간이 많이 걸리고, 운영 오버헤드가 큽니다. 또한, 스냅샷 복원 시 데이터베이스 설정을 다시 구성해야 할 수 있습니다.
- **D. 인스턴스 용량 조정:** 인스턴스 용량을 낮추고 다시 높이는 것은 운영 오버헤드가 크며, 인스턴스 크기를 변경하는 동안 다운타임이 발생할 수 있습니다. 이는 테스트 요구 사항을 충족하지 못할 수 있습니다.

**출제 의도:**
이 문제는 AWS RDS 인스턴스를 사용하여 비용을 절감하면서도 성능 요구 사항을 충족하는 방법을 평가합니다. 특히, RDS 인스턴스를 중지하고 다시 시작하여 비용을 절감하는 방법을 이해하는 것이 목적입니다.

**공부해야 하는 부분:**
1. **Amazon RDS:**
   - RDS의 기본 개념과 사용 사례
   - RDS 인스턴스를 중지하고 다시 시작하는 방법

2. **비용 절감 전략:**
   - AWS에서 비용을 절감하는 다양한 전략
   - 인스턴스를 중지하고 다시 시작하여 비용을 절감하는 방법

이 부분들을 공부하면, AWS에서 RDS 인스턴스를 효율적으로 관리하고 비용을 절감하는 방법을 더 잘 이해할 수 있습니다.

# 33번
**정답: C. Stream the transactions data into Amazon Kinesis Data Streams. Use AWS Lambda integration to remove sensitive data from every transaction and then store the transactions data in Amazon DynamoDB. Other applications can consume the transactions data off the Kinesis data stream.**

**해설:**
- **Amazon Kinesis Data Streams:**
  - **실시간 데이터 스트리밍:** Kinesis Data Streams는 실시간으로 데이터를 스트리밍할 수 있는 서비스로, 수백만 건의 트랜잭션 데이터를 처리하는 데 적합합니다.
  - **확장성:** Kinesis Data Streams는 자동으로 확장되어 높은 트래픽을 처리할 수 있습니다.

- **AWS Lambda 통합:**
  - **데이터 처리:** Lambda 함수를 사용하여 Kinesis Data Streams에서 데이터를 읽고, 민감한 데이터를 제거한 후, 데이터를 DynamoDB에 저장할 수 있습니다. 이는 데이터 처리와 저장을 자동화하고, 민감한 데이터를 안전하게 제거할 수 있습니다.
  - **비용 효율성:** Lambda는 서버리스 아키텍처로, 사용한 만큼만 비용을 지불하므로 비용 효율적입니다.

- **Amazon DynamoDB:**
  - **저지연 데이터베이스:** DynamoDB는 저지연 데이터베이스로, 빠른 데이터 검색이 필요한 경우에 적합합니다.
  - **내구성 및 확장성:** DynamoDB는 높은 내구성과 확장성을 제공하여, 대규모 트랜잭션 데이터를 효율적으로 저장하고 검색할 수 있습니다.

**다른 보기가 정답이 될 수 없는 이유:**
- **A. DynamoDB와 DynamoDB Streams:** DynamoDB는 데이터 저장에 적합하지만, 데이터 처리(민감한 데이터 제거)를 위한 규칙을 설정하는 기능이 부족합니다. 또한, DynamoDB Streams는 실시간 데이터 스트리밍에 적합하지 않습니다.
- **B. Kinesis Data Firehose:** Kinesis Data Firehose는 주로 데이터를 S3, Redshift, Elasticsearch로 전송하는 데 사용됩니다. DynamoDB와의 통합이 제한적이며, 실시간 데이터 처리에 적합하지 않습니다.
- **D. S3와 Lambda:** S3에 데이터를 배치로 저장하고 Lambda를 사용하여 처리하는 것은 실시간 데이터 처리에 적합하지 않습니다. 또한, S3는 저지연 데이터베이스로 사용하기에 적합하지 않습니다.

**출제 의도:**
이 문제는 AWS에서 실시간으로 대규모 트랜잭션 데이터를 처리하고, 민감한 데이터를 제거한 후, 저지연 데이터베이스에 저장하는 방법을 평가합니다. 특히, Kinesis Data Streams와 Lambda를 사용하여 실시간 데이터 처리를 구현하는 방법을 이해하는 것이 목적입니다.

**공부해야 하는 부분:**
1. **Amazon Kinesis Data Streams:**
   - Kinesis Data Streams의 기본 개념과 사용 사례
   - Kinesis Data Streams를 사용하여 실시간 데이터를 스트리밍하는 방법

2. **AWS Lambda:**
   - Lambda의 기본 개념과 사용 사례
   - Lambda를 사용하여 데이터를 처리하고, 다른 서비스와 통합하는 방법

3. **Amazon DynamoDB:**
   - DynamoDB의 기본 개념과 사용 사례
   - DynamoDB를 사용하여 데이터를 저장하고, 저지연으로 검색하는 방법

이 부분들을 공부하면, AWS에서 실시간으로 대규모 트랜잭션 데이터를 처리하고, 민감한 데이터를 제거한 후, 저지연 데이터베이스에 저장하는 방법을 더 잘 이해할 수 있습니다.

# 36번
**정답: B. Create a customer managed multi-Region KMS key. Create an S3 bucket in each Region. Configure replication between the S3 buckets. Configure the application to use the KMS key with client-side encryption.**

**해설:**
- **Multi-Region KMS Key:**
  - **다중 리전 지원:** AWS KMS는 다중 리전 키를 지원하여, 동일한 키를 여러 리전에서 사용할 수 있습니다. 이를 통해 두 리전의 S3 버킷에서 동일한 KMS 키를 사용하여 데이터를 암호화하고 복호화할 수 있습니다.
  - **운영 오버헤드 최소화:** 다중 리전 KMS 키를 사용하면, 각 리전에 별도의 키를 생성하고 관리할 필요가 없으므로 운영 오버헤드가 줄어듭니다.

- **S3 버킷 및 복제:**
  - **S3 버킷 생성:** 각 리전에 S3 버킷을 생성하고, 데이터를 저장합니다.
  - **복제 구성:** S3 버킷 간의 복제를 구성하여, 한 리전에서 다른 리전으로 데이터를 자동으로 복제할 수 있습니다.

- **클라이언트 측 암호화:**
  - **클라이언트 측 암호화:** 애플리케이션에서 KMS 키를 사용하여 데이터를 클라이언트 측에서 암호화하고, 암호화된 데이터를 S3 버킷에 저장합니다. 이를 통해 데이터가 전송 중에도 보호됩니다.

**다른 보기가 정답이 될 수 없는 이유:**
- **A. SSE-S3 사용:** SSE-S3는 Amazon S3 관리형 키를 사용하여 데이터를 암호화하지만, 고객 관리형 KMS 키를 사용하지 않습니다. 또한, 동일한 키를 여러 리전에서 사용할 수 없습니다.
- **C. SSE-S3 사용:** 이 옵션도 SSE-S3를 사용하여 데이터를 암호화하므로, 고객 관리형 KMS 키를 사용하지 않습니다.
- **D. 각 리전에 별도의 KMS 키 생성:** 각 리전에 별도의 KMS 키를 생성하면, 동일한 키를 여러 리전에서 사용할 수 없으므로 요구 사항을 충족하지 않습니다. 또한, 운영 오버헤드가 증가합니다.

**출제 의도:**
이 문제는 AWS에서 다중 리전 환경에서 데이터를 암호화하고, 동일한 KMS 키를 사용하여 데이터를 보호하는 방법을 평가합니다. 특히, 다중 리전 KMS 키를 사용하여 운영 오버헤드를 최소화하는 방법을 이해하는 것이 목적입니다.

**공부해야 하는 부분:**
1. **AWS KMS:**
   - KMS의 기본 개념과 사용 사례
   - 다중 리전 KMS 키를 생성하고 사용하는 방법

2. **Amazon S3:**
   - S3의 기본 개념과 사용 사례
   - S3 버킷 간의 복제를 구성하는 방법

3. **클라이언트 측 암호화:**
   - 클라이언트 측 암호화의 기본 개념과 사용 사례
   - KMS 키를 사용하여 데이터를 클라이언트 측에서 암호화하는 방법

이 부분들을 공부하면, AWS에서 다중 리전 환경에서 데이터를 암호화하고, 동일한 KMS 키를 사용하여 데이터를 보호하는 방법을 더 잘 이해할 수 있습니다.

# 43번
**정답: B. Establish a new AWS Direct Connect connection and direct backup traffic through this new connection.**

**해설:**
- **AWS Direct Connect:**
  - **전용 네트워크 연결:** AWS Direct Connect는 온프레미스 데이터 센터와 AWS 간의 전용 네트워크 연결을 제공합니다. 이는 인터넷을 거치지 않으므로, 인터넷 대역폭에 영향을 주지 않고 안정적이고 빠른 데이터 전송을 가능하게 합니다.
  - **대용량 데이터 전송:** Direct Connect는 대용량 데이터 전송에 적합하며, 시간에 민감한 데이터를 신속하게 백업할 수 있습니다. 이는 인터넷 대역폭 제한 문제를 해결할 수 있습니다.

**다른 보기가 정답이 될 수 없는 이유:**
- **A. AWS VPN 연결:** VPN 연결은 인터넷을 통해 데이터를 전송하므로, 인터넷 대역폭 제한 문제를 해결하지 못합니다. 또한, 대용량 데이터 전송에 적합하지 않습니다.
- **C. AWS Snowball:** Snowball은 대용량 데이터를 물리적으로 전송하는 데 사용되지만, 매일 장치를 주문하고 데이터를 로드하여 반환하는 것은 비효율적이며, 장기적인 솔루션으로 적합하지 않습니다.
- **D. S3 서비스 한도 제거 요청:** S3 서비스 한도 제거는 데이터 전송 속도나 인터넷 대역폭 문제를 해결하지 못합니다. 이는 문제의 근본 원인을 해결하지 않습니다.

**출제 의도:**
이 문제는 AWS에서 온프레미스 데이터 센터와 AWS 간의 대용량 데이터 전송을 효율적으로 관리하고, 인터넷 대역폭에 미치는 영향을 최소화하는 방법을 평가합니다. 특히, AWS Direct Connect를 사용하여 안정적이고 빠른 데이터 전송을 구현하는 방법을 이해하는 것이 목적입니다.

**공부해야 하는 부분:**
1. **AWS Direct Connect:**
   - Direct Connect의 기본 개념과 사용 사례
   - Direct Connect를 사용하여 온프레미스 데이터 센터와 AWS 간의 전용 네트워크 연결을 설정하는 방법

2. **AWS VPN:**
   - VPN의 기본 개념과 사용 사례
   - VPN을 사용하여 온프레미스 데이터 센터와 AWS 간의 연결을 설정하는 방법

3. **AWS Snowball:**
   - Snowball의 기본 개념과 사용 사례
   - Snowball을 사용하여 대용량 데이터를 물리적으로 전송하는 방법

이 부분들을 공부하면, AWS에서 온프레미스 데이터 센터와 AWS 간의 대용량 데이터 전송을 효율적으로 관리하고, 인터넷 대역폭에 미치는 영향을 최소화하는 방법을 더 잘 이해할 수 있습니다.

# 47번
**정답: D. Create an On-Demand Capacity Reservation that specifies the Region and three Availability Zones needed.**

**해설:**
- **On-Demand Capacity Reservation:**
  - **즉시 용량 확보:** On-Demand Capacity Reservation을 사용하면 특정 리전과 가용 영역에서 EC2 인스턴스 용량을 즉시 확보할 수 있습니다. 이는 특정 기간 동안 필요한 용량을 보장합니다.
  - **단기 이벤트:** Capacity Reservation은 단기 이벤트에 적합하며, 예약된 기간 동안 용량을 보장합니다. 이는 1주일 동안 지속되는 이벤트에 적합합니다.
  - **가용 영역 지정:** Capacity Reservation을 생성할 때 특정 가용 영역을 지정할 수 있으므로, 세 개의 특정 가용 영역에서 용량을 보장할 수 있습니다.

**다른 보기가 정답이 될 수 없는 이유:**
- **A. 리전을 지정한 예약 인스턴스 구매:** 예약 인스턴스는 특정 리전에서 할인된 요금으로 인스턴스를 사용할 수 있게 하지만, 용량을 보장하지 않습니다.
- **B. 리전을 지정한 On-Demand Capacity Reservation:** 리전만 지정한 Capacity Reservation은 특정 가용 영역에서의 용량을 보장하지 않습니다.
- **C. 리전과 가용 영역을 지정한 예약 인스턴스 구매:** 예약 인스턴스는 특정 가용 영역에서 할인된 요금으로 인스턴스를 사용할 수 있게 하지만, 용량을 보장하지 않습니다.

**출제 의도:**
이 문제는 AWS에서 특정 기간 동안 특정 가용 영역에서 EC2 인스턴스 용량을 보장하는 방법을 평가합니다. 특히, On-Demand Capacity Reservation을 사용하여 용량을 보장하는 방법을 이해하는 것이 목적입니다.

**공부해야 하는 부분:**
1. **On-Demand Capacity Reservation:**
   - Capacity Reservation의 기본 개념과 사용 사례
   - Capacity Reservation을 사용하여 특정 리전과 가용 영역에서 용량을 보장하는 방법

2. **Reserved Instances:**
   - 예약 인스턴스의 기본 개념과 사용 사례
   - 예약 인스턴스를 사용하여 비용을 절감하는 방법과 용량 보장의 차이점

이 부분들을 공부하면, AWS에서 특정 기간 동안 특정 가용 영역에서 EC2 인스턴스 용량을 보장하는 방법을 더 잘 이해할 수 있습니다.**정답: D. Create an On-Demand Capacity Reservation that specifies the Region and three Availability Zones needed.**

**해설:**
- **On-Demand Capacity Reservation:**
  - **즉시 용량 확보:** On-Demand Capacity Reservation을 사용하면 특정 리전과 가용 영역에서 EC2 인스턴스 용량을 즉시 확보할 수 있습니다. 이는 특정 기간 동안 필요한 용량을 보장합니다.
  - **단기 이벤트:** Capacity Reservation은 단기 이벤트에 적합하며, 예약된 기간 동안 용량을 보장합니다. 이는 1주일 동안 지속되는 이벤트에 적합합니다.
  - **가용 영역 지정:** Capacity Reservation을 생성할 때 특정 가용 영역을 지정할 수 있으므로, 세 개의 특정 가용 영역에서 용량을 보장할 수 있습니다.

**다른 보기가 정답이 될 수 없는 이유:**
- **A. 리전을 지정한 예약 인스턴스 구매:** 예약 인스턴스는 특정 리전에서 할인된 요금으로 인스턴스를 사용할 수 있게 하지만, 용량을 보장하지 않습니다.
- **B. 리전을 지정한 On-Demand Capacity Reservation:** 리전만 지정한 Capacity Reservation은 특정 가용 영역에서의 용량을 보장하지 않습니다.
- **C. 리전과 가용 영역을 지정한 예약 인스턴스 구매:** 예약 인스턴스는 특정 가용 영역에서 할인된 요금으로 인스턴스를 사용할 수 있게 하지만, 용량을 보장하지 않습니다.

**출제 의도:**
이 문제는 AWS에서 특정 기간 동안 특정 가용 영역에서 EC2 인스턴스 용량을 보장하는 방법을 평가합니다. 특히, On-Demand Capacity Reservation을 사용하여 용량을 보장하는 방법을 이해하는 것이 목적입니다.

**공부해야 하는 부분:**
1. **On-Demand Capacity Reservation:**
   - Capacity Reservation의 기본 개념과 사용 사례
   - Capacity Reservation을 사용하여 특정 리전과 가용 영역에서 용량을 보장하는 방법

2. **Reserved Instances:**
   - 예약 인스턴스의 기본 개념과 사용 사례
   - 예약 인스턴스를 사용하여 비용을 절감하는 방법과 용량 보장의 차이점

이 부분들을 공부하면, AWS에서 특정 기간 동안 특정 가용 영역에서 EC2 인스턴스 용량을 보장하는 방법을 더 잘 이해할 수 있습니다.

# 48번
**정답: D. Move the catalog to an Amazon Elastic File System (Amazon EFS) file system.**

**해설:**
- **Amazon Elastic File System (EFS):**
  - **고가용성 및 내구성:** Amazon EFS는 여러 가용 영역에 걸쳐 데이터를 저장하여 고가용성과 내구성을 제공합니다. 이는 데이터 손실 위험을 줄이고, 데이터가 항상 접근 가능하도록 보장합니다.
  - **확장성:** EFS는 자동으로 확장되므로, 데이터 양이 증가해도 별도의 관리 없이 확장할 수 있습니다.
  - **공유 파일 시스템:** EFS는 여러 EC2 인스턴스에서 동시에 접근할 수 있는 공유 파일 시스템을 제공하므로, 웹사이트의 카탈로그 데이터를 여러 인스턴스에서 사용할 수 있습니다.

**다른 보기가 정답이 될 수 없는 이유:**
- **A. ElastiCache for Redis:** ElastiCache for Redis는 주로 캐싱을 위한 인메모리 데이터 저장소로, 내구성 있는 데이터 저장소로 사용하기에는 적합하지 않습니다.
- **B. 더 큰 인스턴스 스토어:** 더 큰 인스턴스 스토어를 사용하는 것은 내구성을 보장하지 않습니다. 인스턴스 스토어는 인스턴스가 종료되면 데이터가 손실될 수 있습니다.
- **C. S3 Glacier Deep Archive:** S3 Glacier Deep Archive는 장기 보관을 위한 저비용 스토리지로, 자주 접근해야 하는 데이터에는 적합하지 않습니다. 또한, 데이터 복구 시간이 길어질 수 있습니다.

**출제 의도:**
이 문제는 AWS에서 데이터를 고가용성 및 내구성을 보장하는 위치에 저장하는 방법을 평가합니다. 특히, Amazon EFS를 사용하여 데이터를 안전하게 저장하고, 여러 인스턴스에서 접근할 수 있도록 하는 방법을 이해하는 것이 목적입니다.

**공부해야 하는 부분:**
1. **Amazon Elastic File System (EFS):**
   - EFS의 기본 개념과 사용 사례
   - EFS를 사용하여 데이터를 고가용성 및 내구성을 보장하는 방법

2. **Amazon ElastiCache:**
   - ElastiCache의 기본 개념과 사용 사례
   - ElastiCache를 사용하여 데이터를 캐싱하는 방법

3. **Amazon S3 Glacier Deep Archive:**
   - S3 Glacier Deep Archive의 기본 개념과 사용 사례
   - S3 Glacier Deep Archive를 

# 49번
**정답: B. Store individual files in Amazon S3 Intelligent-Tiering. Use S3 Lifecycle policies to move the files to S3 Glacier Flexible Retrieval after 1 year. Query and retrieve the files that are in Amazon S3 by using Amazon Athena. Query and retrieve the files that are in S3 Glacier by using S3 Glacier Select.**

**해설:**
- **Amazon S3 Intelligent-Tiering:**
  - **비용 최적화:** S3 Intelligent-Tiering은 데이터 액세스 패턴에 따라 자동으로 데이터를 가장 비용 효율적인 스토리지 클래스로 이동시킵니다. 이는 자주 액세스되는 데이터와 드물게 액세스되는 데이터를 자동으로 구분하여 비용을 절감할 수 있습니다.
  - **빠른 액세스:** 1년 이내에 자주 액세스되는 파일은 S3 Intelligent-Tiering의 표준 또는 인빈티드 액세스 계층에 저장되어 빠르게 액세스할 수 있습니다.

- **S3 Glacier Flexible Retrieval:**
  - **장기 보관:** 1년 이후에 드물게 액세스되는 파일은 S3 Glacier Flexible Retrieval로 이동하여 비용을 절감할 수 있습니다. 이 스토리지 클래스는 저렴한 비용으로 데이터를 장기 보관할 수 있으며, 액세스 지연이 허용되는 경우에 적합합니다.

- **Amazon Athena 및 S3 Glacier Select:**
  - **데이터 쿼리:** Athena를 사용하여 S3에 저장된 데이터를 쿼리하고, S3 Glacier Select를 사용하여 Glacier에 저장된 데이터를 쿼리할 수 있습니다. 이는 데이터를 효율적으로 검색하고, 필요한 경우에만 데이터를 복원할 수 있게 합니다.

**다른 보기가 정답이 될 수 없는 이유:**
- **A. S3 Glacier Instant Retrieval:** S3 Glacier Instant Retrieval은 빠른 액세스를 제공하지만, 비용이 더 높을 수 있습니다. 또한, 1년 이내에 자주 액세스되는 데이터를 위한 최적의 솔루션이 아닙니다.
- **C. S3 Standard 및 S3 Glacier Instant Retrieval:** S3 Standard는 비용이 더 높을 수 있으며, S3 Glacier Instant Retrieval은 비용 효율적이지 않습니다. 또한, 메타데이터를 별도로 저장하고 쿼리하는 것은 복잡성을 증가시킵니다.
- **D. S3 Standard 및 S3 Glacier Deep Archive:** S3 Glacier Deep Archive는 매우 저렴한 비용으로 데이터를 장기 보관할 수 있지만, 데이터 복구 시간이 길어질 수 있습니다. 이는 1년 이내에 자주 액세스되는 데이터를 위한 최적의 솔루션이 아닙니다.

**출제 의도:**
이 문제는 AWS에서 데이터를 비용 효율적으로 저장하고, 액세스 패턴에 따라 최적화하는 방법을 평가합니다. 

# 50번
**정답: D. Use AWS Systems Manager Run Command to run a custom command that applies the patch to all EC2 instances.**

**해설:**
- **AWS Systems Manager Run Command:**
  - **즉시 실행:** Run Command를 사용하면 EC2 인스턴스에 명령을 즉시 실행할 수 있습니다. 이는 긴급한 패치 작업을 빠르게 수행하는 데 적합합니다.
  - **대규모 인스턴스 관리:** Run Command는 여러 인스턴스에 동시에 명령을 실행할 수 있으므로, 1,000개의 EC2 인스턴스에 패치를 빠르게 적용할 수 있습니다.
  - **커스텀 명령:** Run Command를 사용하여 특정 패치 명령을 정의하고 실행할 수 있습니다. 이는 특정 소프트웨어 패치를 적용하는 데 유연성을 제공합니다.

**다른 보기가 정답이 될 수 없는 이유:**
- **A. AWS Lambda 함수 생성:** Lambda 함수는 짧은 실행 시간과 제한된 리소스를 가지므로, 1,000개의 EC2 인스턴스에 패치를 적용하는 데 적합하지 않습니다.
- **B. AWS Systems Manager Patch Manager 구성:** Patch Manager는 주로 운영 체제 패치를 관리하는 데 사용됩니다. 특정 서드파티 소프트웨어 패치를 적용하는 데는 적합하지 않을 수 있습니다.
- **C. AWS Systems Manager 유지 관리 창 스케줄링:** 유지 관리 창을 사용하면 패치를 예약할 수 있지만, 긴급한 패치 작업을 즉시 수행하는 데는 적합하지 않습니다.

**출제 의도:**
이 문제는 AWS에서 대규모 EC2 인스턴스에 긴급한 패치를 빠르게 적용하는 방법을 평가합니다. 특히, AWS Systems Manager Run Command를 사용하여 커스텀 명령을 실행하고, 패치를 빠르게 적용하는 방법을 이해하는 것이 목적입니다.

**공부해야 하는 부분:**
1. **AWS Systems Manager Run Command:**
   - Run Command의 기본 개념과 사용 사례
   - Run Command를 사용하여 여러 인스턴스에 명령을 실행하는 방법

2. **AWS Systems Manager Patch Manager:**
   - Patch Manager의 기본 개념과 사용 사례
   - Patch Manager를 사용하여 운영 체제 패치를 관리하는 방법

3. **AWS Lambda:**
   - Lambda의 기본 개념과 사용 사례
   - Lambda를 사용하여 짧은 실행 시간의 작업을 수행하는 방법

4. **AWS Systems Manager Maintenance Window:**
   - Maintenance Window의 기본 개념과 사용 사례
   - Maintenance Window를 사용하여 유지 관리 작업을 예약하는 방법

이 부분들을 공부하면, AWS에서 대규모 EC2 인스턴스에 긴급한 패치를 빠르게 적용하는 방법을 더 잘 이해할 수 있습니다.

# 57번
**정답: B. Use Amazon Rekognition to detect inappropriate content. Use human review for low-confidence predictions.**

**해설:**
- **Amazon Rekognition:**
  - **이미지 분석:** Amazon Rekognition은 이미지와 비디오에서 객체, 사람, 텍스트, 장면 및 활동을 식별할 수 있는 완전 관리형 서비스입니다. 특히, 부적절한 콘텐츠를 감지하는 데 사용될 수 있는 내장된 기능을 제공합니다.
  - **개발 노력 최소화:** Rekognition은 사전 훈련된 모델을 제공하므로, 별도의 모델을 훈련하거나 배포할 필요가 없습니다. 이는 개발 노력을 최소화합니다.
  - **인간 검토:** Rekognition은 낮은 신뢰도의 예측에 대해 인간 검토를 추가할 수 있는 기능을 제공합니다. 이는 부적절한 콘텐츠를 더 정확하게 필터링하는 데 도움이 됩니다.

**다른 보기가 정답이 될 수 없는 이유:**
- **A. Amazon Comprehend:** Comprehend는 주로 텍스트 분석을 위한 서비스로, 이미지에서 부적절한 콘텐츠를 감지하는 데 적합하지 않습니다.
- **C. Amazon SageMaker:** SageMaker는 맞춤형 머신 러닝 모델을 훈련하고 배포하는 데 사용됩니다. 이는 개발 노력이 많이 들며, 사전 훈련된 모델을 제공하지 않으므로 부적절한 콘텐츠 감지에 적합하지 않습니다.
- **D. AWS Fargate:** Fargate는 컨테이너를 배포하고 관리하는 데 사용됩니다. 맞춤형 머신 러닝 모델을 배포하려면 많은 개발 노력이 필요하며, 사전 훈련된 모델을 제공하지 않으므로 부적절한 콘텐츠 감지에 적합하지 않습니다.

**출제 의도:**
이 문제는 AWS에서 부적절한 콘텐츠를 감지하고, 개발 노력을 최소화하는 방법을 평가합니다. 특히, Amazon Rekognition을 사용하여 이미지에서 부적절한 콘텐츠를 감지하고, 낮은 신뢰도의 예측에 대해 인간 검토를 추가하는 방법을 이해하는 것이 목적입니다.

**공부해야 하는 부분:**
1. **Amazon Rekognition:**
   - Rekognition의 기본 개념과 사용 사례
   - Rekognition을 사용하여 이미지에서 부적절한 콘텐츠를 감지하는 방법

2. **Amazon Comprehend:**
   - Comprehend의 기본 개념과 사용 사례
   - Comprehend를 사용하여 텍스트를 분석하는 방법

3. **Amazon SageMaker:**
   - SageMaker의 기본 개념과 사용 사례
   - SageMaker를 사용하여 맞춤형 머신 러닝 모델을 훈련하고 배포하는 방법

4. **AWS Fargate:**
   - Fargate의 기본 개념과 사용 사례
   - Fargate를 사용하여 컨테이너를 배포하고 관리하는 방법

이 부분들을 공부하면, AWS에서 부적절한 콘텐츠를 감지하고, 개발 노력을 최소화하는 방법을 더 잘 이해할 수 있습니다.

**정답: C. Create an S3 bucket lifecycle policy to move files from S3 Standard to S3 Standard-Infrequent Access (S3 Standard-IA) 30 days from object creation. Delete the files 4 years after object creation.**

**해설:**
- **S3 Standard-Infrequent Access (S3 Standard-IA):**
  - **비용 효율성:** S3 Standard-IA는 자주 접근하지 않는 데이터를 저장하는 데 적합하며, S3 Standard보다 저렴한 비용으로 데이터를 저장할 수 있습니다.
  - **즉시 접근 가능:** S3 Standard-IA는 데이터를 즉시 접근할 수 있도록 보장하므로, 중요한 비즈니스 데이터를 저장하는 데 적합합니다.
  - **사용 패턴:** 문제에서 주어진 사용 패턴(처음 30일 동안 자주 접근, 이후 드물게 접근)에 적합합니다.

**다른 보기가 정답이 될 수 없는 이유:**
- **A. S3 Glacier:** S3 Glacier는 장기 보관을 위한 저비용 스토리지로, 데이터 접근 시간이 길어질 수 있습니다. 즉시 접근이 필요한 데이터에는 적합하지 않습니다.
- **B. S3 One Zone-IA:** S3 One Zone-IA는 단일 가용 영역에 데이터를 저장하므로, 내구성이 낮아질 수 있습니다. 중요한 비즈니스 데이터를 저장하는 데 적합하지 않습니다.
- **D. S3 Standard-IA에서 S3 Glacier로 이동:** S3 Glacier로 이동하면 데이터 접근 시간이 길어질 수 있습니다. 즉시 접근이 필요한 데이터에는 적합하지 않습니다.

**출제 의도:**
이 문제는 AWS에서 데이터를 비용 효율적으로 저장하고, 즉시 접근 가능성을 보장하는 방법을 평가합니다. 특히, S3 Standard-IA를 사용하여 자주 접근하지 않는 데이터를 저장하고, S3 Lifecycle 정책을 사용하여 데이터를 관리하는 방법을 이해하는 것이 목적입니다.

**공부해야 하는 부분:**
1. **Amazon S3 Storage Classes:**
   - S3 Standard, S3 Standard-IA, S3 One Zone-IA, S3 Glacier의 기본 개념과 사용 사례
   - 각 스토리지 클래스의 비용 및 접근 시간

2. **S3 Lifecycle Policies:**
   - S3 Lifecycle 정책의 기본 개념과 사용 사례
   - S3 Lifecycle 정책을 사용하여 데이터를 자동으로 이동하고 삭제하는 방법

이 부분들을 공부하면, AWS에서 데이터를 비용 효율적으로 저장하고, 즉시 접근 가능성을 보장하는 방법을 더 잘 이해할 수 있습니다.

# 68번
**정답: A. Provision an AWS Direct Connect connection to a Region. Provision a VPN connection as a backup if the primary Direct Connect connection fails.**

**해설:**
- **AWS Direct Connect:**
  - **고가용성 및 저지연:** Direct Connect는 AWS와 온프레미스 데이터 센터 간의 전용 네트워크 연결을 제공하여, 일관된 저지연과 높은 가용성을 보장합니다.
  - **비용 효율성:** Direct Connect는 대규모 데이터 전송에 대해 비용 효율적입니다.

- **VPN 연결 백업:**
  - **비용 절감:** VPN 연결은 Direct Connect에 비해 저렴하며, 백업 연결로 사용하기에 적합합니다.
  - **자동 페일오버:** Direct Connect 연결이 실패할 경우, VPN 연결을 통해 트래픽을 전송할 수 있습니다. 이는 트래픽이 느려질 수 있지만, 비용을 절감하면서 고가용성을 유지할 수 있습니다.

**다른 보기가 정답이 될 수 없는 이유:**
- **B. 두 개의 VPN 터널:** 두 개의 VPN 터널을 사용하는 것은 비용이 저렴하지만, 일관된 저지연을 제공하지 못합니다. 이는 고가용성과 저지연 요구 사항을 충족하지 못합니다.
- **C. 두 개의 Direct Connect 연결:** 두 개의 Direct Connect 연결을 사용하는 것은 고가용성을 보장하지만, 비용이 많이 듭니다. 비용을 최소화하려는 요구 사항을 충족하지 못합니다.
- **D. Direct Connect 페일오버 속성:** Direct Connect 페일오버 속성은 자동 백업 연결을 생성하지 않습니다. 백업 연결을 수동으로 설정해야 합니다.

**출제 의도:**
이 문제는 AWS에서 온프레미스 인프라를 확장하고, 고가용성과 저지연을 보장하면서 비용을 최소화하는 방법을 평가합니다. 특히, Direct Connect와 VPN 연결을 조합하여 고가용성과 비용 효율성을 유지하는 방법을 이해하는 것이 목적입니다.

**공부해야 하는 부분:**
1. **AWS Direct Connect:**
   - Direct Connect의 기본 개념과 사용 사례
   - Direct Connect를 사용하여 고가용성과 저지연을 보장하는 방법

2. **AWS VPN:**
   - VPN의 기본 개념과 사용 사례
   - VPN을 백업 연결로 사용하는 방법

3. **하이브리드 아키텍처:**
   - 온프레미스 인프라와 AWS 간의 하이브리드 아키텍처 설계 방법
   - 고가용성과 비용 효율성을 유지하는 방법

이 부분들을 공부하면, AWS에서 온프레미스 인프라를 확장하고, 고가용성과 저지연을 보장하면서 비용을 최소화하는 방법을 더 잘 이해할 수 있습니다.

# 72번
**정답: D. Deploy an S3 VPC gateway endpoint into the VPC and attach an endpoint policy that allows access to the S3 buckets.**

**해설:**
- **S3 VPC Gateway Endpoint:**
  - **내부 네트워크 트래픽:** S3 VPC Gateway Endpoint를 사용하면 VPC 내에서 Amazon S3에 직접 연결할 수 있습니다. 이는 인터넷을 통해 트래픽을 라우팅할 필요가 없으므로 데이터 전송 비용을 줄일 수 있습니다.
  - **비용 절감:** VPC Endpoint를 사용하면 인터넷 게이트웨이, NAT 게이트웨이 또는 다른 네트워크 장치를 통해 트래픽을 라우팅할 필요가 없으므로 데이터 전송 비용을 절감할 수 있습니다.
  - **보안:** VPC Endpoint를 사용하면 트래픽이 AWS 네트워크 내에서 유지되므로 보안이 강화됩니다.

**다른 보기가 정답이 될 수 없는 이유:**
- **A. API Gateway 사용:** API Gateway는 주로 API 관리를 위해 사용되며, S3와의 데이터 전송 비용을 줄이는 데 적합하지 않습니다.
- **B. NAT Gateway 사용:** NAT Gateway를 사용하면 인터넷을 통해 트래픽이 라우팅되므로 데이터 전송 비용이 발생합니다.
- **C. 인터넷 게이트웨이 사용:** 인터넷 게이트웨이를 통해 S3에 접근하면 데이터 전송 비용이 발생합니다.

**출제 의도:**
이 문제는 AWS에서 데이터 전송 비용을 줄이기 위해 S3 VPC Gateway Endpoint를 사용하는 방법을 평가합니다. 특히, VPC Endpoint를 사용하여 VPC 내에서 S3에 직접 연결하고, 데이터 전송 비용을 절감하는 방법을 이해하는 것이 목적입니다.

**공부해야 하는 부분:**
1. **Amazon S3 VPC Gateway Endpoint:**
   - S3 VPC Gateway Endpoint의 기본 개념과 사용 사례
   - VPC Endpoint를 사용하여 데이터 전송 비용을 절감하는 방법

2. **AWS 네트워킹:**
   - VPC, 서브넷, 인터넷 게이트웨이, NAT 게이트웨이의 기본 개념과 사용 사례
   - 각 네트워킹 구성 요소의 비용 및 보안 고려 사항

이 부분들을 공부하면, AWS에서 데이터 전송 비용을 줄이기 위해 S3 VPC Gateway Endpoint를 사용하는 방법을 더 잘 이해할 수 있습니다.


# 82번
**정답: B. Create an AWS Config rule that checks for certificates that will expire within 30 days. Configure Amazon EventBridge (Amazon CloudWatch Events) to invoke a custom alert by way of Amazon Simple Notification Service (Amazon SNS) when AWS Config reports a noncompliant resource.**

**해설:**
- **AWS Config Rule:**
  - **자동화된 규칙 검사:** AWS Config는 리소스 구성을 지속적으로 평가하고, 규칙을 기반으로 비준수 리소스를 식별할 수 있습니다. 이를 통해 인증서 만료를 자동으로 감지할 수 있습니다.
  - **30일 이내 만료 확인:** AWS Config 규칙을 사용하여 30일 이내에 만료되는 인증서를 확인할 수 있습니다.

- **Amazon EventBridge (CloudWatch Events):**
  - **이벤트 기반 알림:** EventBridge를 사용하여 AWS Config에서 비준수 리소스를 감지할 때마다 이벤트를 트리거할 수 있습니다. 이를 통해 자동으로 알림을 보낼 수 있습니다.
  - **SNS 통합:** EventBridge 이벤트를 Amazon SNS를 통해 알림으로 전송할 수 있습니다. 이를 통해 보안 팀에 인증서 만료 알림을 보낼 수 있습니다.

**다른 보기가 정답이 될 수 없는 이유:**
- **A. ACM 규칙 추가:** ACM 자체에는 인증서 만료 알림을 위한 규칙을 설정하는 기능이 없습니다.
- **C. Trusted Advisor 사용:** Trusted Advisor는 인증서 만료를 확인할 수 있지만, AWS Config와 EventBridge를 사용하는 것이 더 자동화되고 효율적입니다.
- **D. EventBridge와 Lambda 사용:** Lambda 함수를 사용하여 알림을 보내는 것은 가능하지만, AWS Config 규칙을 사용하는 것이 더 간단하고 운영 오버헤드가 적습니다.

**출제 의도:**
이 문제는 AWS에서 인증서 만료를 자동으로 감지하고, 알림을 보내는 방법을 평가합니다. 특히, AWS Config와 EventBridge를 사용하여 인증서 만료를 감지하고, SNS를 통해 알림을 보내는 방법을 이해하는 것이 목적입니다.

**공부해야 하는 부분:**
1. **AWS Config:**
   - AWS Config의 기본 개념과 사용 사례
   - AWS Config 규칙을 설정하여 리소스 구성을 평가하는 방법

2. **Amazon EventBridge (CloudWatch Events):**
   - EventBridge의 기본 개념과 사용 사례
   - EventBridge를 사용하여 이벤트 기반 알림을 설정하는 방법

3. **Amazon SNS:**
   - SNS의 기본 개념과 사용 사례
   - SNS를 사용하여 알림을 전송하는 방법

이 부분들을 공부하면, AWS에서 인증서 만료를 자동으로 감지하고, 알림을 보내는 방법을 더 잘 이해할 수 있습니다.

# 93번
**정답: B. Use Amazon Aurora MySQL with Multi-AZ Aurora Replicas for production. Use database cloning to create the staging database on-demand.**

**해설:**
- **Amazon Aurora MySQL:**
  - **고가용성 및 확장성:** Aurora MySQL은 고가용성과 확장성을 제공하며, Multi-AZ Aurora Replicas를 사용하여 읽기 성능을 향상시킬 수 있습니다.
  - **Aurora Replicas:** Aurora Replicas는 읽기 작업을 분산시켜 데이터베이스의 부하를 줄이고 성능을 향상시킵니다.

- **Database Cloning:**
  - **빠른 복제:** 데이터베이스 클로닝을 사용하면 전체 데이터베이스를 빠르게 복제할 수 있습니다. 이는 스테이징 환경을 신속하게 설정할 수 있도록 합니다.
  - **운영 오버헤드 최소화:** 클로닝은 백업 및 복원 과정보다 훨씬 빠르고 효율적이며, 운영 오버헤드를 최소화합니다.

**다른 보기가 정답이 될 수 없는 이유:**
- **A. mysqldump 사용:** mysqldump를 사용한 백업 및 복원 과정은 시간이 많이 걸리며, 여전히 애플리케이션 지연 문제를 해결하지 못할 수 있습니다.
- **C. 스탠바이 인스턴스 사용:** 스탠바이 인스턴스는 장애 복구를 위해 사용되며, 스테이징 데이터베이스로 사용하는 것은 적절하지 않습니다.
- **D. mysqldump 사용:** mysqldump를 사용한 백업 및 복원 과정은 시간이 많이 걸리며, 여전히 애플리케이션 지연 문제를 해결하지 못할 수 있습니다.

**출제 의도:**
이 문제는 AWS에서 MySQL 데이터베이스를 고가용성과 확장성을 갖춘 아키텍처로 마이그레이션하고, 애플리케이션 지연 문제를 해결하는 방법을 평가합니다. 특히, Amazon Aurora MySQL과 데이터베이스 클로닝을 사용하여 스테이징 환경을 신속하게 설정하고, 운영 오버헤드를 최소화하는 방법을 이해하는 것이 목적입니다.

**공부해야 하는 부분:**
1. **Amazon Aurora MySQL:**
   - Aurora MySQL의 기본 개념과 사용 사례
   - Multi-AZ Aurora Replicas를 사용하여 읽기 성능을 향상시키는 방법

2. **Database Cloning:**
   - 데이터베이스 클로닝의 기본 개념과 사용 사례
   - 클로닝을 사용하여 스테이징 환경을 신속하게 설정하는 방법

이 부분들을 공부하면, AWS에서 MySQL 데이터베이스를 고가용성과 확장성을 갖춘 아키텍처로 마이그레이션하고, 애플리케이션 지연 문제를 해결하는 방법을 더 잘 이해할 수 있습니다.

# 95번
- Creating read replicas allows the application to offload read traffic from the source database, improving its performance. The read replicas should be configured with the same compute and storage resources as the source database to ensure that they can handle the read workload effectively.

- 오프로딩(offloading): 컴퓨팅 자원 및 계산 속도의 한계를 극복하기 위해 로컬 컴퓨터에서 수행하는 어플리케이션 의 일부를 컴퓨팅 자원과 처리능력이 우수한 원격지 컴퓨터에 전달하여 처리한 후 결과를 반환받는 방식

# 96번
- SourceIp
    - 요청자의 IP주소를 정책에서 지정한 IP주소와 비교
    - 퍼블릭 IP 주소 범위에만 사용 가능
    - 정책 내에서 aws:SourceIp 조건 키를 사용하여 보안 주체가 지정된 IP 범위 내에서만 요청하도록 할 수 있음


# 98번
**정답: B. Change the SQS standard queue to an SQS FIFO queue. Use the message deduplication ID to discard duplicate messages.**

**해설:**
- **SQS FIFO Queue:**
  - **메시지 중복 제거:** SQS FIFO 큐는 메시지 중복 제거 기능을 제공하여 동일한 메시지가 여러 번 처리되는 것을 방지할 수 있습니다. 메시지 중복 제거 ID를 사용하면 동일한 메시지가 여러 번 처리되지 않도록 할 수 있습니다.
  - **순서 보장:** FIFO 큐는 메시지의 순서를 보장하므로, 메시지가 올바른 순서로 처리됩니다.

**다른 보기가 정답이 될 수 없는 이유:**
- **A. Long Polling:** Long Polling은 메시지를 더 효율적으로 수신하는 데 도움이 되지만, 메시지 중복 문제를 해결하지는 않습니다.
- **C. Visibility Timeout 증가:** Visibility Timeout을 증가시키면 메시지가 다시 처리되는 것을 방지할 수 있지만, 이는 메시지 처리 시간이 길어질 수 있는 경우에만 유효합니다. 또한, 이는 메시지 중복 문제를 완전히 해결하지 못할 수 있습니다.
- **D. Lambda 함수 수정:** Lambda 함수에서 메시지를 읽은 후 즉시 삭제하는 것은 메시지가 성공적으로 처리되었는지 확인하기 전에 삭제하는 것이므로, 데이터 손실의 위험이 있습니다.

**출제 의도:**
이 문제는 AWS에서 SQS와 Lambda를 사용하여 이벤트 기반 처리를 구현할 때 메시지 중복 문제를 해결하는 방법을 평가합니다. 특히, SQS FIFO 큐를 사용하여 메시지 중복 제거 기능을 활용하는 방법을 이해하는 것이 목적입니다.

**공부해야 하는 부분:**
1. **Amazon SQS FIFO Queue:**
   - FIFO 큐의 기본 개념과 사용 사례
   - 메시지 중복 제거 ID를 사용하여 메시지 중복을 방지하는 방법

2. **Visibility Timeout:**
   - Visibility Timeout의 기본 개념과 사용 사례
   - Visibility Timeout을 적절히 설정하여 메시지 중복 처리를 방지하는 방법

이 부분들을 공부하면, AWS에서 SQS와 Lambda를 사용하여 이벤트 기반 처리를 구현할 때 메시지 중복 문제를 해결하는 방법을 더 잘 이해할 수 있습니다.

# 102번
**정답: B. Install an AWS DataSync agent in the on-premises data center. E. Use AWS DataSync to create a suitable location configuration for the on-premises SFTP server.**

**해설:**
- **AWS DataSync:**
  - **데이터 전송 자동화:** DataSync는 온프레미스 데이터 센터와 AWS 간의 데이터 전송을 자동화하고 가속화하는 서비스입니다. 이를 통해 200GB의 데이터를 효율적으로 전송할 수 있습니다.
  - **NFS 지원:** DataSync는 NFS 기반 파일 시스템을 지원하므로, 온프레미스 SFTP 서버의 데이터를 EFS로 쉽게 전송할 수 있습니다.

- **B. DataSync 에이전트 설치:**
  - **온프레미스 데이터 센터:** DataSync 에이전트를 온프레미스 데이터 센터에 설치하여, 데이터를 AWS로 전송할 수 있습니다.

- **E. 위치 구성:**
  - **적절한 위치 구성:** DataSync를 사용하여 온프레미스 SFTP 서버의 위치 구성을 생성하고, 데이터를 EFS로 전송할 수 있습니다.

**다른 보기가 정답이 될 수 없는 이유:**
- **A. 동일한 가용 영역:** EC2 인스턴스를 EFS 파일 시스템과 동일한 가용 영역에 배치하는 것은 성능에 도움이 될 수 있지만, 데이터 전송을 자동화하는 데는 직접적인 관련이 없습니다.
- **C. EBS 볼륨 생성:** EBS 볼륨을 생성하는 것은 EFS를 사용하는 요구 사항과 맞지 않습니다.
- **D. 수동 복사:** 수동으로 데이터를 복사하는 것은 자동화된 솔루션이 아니며, 운영 오버헤드가 큽니다.

**출제 의도:**
이 문제는 AWS에서 온프레미스 데이터 센터의 데이터를 자동으로 AWS로 전송하는 방법을 평가합니다. 특히, AWS DataSync를 사용하여 데이터를 효율적으로 전송하고, 운영 오버헤드를 최소화하는 방법을 이해하는 것이 목적입니다.

**공부해야 하는 부분:**
1. **AWS DataSync:**
   - DataSync의 기본 개념과 사용 사례
   - DataSync를 사용하여 온프레미스 데이터 센터와 AWS 간의 데이터를 전송하는 방법

2. **Amazon EFS:**
   - EFS의 기본 개념과 사용 사례
   - EFS를 사용하여 데이터를 저장하고, EC2 인스턴스와 통합하는 방법

이 부분들을 공부하면, AWS에서 온프레미스 데이터 센터의 데이터를 자동으로 AWS로 전송하는 방법을 더 잘 이해할 수 있습니다.

# 104번
- B: GuardDuty는 공격자를 블락할 수 없으며, 데이터 소스나 이벤트 로그를 모니터링하고, 멀웨어 탐지 및 결과를 생성할 뿐임


# 107번
- Amazon Kinesis Data Analytics는 데이터 검색은 할 수 있으나 저장은 못함
- 저장을 하는 같은 계열의 서비스는 Amazon Kinesis Data Firehose임
- 그렇기 때문에 저장을 위해서는 B의 AWS Lambda를 사용해야 함

# 108번
- Amazon SNS는 Pub/Sub의 브로드캐스트 모델이고, Amazon SQS 큐잉 모델
- 브로드캐스트 모델은 단순히 전달만 할 뿐, 정상적으로 전달되었는지 여부는 상관하지 않음
- 반면 큐잉 모델은 데이터가 전달되어야 하는 정상 상태의 처리자가 반드시 필요하며, 데이터를 받을 처리자가 없으면 해당 데이터는 큐에 보관됨
- 이 문제에서 회사는 Multiple target systems를 보유하므로, SNS를 통해 갱신 정보를 브로드캐스팅하여 각각의 시스템이 개별적으로 람다를 실행시키는 것이 효과적임
- A의 문제점은 단일 SQS를 사용하는 점인데, 하나의 SQS는 곧 여러 시스템에 의한 중복 소비를 발생시키는데 이를 방지하기 위한 처리가 상당히 까다롭고 복잡함

# 113번
- AWS Snowball Edge Storage Optimized는 대용량 데이터를 효율적으로 전송할 수 있는 장치로, 네트웤크 대역폭이 부족한 상황에서도 사용 가능
- A: AWS DataSync는 네트워크를 통한 데이터 전송 서비스로, 추가적인 대역폭이 없음
- B: AWS Snowcones는 소규모 데이터 전송에 적합
- D: AWS Snowball Edge Storage Optimized 장치에 EC2 컴퓨팅 기능 포함 가능하지만, 데이터 전송 후에 AWS Glue를 사용하는 것이 더 효율적이며 운영 오버헤드가 적음


# 116번
**정답: A. Configure Amazon CloudFront in front of the website to use HTTPS functionality. D. Create the new website and an Amazon S3 bucket. Deploy the website on the S3 bucket with static website hosting enabled.**

**해설:**
- **Amazon S3 with Static Website Hosting:**
  - **저비용 및 고확장성:** S3는 정적 웹사이트 호스팅을 지원하며, 저비용으로 높은 확장성을 제공합니다. 정적 콘텐츠를 저장하고 제공하는 데 적합합니다.
  - **운영 오버헤드 최소화:** S3는 관리형 서비스로, 패치 및 유지 관리가 필요하지 않습니다. 이는 운영 오버헤드를 최소화합니다.

- **Amazon CloudFront:**
  - **콘텐츠 전송 네트워크 (CDN):** CloudFront는 전 세계에 분산된 엣지 로케이션을 통해 콘텐츠를 제공하므로, 웹사이트의 성능과 가용성을 향상시킵니다.
  - **HTTPS 지원:** CloudFront는 HTTPS를 지원하여, 웹사이트의 보안을 강화할 수 있습니다.

**다른 보기가 정답이 될 수 없는 이유:**
- **B. AWS WAF:** WAF는 웹 애플리케이션 방화벽으로, HTTPS 기능을 제공하지 않습니다. 보안 강화에는 도움이 되지만, HTTPS를 설정하는 데는 적합하지 않습니다.
- **C. AWS Lambda:** Lambda는 서버리스 컴퓨팅 서비스로, 정적 콘텐츠를 제공하는 데는 적합하지 않습니다. 또한, 운영 오버헤드가 증가할 수 있습니다.
- **E. EC2와 Auto Scaling:** EC2 인스턴스를 사용하여 웹사이트를 호스팅하는 것은 운영 오버헤드가 크며, 정적 콘텐츠를 제공하는 데는 과도한 솔루션입니다.

**출제 의도:**
이 문제는 AWS에서 정적 웹사이트를 호스팅하고, 높은 확장성과 보안을 제공하는 방법을 평가합니다. 특히, Amazon S3와 CloudFront를 사용하여 정적 웹사이트를 호스팅하고, HTTPS를 통해 보안을 강화하는 방법을 이해하는 것이 목적입니다.

**공부해야 하는 부분:**
1. **Amazon S3 Static Website Hosting:**
   - S3의 정적 웹사이트 호스팅 기능과 사용 사례
   - S3를 사용하여 정적 웹사이트를 호스팅하는 방법

2. **Amazon CloudFront:**
   - CloudFront의 기본 개념과 사용 사례
   - CloudFront를 사용하여 콘텐츠를 전송하고, HTTPS를 통해 보안을 강화하는 방법

이 부분들을 공부하면, AWS에서 정적 웹사이트를 호스팅하고, 높은 확장성과 보안을 제공하는 방법을 더 잘 이해할 수 있습니다.

# 119번
**정답: B. Set up AWS Firewall Manager in both Regions. Centrally configure AWS WAF rules.**

**해설:**
- **AWS Firewall Manager:**
  - **중앙 관리:** Firewall Manager는 여러 계정과 리전에서 AWS WAF 규칙을 중앙에서 관리할 수 있습니다. 이는 관리 오버헤드를 줄이고, 일관된 보안 정책을 적용하는 데 도움이 됩니다.
  - **자동 적용:** Firewall Manager는 새로운 리소스가 생성될 때 자동으로 WAF 규칙을 적용할 수 있어, 관리 작업을 최소화합니다.

- **AWS WAF:**
  - **웹 애플리케이션 방화벽:** WAF는 SQL 인젝션 및 크로스 사이트 스크립팅(XSS) 공격을 방어할 수 있는 규칙을 제공합니다. API Gateway와 통합하여 REST API를 보호할 수 있습니다.

**다른 보기가 정답이 될 수 없는 이유:**
- **A. AWS WAF in both Regions:** 각 리전에 별도로 WAF를 설정하고 관리하는 것은 관리 오버헤드가 큽니다. 중앙에서 관리할 수 있는 Firewall Manager를 사용하는 것이 더 효율적입니다.
- **C. AWS Shield:** AWS Shield는 주로 DDoS 공격을 방어하는 데 사용되며, SQL 인젝션 및 XSS 공격을 방어하는 데는 적합하지 않습니다.
- **D. AWS Shield in one Region:** AWS Shield는 DDoS 공격 방어에 적합하며, SQL 인젝션 및 XSS 공격을 방어하는 데는 적합하지 않습니다. 또한, 한 리전에만 설정하는 것은 글로벌 보호를 제공하지 않습니다.

**출제 의도:**
이 문제는 AWS에서 여러 계정과 리전에 걸쳐 API Gateway를 보호하는 방법을 평가합니다. 특히, AWS Firewall Manager와 WAF를 사용하여 중앙에서 보안 규칙을 관리하고, SQL 인젝션 및 XSS 공격을 방어하는 방법을 이해하는 것이 목적입니다.

**공부해야 하는 부분:**
1. **AWS Firewall Manager:**
   - Firewall Manager의 기본 개념과 사용 사례
   - Firewall Manager를 사용하여 여러 계정과 리전에서 WAF 규칙을 중앙에서 관리하는 방법

2. **AWS WAF:**
   - WAF의 기본 개념과 사용 사례
   - WAF를 사용하여 SQL 인젝션 및 XSS 공격을 방어하는 방법

이 부분들을 공부하면, AWS에서 여러 계정과 리전에 걸쳐 API Gateway를 보호하는 방법을 더 잘 이해할 수 있습니다.

# 121번
**정답: A. Encrypt a copy of the latest DB snapshot. Replace existing DB instance by restoring the encrypted snapshot.**

**해설:**
- **RDS 스냅샷 암호화:**
  - **스냅샷 암호화:** RDS 인스턴스가 암호화되지 않은 경우, 직접적으로 인스턴스를 암호화할 수 없습니다. 대신, 최신 스냅샷을 암호화된 스냅샷으로 복사한 후, 이 암호화된 스냅샷을 사용하여 새로운 암호화된 RDS 인스턴스를 생성할 수 있습니다.
  - **기존 인스턴스 교체:** 암호화된 스냅샷을 복원하여 새로운 암호화된 RDS 인스턴스를 생성한 후, 기존의 암호화되지 않은 인스턴스를 교체할 수 있습니다.

**다른 보기가 정답이 될 수 없는 이유:**
- **B. EBS 볼륨 암호화:** RDS 인스턴스의 스냅샷을 EBS 볼륨으로 복사하는 것은 적절한 방법이 아닙니다. RDS 스냅샷은 RDS 인스턴스와 직접적으로 연관되어 있어야 합니다.
- **C. 기존 인스턴스에 복원:** 암호화된 스냅샷을 기존의 암호화되지 않은 인스턴스에 복원할 수 없습니다. 새로운 암호화된 인스턴스를 생성해야 합니다.
- **D. S3로 복사:** 스냅샷을 S3로 복사하는 것은 백업 목적으로는 유용할 수 있지만, RDS 인스턴스를 암호화하는 데는 적합하지 않습니다.

**출제 의도:**
이 문제는 AWS에서 RDS 인스턴스와 스냅샷을 암호화하는 방법을 평가합니다. 특히, 암호화되지 않은 RDS 인스턴스를 암호화된 인스턴스로 교체하는 방법을 이해하는 것이 목적입니다.

**공부해야 하는 부분:**
1. **Amazon RDS 스냅샷 암호화:**
   - RDS 스냅샷을 암호화하는 방법
   - 암호화된 스냅샷을 사용하여 새로운 암호화된 RDS 인스턴스를 생성하는 방법

2. **AWS Key Management Service (KMS):**
   - KMS의 기본 개념과 사용 사례
   - KMS를 사용하여 RDS 스냅샷을 암호화하는 방법

이 부분들을 공부하면, AWS에서 RDS 인스턴스와 스냅샷을 암호화하는 방법을 더 잘 이해할 수 있습니다.

# 122번
문제: 회사는 개발자가 애플리케이션에서 데이터를 암호화할 수 있도록 지원하는 확장 가능한 키 관리 인프라를 구축하고자 합니다. 운영 부담을 줄이기 위해 솔루션 아키텍트는 무엇을 해야 합니까?

해설
B: AWS Key Management Service (AWS KMS)는 암호화 키를 생성, 관리 및 보호하는 완전 관리형 서비스입니다. KMS를 사용하면 키 관리와 관련된 많은 운영 부담을 AWS가 대신 처리해주므로, 운영 부담을 크게 줄일 수 있습니다. 또한, KMS는 자동으로 키를 회전하고, 키 사용을 모니터링하며, 다양한 AWS 서비스와 통합되어 사용이 편리합니다.

다른 선택지의 문제점
A: 다중 요소 인증(MFA)은 보안 강화를 위해 유용하지만, 키 관리 인프라의 운영 부담을 줄이는 데 직접적인 도움이 되지 않습니다.
C: AWS Certificate Manager (ACM)는 SSL/TLS 인증서를 관리하는 서비스로, 암호화 키 관리와는 다른 목적을 가지고 있습니다.
D: IAM 정책을 사용하여 사용자 접근 권한

# 124번
문제 번역
회사는 많은 Amazon EC2 인스턴스를 사용하여 완료하는 매우 동적인 배치 처리 작업을 가지고 있습니다. 이 작업은 상태가 없으며, 언제든지 시작하고 중지할 수 있으며, 총 완료 시간은 보통 60분 이상 걸립니다. 회사는 솔루션 아키텍트에게 이 작업의 요구사항을 충족하는 확장 가능하고 비용 효율적인 솔루션을 설계해 달라고 요청했습니다. 솔루션 아키텍트는 무엇을 추천해야 합니까?

정답
A. Implement EC2 Spot Instances.

해설
A: EC2 Spot Instances는 AWS의 미사용 EC2 용량을 활용하여 최대 90%까지 비용을 절감할 수 있는 옵션입니다. 이 작업은 상태가 없고 언제든지 중지 및 시작할 수 있으므로, Spot Instances의 일시적인 중단 가능성에도 불구하고 적합합니다. 이는 확장 가능하고 비용 효율적인 솔루션입니다.
다른 선택지의 문제점
B: EC2 Reserved Instances는 장기적으로 특정 용량을 예약하여 비용을 절감할 수 있지만, 동적인 배치 처리 작업에는 유연성이 부족합니다.
C: EC2 On-Demand Instances는 유연하지만, 비용이 더 높을 수 있습니다. 상태가 없는 작업에는 Spot Instances가 더 비용 효율적입니다.
D: AWS Lambda는 짧은 실행 시간의 이벤트 기반 작업에 적합하지만, 60분 이상 걸리는 배치 처리 작업에는 적합하지 않습니다.
따라서, A 선택지가 확장 가능하고 비용 효율적인 솔루션을 제공하는 데 가장 적합합니다.

# 125번
**정답: A. Use an Auto Scaling group to launch the EC2 instances in private subnets. Deploy an RDS Multi-AZ DB instance in private subnets. E. Configure a VPC with two public subnets, two private subnets, and two NAT gateways across two Availability Zones. Deploy an Application Load Balancer in the public subnets.**

**해설:**
- **A. EC2 인스턴스와 RDS 인스턴스를 프라이빗 서브넷에 배치:**
  - **보안:** EC2 인스턴스와 RDS 인스턴스를 프라이빗 서브넷에 배치하면, 이 인스턴스들이 공용 인터넷에 노출되지 않으므로 보안이 강화됩니다.
  - **고가용성:** Auto Scaling 그룹을 사용하여 EC2 인스턴스를 관리하면, 인스턴스의 가용성을 높일 수 있습니다. RDS Multi-AZ 배포는 데이터베이스의 고가용성을 보장합니다.

- **E. VPC 구성:**
  - **공용 및 프라이빗 서브넷:** 두 개의 공용 서브넷과 두 개의 프라이빗 서브넷을 사용하여, 애플리케이션의 웹 계층과 데이터베이스 계층을 분리할 수 있습니다.
  - **NAT 게이트웨이:** 두 개의 NAT 게이트웨이를 사용하여, 프라이빗 서브넷의 EC2 인스턴스가 인터넷에 접근할 수 있도록 합니다. 이는 EC2 인스턴스가 결제 처리와 같은 외부 웹 서비스를 사용할 수 있도록 합니다.
  - **Application Load Balancer:** ALB를 공용 서브넷에 배치하여, 외부 트래픽을 EC2 인스턴스로 라우팅할 수 있습니다.

**다른 보기가 정답이 될 수 없는 이유:**
- **B. ALB를 프라이빗 서브넷에 배치:** ALB를 프라이빗 서브넷에 배치하면, 외부 트래픽을 수신할 수 없으므로 적합하지 않습니다.
- **C. EC2 인스턴스를 공용 서브넷에 배치:** EC2 인스턴스를 공용 서브넷에 배치하면, 인스턴스가 공용 인터넷에 노출되므로 보안 요구 사항을 충족하지 않습니다.
- **D. 하나의 공용 서브넷과 하나의 프라이빗 서브넷:** 하나의 공용 서브넷과 하나의 프라이빗 서브넷만 사용하는 것은 고가용성을 보장하지 않습니다.

**출제 의도:**
이 문제는 AWS에서 이중 계층 아키텍처를 사용하여 웹 애플리케이션을 배포하고, 보안과 고가용성을 보장하는 방법을 평가합니다. 특히, VPC 서브넷 구성, NAT 게이트웨이 사용, Auto Scaling 그룹 및 RDS Multi-AZ 배포를 이해하는 것이 목적입니다.

**공부해야 하는 부분:**
1. **VPC 서브넷 구성:**
   - 공용 서브넷과 프라이빗 서브넷의 차이점과 사용 사례
   - NAT 게이트웨이를 사용하여 프라이빗 서브넷의 인스턴스가 인터넷에 접근하는 방법

2. **Auto Scaling 그룹:**
   - Auto Scaling 그룹의 기본 개념과 사용 사례
   - Auto Scaling 그룹을 사용하여 EC2 인스턴스의 가용성을 높이는 방법

3. **RDS Multi-AZ 배포:**
   - RDS Multi-AZ 배포의 기본 개념과 사용 사례
   - RDS Multi-AZ 배포를 사용하여 데이터베이스의 고가용성을 보장하는 방법

이 부분들을 공부하면, AWS에서 이중 계층 아키텍처를 사용하여 웹 애플리케이션을 배포하고, 보안과 고가용성을 보장하는 방법을 더 잘 이해할 수 있습니다.

# 127번
문제 번역
미디어 회사가 시스템을 AWS 클라우드로 이전할 가능성을 평가하고 있습니다. 회사는 비디오 처리에 최대한의 I/O 성능을 제공하는 최소 10TB의 스토리지, 미디어 콘텐츠를 저장하기 위한 300TB의 매우 내구성 있는 스토리지, 더 이상 사용되지 않는 아카이브 미디어를 위한 900TB의 스토리지가 필요합니다. 솔루션 아키텍트는 이러한 요구사항을 충족하기 위해 어떤 서비스 세트를 추천해야 합니까?

정답
A. Amazon EBS for maximum performance, Amazon S3 for durable data storage, and Amazon S3 Glacier for archival storage

해설
Amazon EBS (Elastic Block Store): EBS는 고성능 I/O를 제공하는 블록 스토리지 서비스로, 비디오 처리와 같은 고성능 작업에 적합합니다.
Amazon S3 (Simple Storage Service): S3는 높은 내구성과 가용성을 제공하는 객체 스토리지 서비스로, 미디어 콘텐츠와 같은 데이터를 저장하는 데 적합합니다.
Amazon S3 Glacier: S3 Glacier는 장기 아카이브 스토리지 서비스로, 자주 접근하지 않는 데이터를 비용 효율적으로 저장하는 데 적합합니다.
다른 선택지의 문제점
B: Amazon EFS는 파일 스토리지 서비스로, 대규모 데이터 저장에는 적합하지만, S3보다 비용이 높을 수 있습니다.
C: Amazon EC2 instance store는 인스턴스가 종료되면 데이터가 사라지므로, 내구성 있는 데이터 저장에는 적합하지 않습니다.
D: Amazon EC2 instance store는 내구성 있는 데이터 저장에 적합하지 않으며, S3는 아카이브 스토리지로 사용하기에는 비용이 높을 수 있습니다.
따라서, A 선택지가 요구사항을 충족하는 가장 적합한 솔루션입니다.

# 127번
문제 번역
회사는 AWS 클라우드에서 컨테이너로 애플리케이션을 실행하고자 합니다. 이 애플리케이션들은 상태가 없으며, 기본 인프라의 중단을 견딜 수 있습니다. 회사는 비용과 운영 오버헤드를 최소화하는 솔루션이 필요합니다. 솔루션 아키텍트는 이러한 요구사항을 충족하기 위해 무엇을 해야 합니까?

정답
B. Use Spot Instances in an Amazon Elastic Kubernetes Service (Amazon EKS) managed node group.

해설
B: Amazon EKS는 관리형 Kubernetes 서비스로, 컨테이너 오케스트레이션을 자동화하여 운영 오버헤드를 줄입니다. Spot Instances를 사용하면 비용을 크게 절감할 수 있으며, 애플리케이션이 상태가 없고 중단을 견딜 수 있으므로 적합합니다. EKS 관리 노드 그룹을 사용하면 Kubernetes 클러스터의 노드 관리를 AWS가 대신 처리해주므로 운영 오버헤드가 최소화됩니다.
다른 선택지의 문제점
A: EC2 Auto Scaling 그룹을 사용하여 컨테이너를 실행하는 것은 가능하지만, EKS를 사용하면 Kubernetes 관리가 자동화되어 운영 오버헤드가 더 낮습니다.
C: On-Demand Instances는 유연하지만 비용이 더 높을 수 있습니다. 상태가 없는 애플리케이션에는 Spot Instances가 더 비용 효율적입니다.
D: On-Demand Instances는 비용이 더 높을 수 있으며, 상태가 없는 애플리케이션에는 Spot Instances가 더 적합합니다.
따라서, B 선택지가 요구사항을 충족하는 가장 적합한 솔루션입니다.

# 130번
문제 번역
애플리케이션이 여러 가용 영역에 걸쳐 Amazon EC2 인스턴스에서 실행됩니다. 인스턴스는 Application Load Balancer 뒤에 있는 Amazon EC2 Auto Scaling 그룹에서 실행됩니다. 애플리케이션은 EC2 인스턴스의 CPU 사용률이 40%에 가깝거나 그 이하일 때 최상의 성능을 발휘합니다. 솔루션 아키텍트는 그룹의 모든 인스턴스에서 원하는 성능을 유지하기 위해 무엇을 해야 합니까?

정답
B. Use a target tracking policy to dynamically scale the Auto Scaling group.

해설
B: 타겟 추적 정책(Target Tracking Policy)은 Auto Scaling 그룹의 평균 CPU 사용률을 특정 목표(이 경우 40%)로 유지하도록 자동으로 조정합니다. 이는 CPU 사용률이 목표 수준에 도달하도록 인스턴스를 동적으로 추가하거나 제거하여 원하는 성능을 유지하는 데 가장 적합한 방법입니다.
다른 선택지의 문제점
A: 단순 스케일링 정책(Simple Scaling Policy)은 특정 조건이 충족될 때만 인스턴스를 추가하거나 제거합니다. 이는 CPU 사용률을 일정하게 유지하는 데 충분하지 않을 수 있습니다.
C: AWS Lambda 함수를 사용하여 Auto Scaling 그룹의 용량을 업데이트하는 것은 복잡하고 유지 관리가 어려울 수 있습니다.
D: 예약된 스케일링 작업(Scheduled Scaling Actions)은 특정 시간에만 스케일링을 수행하므로, 실시간으로 변동하는 CPU 사용률을 효과적으로 관리하지 못할 수 있습니다.
따라서, B 선택지가 그룹의 모든 인스턴스에서 원하는 성능을 유지하는 데 가장 적합한 솔루션입니다.


# 131번
문제 번역
회사는 파일 공유 애플리케이션을 개발 중이며, Amazon S3 버킷을 스토리지로 사용할 예정입니다. 회사는 모든 파일을 Amazon CloudFront 배포를 통해 제공하고자 합니다. 회사는 파일이 S3 URL을 통해 직접 접근되지 않도록 하고 싶습니다. 솔루션 아키텍트는 이러한 요구사항을 충족하기 위해 무엇을 해야 합니까?

정답
D. Create an origin access identity (OAI). Assign the OAI to the CloudFront distribution. Configure the S3 bucket permissions so that only the OAI has read permission.

해설
D: Origin Access Identity (OAI)를 생성하고 이를 CloudFront 배포에 할당하면, CloudFront를 통해서만 S3 버킷의 객체에 접근할 수 있습니다. S3 버킷 권한을 설정하여 OAI만 읽기 권한을 가지도록 구성하면, S3 URL을 통한 직접 접근을 방지할 수 있습니다.
다른 선택지의 문제점
A: 각 S3 버킷에 대해 개별 정책을 작성하는 것은 복잡하고 관리하기 어렵습니다. 또한, CloudFront에 대한 접근 권한을 효과적으로 제어하지 못할 수 있습니다.
B: IAM 사용자를 생성하고 읽기 권한을 부여하는 것은 CloudFront와의 통합을 보장하지 않으며, S3 URL을 통한 직접 접근을 방지하지 못합니다.
C: S3 버킷 정책에 CloudFront 배포 ID를 Principal로 지정하는 것은 일반적인 접근 제어 방법이 아니며, OAI를 사용하는 것이 더 적합합니다.
따라서, D 선택지가 요구사항을 충족하는 가장 적합한 솔루션입니다.

# 133번
cerulean85
A company runs an Oracle database on premises. As part of the company’s migration to AWS, the company wants to upgrade the database to the most recent available version. The company also wants to set up disaster recovery (DR) for the database. The company needs to minimize the operational overhead for normal operations and DR setup. The company also needs to maintain access to the database's underlying operating system. Which solution will meet these requirements?

A. Migrate the Oracle database to an Amazon EC2 instance. Set up database replication to a different AWS Region. B. Migrate the Oracle database to Amazon RDS for Oracle. Activate Cross-Region automated backups to replicate the snapshots to another AWS Region. C. Migrate the Oracle database to Amazon RDS Custom for Oracle. Create a read replica for the database in another AWS Region. D. Migrate the Oracle database to Amazon RDS for Oracle. Create a standby database in another Availability Zone.

GitHub Copilot
문제 번역
회사는 온프레미스에서 Oracle 데이터베이스를 운영하고 있습니다. 회사의 AWS로의 마이그레이션의 일환으로, 회사는 데이터베이스를 최신 버전으로 업그레이드하고자 합니다. 또한, 회사는 데이터베이스에 대한 재해 복구(DR)를 설정하고자 합니다. 회사는 정상 운영과 DR 설정에 대한 운영 오버헤드를 최소화해야 하며, 데이터베이스의 기본 운영 체제에 대한 접근을 유지해야 합니다. 이 요구사항을 충족하는 솔루션은 무엇입니까?

정답
C. Migrate the Oracle database to Amazon RDS Custom for Oracle. Create a read replica for the database in another AWS Region.

해설
C: Amazon RDS Custom for Oracle는 사용자가 데이터베이스의 기본 운영 체제에 접근할 수 있도록 허용하는 관리형 데이터베이스 서비스입니다. 이는 운영 오버헤드를 줄이면서도 데이터베이스의 기본 운영 체제에 대한 접근을 유지할 수 있습니다. 또한, 다른 AWS 리전에서 읽기 복제본을 생성하여 재해 복구를 설정할 수 있습니다.
다른 선택지의 문제점
A: Oracle 데이터베이스를 Amazon EC2 인스턴스로 마이그레이션하면 운영 오버헤드가 증가할 수 있으며, 관리형 서비스의 이점을 누리지 못합니다.
B: Amazon RDS for Oracle은 기본 운영 체제에 대한 접근을 제공하지 않습니다.
D: Amazon RDS for Oracle은 기본 운영 체제에 대한 접근을 제공하지 않으며, 다른 가용 영역에 대기 데이터베이스를 생성하는 것은 재해 복구를 위한 최적의 솔루션이 아닙니다.
따라서, C 선택지가 요구사항을 충족하는 가장 적합한 솔루션입니다.


# 134번
**정답: A. Create a new S3 bucket. Load the data into the new S3 bucket. Use S3 Cross-Region Replication (CRR) to replicate encrypted objects to an S3 bucket in another Region. Use server-side encryption with AWS KMS multi-Region keys (SSE-KMS). Use Amazon Athena to query the data.**

**해설:**
- **Amazon S3 Cross-Region Replication (CRR):**
  - **데이터 복제:** CRR을 사용하면 S3 버킷 간에 데이터를 자동으로 복제할 수 있습니다. 이는 데이터의 가용성과 내구성을 높이는 데 도움이 됩니다.
  - **암호화:** CRR은 암호화된 객체를 다른 리전의 S3 버킷으로 복제할 수 있습니다.

- **AWS KMS Multi-Region Keys (SSE-KMS):**
  - **보안:** KMS를 사용하여 데이터를 암호화하면, 강력한 보안과 키 관리 기능을 제공받을 수 있습니다. Multi-Region Keys를 사용하면 여러 리전에 걸쳐 일관된 암호화 키를 사용할 수 있습니다.

- **Amazon Athena:**
  - **서버리스 분석:** Athena는 S3에 저장된 데이터를 SQL을 사용하여 분석할 수 있는 서버리스 쿼리 서비스입니다. 이는 운영 오버헤드를 최소화하면서 데이터를 분석하는 데 적합합니다.

**다른 보기가 정답이 될 수 없는 이유:**
- **B. Amazon RDS:** RDS는 관리형 관계형 데이터베이스 서비스로, 서버리스 솔루션이 아니며, 운영 오버헤드가 증가할 수 있습니다.
- **C. SSE-S3:** SSE-S3는 S3 관리형 키를 사용하여 데이터를 암호화하지만, KMS를 사용하는 것보다 보안과 관리 기능이 제한적입니다.
- **D. Amazon RDS:** RDS는 서버리스 솔루션이 아니며, 운영 오버헤드가 증가할 수 있습니다.

**출제 의도:**
이 문제는 AWS에서 서버리스 솔루션을 사용하여 데이터를 분석하고, 데이터의 암호화와 리전 간 복제를 설정하는 방법을 평가합니다. 특히, Amazon S3, AWS KMS, Amazon Athena를 사용하여 운영 오버헤드를 최소화하면서 요구 사항을 충족하는 방법을 이해하는 것이 목적입니다.

**공부해야 하는 부분:**
1. **Amazon S3 Cross-Region Replication (CRR):**
   - CRR의 기본 개념과 사용 사례
   - CRR을 사용하여 데이터를 다른 리전의 S3 버킷으로 복제하는 방법

2. **AWS KMS Multi-Region Keys (SSE-KMS):**
   - KMS의 기본 개념과 사용 사례
   - Multi-Region Keys를 사용하여 데이터를 암호화하고, 여러 리전에 걸쳐 일관된 키를 사용하는 방법

3. **Amazon Athena:**
   - Athena의 기본 개념과 사용 사례
   - Athena를 사용하여 S3에 저장된 데이터를 SQL을 사용하여 분석하는 방법

이 부분들을 공부하면, AWS에서 서버리스 솔루션을 사용하여 데이터를 분석하고, 데이터의 암호화와 리전 간 복제를 설정하는 방법을 더 잘 이해할 수 있습니다.


# 135번
# 135
A company runs workloads on AWS. The company needs to connect to a service from an external provider. The service is hosted in the provider's VPC. According to the company’s security team, the connectivity must be private and must be restricted to the target service. The connection must be initiated only from the company’s VPC.
Which solution will mast these requirements?

A. Create a VPC peering connection between the company's VPC and the provider's VPC. Update the route table to connect to the target service.
B. Ask the provider to create a virtual private gateway in its VPC. Use AWS PrivateLink to connect to the target service.
C. Create a NAT gateway in a public subnet of the company’s VPUpdate the route table to connect to the target service.
D. Ask the provider to create a VPC endpoint for the target service. Use AWS PrivateLink to connect to the target service. 


# 136번
문제 번역
회사는 온프레미스 PostgreSQL 데이터베이스를 Amazon Aurora PostgreSQL로 마이그레이션하고 있습니다. 마이그레이션 중에도 온프레미스 데이터베이스는 온라인 상태를 유지하고 접근 가능해야 합니다. Aurora 데이터베이스는 온프레미스 데이터베이스와 동기화 상태를 유지해야 합니다. 솔루션 아키텍트는 이러한 요구사항을 충족하기 위해 어떤 조치를 취해야 합니까? (두 가지를 선택하십시오.)

정답
A. Create an ongoing replication task.

C. Create an AWS Database Migration Service (AWS DMS) replication server.

해설
A: 지속적인 복제 작업을 생성하면 온프레미스 데이터베이스와 Amazon Aurora PostgreSQL 간의 데이터 동기화를 유지할 수 있습니다.
C: AWS Database Migration Service (AWS DMS) 복제 서버를 생성하면 온프레미스 데이터베이스에서 Amazon Aurora PostgreSQL로의 데이터 마이그레이션을 관리할 수 있습니다. DMS는 데이터베이스를 마이그레이션하면서도 소스 데이터베이스를 온라인 상태로 유지할 수 있습니다.
다른 선택지의 문제점
B: 데이터베이스 백업을 생성하는 것은 초기 데이터 전송에 유용할 수 있지만, 지속적인 동기화를 보장하지 않습니다.
D: AWS Schema Conversion Tool (AWS SCT)은 데이터베이스 스키마 변환에 사용되며, 지속적인 데이터 동기화를 보장하지 않습니다.
E: Amazon EventBridge (Amazon CloudWatch Events) 규칙은 모니터링에 유용할 수 있지만, 데이터 동기화를 직접적으로 관리하지 않습니다.
따라서, A와 C 선택지가 요구사항을 충족하는 가장 적합한 솔루션입니다.

# 137번
문제 번역
회사는 각 비즈니스 유닛을 위해 전용 AWS 계정을 생성하고, 각 비즈니스 유닛의 계정을 독립적으로 관리할 수 있도록 AWS Organizations를 사용하고 있습니다. 루트 이메일 수신자가 한 계정의 루트 사용자 이메일 주소로 전송된 알림을 놓쳤습니다. 회사는 향후 모든 알림이 놓치지 않도록 하고자 합니다. 향후 알림은 계정 관리자에게만 제한되어야 합니다. 이 요구사항을 충족하는 솔루션은 무엇입니까?

정답
B. Configure all AWS account root user email addresses as distribution lists that go to a few administrators who can respond to alerts. Configure AWS account alternate contacts in the AWS Organizations console or programmatically.

해설
B: 모든 AWS 계정 루트 사용자 이메일 주소를 몇 명의 관리자에게 전달되는 배포 목록으로 구성하면, 알림이 놓치지 않도록 할 수 있습니다. 또한, AWS Organizations 콘솔 또는 프로그래밍 방식으로 AWS 계정 대체 연락처를 구성하여 알림을 받을 수 있는 추가적인 보안을 제공합니다.
다른 선택지의 문제점
A: 회사의 이메일 서버를 구성하여 알림 이메일 메시지를 조직의 모든 사용자에게 전달하는 것은 보안 위험이 있으며, 알림이 너무 많은 사람에게 전달될 수 있습니다.
C: 모든 알림을 한 명의 관리자에게 보내는 것은 단일 실패 지점을 만들 수 있으며, 알림이 적절한 그룹에 전달되지 않을 수 있습니다.
D: 모든 계정에 동일한 루트 사용자 이메일 주소를 사용하는 것은 관리 및 보안 측면에서 비효율적이며, 각 계정의 독립성을 유지하지 못합니다.
따라서, B 선택지가 요구사항을 충족하는 가장 적합한 솔루션입니다.

# 138번
문제 번역
회사는 AWS에서 전자상거래 애플리케이션을 운영하고 있습니다. 새로운 주문이 들어올 때마다 RabbitMQ 큐에 메시지가 게시되며, 이 큐는 단일 가용 영역의 Amazon EC2 인스턴스에서 실행됩니다. 이러한 메시지는 별도의 EC2 인스턴스에서 실행되는 다른 애플리케이션에 의해 처리되며, 이 애플리케이션은 세부 정보를 또 다른 EC2 인스턴스에서 실행되는 PostgreSQL 데이터베이스에 저장합니다. 모든 EC2 인스턴스는 동일한 가용 영역에 있습니다. 회사는 가장 높은 가용성을 제공하고 운영 오버헤드를 최소화하기 위해 아키텍처를 재설계해야 합니다. 솔루션 아키텍트는 이러한 요구사항을 충족하기 위해 무엇을 해야 합니까?

정답
B. Migrate the queue to a redundant pair (active/standby) of RabbitMQ instances on Amazon MQ. Create a Multi-AZ Auto Scaling group for EC2 instances that host the application. Migrate the database to run on a Multi-AZ deployment of Amazon RDS for PostgreSQL.

해설
B: RabbitMQ 큐를 Amazon MQ의 활성/대기 페어로 마이그레이션하면 높은 가용성을 제공할 수 있습니다. 애플리케이션을 호스팅하는 EC2 인스턴스에 대해 다중 가용 영역(AZ) Auto Scaling 그룹을 생성하면 애플리케이션의 가용성을 높일 수 있습니다. PostgreSQL 데이터베이스를 Amazon RDS for PostgreSQL의 다중 AZ 배포로 마이그레이션하면 데이터베이스의 가용성과 관리 오버헤드를 최소화할 수 있습니다.
다른 선택지의 문제점
A: PostgreSQL 데이터베이스를 EC2 인스턴스에서 호스팅하는 것은 관리 오버헤드를 증가시키며, RDS를 사용하는 것보다 가용성이 낮을 수 있습니다.
C: RabbitMQ 큐를 EC2 인스턴스에서 호스팅하는 것은 관리 오버헤드를 증가시키며, Amazon MQ를 사용하는 것보다 가용성이 낮을 수 있습니다.
D: PostgreSQL 데이터베이스를 EC2 인스턴스에서 호스팅하는 것은 관리 오버헤드를 증가시키며, RDS를 사용하는 것보다 가용성이 낮을 수 있습니다.
따라서, B 선택지가 요구사항을 충족하는 가장 적합한 솔루션입니다.

# 139번
**정답: C. Configure S3 replication between the S3 buckets. Create an S3 event notification for the analysis S3 bucket. Configure Lambda and SageMaker Pipelines as destinations of the event notification. Configure s3:ObjectCreated:Put as the event type.**

**해설:**
- **S3 Replication:**
  - **자동 복제:** S3 복제를 설정하면, 초기 S3 버킷에 파일이 업로드될 때 자동으로 분석 S3 버킷으로 복제됩니다. 이는 수동 작업을 자동화하고 운영 오버헤드를 줄이는 데 도움이 됩니다.
  - **고가용성:** S3 복제는 데이터를 다른 버킷으로 자동으로 복제하여 고가용성을 제공합니다.

- **S3 Event Notification:**
  - **이벤트 기반 처리:** 분석 S3 버킷에 이벤트 알림을 설정하여, 파일이 복제될 때 Lambda 함수와 SageMaker Pipelines를 트리거할 수 있습니다. 이는 파일이 복제될 때마다 자동으로 패턴 매칭 코드와 데이터 파이프라인을 실행할 수 있도록 합니다.
  - **s3:ObjectCreated:Put 이벤트:** 이 이벤트 유형을 사용하면, 객체가 생성될 때마다 이벤트 알림이 트리거됩니다.

**다른 보기가 정답이 될 수 없는 이유:**
- **A. Lambda 함수로 파일 복사:** Lambda 함수를 사용하여 파일을 복사하는 것은 가능하지만, S3 복제를 사용하는 것보다 운영 오버헤드가 큽니다.
- **B. EventBridge 사용:** EventBridge를 사용하여 이벤트를 처리하는 것은 가능하지만, S3 이벤트 알림을 직접 사용하는 것이 더 간단하고 운영 오버헤드가 적습니다.
- **D. EventBridge 사용:** EventBridge를 사용하여 이벤트를 처리하는 것은 가능하지만, S3 이벤트 알림을 직접 사용하는 것이 더 간단하고 운영 오버헤드가 적습니다.

**출제 의도:**
이 문제는 AWS에서 S3 버킷 간의 데이터 복제를 자동화하고, 이벤트 기반 처리를 설정하는 방법을 평가합니다. 특히, S3 복제와 S3 이벤트 알림을 사용하여 운영 오버헤드를 최소화하면서 요구 사항을 충족하는 방법을 이해하는 것이 목적입니다.

**공부해야 하는 부분:**
1. **Amazon S3 Replication:**
   - S3 복제의 기본 개념과 사용 사례
   - S3 복제를 설정하여 데이터를 자동으로 복제하는 방법

2. **S3 Event Notification:**
   - S3 이벤트 알림의 기본 개념과 사용 사례
   - S3 이벤트 알림을 설정하여 특정 이벤트가 발생할 때 Lambda 함수와 SageMaker Pipelines를 트리거하는 방법

이 부분들을 공부하면, AWS에서 S3 버킷 간의 데이터 복제를 자동화하고, 이벤트 기반 처리를 설정하는 방법을 더 잘 이해할 수 있습니다.

# 140번
**정답: A. Use Spot Instances for the data ingestion layer C. Purchase a 1-year Compute Savings Plan for the front end and API layer.**

**해설:**
- **Spot Instances:**
  - **비용 절감:** Spot Instances는 사용하지 않는 EC2 용량을 활용하여 최대 90%까지 비용을 절감할 수 있습니다. 이는 데이터 수집 계층의 스포라딕하고 예측 불가능한 사용 패턴에 적합합니다.
  - **중단 가능성:** Spot Instances는 언제든지 중단될 수 있지만, 데이터 수집 계층의 작업이 중단을 견딜 수 있으므로 적합합니다.

- **Compute Savings Plan:**
  - **비용 절감:** Compute Savings Plan은 특정 인스턴스 유형에 구애받지 않고, EC2, Fargate, Lambda 등 다양한 컴퓨팅 옵션에 대해 비용을 절감할 수 있습니다.
  - **예측 가능한 사용:** 프론트엔드와 API 계층의 사용량이 예측 가능하므로, 1년 Compute Savings Plan을 구매하면 비용을 절감할 수 있습니다.

**다른 보기가 정답이 될 수 없는 이유:**
- **B. On-Demand Instances:** On-Demand Instances는 비용이 더 높으며, 스포라딕하고 예측 불가능한 사용 패턴에 적합하지 않습니다.
- **D. Reserved Instances:** 데이터 수집 계층의 사용 패턴이 예측 불가능하므로, Reserved Instances는 적합하지 않습니다.
- **E. EC2 instance Savings Plan:** EC2 instance Savings Plan은 특정 인스턴스 패밀리와 리전에만 적용되므로, Compute Savings Plan이 더 유연하고 비용 효율적입니다.

**출제 의도:**
이 문제는 AWS에서 다양한 컴퓨팅 옵션을 사용하여 비용을 최적화하는 방법을 평가합니다. 특히, Spot Instances와 Compute Savings Plan을 사용하여 비용을 절감하고, 예측 가능한 사용 패턴에 맞는 구매 옵션을 선택하는 방법을 이해하는 것이 목적입니다.

**공부해야 하는 부분:**
1. **Spot Instances:**
   - Spot Instances의 기본 개념과 사용 사례
   - Spot Instances를 사용하여 비용을 절감하고, 중단 가능성을 관리하는 방법

2. **Savings Plans:**
   - Compute Savings Plan과 EC2 instance Savings Plan의 차이점과 사용 사례
   - Savings Plan을 사용하여 비용을 절감하는 방법

이 부분들을 공부하면, AWS에서 다양한 컴퓨팅 옵션을 사용하여 비용을 최적화하는 방법을 더 잘 이해할 수 있습니다.


# 141번
**정답: B. Deploy the application stack in two AWS Regions. Use an Amazon Route 53 latency routing policy to serve all content from the ALB in the closest Region.**

**해설:**
- **다중 리전 배포:**
  - **고가용성:** 두 개의 AWS 리전에 애플리케이션 스택을 배포하면, 하나의 리전에서 장애가 발생하더라도 다른 리전에서 서비스를 계속 제공할 수 있습니다.
  - **지연 시간 최소화:** 여러 리전에 배포하면, 사용자가 가장 가까운 리전에서 콘텐츠를 제공받을 수 있어 지연 시간을 최소화할 수 있습니다.

- **Amazon Route 53 Latency Routing Policy:**
  - **지연 시간 기반 라우팅:** Route 53의 지연 시간 라우팅 정책을 사용하면, 사용자가 가장 낮은 지연 시간을 제공하는 리전의 ALB에서 콘텐츠를 제공받을 수 있습니다. 이는 전 세계 사용자에게 최적의 성능을 제공합니다.

**다른 보기가 정답이 될 수 없는 이유:**
- **A. 단일 리전 배포 및 CloudFront:** 단일 리전에 배포하면, 해당 리전에서 장애가 발생할 경우 서비스가 중단될 수 있습니다. 또한, CloudFront는 정적 콘텐츠 캐싱에 적합하지만, 동적 콘텐츠의 지연 시간을 최소화하는 데는 한계가 있습니다.
- **C. 단일 리전 배포 및 CloudFront:** 단일 리전에 배포하면, 해당 리전에서 장애가 발생할 경우 서비스가 중단될 수 있습니다. 또한, 동적 콘텐츠를 ALB에서 직접 제공하면 지연 시간이 증가할 수 있습니다.
- **D. 지리적 라우팅 정책:** 지리적 라우팅 정책은 사용자의 지리적 위치에 따라 라우팅하지만, 지연 시간을 최적화하는 데는 적합하지 않습니다.

**출제 의도:**
이 문제는 AWS에서 전 세계 사용자에게 최적의 성능을 제공하기 위해 애플리케이션을 설계하는 방법을 평가합니다. 특히, 다중 리전 배포와 Route 53 지연 시간 라우팅 정책을 사용하여 지연 시간을 최소화하고, 고가용성을 제공하는 방법을 이해하는 것이 목적입니다.

**공부해야 하는 부분:**
1. **다중 리전 배포:**
   - 여러 리전에 애플리케이션을 배포하여 고가용성과 성능을 최적화하는 방법
   - 다중 리전 배포의 장단점

2. **Amazon Route 53 라우팅 정책:**
   - Route 53의 다양한 라우팅 정책(지연 시간, 지리적, 가중치 등)의 기본 개념과 사용 사례
   - 지연 시간 라우팅 정책을 사용하여 사용자에게 최적의 성능을 제공하는 방법

이 부분들을 공부하면, AWS에서 전 세계 사용자에게 최적의 성능을 제공하기 위해 애플리케이션을 설계하는 방법을 더 잘 이해할 수 있습니다.  


# 143번
이 문제는 AWS로 기존의 온프레미스 모놀리식 애플리케이션을 마이그레이션하려는 회사의 요구사항을 다루고 있습니다. 회사는 가능한 한 많은 프론트엔드 코드와 백엔드 코드를 유지하면서 애플리케이션을 더 작은 애플리케이션으로 나누고 싶어합니다. 각 애플리케이션은 다른 팀에서 관리하며, **고가용성**과 **운영 오버헤드 최소화**를 목표로 하는 **확장 가능한 솔루션**이 필요합니다. 

각 선택지의 설명과 정답을 분석해 보겠습니다.

### 선택지 분석

**A. Host the application on AWS Lambda. Integrate the application with Amazon API Gateway.**
- **설명**: AWS Lambda는 서버리스 컴퓨팅 서비스를 제공하여 자동으로 확장할 수 있으며, 운영 오버헤드가 적습니다. Amazon API Gateway를 사용하여 API를 생성하고 관리할 수 있습니다. 
- **장점**: 
  - 서버리스 아키텍처로 인해 운영 관리가 최소화됩니다.
  - Lambda는 요청 수에 따라 자동으로 확장됩니다.
  - API Gateway와의 통합이 간편하여 애플리케이션을 마이크로서비스로 분리할 수 있습니다.
- **단점**: 모놀리식 애플리케이션에서 Lambda 기반으로 이전할 때 기존 코드를 완전히 재작성해야 할 수 있습니다.

---

**B. Host the application with AWS Amplify. Connect the application to an Amazon API Gateway API that is integrated with AWS Lambda.**
- **설명**: AWS Amplify는 풀스택 애플리케이션을 쉽게 구축하고 배포할 수 있도록 돕는 플랫폼입니다. API Gateway와 AWS Lambda와 통합하여 프론트엔드를 서버리스로 구축할 수 있습니다.
- **장점**: 
  - Amplify는 프론트엔드 및 백엔드 개발을 간편하게 관리할 수 있습니다.
  - 서버리스 아키텍처를 통해 확장성과 운영 오버헤드를 최소화할 수 있습니다.
- **단점**: AWS Amplify는 주로 정적 웹사이트 및 서버리스 애플리케이션에 적합합니다. 모놀리식 애플리케이션을 완전히 재작성해야 할 수 있습니다.

---

**C. Host the application on Amazon EC2 instances. Set up an Application Load Balancer with EC2 instances in an Auto Scaling group as targets.**
- **설명**: Amazon EC2에서 애플리케이션을 호스팅하고, Auto Scaling 그룹과 함께 Application Load Balancer를 설정하여 트래픽을 분산합니다.
- **장점**: 
  - 기존의 EC2 기반 아키텍처로 쉽게 마이그레이션할 수 있습니다.
  - EC2 인스턴스는 높은 커스터마이징을 제공하고, 부하에 따라 확장할 수 있습니다.
- **단점**: 운영 관리가 상대적으로 많으며, 모놀리식 구조로 인해 애플리케이션을 마이크로서비스로 분할하는 데 어려움이 있을 수 있습니다.

---

**D. Host the application on Amazon Elastic Container Service (Amazon ECS). Set up an Application Load Balancer with Amazon ECS as the target.**
- **설명**: Amazon ECS를 사용하여 컨테이너화된 애플리케이션을 호스팅하고, Application Load Balancer를 설정하여 트래픽을 분산합니다.
- **장점**: 
  - ECS는 컨테이너 관리 서비스로, 마이크로서비스 아키텍처를 지원하며, 애플리케이션을 더 작은 서비스로 나누는 데 유리합니다.
  - 자동 확장 기능을 제공하며, 운영 오버헤드가 적습니다.
  - 애플리케이션의 개별 구성 요소를 각 팀이 독립적으로 관리할 수 있도록 합니다.
- **단점**: 컨테이너 환경에 대한 학습 곡선이 있을 수 있습니다.

---

### **정답 및 해설**
**정답: D. Host the application on Amazon Elastic Container Service (Amazon ECS). Set up an Application Load Balancer with Amazon ECS as the target.**

**해설**:
- **모놀리식 애플리케이션을 더 작은 서비스로 분할**하는 데 유리한 컨테이너 기반 아키텍처를 제공합니다. 
- **ECS를 사용하면** 여러 팀이 각각의 서비스를 관리할 수 있으며, **각 서비스는 독립적으로 배포되고 확장**될 수 있습니다. 
- **운영 오버헤드가 적고, 자동 확장 기능을 통해** 고가용성과 높은 트래픽 처리 능력을 제공하므로 기업의 요구 사항에 가장 적합합니다.

따라서 **ECS와 Application Load Balancer** 조합은 주어진 조건을 모두 충족하며, **기존 코드를 최대한 유지하면서** 마이크로서비스 아키텍처로 이전할 수 있는 최적의 선택입니다.


# 145번
**정답: A. Migrate the database to an Amazon RDS for MySQL DB instance. Create an AMI of the web application. Use the AMI to launch a second EC2 On-Demand Instance. Use an Application Load Balancer to distribute the load to each EC2 instance.**

**해설:**
- **Amazon RDS for MySQL:**
  - **데이터베이스 분리:** RDS를 사용하여 데이터베이스를 EC2 인스턴스에서 분리하면, 데이터베이스 관리와 성능 최적화가 쉬워집니다. 이는 애플리케이션의 성능을 향상시키는 데 도움이 됩니다.
  - **관리형 서비스:** RDS는 관리형 서비스로, 백업, 복구, 소프트웨어 패치 등을 자동으로 처리하여 운영 오버헤드를 줄입니다.

- **Application Load Balancer (ALB):**
  - **로드 밸런싱:** ALB를 사용하여 여러 EC2 인스턴스 간에 트래픽을 분산시키면, 애플리케이션의 가용성과 성능을 향상시킬 수 있습니다.
  - **확장성:** ALB와 Auto Scaling을 결합하면, 트래픽 증가에 따라 자동으로 인스턴스를 추가하여 확장할 수 있습니다.

**다른 보기가 정답이 될 수 없는 이유:**
- **B. Route 53 weighted routing:** Route 53의 가중치 라우팅은 로드 밸런싱을 제공할 수 있지만, ALB를 사용하는 것이 더 일반적이고 효율적입니다.
- **C. Lambda와 CloudWatch:** Lambda와 CloudWatch를 사용하여 인스턴스 유형을 변경하는 것은 성능 문제를 해결할 수 있지만, 이는 자동 확장과 로드 밸런싱을 제공하지 않습니다.
- **D. Aurora와 Spot Fleet:** Aurora는 고성능 데이터베이스를 제공하지만, Spot Fleet을 사용하는 것은 비용 효율적일 수 있지만, 인스턴스가 중단될 수 있어 안정적인 서비스 제공에 문제가 있을 수 있습니다.

**출제 의도:**
이 문제는 AWS에서 웹 애플리케이션의 성능 문제를 해결하고, 비용 효율적으로 확장 가능한 아키텍처를 설계하는 방법을 평가합니다. 특히, Amazon RDS와 Application Load Balancer를 사용하여 데이터베이스를 분리하고, 로드 밸런싱을 통해 애플리케이션의 성능을 향상시키는 방법을 이해하는 것이 목적입니다.

**공부해야 하는 부분:**
1. **Amazon RDS:**
   - RDS의 기본 개념과 사용 사례
   - RDS를 사용하여 데이터베이스를 관리하고 성능을 최적화하는 방법

2. **Application Load Balancer (ALB):**
   - ALB의 기본 개념과 사용 사례
   - ALB를 사용하여 트래픽을 분산시키고, 애플리케이션의 가용성과 성능을 향상시키는 방법

이 부분들을 공부하면, AWS에서 웹 애플리케이션의 성능 문제를 해결하고, 비용 효율적으로 확장 가능한 아키텍처를 설계하는 방법을 더 잘 이해할 수 있습니다.


# 150번
**정답: A. Create Amazon CloudWatch composite alarms where possible.**

**해설:**
- **Amazon CloudWatch Composite Alarms:**
  - **복합 조건:** Composite Alarms는 여러 개의 단일 알람을 결합하여, 특정 조건이 모두 충족될 때만 알람을 발생시킬 수 있습니다. 이는 CPU 사용률이 50%를 초과하고 동시에 디스크의 읽기 IOPS가 높은 경우에만 알람을 발생시키는 데 적합합니다.
  - **거짓 알람 감소:** Composite Alarms를 사용하면, 단일 조건이 충족될 때 발생하는 거짓 알람을 줄일 수 있습니다. 이는 CPU 사용률이 일시적으로 50%를 초과하는 경우와 같은 상황에서 불필요한 알람을 방지합니다.

**다른 보기가 정답이 될 수 없는 이유:**
- **B. CloudWatch Dashboards:** 대시보드는 메트릭을 시각화하고 문제를 빠르게 파악하는 데 유용하지만, 자동으로 알람을 발생시키는 기능은 없습니다.
- **C. CloudWatch Synthetics Canaries:** Synthetics Canaries는 애플리케이션의 엔드포인트를 모니터링하고 가용성을 테스트하는 데 사용되며, 인프라 메트릭 알람을 설정하는 데 적합하지 않습니다.
- **D. Single Metric Alarms:** 단일 메트릭 알람은 여러 메트릭 조건을 결합할 수 없으므로, CPU 사용률과 디스크 읽기 IOPS를 동시에 모니터링하는 데 적합하지 않습니다.

**출제 의도:**
이 문제는 AWS에서 인프라 메트릭을 모니터링하고, 특정 조건이 충족될 때만 알람을 발생시키는 방법을 평가합니다. 특히, Amazon CloudWatch Composite Alarms를 사용하여 거짓 알람을 줄이고, 필요한 경우에만 알람을 발생시키는 방법을 이해하는 것이 목적입니다.

**공부해야 하는 부분:**
1. **Amazon CloudWatch Composite Alarms:**
   - Composite Alarms의 기본 개념과 사용 사례
   - Composite Alarms를 사용하여 여러 메트릭 조건을 결합하고, 특정 조건이 충족될 때만 알람을 발생시키는 방법

2. **Amazon CloudWatch Alarms:**
   - CloudWatch Alarms의 기본 개념과 사용 사례
   - 단일 메트릭 알람과 복합 알람의 차이점과 사용 사례

이 부분들을 공부하면, AWS에서 인프라 메트릭을 모니터링하고, 특정 조건이 충족될 때만 알람을 발생시키는 방법을 더 잘 이해할 수 있습니다.


# 151번
**정답: A. Use AWS Control Tower to implement data residency guardrails to deny internet access and deny access to all AWS Regions except ap-northeast-3. C. Use AWS Organizations to configure service control policies (SCPS) that prevent VPCs from gaining internet access. Deny access to all AWS Regions except ap-northeast-3.**

**해설:**
- **AWS Control Tower:**
  - **데이터 거주성 가드레일:** Control Tower는 데이터 거주성 가드레일을 사용하여 특정 리전 외의 리전에 대한 접근을 차단하고, 인터넷 접근을 차단할 수 있습니다. 이는 컴플라이언스 요구 사항을 충족하는 데 도움이 됩니다.

- **AWS Organizations와 SCPs:**
  - **서비스 제어 정책 (SCPs):** SCPs를 사용하여 특정 리전 외의 리전에 대한 접근을 차단하고, VPC가 인터넷에 접근하지 못하도록 설정할 수 있습니다. 이는 중앙에서 관리할 수 있는 강력한 보안 정책을 제공합니다.

**다른 보기가 정답이 될 수 없는 이유:**
- **B. AWS WAF:** WAF는 웹 애플리케이션 방화벽으로, 인터넷 접근을 차단하는 데 적합하지 않습니다. 또한, AWS 계정 설정에서 리전 접근을 차단하는 기능이 없습니다.
- **D. 네트워크 ACL 및 IAM 정책:** 네트워크 ACL을 사용하여 인터넷 접근을 차단할 수 있지만, 이는 각 VPC마다 설정해야 하므로 관리 오버헤드가 큽니다. 또한, IAM 정책으로 리전 접근을 차단하는 것은 적절하지 않습니다.
- **E. AWS Config:** AWS Config는 리소스 변경을 감지하고 알림을 제공하는 데 유용하지만, 인터넷 접근을 차단하거나 리전 접근을 차단하는 데 직접적인 역할을 하지 않습니다.

**출제 의도:**
이 문제는 AWS에서 특정 리전으로의 데이터 마이그레이션을 설정하고, 인터넷 접근을 차단하는 방법을 평가합니다. 특히, AWS Control Tower와 AWS Organizations의 SCPs를 사용하여 중앙에서 관리할 수 있는 보안 정책을 설정하는 방법을 이해하는 것이 목적입니다.

**공부해야 하는 부분:**
1. **AWS Control Tower:**
   - Control Tower의 기본 개념과 사용 사례
   - Control Tower를 사용하여 데이터 거주성 가드레일을 설정하는 방법

2. **AWS Organizations와 SCPs:**
   - AWS Organizations의 기본 개념과 사용 사례
   - SCPs를 사용하여 특정 리전 외의 리전에 대한 접근을 차단하고, 인터넷 접근을 차단하는 방법

이 부분들을 공부하면, AWS에서 특정 리전으로의 데이터 마이그레이션을 설정하고, 인터넷 접근을 차단하는 방법을 더 잘 이해할 수 있습니다.

# 152번
**정답: D. Create AWS Lambda functions to start and stop the DB instance. Create Amazon EventBridge (Amazon CloudWatch Events) scheduled rules to invoke the Lambda functions. Configure the Lambda functions as event targets for the rules.**

**해설:**
- **AWS Lambda와 EventBridge:**
  - **자동화:** Lambda 함수를 사용하여 RDS 인스턴스를 시작하고 중지하는 작업을 자동화할 수 있습니다. 이는 수동 작업을 줄이고 운영 오버헤드를 최소화합니다.
  - **스케줄링:** EventBridge (이전의 CloudWatch Events)를 사용하여 정기적인 스케줄을 설정하고, 특정 시간에 Lambda 함수를 트리거하여 RDS 인스턴스를 시작하거나 중지할 수 있습니다. 이는 애플리케이션이 사용되지 않는 시간 동안 비용을 절감하는 데 도움이 됩니다.

**다른 보기가 정답이 될 수 없는 이유:**
- **A. IAM 정책과 Systems Manager Session Manager:** 이 방법은 RDS 인스턴스를 자동으로 시작하고 중지하는 데 적합하지 않습니다.
- **B. ElastiCache for Redis:** ElastiCache를 사용하여 데이터를 캐싱하는 것은 가능하지만, RDS 인스턴스를 중지하는 동안 데이터를 캐싱하는 것은 복잡하고 비용 효율적이지 않습니다.
- **C. EC2 인스턴스와 cron job:** EC2 인스턴스를 사용하여 스케줄링 작업을 설정하는 것은 가능하지만, Lambda와 EventBridge를 사용하는 것이 더 간단하고 비용 효율적입니다.

**출제 의도:**
이 문제는 AWS에서 RDS 인스턴스를 자동으로 시작하고 중지하여 비용을 절감하는 방법을 평가합니다. 특히, AWS Lambda와 EventBridge를 사용하여 스케줄링 작업을 자동화하는 방법을 이해하는 것이 목적입니다.

**공부해야 하는 부분:**
1. **AWS Lambda:**
   - Lambda의 기본 개념과 사용 사례
   - Lambda를 사용하여 RDS 인스턴스를 시작하고 중지하는 방법

2. **Amazon EventBridge (CloudWatch Events):**
   - EventBridge의 기본 개념과 사용 사례
   - EventBridge를 사용하여 정기적인 스케줄을 설정하고, Lambda 함수를 트리거하는 방법

이 부분들을 공부하면, AWS에서 RDS 인스턴스를 자동으로 시작하고 중지하여 비용을 절감하는 방법을 더 잘 이해할 수 있습니다.



# 156번
**정답: A. Use Amazon Athena for one-time queries. Use Amazon QuickSight to create dashboards for KPIs. E. Use blueprints in AWS Lake Formation to identify the data that can be ingested into a data lake. Use AWS Glue to crawl the source, extract the data, and load the data into Amazon S3 in Apache Parquet format.**

**해설:**
- **Amazon Athena와 Amazon QuickSight:**
  - **Athena:** Athena는 S3에 저장된 데이터를 SQL을 사용하여 쿼리할 수 있는 서버리스 쿼리 서비스입니다. 이는 일회성 쿼리에 적합하며, 운영 오버헤드가 적습니다.
  - **QuickSight:** QuickSight는 비즈니스 인텔리전스 도구로, Athena에서 쿼리한 데이터를 시각화하고 대시보드를 생성하는 데 사용할 수 있습니다. 이는 KPI를 표시하는 데 적합합니다.

- **AWS Lake Formation과 AWS Glue:**
  - **Lake Formation:** Lake Formation은 데이터 레이크를 쉽게 설정하고 관리할 수 있도록 도와줍니다. 블루프린트를 사용하여 데이터를 식별하고, 데이터 레이크에 적재할 수 있습니다.
  - **AWS Glue:** Glue는 ETL(추출, 변환, 로드) 작업을 자동화하는 관리형 서비스입니다. Glue 크롤러를 사용하여 소스 데이터를 크롤링하고, 데이터를 S3에 Apache Parquet 형식으로 적재할 수 있습니다. 이는 다양한 데이터 소스를 통합하고, 데이터를 분석하기 쉽게 만듭니다.

**다른 보기가 정답이 될 수 없는 이유:**
- **B. Kinesis Data Analytics:** Kinesis Data Analytics는 실시간 데이터 스트림을 분석하는 데 적합하지만, 일회성 쿼리에는 적합하지 않습니다.
- **C. Lambda와 Redshift:** Lambda 함수를 사용하여 데이터를 Redshift로 이동하는 것은 가능하지만, 이는 운영 오버헤드가 크고, 요구 사항에 비해 복잡합니다.
- **D. Glue와 OpenSearch Service:** OpenSearch Service는 검색 및 분석 엔진으로, 데이터 레이크와 비즈니스 인텔리전스 도구로 사용하기에는 적합하지 않습니다.

**출제 의도:**
이 문제는 AWS에서 다양한 데이터 소스를 통합하고, 비즈니스 인텔리전스를 위해 데이터를 분석하는 방법을 평가합니다. 특히, Amazon Athena와 QuickSight를 사용하여 데이터를 쿼리하고 시각화하는 방법과, AWS Lake Formation과 Glue를 사용하여 데이터를 통합하고 적재하는 방법을 이해하는 것이 목적입니다.

**공부해야 하는 부분:**
1. **Amazon Athena와 QuickSight:**
   - Athena의 기본 개념과 사용 사례
   - QuickSight를 사용하여 데이터를 시각화하고 대시보드를 생성하는 방법

2. **AWS Lake Formation과 AWS Glue:**
   - Lake Formation의 기본 개념과 사용 사례
   - Glue를 사용하여 데이터를 크롤링하고, ETL 작업을 자동화하는 방법

이 부분들을 공부하면, AWS에서 다양한 데이터 소스를 통합하고, 비즈니스 인텔리전스를 위해 데이터를 분석하는 방법을 더 잘 이해할 수 있습니다.


# 157번
**정답: D. Configure an Amazon CloudWatch Logs export for the DB cluster. E. Use AWS Backup to take the backups and to keep the backups for 5 years.**

**해설:**
- **Amazon CloudWatch Logs Export:**
  - **감사 로그 보관:** CloudWatch Logs를 사용하여 데이터베이스에서 수행된 작업의 감사 로그를 무기한으로 보관할 수 있습니다. 이는 감사 로그를 영구적으로 보관해야 하는 요구 사항을 충족합니다.

- **AWS Backup:**
  - **백업 보존:** AWS Backup을 사용하여 Aurora DB 클러스터의 백업을 자동으로 생성하고, 백업 보존 기간을 5년으로 설정할 수 있습니다. 이는 데이터를 5년 동안 보관하고, 5년 후에 삭제해야 하는 요구 사항을 충족합니다.
  - **자동화:** AWS Backup은 백업 작업을 자동화하여 운영 오버헤드를 줄이고, 백업 보존 정책을 쉽게 관리할 수 있습니다.

**다른 보기가 정답이 될 수 없는 이유:**
- **A. Manual Snapshot:** 수동 스냅샷은 백업을 수동으로 관리해야 하므로, 운영 오버헤드가 증가합니다. 또한, 수동 스냅샷은 자동으로 삭제되지 않으므로, 5년 후에 데이터를 자동으로 삭제하는 요구 사항을 충족하지 않습니다.
- **B. Lifecycle Policy for Automated Backups:** Aurora는 기본적으로 자동 백업에 대한 수명 주기 정책을 지원하지 않습니다.
- **C. Automated Backup Retention:** Aurora의 자동 백업 보존 기간은 최대 35일로 제한되므로, 5년 동안 데이터를 보관하는 요구 사항을 충족하지 않습니다.

**출제 의도:**
이 문제는 AWS에서 데이터베이스 백업과 감사 로그를 관리하고, 특정 보존 기간 동안 데이터를 안전하게 보관하는 방법을 평가합니다. 특히, AWS Backup과 CloudWatch Logs를 사용하여 데이터를 자동으로 백업하고, 감사 로그를 영구적으로 보관하는 방법을 이해하는 것이 목적입니다.

**공부해야 하는 부분:**
1. **AWS Backup:**
   - AWS Backup의 기본 개념과 사용 사례
   - AWS Backup을 사용하여 데이터베이스 백업을 자동화하고, 보존 기간을 설정하는 방법

2. **Amazon CloudWatch Logs:**
   - CloudWatch Logs의 기본 개념과 사용 사례
   - CloudWatch Logs를 사용하여 데이터베이스 감사 로그를 무기한으로 보관하는 방법

이 부분들을 공부하면, AWS에서 데이터베이스 백업과 감사 로그를 관리하고, 특정 보존 기간 동안 데이터를 안전하게 보관하는 방법을 더 잘 이해할 수 있습니다.


# 162번
**정답: A. Amazon FSx for Lustre integrated with Amazon S3**

**해설:**
- **Amazon FSx for Lustre:**
  - **고성능 파일 시스템:** FSx for Lustre는 고성능 컴퓨팅(HPC) 워크로드에 최적화된 파일 시스템으로, 높은 처리량과 낮은 지연 시간을 제공합니다. 이는 금융 리스크 모델링과 같은 HPC 워크로드에 적합합니다.
  - **S3 통합:** FSx for Lustre는 Amazon S3와 통합되어, 데이터를 S3에 저장하고 필요할 때 FSx for Lustre 파일 시스템으로 가져올 수 있습니다. 이는 장기 보관 및 분석을 위한 데이터를 효율적으로 관리할 수 있게 합니다.

**다른 보기가 정답이 될 수 없는 이유:**
- **B. Amazon FSx for Windows File Server:** FSx for Windows File Server는 Windows 기반 워크로드에 최적화되어 있으며, Linux 기반 HPC 워크로드에는 적합하지 않습니다.
- **C. Amazon S3 Glacier와 EBS:** S3 Glacier는 장기 보관을 위한 저비용 스토리지로, 고성능 파일 시스템을 제공하지 않습니다. EBS는 블록 스토리지로, 파일 시스템으로 사용하기에는 적합하지 않습니다.
- **D. S3와 EBS:** S3와 EBS를 통합하여 사용할 수 있지만, 이는 고성능 파일 시스템을 제공하지 않으며, HPC 워크로드에 적합하지 않습니다.

**출제 의도:**
이 문제는 AWS에서 고성능 컴퓨팅(HPC) 워크로드를 위한 스토리지 솔루션을 선택하는 방법을 평가합니다. 특히, Amazon FSx for Lustre와 Amazon S3를 사용하여 고성능 파일 시스템과 장기 보관 스토리지를 통합하는 방법을 이해하는 것이 목적입니다.

**공부해야 하는 부분:**
1. **Amazon FSx for Lustre:**
   - FSx for Lustre의 기본 개념과 사용 사례
   - FSx for Lustre를 사용하여 고성능 컴퓨팅 워크로드를 처리하는 방법

2. **Amazon S3:**
   - S3의 기본 개념과 사용 사례
   - S3를 사용하여 데이터를 장기 보관하고, FSx for Lustre와 통합하는 방법

이 부분들을 공부하면, AWS에서 고성능 컴퓨팅(HPC) 워크로드를 위한 스토리지 솔루션을 선택하는 방법을 더 잘 이해할 수 있습니다.


# 179번
**정답: A. Create an IAM role that has read access to the Parameter Store parameter. Allow Decrypt access to an AWS Key Management Service (AWS KMS) key that is used to encrypt the parameter. Assign this IAM role to the EC2 instance.**

**해설:**
- **IAM Role 및 KMS 통합:**
  - **IAM Role:** EC2 인스턴스에 IAM 역할을 할당하여, 해당 역할이 Systems Manager Parameter Store의 매개변수에 대한 읽기 권한을 가지도록 설정합니다. 이는 보안 모범 사례에 부합하며, EC2 인스턴스가 필요한 권한만 가지도록 제한할 수 있습니다.
  - **KMS 키:** 매개변수를 암호화하는 데 사용된 AWS KMS 키에 대한 복호화 권한을 IAM 역할에 부여합니다. 이는 매개변수가 암호화된 상태로 저장되고, 필요한 경우에만 복호화할 수 있도록 보장합니다.

**다른 보기가 정답이 될 수 없는 이유:**
- **B. IAM Policy:** IAM 정책을 EC2 인스턴스에 직접 할당하는 것은 보안 모범 사례에 부합하지 않습니다. 대신 IAM 역할을 사용하여 권한을 부여하는 것이 더 안전하고 관리하기 쉽습니다.
- **C. IAM Trust Relationship:** Parameter Store와 EC2 인스턴스 간의 신뢰 관계를 설정하는 것은 적절한 접근 방식이 아닙니다. 또한, Amazon RDS를 주체로 지정하는 것은 이 시나리오와 관련이 없습니다.
- **D. IAM Trust Relationship:** DB 인스턴스와 EC2 인스턴스 간의 신뢰 관계를 설정하는 것은 적절한 접근 방식이 아닙니다. 또한, Systems Manager를 주체로 지정하는 것은 이 시나리오와 관련이 없습니다.

**출제 의도:**
이 문제는 AWS에서 보안 모범 사례를 따르면서 애플리케이션이 데이터베이스 자격 증명을 안전하게 저장하고 접근할 수 있도록 설정하는 방법을 평가합니다. 특히, IAM 역할과 KMS 키를 사용하여 Systems Manager Parameter Store의 매개변수를 안전하게 관리하는 방법을 이해하는 것이 목적입니다.

**공부해야 하는 부분:**
1. **AWS Systems Manager Parameter Store:**
   - Parameter Store의 기본 개념과 사용 사례
   - Parameter Store를 사용하여 애플리케이션 자격 증명을 안전하게 저장하고 관리하는 방법

2. **IAM Roles and Policies:**
   - IAM 역할과 정책의 기본 개념과 사용 사례
   - IAM 역할을 사용하여 EC2 인스턴스에 권한을 부여하는 방법

3. **AWS Key Management Service (KMS):**
   - KMS의 기본 개념과 사용 사례
   - KMS 키를 사용하여 데이터를 


# 184번
**정답: A. Configure the Lambda function to run in the VPC with the appropriate security group.**

**해설:**
- **Lambda 함수 VPC 설정:**
  - **VPC 내 실행:** Lambda 함수를 VPC 내에서 실행하도록 설정하면, VPC의 리소스에 접근할 수 있습니다. 이는 Lambda 함수가 VPC 내의 서브넷과 보안 그룹을 사용하여 네트워크 트래픽을 제어할 수 있게 합니다.
  - **보안 그룹:** 적절한 보안 그룹을 설정하여 Lambda 함수가 온프레미스 데이터 센터의 데이터베이스에 접근할 수 있도록 허용합니다. 보안 그룹은 인바운드 및 아웃바운드 트래픽을 제어합니다.

**다른 보기가 정답이 될 수 없는 이유:**
- **B. VPN 연결 설정:** 이미 Direct Connect를 통해 온프레미스 데이터 센터에 접근할 수 있으므로, 추가적인 VPN 연결을 설정할 필요가 없습니다.
- **C. 라우트 테이블 업데이트:** 라우트 테이블을 업데이트하는 것만으로는 Lambda 함수가 VPC 내에서 실행되지 않으면 온프레미스 데이터 센터에 접근할 수 없습니다.
- **D. Elastic IP 주소 사용:** Elastic IP 주소를 사용하여 트래픽을 라우팅하는 것은 적절한 방법이 아닙니다. Lambda 함수는 ENI(Elastic Network Interface)를 통해 VPC 내에서 실행되어야 합니다.

**출제 의도:**
이 문제는 AWS Lambda 함수를 VPC 내에서 실행하여 온프레미스 데이터 센터의 리소스에 접근할 수 있도록 설정하는 방법을 평가합니다. 특히, Lambda 함수를 VPC 내에서 실행하고, 적절한 보안 그룹을 설정하여 네트워크 트래픽을 제어하는 방법을 이해하는 것이 목적입니다.

**공부해야 하는 부분:**
1. **AWS Lambda와 VPC 통합:**
   - Lambda 함수를 VPC 내에서 실행하는 방법
   - Lambda 함수에 VPC 서브넷과 보안 그룹을 할당하는 방법

2. **AWS Direct Connect:**
   - Direct Connect의 기본 개념과 사용 사례
   - Direct Connect를 사용하여 온프레미스 데이터 센터와 AWS 간의 네트워크 연결을 설정하는 방법

이 부분들을 공부하면, AWS Lambda 함수를 VPC 내에서 실행하여 온프레미스 데이터 센터의 리소스에 접근할 수 있도록 설정하는 방법을 더 잘 이해할 수 있습니다.


# 186번
- 틀리지는 않았으나 FSx, Storage Gateway 차이점을 알 수 있음

**정답: B. Configure Amazon FSx for Windows File Server. Mount the Amazon FSx file system to each Windows instance.**

**해설:**
- **Amazon FSx for Windows File Server:**
  - **Windows 네이티브 파일 시스템:** Amazon FSx for Windows File Server는 완전 관리형 네이티브 Windows 파일 시스템을 제공하여, Windows 기반 애플리케이션에 적합합니다.
  - **다중 AZ 지원:** FSx for Windows File Server는 다중 가용 영역(AZ)에 걸쳐 배포할 수 있어, 고가용성과 내구성을 제공합니다.
  - **SMB 프로토콜 지원:** FSx for Windows File Server는 SMB 프로토콜을 지원하여, 여러 EC2 Windows 인스턴스에서 파일 시스템을 공유할 수 있습니다.

**다른 보기가 정답이 될 수 없는 이유:**
- **A. AWS Storage Gateway:** Storage Gateway는 온프레미스와 AWS 간의 하이브리드 클라우드 스토리지 솔루션으로, 다중 AZ에 걸친 Windows 파일 시스템을 제공하는 데 적합하지 않습니다.
- **C. Amazon EFS:** EFS는 Linux 기반 파일 시스템으로, Windows 기반 애플리케이션에는 적합하지 않습니다.
- **D. Amazon EBS:** EBS 볼륨은 단일 EC2 인스턴스에만 연결할 수 있으며, 여러 인스턴스에서 동시에 액세스할 수 없습니다.

**출제 의도:**
이 문제는 AWS에서 Windows 기반 애플리케이션을 마이그레이션하고, 다중 AZ에 걸쳐 여러 EC2 Windows 인스턴스에서 공유할 수 있는 파일 시스템을 설정하는 방법을 평가합니다. 특히, Amazon FSx for Windows File Server를 사용하여 Windows 네이티브 파일 시스템을 제공하는 방법을 이해하는 것이 목적입니다.

**공부해야 하는 부분:**
1. **Amazon FSx for Windows File Server:**
   - FSx for Windows File Server의 기본 개념과 사용 사례
   - FSx for Windows File Server를 사용하여 Windows 기반 애플리케이션에 적합한 파일 시스템을 설정하는 방법

2. **AWS Storage Gateway:**
   - Storage Gateway의 기본 개념과 사용 사례
   - Storage Gateway를 사용하여 온프레미스와 AWS 간의 하이브리드 클라우드 스토리지를 설정하는 방법

3. **Amazon Elastic File System (EFS):**
   - EFS의 기본 개념과 사용 사례
   - EFS를 사용하여 Linux 기반 파일 시스템을 설정하는 방법

4. **Amazon Elastic Block Store (EBS):**
   - EBS의 기본 개념과 사용 사례
   - EBS 볼륨을 사용하여 단일 EC2 인스턴스에 스토리지를 제공하는 방법

이 부분들을 공부하면, AWS에서 Windows 기반 애플리케이션을 마이그레이션하고, 다중 AZ에 걸쳐 여러 EC2 Windows 인스턴스에서 공유할 수 있는 파일 시스템을 설정하는 방법을 더 잘 이해할 수 있습니다.

# 200번
### 정답:
정답은 D입니다.

### 해설:
- **옵션 A**: AWS Lambda 함수를 API Gateway의 authorizer로 구성하여 사용자를 검증하는 방법은 가능하지만, Lambda 함수를 작성하고 유지 관리해야 하므로 운영 오버헤드가 증가합니다.
- **옵션 B**: 각 사용자에 대해 API 키를 생성하고 요청마다 키를 검증하는 방법은 많은 관리 작업이 필요하며, Lambda 함수를 사용하여 키를 검증해야 하므로 운영 오버헤드가 큽니다.
- **옵션 C**: 요청마다 사용자의 이메일 주소를 헤더에 포함시키고, Lambda 함수를 호출하여 사용자의 접근 권한을 검증하는 방법은 많은 개발 작업과 운영 오버헤드가 필요합니다.
- **옵션 D**: Amazon Cognito 사용자 풀 authorizer를 API Gateway에 구성하여 Amazon Cognito가 각 요청을 검증하도록 하는 방법은 AWS 관리 솔루션을 사용하여 운영 오버헤드를 최소화할 수 있는 최적의 방법입니다. 이 방법은 추가적인 개발 작업 없이 Amazon Cognito의 기능을 활용하여 사용자를 검증할 수 있습니다.

### 출제의도:
이 문제는 AWS 관리 솔루션을 사용하여 최소한의 운영 오버헤드로 REST API에 대한 접근을 제어하는 방법에 대한 이해를 평가하기 위해 출제되었습니다. 문제는 Amazon Cognito와 API Gateway의 통합을 통해 효율적으로 사용자 인증을 처리할 수 있는 능력을 테스트합니다.

### 문제를 풀기 위해 학습해야 하는 부분:
1. **Amazon Cognito**: Cognito 사용자 풀의 기본 개념, 사용자 인증 및 관리.
2. **Amazon API Gateway**: API Gateway의 기본 개념, authorizer 설정, Cognito와의 통합.
3. **AWS Lambda**: Lambda 함수의 기본 개념, API Gateway와의 통합.
4. **API 보안**: API 키 관리, 사용자 인증 및 권한 부여.
5. **AWS 관리 솔루션**: AWS 관리 솔루션을 사용하여 운영 오버헤드를 최소화하는 방법.

이러한 학습 내용을 통해 문제에서 요구하는 최적의 솔루션을 선택할 수 있습니다.


# 201번
**정답: B. Build an Amazon Pinpoint journey. Configure Amazon Pinpoint to send events to an Amazon Kinesis data stream for analysis and archiving.**

**해설:**
- **Amazon Pinpoint:**
  - **SMS 메시지 전송:** Amazon Pinpoint는 마케팅 커뮤니케이션 서비스로, SMS 메시지를 전송하는 데 적합합니다. Pinpoint는 사용자에게 SMS 메시지를 보내고, 사용자의 응답을 처리할 수 있습니다.
  - **이벤트 전송:** Pinpoint는 이벤트를 Amazon Kinesis 데이터 스트림으로 전송하여, 실시간으로 데이터를 분석하고 아카이빙할 수 있습니다. 이는 사용자의 응답을 1년 동안 저장하고 분석하는 요구 사항을 충족합니다.

**다른 보기가 정답이 될 수 없는 이유:**
- **A. Amazon Connect:** Amazon Connect는 주로 콜 센터 솔루션으로 사용되며, SMS 메시지 전송에 적합하지 않습니다.
- **C. Amazon SQS:** SQS는 메시지 큐잉 서비스로, SMS 메시지 전송에 적합하지 않습니다. 또한, SQS는 메시지의 장기 저장을 제공하지 않습니다.
- **D. Amazon SNS FIFO:** SNS는 주로 알림 전송에 사용되며, SMS 메시지 전송에 적합하지 않습니다. 또한, SNS FIFO 주제는 메시지 순서를 보장하지만, SMS 메시지 전송과 응답 처리에는 적합하지 않습니다.

**출제 의도:**
이 문제는 AWS에서 SMS 메시지를 전송하고, 사용자의 응답을 저장하고 분석하는 솔루션을 설계하는 방법을 평가합니다. 특히, Amazon Pinpoint를 사용하여 SMS 메시지를 전송하고, Kinesis 데이터 스트림을 사용하여 데이터를 실시간으로 분석하고 아카이빙하는 방법을 이해하는 것이 목적입니다.

**공부해야 하는 부분:**
1. **Amazon Pinpoint:**
   - Pinpoint의 기본 개념과 사용 사례
   - Pinpoint를 사용하여 SMS 메시지를 전송하고, 사용자의 응답을 처리하는 방법

2. **Amazon Kinesis:**
   - Kinesis 데이터 스트림의 기본 개념과 사용 사례
   - Kinesis를 사용하여 데이터를 실시간으로 분석하고 아카이빙하는 방법

이 부분들을 공부하면, AWS에서 SMS 메시지를 전송하고, 사용자의 응답을 저장하고 분석하는 솔루션을 설계하는 방법을 더 잘 이해할 수 있습니다.

# 203번
**정답: D. Add an Auto Scaling group for the application that sends meeting invitations. Configure the Auto Scaling group to scale based on the depth of the SQS queue.**

**해설:**
- **Auto Scaling Group:**
  - **자동 확장:** Auto Scaling 그룹을 사용하면 애플리케이션 인스턴스 수를 자동으로 조정할 수 있습니다. SQS 큐의 깊이에 따라 인스턴스를 확장하면, 대기 중인 메시지를 더 빠르게 처리할 수 있습니다.
  - **큐 기반 확장:** SQS 큐의 깊이를 모니터링하고, 큐에 쌓인 메시지 수에 따라 인스턴스를 확장하면, 고객의 미팅 초대장이 지연 없이 발송될 수 있습니다.

**다른 보기가 정답이 될 수 없는 이유:**
- **A. DynamoDB Accelerator (DAX):** DAX는 DynamoDB의 읽기 성능을 향상시키는 데 사용되며, 현재 문제는 미팅 초대장 발송 지연이므로 적합하지 않습니다.
- **B. Amazon API Gateway:** API Gateway는 웹 애플리케이션 앞에 API를 제공하는 데 사용되며, 현재 문제는 미팅 초대장 발송 지연이므로 적합하지 않습니다.
- **C. Amazon CloudFront:** CloudFront는 콘텐츠 전송 네트워크(CDN)로, 웹 애플리케이션의 성능을 향상시키는 데 사용됩니다. 현재 문제는 미팅 초대장 발송 지연이므로 적합하지 않습니다.

**출제 의도:**
이 문제는 AWS에서 SQS 큐를 사용하여 메시지를 처리하는 애플리케이션의 성능을 향상시키는 방법을 평가합니다. 특히, Auto Scaling 그룹을 사용하여 SQS 큐의 깊이에 따라 애플리케이션 인스턴스를 자동으로 확장하는 방법을 이해하는 것이 목적입니다.

**공부해야 하는 부분:**
1. **Amazon SQS:**
   - SQS의 기본 개념과 사용 사례
   - SQS 큐의 깊이를 모니터링하고, 큐 기반 확장을 설정하는 방법

2. **Auto Scaling Group:**
   - Auto Scaling 그룹의 기본 개념과 사용 사례
   - Auto Scaling 그룹을 사용하여 애플리케이션 인스턴스를 자동으로 확장하는 방법

이 부분들을 공부하면, AWS에서 SQS 큐를 사용하여 메시지를 처리하는 애플리케이션의 성능을 향상시키는 방법을 더 잘 이해할 수 있습니다.

# 204번
**정답: C. Create a data lake by using AWS Lake Formation. Create an AWS Glue JDBC connection to Amazon RDS. Register the S3 bucket in Lake Formation. Use Lake Formation access controls to limit access.**

**해설:**
- **AWS Lake Formation:**
  - **데이터 레이크 관리:** Lake Formation은 데이터 레이크를 쉽게 설정하고 관리할 수 있는 서비스입니다. S3에 저장된 데이터를 등록하고, 다양한 데이터 소스와 통합할 수 있습니다.
  - **세분화된 권한 관리:** Lake Formation은 세분화된 데이터 액세스 제어를 제공하여, 다양한 팀이 필요한 데이터에만 접근할 수 있도록 설정할 수 있습니다. 이는 데이터 보안을 강화하고, 운영 오버헤드를 최소화합니다.
  - **AWS Glue 통합:** AWS Glue를 사용하여 RDS와의 JDBC 연결을 설정하고, 데이터를 크롤링하여 카탈로그에 등록할 수 있습니다. 이를 통해 데이터에 대한 통합된 뷰를 제공할 수 있습니다.

**다른 보기가 정답이 될 수 없는 이유:**
- **A. Amazon RDS:** 모든 데이터를 RDS로 마이그레이션하는 것은 비효율적이며, RDS의 비용과 성능 문제를 초래할 수 있습니다. 또한, RDS는 데이터 레이크 기능을 제공하지 않습니다.
- **B. AWS Lambda와 Athena:** Lambda를 사용하여 데이터를 복사하고, Athena를 사용하여 데이터를 쿼리하는 것은 가능하지만, 세분화된 권한 관리를 제공하는 데 한계가 있습니다.
- **D. Amazon Redshift:** Redshift는 데이터 웨어하우스 솔루션으로, 대규모 데이터 분석에 적합하지만, 데이터 레이크 기능을 제공하지 않습니다. 또한, Redshift로 데이터를 복사하는 것은 운영 오버헤드를 증가시킬 수 있습니다.

**출제 의도:**
이 문제는 AWS에서 대규모 데이터를 관리하고, 다양한 팀이 데이터를 분석할 수 있도록 세분화된 권한 관리를 제공하는 솔루션을 설계하는 방법을 평가합니다. 특히, AWS Lake Formation을 사용하여 데이터 레이크를 설정하고, 세분화된 권한 관리를 제공하는 방법을 이해하는 것이 목적입니다.

**공부해야 하는 부분:**
1. **AWS Lake Formation:**
   - Lake Formation의 기본 개념과 사용 사례
   - Lake Formation을 사용하여 데이터 레이크를 설정하고, 세분화된 권한 관리를 제공하는 방법

2. **AWS Glue:**
   - Glue의 기본 개념과 사용 사례
   - Glue를 사용하여 다양한 데이터 소스와 통합하고, 데이터를 크롤링하여 카탈로그에 등록하는 방법

이 부분들을 공부하면, AWS에서 대규모 데이터를 관리하고, 다양한 팀이 데이터를 분석할 수 있도록 세분화된 권한 관리를 제공하는 솔루션을 설계하는 방법을 더 잘 이해할 수 있습니다.

# 205번
**정답: C. Create a private Amazon S3 bucket. Use an S3 bucket policy to allow access from a CloudFront origin access identity (OAI). Upload website content by using the AWS CLI.**

**해설:**
- **Amazon S3와 CloudFront:**
  - **비용 효율성:** S3는 정적 콘텐츠를 호스팅하는 데 매우 비용 효율적입니다. S3 버킷을 사용하면 서버를 관리할 필요가 없으며, 스토리지 비용만 지불하면 됩니다.
  - **내구성 및 가용성:** S3는 높은 내구성과 가용성을 제공하여, 웹사이트 콘텐츠를 안전하게 저장하고 제공할 수 있습니다.
  - **CloudFront 통합:** CloudFront와 S3를 통합하면, 전 세계 사용자에게 빠르고 안정적으로 콘텐츠를 제공할 수 있습니다. OAI를 사용하여 S3 버킷에 대한 액세스를 제어할 수 있습니다.

**다른 보기가 정답이 될 수 없는 이유:**
- **A. Amazon Lightsail:** Lightsail은 가상 서버를 제공하지만, S3를 사용하는 것보다 비용 효율적이지 않습니다. 또한, 서버를 관리해야 하는 오버헤드가 있습니다.
- **B. AWS Auto Scaling과 EC2:** EC2 인스턴스를 사용하고 Auto Scaling 그룹을 설정하는 것은 정적 웹사이트 호스팅에 비해 과도한 솔루션입니다. 비용이 많이 들고, 관리 오버헤드가 큽니다.
- **D. Public S3 bucket과 AWS Transfer for SFTP:** S3 버킷을 공개로 설정하는 것은 보안 위험이 있습니다. 또한, AWS Transfer for SFTP를 사용하는 것은 추가 비용이 발생할 수 있습니다.

**출제 의도:**
이 문제는 AWS에서 정적 웹사이트를 호스팅하고, 비용 효율적이고 내구성 있는 솔루션을 설계하는 방법을 평가합니다. 특히, Amazon S3와 CloudFront를 사용하여 정적 콘텐츠를 호스팅하고, OAI를 사용하여 S3 버킷에 대한 액세스를 제어하는 방법을 이해하는 것이 목적입니다.

**공부해야 하는 부분:**
1. **Amazon S3:**
   - S3의 기본 개념과 사용 사례
   - S3 버킷을 사용하여 정적 웹사이트를 호스팅하는 방법
   - S3 버킷 정책과 OAI를 사용하여 액세스를 제어하는 방법

2. **Amazon CloudFront:**
   - CloudFront의 기본 개념과 사용 사례
   - CloudFront를 사용하여 전 세계 사용자에게 콘텐츠를 빠르고 안정적으로 제공하는 방법

이 부분들을 공부하면, AWS에서 정적 웹사이트를 호스팅하고, 비용 효율적이고 내구성 있는 솔루션을 설계하는 방법을 더 잘 이해할 수 있습니다.

# 209번
**정답: A. Use Amazon ElastiCache to manage and store session data.**

**해설:**
- **Amazon ElastiCache:**
  - **분산 세션 관리:** ElastiCache는 Redis 또는 Memcached를 사용하여 세션 데이터를 관리하고 저장할 수 있습니다. 이는 분산 환경에서 세션 데이터를 중앙 집중식으로 관리할 수 있게 합니다.
  - **고성능:** ElastiCache는 인메모리 데이터 스토어로, 세션 데이터를 빠르게 읽고 쓸 수 있어 성능이 뛰어납니다.
  - **확장성:** ElastiCache는 자동으로 확장할 수 있어, EC2 인스턴스가 자주 스케일링되는 환경에서도 안정적으로 세션 데이터를 관리할 수 있습니다.

**다른 보기가 정답이 될 수 없는 이유:**
- **B. Session Affinity (Sticky Sessions):** ALB의 세션 어피니티(스티키 세션)는 세션 데이터를 특정 인스턴스에 고정시키는 방식으로, 인스턴스가 자주 스케일링되는 환경에서는 적합하지 않습니다. 또한, 인스턴스가 종료되면 세션 데이터가 손실될 수 있습니다.
- **C. Session Manager from AWS Systems Manager:** Session Manager는 EC2 인스턴스에 대한 원격 접속을 관리하는 도구로, 세션 데이터 관리를 위한 도구가 아닙니다.
- **D. GetSessionToken API in AWS STS:** GetSessionToken API는 임시 보안 자격 증명을 생성하는 데 사용되며, 세션 데이터 관리를 위한 도구가 아닙니다.

**출제 의도:**
이 문제는 AWS에서 분산 세션 데이터를 관리하고, 자동으로 확장되는 환경에서 안정적으로 세션 데이터를 관리하는 방법을 평가합니다. 특히, Amazon ElastiCache를 사용하여 세션 데이터를 중앙 집중식으로 관리하고, 성능과 확장성을 보장하는 방법을 이해하는 것이 목적입니다.

**공부해야 하는 부분:**
1. **Amazon ElastiCache:**
   - ElastiCache의 기본 개념과 사용 사례
   - ElastiCache를 사용하여 세션 데이터를 관리하고 저장하는 방법

2. **Application Load Balancer (ALB):**
   - ALB의 기본 개념과 사용 사례
   - ALB의 세션 어피니티(스티키 세션) 기능과 그 한계

이 부분들을 공부하면, AWS에서 분산 세션 데이터를 관리하고, 자동으로 확장되는 환경에서 안정적으로 세션 데이터를 관리하는 방법을 더 잘 이해할 수 있습니다.


# 215번
**정답: A. Order AWS Snowball devices to transfer the data. Use a lifecycle policy to transition the files to Amazon S3 Glacier Deep Archive.**

**해설:**
- **AWS Snowball:**
  - **대용량 데이터 전송:** AWS Snowball는 대용량 데이터를 물리적으로 전송하는 데 적합한 솔루션입니다. 700 TB의 데이터를 1개월 내에 전송해야 하는 경우, 인터넷 연결을 통한 전송은 시간이 많이 걸릴 수 있습니다.
  - **비용 효율성:** Snowball을 사용하면 대규모 데이터를 빠르고 안전하게 전송할 수 있으며, 인터넷 대역폭을 사용하지 않으므로 비용 효율적입니다.
  - **S3 Glacier Deep Archive:** 데이터를 S3로 전송한 후, 수명 주기 정책을 사용하여 데이터를 S3 Glacier Deep Archive로 전환하면, 장기 보관 비용을 최소화할 수 있습니다.

**다른 보기가 정답이 될 수 없는 이유:**
- **B. VPN과 AWS CLI:** VPN 연결을 통해 데이터를 전송하는 것은 500 Mbps의 대역폭으로는 700 TB의 데이터를 1개월 내에 전송하기 어렵습니다.
- **C. AWS Direct Connect:** Direct Connect를 통해 데이터를 전송하는 것은 가능하지만, 500 Mbps의 대역폭으로는 700 TB의 데이터를 1개월 내에 전송하기 어렵습니다. 또한, Direct Connect는 설정과 비용 측면에서 더 복잡할 수 있습니다.
- **D. AWS DataSync:** DataSync를 사용하여 데이터를 전송하는 것은 가능하지만, 500 Mbps의 대역폭으로는 700 TB의 데이터를 1개월 내에 전송하기 어렵습니다.

**출제 의도:**
이 문제는 AWS에서 대규모 데이터를 효율적으로 전송하고, 장기 보관 비용을 최소화하는 방법을 평가합니다. 특히, AWS Snowball을 사용하여 대규모 데이터를 빠르고 안전하게 전송하고, S3 Glacier Deep Archive를 사용하여 장기 보관 비용을 최소화하는 방법을 이해하는 것이 목적입니다.

**공부해야 하는 부분:**
1. **AWS Snowball:**
   - Snowball의 기본 개념과 사용 사례
   - Snowball을 사용하여 대규모 데이터를 전송하는 방법

2. **Amazon S3 Glacier Deep Archive:**
   - S3 Glacier Deep Archive의 기본 개념과 사용 사례
   - 수명 주기 정책을 사용하여 데이터를 S3 Glacier Deep Archive로 전환하는 방법

이 부분들을 공부하면, AWS에서 대규모 데이터를 효율적으로 전송하고, 장기 보관 비용을 최소화하는 방법을 더 잘 이해할 수 있습니다.


# 217번
**정답: A. Deploy the application with the required infrastructure elements in place. Use Amazon Route 53 to configure active-passive failover. Create an Aurora Replica in a second AWS Region.**

**해설:**
- **Active-Passive Failover:**
  - **Route 53 Active-Passive Failover:** Route 53을 사용하여 활성-수동 페일오버를 구성하면, 기본 인프라가 정상일 때는 트래픽을 기본 리전으로 라우팅하고, 장애가 발생하면 대기 리전으로 트래픽을 전환할 수 있습니다.
  - **Aurora Replica:** Aurora 복제본을 두 번째 AWS 리전에 생성하면, 데이터베이스의 복구 시간을 최소화할 수 있습니다. Aurora 복제본은 기본 인스턴스의 데이터를 실시간으로 복제하므로, 데이터 손실을 최소화할 수 있습니다.

**다른 보기가 정답이 될 수 없는 이유:**
- **B. Active-Active Failover:** 활성-활성 페일오버는 두 리전 모두에서 트래픽을 처리할 수 있도록 설정하는 방식으로, 현재 요구 사항(기본 인프라가 정상일 때는 대기 리전이 로드를 처리할 필요 없음)과 맞지 않습니다.
- **C. Snapshot 복구:** 스냅샷에서 복구된 Aurora 데이터베이스를 사용하는 것은 데이터 복구 시간이 길어질 수 있으며, 30분의 다운타임 요구 사항을 충족하지 못할 수 있습니다.
- **D. AWS Backup:** AWS Backup을 사용하여 데이터를 백업하고, 이를 사용하여 두 번째 리전에 인프라를 생성하는 것은 데이터 복구 시간이 길어질 수 있으며, 30분의 다운타임 요구 사항을 충족하지 못할 수 있습니다.

**출제 의도:**
이 문제는 AWS에서 재해 복구 솔루션을 설계하고, 특정 다운타임 및 데이터 손실 허용 범위 내에서 요구 사항을 충족하는 방법을 평가합니다. 특히, Route 53을 사용하여 활성-수동 페일오버를 구성하고, Aurora 복제본을 사용하여 데이터베이스 복구 시간을 최소화하는 방법을 이해하는 것이 목적입니다.

**공부해야 하는 부분:**
1. **Amazon Route 53:**
   - Route 53의 기본 개념과 사용 사례
   - Route 53을 사용하여 활성-수동 페일오버를 구성하는 방법

2. **Amazon Aurora:**
   - Aurora의 기본 개념과 사용 사례
   - Aurora 복제본을 생성하고, 이를 사용하여 데이터베이스 복구 시간을 최소화하는 방법

이 부분들을 공부하면, AWS에서 재해 복구 솔루션을 설계하고, 특정 다운타임 및 데이터 손실 허용 범위 내에서 요구 사항을 충족하는 방법을 더 잘 이해할 수 있습니다.


# 219번
**정답: D. Modify the CloudFormation templates. Replace the EC2 instances with R5 EC2 instances. Deploy the Amazon CloudWatch agent on the EC2 instances to generate custom application latency metrics for future capacity planning.**

**해설:**
- **R5 EC2 인스턴스:**
  - **메모리 최적화:** R5 인스턴스는 메모리 최적화 인스턴스로, 메모리 집약적인 작업을 수행하는 애플리케이션에 적합합니다. 현재 애플리케이션이 메모리 집약적인 작업을 수행하고 있으므로, R5 인스턴스로 교체하면 성능이 향상될 수 있습니다.
  
- **CloudWatch 에이전트:**
  - **커스텀 메트릭:** CloudWatch 에이전트를 사용하여 애플리케이션 지연 시간과 같은 커스텀 메트릭을 생성하면, 애플리케이션 성능을 모니터링하고 향후 용량 계획에 도움이 됩니다.

**다른 보기가 정답이 될 수 없는 이유:**
- **A. T3 인스턴스:** T3 인스턴스는 버스트 가능한 성능을 제공하지만, 지속적인 고성능이 필요한 메모리 집약적인 작업에는 적합하지 않습니다.
- **B. Auto Scaling 그룹:** Auto Scaling 그룹을 사용하여 인스턴스를 확장하는 것은 가능하지만, 상태 저장 애플리케이션의 경우 상태를 유지하는 데 어려움이 있을 수 있습니다. 또한, 메모리 최적화 인스턴스로 교체하는 것이 더 효과적입니다.
- **C. CloudWatch 메모리 메트릭:** CloudWatch의 기본 메모리 메트릭을 사용하는 것은 가능하지만, 애플리케이션 지연 시간과 같은 커스텀 메트릭을 생성하는 것이 더 유용합니다.

**출제 의도:**
이 문제는 AWS에서 메모리 집약적인 애플리케이션의 성능 문제를 해결하고, 운영 효율성을 극대화하는 방법을 평가합니다. 특히, 메모리 최적화 인스턴스로 교체하고, CloudWatch 에이전트를 사용하여 커스텀 메트릭을 생성하는 방법을 이해하는 것이 목적입니다.

**공부해야 하는 부분:**
1. **EC2 인스턴스 유형:**
   - M5, T3, R5 인스턴스의 기본 개념과 사용 사례
   - 메모리 최적화 인스턴스(R5)를 사용하여 메모리 집약적인 작업을 수행하는 방법

2. **Amazon CloudWatch:**
   - CloudWatch의 기본 개념과 사용 사례
   - CloudWatch 에이전트를 사용하여 커스텀 메트릭을 생성하고, 애플리케이션 성능을 모니터링하는 방법

이 부분들을 공부하면, AWS에서 메모리 집약적인 애플리케이션의 성능 문제를 해결하고, 운영 효율성을 극대화하는 방법을 더 잘 이해할 수 있습니다.

# 224번
**정답: C. Create an Amazon Route 53 multivalue answer routing policy. E. Launch four EC2 instances: two instances in one Availability Zone and two instances in another Availability Zone.**

**해설:**
- **Amazon Route 53 Multivalue Answer Routing Policy:**
  - **C. Multivalue Answer Routing Policy:** 이 라우팅 정책은 여러 IP 주소를 반환하여 트래픽을 무작위로 분산시킬 수 있습니다. 이는 모든 실행 중인 EC2 인스턴스에 트래픽을 무작위로 분산시키는 요구 사항을 충족합니다.

- **다중 가용 영역 배포:**
  - **E. Launch four EC2 instances:** 두 개의 가용 영역에 각각 두 개의 EC2 인스턴스를 배포하면, 고가용성과 장애 내성을 보장할 수 있습니다. 이는 하나의 가용 영역에 장애가 발생하더라도 다른 가용 영역의 인스턴스가 트래픽을 처리할 수 있도록 합니다.

**다른 보기가 정답이 될 수 없는 이유:**
- **A. Failover Routing Policy:** 이 라우팅 정책은 주로 장애 조치(failover)를 위해 사용되며, 트래픽을 무작위로 분산시키는 데 적합하지 않습니다.
- **B. Weighted Routing Policy:** 가중치 라우팅 정책은 트래픽을 특정 비율로 분산시키는 데 사용되며, 무작위 분산을 보장하지 않습니다.
- **D. Launch three EC2 instances:** 세 개의 인스턴스를 배포하는 것은 고가용성과 장애 내성을 보장하기에 충분하지 않을 수 있습니다. 두 개의 가용 영역에 각각 두 개의 인스턴스를 배포하는 것이 더 적합합니다.

**출제 의도:**
이 문제는 AWS에서 웹 애플리케이션의 아키텍처를 고가용성과 장애 내성을 갖추도록 설계하는 방법을 평가합니다. 특히, Route 53의 Multivalue Answer Routing Policy를 사용하여 트래픽을 무작위로 분산시키고, 다중 가용 영역에 인스턴스를 배포하여 고가용성을 보장하는 방법을 이해하는 것이 목적입니다.

**공부해야 하는 부분:**
1. **Amazon Route 53 Routing Policies:**
   - Route 53의 다양한 라우팅 정책(예: Multivalue Answer, Weighted, Failover)의 기본 개념과 사용 사례
   - Multivalue Answer Routing Policy를 사용하여 트래픽을 무작위로 분산시키는 방법

2. **고가용성과 장애 내성:**
   - 다중 가용 영역에 인스턴스를 배포하여 고가용성과 장애 내성을 보장하는 방법
   - AWS에서 고가용성과 장애 내성을 갖춘 아키텍처를 설계하는 모범 사례

이 부분들을 공부하면, AWS에서 웹 애플리케이션의 아키텍처를 고가용성과 장애 내성을 갖추도록 설계하는 방법을 더 잘 이해할 수 있습니다.


# 230번
**정답: C. Remove the two NAT instances and replace them with two NAT gateways in different Availability Zones.**

**해설:**
- **NAT 게이트웨이:**
  - **고가용성 및 장애 내성:** NAT 게이트웨이는 AWS에서 관리되는 서비스로, 고가용성과 장애 내성을 제공합니다. 서로 다른 가용 영역에 NAT 게이트웨이를 배포하면, 하나의 가용 영역에 장애가 발생하더라도 다른 가용 영역의 NAT 게이트웨이가 트래픽을 처리할 수 있습니다.
  - **자동 확장:** NAT 게이트웨이는 자동으로 확장되어 트래픽 증가를 처리할 수 있습니다. 이는 수동으로 인스턴스를 관리할 필요가 없으므로 운영 오버헤드를 줄여줍니다.

**다른 보기가 정답이 될 수 없는 이유:**
- **A. 동일한 가용 영역에 두 개의 NAT 게이트웨이:** 동일한 가용 영역에 두 개의 NAT 게이트웨이를 배포하는 것은 고가용성과 장애 내성을 제공하지 않습니다. 하나의 가용 영역에 장애가 발생하면 두 개의 NAT 게이트웨이 모두 사용할 수 없게 됩니다.
- **B. Auto Scaling 그룹과 Network Load Balancers:** NAT 인스턴스를 Auto Scaling 그룹과 Network Load Balancers로 관리하는 것은 가능하지만, NAT 게이트웨이를 사용하는 것이 더 간단하고 관리 오버헤드가 적습니다.
- **D. Spot Instances와 Network Load Balancer:** Spot Instances는 비용 효율적일 수 있지만, 인스턴스가 언제든지 종료될 수 있으므로 안정적인 NAT 솔루션으로 적합하지 않습니다. 또한, Network Load Balancer를 사용하는 것은 NAT 게이트웨이를 사용하는 것보다 복잡합니다.

**출제 의도:**
이 문제는 AWS에서 NAT 인스턴스를 NAT 게이트웨이로 교체하여 고가용성, 장애 내성, 자동 확장을 제공하는 방법을 평가합니다. 특히, 서로 다른 가용 영역에 NAT 게이트웨이를 배포하여 고가용성과 장애 내성을 보장하는 방법을 이해하는 것이 목적입니다.

**공부해야 하는 부분:**
1. **NAT 게이트웨이:**
   - NAT 게이트웨이의 기본 개념과 사용 사례
   - NAT 게이트웨이를 사용하여 고가용성, 장애 내성, 자동 확장을 제공하는 방법

2. **NAT 인스턴스:**
   - NAT 인스턴스의 기본 개념과 사용 사례
   - NAT 인스턴스를 NAT 게이트웨이로 교체하는 이유와 장점

이 부분들을 공부하면, AWS에서 NAT 인스턴스를 NAT 게이트웨이로 교체하여 고가용성, 장애 내성, 자동 확장을 제공하는 방법을 더 잘 이해할 수 있습니다.

# 232번
**정답: C. Publish VPC flow logs to Amazon CloudWatch Logs. Create required metric filters. Create an Amazon CloudWatch metric alarm with a notification action for when the alarm is in the ALARM state.**

**해설:**
- **VPC Flow Logs와 CloudWatch Logs:**
  - **VPC Flow Logs:** VPC Flow Logs를 사용하면 VPC 내의 네트워크 트래픽을 캡처하고 분석할 수 있습니다. RDP(포트 3389) 또는 SSH(포트 22) 트래픽을 감지할 수 있습니다.
  - **CloudWatch Logs:** VPC Flow Logs를 CloudWatch Logs로 전송하면, 로그 데이터를 기반으로 메트릭 필터를 생성할 수 있습니다.
  - **CloudWatch Metric Alarm:** 메트릭 필터를 사용하여 특정 조건(RDP 또는 SSH 트래픽 감지)에 대한 알람을 생성하고, 알람 상태가 ALARM일 때 알림을 보낼 수 있습니다.

**다른 보기가 정답이 될 수 없는 이유:**
- **A. CloudWatch Application Insights:** Application Insights는 애플리케이션 모니터링 도구로, RDP 또는 SSH 접근을 감지하는 데 적합하지 않습니다.
- **B. IAM Instance Profile:** IAM 인스턴스 프로파일과 AmazonSSMManagedInstanceCore 정책은 Systems Manager를 사용하여 인스턴스를 관리하는 데 사용됩니다. RDP 또는 SSH 접근을 감지하는 데 직접적인 도움이 되지 않습니다.
- **D. EventBridge Rule:** EC2 Instance State-change Notification은 인스턴스 상태 변경(예: 시작, 중지, 종료)에 대한 알림을 제공합니다. RDP 또는 SSH 접근을 감지하는 데 적합하지 않습니다.

**출제 의도:**
이 문제는 AWS에서 VPC 내의 네트워크 트래픽을 모니터링하고, 특정 조건(RDP 또는 SSH 접근)에 대한 알림을 설정하는 방법을 평가합니다. 특히, VPC Flow Logs와 CloudWatch Logs를 사용하여 네트워크 트래픽을 분석하고, CloudWatch Metric Alarm을 설정하는 방법을 이해하는 것이 목적입니다.

**공부해야 하는 부분:**
1. **VPC Flow Logs:**
   - VPC Flow Logs의 기본 개념과 사용 사례
   - VPC Flow Logs를 사용하여 네트워크 트래픽을 캡처하고 분석하는 방법

2. **Amazon CloudWatch Logs:**
   - CloudWatch Logs의 기본 개념과 사용 사례
   - CloudWatch Logs를 사용하여 로그 데이터를 분석하고, 메트릭 필터를 생성하는 방법

3. **Amazon CloudWatch Alarms:**
   - CloudWatch Alarms의 기본 개념과 사용 사례
   - CloudWatch Alarms를 사용하여 특정 조건에 대한 알림을 설정하는 방법

이 부분들을 공부하면, AWS에서 VPC 내의 네트워크 트래픽을 모니터링하고, 특정 조건에 대한 알림을 설정하는 방법을 더 잘 이해할 수 있습니다.

# 235번
**정답: C. Use the AWS Schema Conversion Tool with AWS Database Migration Service (AWS DMS) using a memory optimized replication instance. Create a full load plus change data capture (CDC) replication task and a table mapping to select all tables.**

**해설:**
- **AWS Schema Conversion Tool (SCT):**
  - **스키마 변환:** SCT는 Oracle 데이터베이스 스키마를 Aurora PostgreSQL로 변환하는 데 사용됩니다. 이는 데이터베이스 구조를 호환되게 만듭니다.
  
- **AWS Database Migration Service (DMS):**
  - **메모리 최적화 인스턴스:** 메모리 최적화 인스턴스를 사용하면, 높은 읽기 및 쓰기 트래픽을 처리하는 데 적합합니다.
  - **전체 로드 및 CDC:** 전체 로드와 변경 데이터 캡처(CDC)를 사용하면, 초기 데이터 로드 후에도 데이터베이스 간의 동기화를 유지할 수 있습니다. 이는 데이터가 계속해서 동기화된 상태로 유지되도록 합니다.

**다른 보기가 정답이 될 수 없는 이유:**
- **A. DataSync와 CDC:** DataSync는 파일 기반 데이터 전송에 적합하며, 데이터베이스 마이그레이션에는 적합하지 않습니다. 또한, 전체 로드 없이 CDC만 사용하는 것은 초기 데이터 로드를 처리하지 못합니다.
- **B. DataSync와 전체 로드 + CDC:** DataSync는 데이터베이스 마이그레이션에 적합하지 않습니다. SCT를 사용하여 스키마 변환을 수행하는 것이 더 적합합니다.
- **D. Compute 최적화 인스턴스와 일부 테이블 선택:** Compute 최적화 인스턴스는 메모리 최적화 인스턴스보다 높은 읽기 및 쓰기 트래픽을 처리하는 데 적합하지 않습니다. 또한, 일부 테이블만 선택하는 것은 전체 데이터 동기화를 보장하지 않습니다.

**출제 의도:**
이 문제는 AWS에서 데이터베이스를 마이그레이션하고, 높은 읽기 및 쓰기 트래픽을 처리하며, 데이터 동기화를 유지하는 방법을 평가합니다. 특히, AWS SCT와 DMS를 사용하여 스키마 변환과 데이터 마이그레이션을 수행하고, 메모리 최적화 인스턴스를 사용하여 높은 트래픽을 처리하는 방법을 이해하는 것이 목적입니다.

**공부해야 하는 부분:**
1. **AWS Schema Conversion Tool (SCT):**
   - SCT의 기본 개념과 사용 사례
   - SCT를 사용하여 Oracle 스키마를 Aurora PostgreSQL로 변환하는 방법

2. **AWS Database Migration Service (DMS):**
   - DMS의 기본 개념과 사용 사례
   - DMS를 사용하여 전체 로드 및 CDC를 통해 데이터베이스를 마이그레이션하고 동기화하는 방법
   - 메모리 최적화 인스턴스를 사용하여 높은 트래픽을 처리하는 방법

이 부분들을 공부하면, AWS에서 데이터베이스를 마이그레이션하고, 높은 읽기 및 쓰기 트래픽을 처리하며, 데이터 동기화를 유지하는 방법을 더 잘 이해할 수 있습니다.


# 237번
**정답: A. Set up a VPC peering connection between VPC-A and VPC-B.**

**해설:**
- **VPC Peering:**
  - **보안 및 성능:** VPC 피어링은 두 VPC 간의 트래픽을 안전하게 전송할 수 있는 방법입니다. 트래픽이 인터넷을 거치지 않고 AWS 네트워크 내에서 전송되므로 보안이 강화됩니다.
  - **고가용성:** VPC 피어링은 AWS 네트워크 인프라를 통해 고가용성과 높은 대역폭을 제공합니다. 이는 단일 장애 지점 없이 안정적인 연결을 보장합니다.
  - **다중 계정 지원:** VPC 피어링은 동일한 AWS 계정 내의 VPC뿐만 아니라, 서로 다른 AWS 계정 간의 VPC 간에도 설정할 수 있습니다.

**다른 보기가 정답이 될 수 없는 이유:**
- **B. VPC Gateway Endpoints:** VPC 게이트웨이 엔드포인트는 S3나 DynamoDB와 같은 특정 AWS 서비스에 대한 프라이빗 연결을 제공하는 데 사용됩니다. EC2 인스턴스 간의 연결에는 적합하지 않습니다.
- **C. Virtual Private Gateway:** 가상 프라이빗 게이트웨이는 온프레미스 네트워크와 VPC 간의 연결을 설정하는 데 사용됩니다. VPC 간의 연결에는 적합하지 않습니다.
- **D. Private Virtual Interface (VIF):** 프라이빗 VIF는 Direct Connect를 통해 온프레미스 네트워크와 VPC 간의 연결을 설정하는 데 사용됩니다. VPC 간의 연결에는 적합하지 않습니다.

**출제 의도:**
이 문제는 AWS에서 서로 다른 계정에 있는 두 VPC 간의 안전하고 고가용성 연결을 설정하는 방법을 평가합니다. 특히, VPC 피어링을 사용하여 두 VPC 간의 트래픽을 안전하게 전송하고, 단일 장애 지점 없이 안정적인 연결을 보장하는 방법을 이해하는 것이 목적입니다.

**공부해야 하는 부분:**
1. **VPC Peering:**
   - VPC 피어링의 기본 개념과 사용 사례
   - VPC 피어링을 설정하여 두 VPC 간의 트래픽을 안전하게 전송하는 방법
   - 서로 다른 AWS 계정 간의 VPC 피어링 설정 방법

2. **VPC Gateway Endpoints 및 Virtual Private Gateway:**
   - VPC 게이트웨이 엔드포인트와 가상 프라이빗 게이트웨이의 기본 개념과 사용 사례
   - 이들이 VPC 간의 연결에 적합하지 않은 이유

이 부분들을 공부하면, AWS에서 서로 다른 계정에 있는 두 VPC 간의 안전하고 고가용성 연결을 설정하는 방법을 더 잘 이해할 수 있습니다.


# 238번
**정답: C. Use AWS Budgets to create a cost budget for each account. Set the period to monthly. Set the scope to EC2 instances. Set an alert threshold for the budget. Configure an Amazon Simple Notification Service (Amazon SNS) topic to receive a notification when a threshold is exceeded.**

**해설:**
- **AWS Budgets:**
  - **비용 관리:** AWS Budgets는 비용 및 사용량을 추적하고, 특정 임계값을 초과할 때 알림을 설정할 수 있는 서비스입니다. 이는 비용 초과를 방지하고, 예산을 관리하는 데 유용합니다.
  - **알림 설정:** 예산을 설정하고, 특정 임계값을 초과할 때 Amazon SNS를 통해 알림을 받을 수 있습니다. 이는 비용 초과를 실시간으로 모니터링하고, 즉시 대응할 수 있도록 합니다.

**다른 보기가 정답이 될 수 없는 이유:**
- **A. Cost Explorer 일일 보고서:** Cost Explorer를 사용하여 일일 보고서를 생성하고, SES를 통해 알림을 설정하는 것은 가능하지만, AWS Budgets를 사용하는 것이 더 간단하고 비용 효율적입니다.
- **B. Cost Explorer 월간 보고서:** Cost Explorer를 사용하여 월간 보고서를 생성하고, SES를 통해 알림을 설정하는 것은 가능하지만, AWS Budgets를 사용하는 것이 더 간단하고 비용 효율적입니다.
- **D. Cost and Usage Reports와 Athena:** Cost and Usage Reports를 사용하여 시간별 보고서를 생성하고, Athena와 EventBridge를 사용하여 쿼리를 스케줄링하는 것은 가능하지만, 이는 복잡하고 관리 오버헤드가 큽니다. AWS Budgets를 사용하는 것이 더 간단하고 비용 효율적입니다.

**출제 의도:**
이 문제는 AWS에서 비용을 관리하고, 특정 임계값을 초과할 때 알림을 설정하는 방법을 평가합니다. 특히, AWS Budgets를 사용하여 비용을 추적하고, 알림을 설정하는 방법을 이해하는 것이 목적입니다.

**공부해야 하는 부분:**
1. **AWS Budgets:**
   - AWS Budgets의 기본 개념과 사용 사례
   - AWS Budgets를 사용하여 비용 및 사용량을 추적하고, 알림을 설정하는 방법

2. **Amazon SNS:**
   - Amazon SNS의 기본 개념과 사용 사례
   - SNS를 사용하여 알림을 설정하고, 알림을 수신하는 방법

이 부분들을 공부하면, AWS에서 비용을 관리하고, 특정 임계값을 초과할 때 알림을 설정하는 방법을 더 잘 이해할 수 있습니다.

# 239번
**정답: B. Create a Lambda function URL for the function. Specify AWS_IAM as the authentication type.**

**해설:**
- **Lambda Function URL:**
  - **운영 효율성:** Lambda Function URL은 Lambda 함수에 직접 HTTPS 엔드포인트를 제공하는 기능입니다. 이를 통해 API Gateway를 설정할 필요 없이 Lambda 함수에 직접 접근할 수 있습니다.
  - **IAM 인증:** Lambda Function URL은 AWS_IAM 인증 유형을 지원하므로, IAM을 사용하여 호출을 인증할 수 있습니다. 이는 보안 요구 사항을 충족합니다.

**다른 보기가 정답이 될 수 없는 이유:**
- **A. API Gateway:** API Gateway를 사용하여 Lambda 함수를 호출하는 것은 가능하지만, Lambda Function URL을 사용하는 것이 더 간단하고 운영 오버헤드가 적습니다.
- **C. Lambda@Edge:** Lambda@Edge는 CloudFront와 통합되어 엣지 로케이션에서 코드를 실행하는 데 사용됩니다. 이는 글로벌 콘텐츠 전송에 적합하지만, 단순한 마이크로서비스 호출에는 과도한 설정이 필요합니다.
- **D. CloudFront Functions:** CloudFront Functions는 CloudFront 배포와 통합되어 엣지에서 간단한 JavaScript 함수를 실행하는 데 사용됩니다. 이는 Lambda 함수를 호출하는 데 적합하지 않습니다.

**출제 의도:**
이 문제는 AWS에서 마이크로서비스를 배포하고, HTTPS 엔드포인트와 IAM 인증을 설정하는 방법을 평가합니다. 특히, Lambda Function URL을 사용하여 운영 오버헤드를 최소화하고, IAM 인증을 설정하는 방법을 이해하는 것이 목적입니다.

**공부해야 하는 부분:**
1. **Lambda Function URL:**
   - Lambda Function URL의 기본 개념과 사용 사례
   - Lambda Function URL을 사용하여 Lambda 함수에 직접 HTTPS 엔드포인트를 제공하는 방법
   - AWS_IAM 인증 유형을 사용하여 호출을 인증하는 방법

2. **Amazon API Gateway:**
   - API Gateway의 기본 개념과 사용 사례
   - API Gateway를 사용하여 Lambda 함수를 호출하고, IAM 인증을 설정하는 방법

이 부분들을 공부하면, AWS에서 마이크로서비스를 배포하고, HTTPS 엔드포인트와 IAM 인증을 설정하는 방법을 더 잘 이해할 수 있습니다.


# 240번
**정답: D. Host the visualization tool in the same AWS Region as the data warehouse and access it over a Direct Connect connection at a location in the same Region.**

**해설:**
- **Direct Connect 비용 절감:**
  - **Direct Connect:** Direct Connect는 AWS와 온프레미스 네트워크 간의 전용 네트워크 연결을 제공하여, 데이터 전송 비용을 절감할 수 있습니다. 특히, 동일한 AWS 리전 내에서 Direct Connect를 사용하는 경우, 인터넷을 통한 데이터 전송보다 비용이 저렴합니다.
  - **동일 리전 내 호스팅:** 시각화 도구를 데이터 웨어하우스와 동일한 AWS 리전에 호스팅하면, 데이터 전송이 AWS 네트워크 내에서 이루어지므로 추가적인 인터넷 데이터 전송 비용이 발생하지 않습니다.

**다른 보기가 정답이 될 수 없는 이유:**
- **A. 인터넷을 통한 쿼리:** 인터넷을 통해 데이터 웨어하우스를 쿼리하면, 데이터 전송 비용이 높아질 수 있습니다. 특히, 50MB 크기의 쿼리 결과를 자주 전송하는 경우, 비용이 크게 증가할 수 있습니다.
- **B. 인터넷을 통한 접근:** 시각화 도구를 AWS 리전에 호스팅하더라도, 인터넷을 통해 접근하면 데이터 전송 비용이 발생합니다. Direct Connect를 사용하는 것이 더 비용 효율적입니다.
- **C. 온프레미스에서 Direct Connect 사용:** 시각화 도구를 온프레미스에 호스팅하고 Direct Connect를 사용하는 것은 가능하지만, 데이터 웨어하우스와 시각화 도구 간의 데이터 전송이 여전히 발생하므로 비용이 더 높아질 수 있습니다.

**출제 의도:**
이 문제는 AWS에서 데이터 전송 비용을 최소화하는 방법을 평가합니다. 특히, Direct Connect를 사용하여 데이터 전송 비용을 절감하고, 동일한 AWS 리전 내에서 시각화 도구와 데이터 웨어하우스를 호스팅하여 추가적인 인터넷 데이터 전송 비용을 피하는 방법을 이해하는 것이 목적입니다.

**공부해야 하는 부분:**
1. **AWS Direct Connect:**
   - Direct Connect의 기본 개념과 사용 사례
   - Direct Connect를 사용하여 데이터 전송 비용을 절감하는 방법

2. **데이터 전송 비용:**
   - AWS에서 데이터 전송 비용 구조
   - 인터넷을 통한 데이터 전송과 Direct Connect를 통한 데이터 전송 비용 비교

이 부분들을 공부하면, AWS에서 데이터 전송 비용을 최소화하는 방법을 더 잘 이해할 수 있습니다.


# 241번
**정답: C. Migrate the PostgreSQL database to an Amazon RDS for PostgreSQL DB instance. Create a read replica in another Region.**

**해설:**
- **Amazon RDS Read Replica:**
  - **다중 리전 가용성:** RDS 읽기 복제본을 다른 리전에 생성하면, 데이터가 여러 리전에 걸쳐 복제되어 고가용성을 보장할 수 있습니다. 이는 데이터가 항상 온라인 상태로 유지되도록 합니다.
  - **운영 오버헤드 최소화:** RDS 읽기 복제본은 AWS에서 관리되므로, 수동으로 복제 설정을 관리할 필요가 없습니다. 이는 운영 오버헤드를 최소화합니다.

**다른 보기가 정답이 될 수 없는 이유:**
- **A. PostgreSQL cluster on EC2:** EC2 인스턴스에서 PostgreSQL 클러스터를 운영하는 것은 많은 관리 오버헤드가 발생합니다. 수동으로 복제를 설정하고 관리해야 하므로, 운영 오버헤드가 큽니다.
- **B. RDS Multi-AZ:** Multi-AZ 배포는 동일한 리전 내에서 고가용성을 제공하지만, 다중 리전 가용성을 제공하지 않습니다.
- **D. DB snapshots:** 스냅샷을 다른 리전에 복사하는 것은 데이터 백업을 위한 방법이며, 실시간 데이터 가용성을 보장하지 않습니다. 이는 데이터가 항상 온라인 상태로 유지되도록 하지 않습니다.

**출제 의도:**
이 문제는 AWS에서 다중 리전 가용성을 제공하고, 운영 오버헤드를 최소화하는 방법을 평가합니다. 특히, RDS 읽기 복제본을 사용하여 데이터가 여러 리전에 걸쳐 복제되고, 항상 온라인 상태로 유지되도록 하는 방법을 이해하는 것이 목적입니다.

**공부해야 하는 부분:**
1. **Amazon RDS Read Replica:**
   - RDS 읽기 복제본의 기본 개념과 사용 사례
   - RDS 읽기 복제본을 사용하여 다중 리전 가용성을 제공하는 방법

2. **Amazon RDS Multi-AZ:**
   - RDS Multi-AZ의 기본 개념과 사용 사례
   - RDS Multi-AZ가 다중 리전 가용성을 제공하지 않는 이유

이 부분들을 공부하면, AWS에서 다중 리전 가용성을 제공하고, 운영 오버헤드를 최소화하는 방법을 더 잘 이해할 수 있습니다.


# 242번
**정답: C. Multivalue routing policy**

**해설:**
- **Multivalue Routing Policy:**
  - **다중 IP 주소 반환:** Multivalue Answer Routing Policy는 여러 IP 주소를 반환할 수 있습니다. 이는 DNS 쿼리에 대해 여러 EC2 인스턴스의 IP 주소를 반환하여, 트래픽을 분산시킬 수 있습니다.
  - **헬스 체크:** Multivalue Answer Routing Policy는 헬스 체크를 지원하여, 건강한 인스턴스의 IP 주소만 반환할 수 있습니다. 이는 요청이 건강하지 않은 인스턴스로 라우팅되지 않도록 보장합니다.

**다른 보기가 정답이 될 수 없는 이유:**
- **A. Simple Routing Policy:** Simple Routing Policy는 단일 IP 주소를 반환합니다. 여러 IP 주소를 반환하는 요구 사항을 충족하지 않습니다.
- **B. Latency Routing Policy:** Latency Routing Policy는 지연 시간을 기준으로 트래픽을 라우팅합니다. 여러 IP 주소를 반환하는 요구 사항을 충족하지 않습니다.
- **D. Geolocation Routing Policy:** Geolocation Routing Policy는 사용자의 지리적 위치를 기준으로 트래픽을 라우팅합니다. 여러 IP 주소를 반환하는 요구 사항을 충족하지 않습니다.

**출제 의도:**
이 문제는 AWS Route 53에서 여러 IP 주소를 반환하고, 헬스 체크를 통해 건강한 인스턴스의 IP 주소만 반환하는 방법을 평가합니다. 특히, Multivalue Answer Routing Policy를 사용하여 이러한 요구 사항을 충족하는 방법을 이해하는 것이 목적입니다.

**공부해야 하는 부분:**
1. **Route 53 Routing Policies:**
   - Route 53의 다양한 라우팅 정책(예: Simple, Latency, Multivalue, Geolocation)의 기본 개념과 사용 사례
   - Multivalue Answer Routing Policy를 사용하여 여러 IP 주소를 반환하고, 헬스 체크를 통해 건강한 인스턴스의 IP 주소만 반환하는 방법

이 부분들을 공부하면, AWS Route 53에서 여러 IP 주소를 반환하고, 헬스 체크를 통해 건강한 인스턴스의 IP 주소만 반환하는 방법을 더 잘 이해할 수 있습니다.


# 246번
**정답: D. Create public subnets in each Availability Zone. Associate the public subnets with the ALB. Update the route tables for the public subnets with a route to the private subnets.**

**해설:**
- **인터넷 접근:** 인터넷에서 접근할 수 있는 ALB는 퍼블릭 서브넷에 배치되어야 합니다. 퍼블릭 서브넷은 인터넷 게이트웨이와 연결되어 있어야 하며, 이를 통해 인터넷 트래픽을 수신할 수 있습니다.
- **프라이빗 서브넷의 EC2 인스턴스:** EC2 인스턴스는 프라이빗 서브넷에 남아 있어도 됩니다. ALB가 퍼블릭 서브넷에 배치되고, 퍼블릭 서브넷의 라우팅 테이블이 프라이빗 서브넷으로의 경로를 포함하면, ALB는 프라이빗 서브넷의 EC2 인스턴스에 트래픽을 전달할 수 있습니다.

**다른 보기가 정답이 될 수 없는 이유:**
- **A. NAT 게이트웨이와 Network Load Balancer:** NAT 게이트웨이는 주로 프라이빗 서브넷의 인스턴스가 인터넷에 접근할 수 있도록 하는 데 사용됩니다. 인터넷에서 접근할 수 있는 ALB를 대체하는 데 적합하지 않습니다.
- **B. EC2 인스턴스를 퍼블릭 서브넷으로 이동:** EC2 인스턴스를 퍼블릭 서브넷으로 이동하는 것은 보안 위험이 있습니다. 프라이빗 서브넷에 인스턴스를 유지하면서 ALB를 퍼블릭 서브넷에 배치하는 것이 더 

# 247번
**정답: A. Enable binlog replication on the RDS primary node. C. Allow long-running transactions to complete on the source DB instance.**

**해설:**
- **A. Enable binlog replication on the RDS primary node:**
  - **Binlog 복제:** RDS MySQL에서 읽기 복제본을 생성하려면 바이너리 로그(binlog) 복제가 활성화되어 있어야 합니다. 이는 데이터 변경 사항을 기록하고, 읽기 복제본으로 복제하는 데 필요합니다.

- **C. Allow long-running transactions to complete on the source DB instance:**
  - **긴 트랜잭션 완료:** 읽기 복제본을 생성하기 전에 소스 DB 인스턴스에서 실행 중인 긴 트랜잭션이 완료되도록 해야 합니다. 이는 데이터 일관성을 보장하고, 복제본 생성 중에 데이터 손실을 방지합니다.

**다른 보기가 정답이 될 수 없는 이유:**
- **B. Choose a failover priority for the source DB instance:** 읽기 복제본을 생성하는 것과는 직접적인 관련이 없습니다. 이는 고가용성을 위한 설정입니다.
- **D. Create a global table and specify the AWS Regions where the table will be available:** 글로벌 테이블은 DynamoDB와 관련된 기능이며, RDS MySQL과는 관련이 없습니다.
- **E. Enable automatic backups on the source instance by setting the backup retention period to a value other than 0:** 자동 백업을 활성화하는 것은 좋은 관행이지만, 읽기 복제본을 생성하는 데 필수적인 단계는 아닙니다.

**출제 의도:**
이 문제는 AWS RDS MySQL에서 읽기 복제본을 생성하기 전에 수행해야 할 필수 작업을 평가합니다. 특히, binlog 복제를 활성화하고, 긴 트랜잭션이 완료되도록 하는 방법을 이해하는 것이 목적입니다.

**공부해야 하는 부분:**
1. **RDS MySQL Read Replica:**
   - 읽기 복제본의 기본 개념과 사용 사례
   - 읽기 복제본을 생성하기 전에 수행해야 할 필수 작업

2. **Binlog Replication:**
   - 바이너리 로그(binlog) 복제의 기본 개념과 사용 사례
   - binlog 복제를 활성화하는 방법

이 부분들을 공부하면, AWS RDS MySQL에서 읽기 복제본을 생성하기 전에 수행해야 할 필수 작업을 더 잘 이해할 수 있습니다.


# 512번
# 514번
# 515번