### 95번
- Creating read replicas allows the application to offload read traffic from the source database, improving its performance. The read replicas should be configured with the same compute and storage resources as the source database to ensure that they can handle the read workload effectively.

- 오프로딩(offloading): 컴퓨팅 자원 및 계산 속도의 한계를 극복하기 위해 로컬 컴퓨터에서 수행하는 어플리케이션 의 일부를 컴퓨팅 자원과 처리능력이 우수한 원격지 컴퓨터에 전달하여 처리한 후 결과를 반환받는 방식

### 96번
- SourceIp
    - 요청자의 IP주소를 정책에서 지정한 IP주소와 비교
    - 퍼블릭 IP 주소 범위에만 사용 가능
    - 정책 내에서 aws:SourceIp 조건 키를 사용하여 보안 주체가 지정된 IP 범위 내에서만 요청하도록 할 수 있음


### 104번
- B: GuardDuty는 공격자를 블락할 수 없으며, 데이터 소스나 이벤트 로그를 모니터링하고, 멀웨어 탐지 및 결과를 생성할 뿐임


### 107번
- Amazon Kinesis Data Analytics는 데이터 검색은 할 수 있으나 저장은 못함
- 저장을 하는 같은 계열의 서비스는 Amazon Kinesis Data Firehose임
- 그렇기 때문에 저장을 위해서는 B의 AWS Lambda를 사용해야 함

### 108번
- Amazon SNS는 Pub/Sub의 브로드캐스트 모델이고, Amazon SQS 큐잉 모델
- 브로드캐스트 모델은 단순히 전달만 할 뿐, 정상적으로 전달되었는지 여부는 상관하지 않음
- 반면 큐잉 모델은 데이터가 전달되어야 하는 정상 상태의 처리자가 반드시 필요하며, 데이터를 받을 처리자가 없으면 해당 데이터는 큐에 보관됨
- 이 문제에서 회사는 Multiple target systems를 보유하므로, SNS를 통해 갱신 정보를 브로드캐스팅하여 각각의 시스템이 개별적으로 람다를 실행시키는 것이 효과적임
- A의 문제점은 단일 SQS를 사용하는 점인데, 하나의 SQS는 곧 여러 시스템에 의한 중복 소비를 발생시키는데 이를 방지하기 위한 처리가 상당히 까다롭고 복잡함

### 113번
- AWS Snowball Edge Storage Optimized는 대용량 데이터를 효율적으로 전송할 수 있는 장치로, 네트웤크 대역폭이 부족한 상황에서도 사용 가능
- A: AWS DataSync는 네트워크를 통한 데이터 전송 서비스로, 추가적인 대역폭이 없음
- B: AWS Snowcones는 소규모 데이터 전송에 적합
- D: AWS Snowball Edge Storage Optimized 장치에 EC2 컴퓨팅 기능 포함 가능하지만, 데이터 전송 후에 AWS Glue를 사용하는 것이 더 효율적이며 운영 오버헤드가 적음


### 116번
- 왠만하면 EC2 새로 추가하는 건 정답이 아니더라. 그래서 E는 탈락. 운영 오버헤드 증가.

### 119번


### 121번
문제: 회사는 AWS에서 온라인 트랜잭션 처리(OLTP) 워크로드를 실행하고 있습니다. 이 워크로드는 암호화되지 않은 Amazon RDS DB 인스턴스를 Multi-AZ 배포로 사용하고 있으며, 매일 데이터베이스 스냅샷을 생성합니다. 솔루션 아키텍트는 데이터베이스와 스냅샷이 항상 암호화되도록 보장해야 합니다.

해설
A: 최신 DB 스냅샷의 암호화된 복사본을 생성하고, 이를 복원하여 기존 DB 인스턴스를 대체하면, 데이터베이스와 스냅샷이 항상 암호화된 상태로 유지됩니다. 이는 RDS 인스턴스와 스냅샷을 암호화하는 가장 직접적이고 확실한 방법입니다.

다른 선택지의 문제점
B: EBS 볼륨을 암호화하고 스냅샷을 복사하는 것은 RDS 인스턴스 자체를 암호화하지 않습니다. RDS 인스턴스의 암호화는 스냅샷을 복원하여 새로운 암호화된 인스턴스를 생성해야 합니다.
C: 스냅샷을 복사하고 AWS KMS를 사용하여 암호화하는 것은 가능하지만, 기존 DB 인스턴스에 복원하는 것은 암호화되지 않은 인스턴스에 복원하는 것이므로 의미가 없습니다.
D: 스냅샷을 S3 버킷에 복사하고 암호화하는 것은 RDS 인스턴스와 직접적인 관련이 없으며, RDS 인스턴스 자체를 암호화하지 않습니다.


### 122번
문제: 회사는 개발자가 애플리케이션에서 데이터를 암호화할 수 있도록 지원하는 확장 가능한 키 관리 인프라를 구축하고자 합니다. 운영 부담을 줄이기 위해 솔루션 아키텍트는 무엇을 해야 합니까?

해설
B: AWS Key Management Service (AWS KMS)는 암호화 키를 생성, 관리 및 보호하는 완전 관리형 서비스입니다. KMS를 사용하면 키 관리와 관련된 많은 운영 부담을 AWS가 대신 처리해주므로, 운영 부담을 크게 줄일 수 있습니다. 또한, KMS는 자동으로 키를 회전하고, 키 사용을 모니터링하며, 다양한 AWS 서비스와 통합되어 사용이 편리합니다.

다른 선택지의 문제점
A: 다중 요소 인증(MFA)은 보안 강화를 위해 유용하지만, 키 관리 인프라의 운영 부담을 줄이는 데 직접적인 도움이 되지 않습니다.
C: AWS Certificate Manager (ACM)는 SSL/TLS 인증서를 관리하는 서비스로, 암호화 키 관리와는 다른 목적을 가지고 있습니다.
D: IAM 정책을 사용하여 사용자 접근 권한

### 124번
문제 번역
회사는 많은 Amazon EC2 인스턴스를 사용하여 완료하는 매우 동적인 배치 처리 작업을 가지고 있습니다. 이 작업은 상태가 없으며, 언제든지 시작하고 중지할 수 있으며, 총 완료 시간은 보통 60분 이상 걸립니다. 회사는 솔루션 아키텍트에게 이 작업의 요구사항을 충족하는 확장 가능하고 비용 효율적인 솔루션을 설계해 달라고 요청했습니다. 솔루션 아키텍트는 무엇을 추천해야 합니까?

정답
A. Implement EC2 Spot Instances.

해설
A: EC2 Spot Instances는 AWS의 미사용 EC2 용량을 활용하여 최대 90%까지 비용을 절감할 수 있는 옵션입니다. 이 작업은 상태가 없고 언제든지 중지 및 시작할 수 있으므로, Spot Instances의 일시적인 중단 가능성에도 불구하고 적합합니다. 이는 확장 가능하고 비용 효율적인 솔루션입니다.
다른 선택지의 문제점
B: EC2 Reserved Instances는 장기적으로 특정 용량을 예약하여 비용을 절감할 수 있지만, 동적인 배치 처리 작업에는 유연성이 부족합니다.
C: EC2 On-Demand Instances는 유연하지만, 비용이 더 높을 수 있습니다. 상태가 없는 작업에는 Spot Instances가 더 비용 효율적입니다.
D: AWS Lambda는 짧은 실행 시간의 이벤트 기반 작업에 적합하지만, 60분 이상 걸리는 배치 처리 작업에는 적합하지 않습니다.
따라서, A 선택지가 확장 가능하고 비용 효율적인 솔루션을 제공하는 데 가장 적합합니다.

### 127번
문제 번역
미디어 회사가 시스템을 AWS 클라우드로 이전할 가능성을 평가하고 있습니다. 회사는 비디오 처리에 최대한의 I/O 성능을 제공하는 최소 10TB의 스토리지, 미디어 콘텐츠를 저장하기 위한 300TB의 매우 내구성 있는 스토리지, 더 이상 사용되지 않는 아카이브 미디어를 위한 900TB의 스토리지가 필요합니다. 솔루션 아키텍트는 이러한 요구사항을 충족하기 위해 어떤 서비스 세트를 추천해야 합니까?

정답
A. Amazon EBS for maximum performance, Amazon S3 for durable data storage, and Amazon S3 Glacier for archival storage

해설
Amazon EBS (Elastic Block Store): EBS는 고성능 I/O를 제공하는 블록 스토리지 서비스로, 비디오 처리와 같은 고성능 작업에 적합합니다.
Amazon S3 (Simple Storage Service): S3는 높은 내구성과 가용성을 제공하는 객체 스토리지 서비스로, 미디어 콘텐츠와 같은 데이터를 저장하는 데 적합합니다.
Amazon S3 Glacier: S3 Glacier는 장기 아카이브 스토리지 서비스로, 자주 접근하지 않는 데이터를 비용 효율적으로 저장하는 데 적합합니다.
다른 선택지의 문제점
B: Amazon EFS는 파일 스토리지 서비스로, 대규모 데이터 저장에는 적합하지만, S3보다 비용이 높을 수 있습니다.
C: Amazon EC2 instance store는 인스턴스가 종료되면 데이터가 사라지므로, 내구성 있는 데이터 저장에는 적합하지 않습니다.
D: Amazon EC2 instance store는 내구성 있는 데이터 저장에 적합하지 않으며, S3는 아카이브 스토리지로 사용하기에는 비용이 높을 수 있습니다.
따라서, A 선택지가 요구사항을 충족하는 가장 적합한 솔루션입니다.

### 127번
문제 번역
회사는 AWS 클라우드에서 컨테이너로 애플리케이션을 실행하고자 합니다. 이 애플리케이션들은 상태가 없으며, 기본 인프라의 중단을 견딜 수 있습니다. 회사는 비용과 운영 오버헤드를 최소화하는 솔루션이 필요합니다. 솔루션 아키텍트는 이러한 요구사항을 충족하기 위해 무엇을 해야 합니까?

정답
B. Use Spot Instances in an Amazon Elastic Kubernetes Service (Amazon EKS) managed node group.

해설
B: Amazon EKS는 관리형 Kubernetes 서비스로, 컨테이너 오케스트레이션을 자동화하여 운영 오버헤드를 줄입니다. Spot Instances를 사용하면 비용을 크게 절감할 수 있으며, 애플리케이션이 상태가 없고 중단을 견딜 수 있으므로 적합합니다. EKS 관리 노드 그룹을 사용하면 Kubernetes 클러스터의 노드 관리를 AWS가 대신 처리해주므로 운영 오버헤드가 최소화됩니다.
다른 선택지의 문제점
A: EC2 Auto Scaling 그룹을 사용하여 컨테이너를 실행하는 것은 가능하지만, EKS를 사용하면 Kubernetes 관리가 자동화되어 운영 오버헤드가 더 낮습니다.
C: On-Demand Instances는 유연하지만 비용이 더 높을 수 있습니다. 상태가 없는 애플리케이션에는 Spot Instances가 더 비용 효율적입니다.
D: On-Demand Instances는 비용이 더 높을 수 있으며, 상태가 없는 애플리케이션에는 Spot Instances가 더 적합합니다.
따라서, B 선택지가 요구사항을 충족하는 가장 적합한 솔루션입니다.

### 130번
문제 번역
애플리케이션이 여러 가용 영역에 걸쳐 Amazon EC2 인스턴스에서 실행됩니다. 인스턴스는 Application Load Balancer 뒤에 있는 Amazon EC2 Auto Scaling 그룹에서 실행됩니다. 애플리케이션은 EC2 인스턴스의 CPU 사용률이 40%에 가깝거나 그 이하일 때 최상의 성능을 발휘합니다. 솔루션 아키텍트는 그룹의 모든 인스턴스에서 원하는 성능을 유지하기 위해 무엇을 해야 합니까?

정답
B. Use a target tracking policy to dynamically scale the Auto Scaling group.

해설
B: 타겟 추적 정책(Target Tracking Policy)은 Auto Scaling 그룹의 평균 CPU 사용률을 특정 목표(이 경우 40%)로 유지하도록 자동으로 조정합니다. 이는 CPU 사용률이 목표 수준에 도달하도록 인스턴스를 동적으로 추가하거나 제거하여 원하는 성능을 유지하는 데 가장 적합한 방법입니다.
다른 선택지의 문제점
A: 단순 스케일링 정책(Simple Scaling Policy)은 특정 조건이 충족될 때만 인스턴스를 추가하거나 제거합니다. 이는 CPU 사용률을 일정하게 유지하는 데 충분하지 않을 수 있습니다.
C: AWS Lambda 함수를 사용하여 Auto Scaling 그룹의 용량을 업데이트하는 것은 복잡하고 유지 관리가 어려울 수 있습니다.
D: 예약된 스케일링 작업(Scheduled Scaling Actions)은 특정 시간에만 스케일링을 수행하므로, 실시간으로 변동하는 CPU 사용률을 효과적으로 관리하지 못할 수 있습니다.
따라서, B 선택지가 그룹의 모든 인스턴스에서 원하는 성능을 유지하는 데 가장 적합한 솔루션입니다.


### 131번
문제 번역
회사는 파일 공유 애플리케이션을 개발 중이며, Amazon S3 버킷을 스토리지로 사용할 예정입니다. 회사는 모든 파일을 Amazon CloudFront 배포를 통해 제공하고자 합니다. 회사는 파일이 S3 URL을 통해 직접 접근되지 않도록 하고 싶습니다. 솔루션 아키텍트는 이러한 요구사항을 충족하기 위해 무엇을 해야 합니까?

정답
D. Create an origin access identity (OAI). Assign the OAI to the CloudFront distribution. Configure the S3 bucket permissions so that only the OAI has read permission.

해설
D: Origin Access Identity (OAI)를 생성하고 이를 CloudFront 배포에 할당하면, CloudFront를 통해서만 S3 버킷의 객체에 접근할 수 있습니다. S3 버킷 권한을 설정하여 OAI만 읽기 권한을 가지도록 구성하면, S3 URL을 통한 직접 접근을 방지할 수 있습니다.
다른 선택지의 문제점
A: 각 S3 버킷에 대해 개별 정책을 작성하는 것은 복잡하고 관리하기 어렵습니다. 또한, CloudFront에 대한 접근 권한을 효과적으로 제어하지 못할 수 있습니다.
B: IAM 사용자를 생성하고 읽기 권한을 부여하는 것은 CloudFront와의 통합을 보장하지 않으며, S3 URL을 통한 직접 접근을 방지하지 못합니다.
C: S3 버킷 정책에 CloudFront 배포 ID를 Principal로 지정하는 것은 일반적인 접근 제어 방법이 아니며, OAI를 사용하는 것이 더 적합합니다.
따라서, D 선택지가 요구사항을 충족하는 가장 적합한 솔루션입니다.

### 133번
cerulean85
A company runs an Oracle database on premises. As part of the company’s migration to AWS, the company wants to upgrade the database to the most recent available version. The company also wants to set up disaster recovery (DR) for the database. The company needs to minimize the operational overhead for normal operations and DR setup. The company also needs to maintain access to the database's underlying operating system. Which solution will meet these requirements?

A. Migrate the Oracle database to an Amazon EC2 instance. Set up database replication to a different AWS Region. B. Migrate the Oracle database to Amazon RDS for Oracle. Activate Cross-Region automated backups to replicate the snapshots to another AWS Region. C. Migrate the Oracle database to Amazon RDS Custom for Oracle. Create a read replica for the database in another AWS Region. D. Migrate the Oracle database to Amazon RDS for Oracle. Create a standby database in another Availability Zone.

GitHub Copilot
문제 번역
회사는 온프레미스에서 Oracle 데이터베이스를 운영하고 있습니다. 회사의 AWS로의 마이그레이션의 일환으로, 회사는 데이터베이스를 최신 버전으로 업그레이드하고자 합니다. 또한, 회사는 데이터베이스에 대한 재해 복구(DR)를 설정하고자 합니다. 회사는 정상 운영과 DR 설정에 대한 운영 오버헤드를 최소화해야 하며, 데이터베이스의 기본 운영 체제에 대한 접근을 유지해야 합니다. 이 요구사항을 충족하는 솔루션은 무엇입니까?

정답
C. Migrate the Oracle database to Amazon RDS Custom for Oracle. Create a read replica for the database in another AWS Region.

해설
C: Amazon RDS Custom for Oracle는 사용자가 데이터베이스의 기본 운영 체제에 접근할 수 있도록 허용하는 관리형 데이터베이스 서비스입니다. 이는 운영 오버헤드를 줄이면서도 데이터베이스의 기본 운영 체제에 대한 접근을 유지할 수 있습니다. 또한, 다른 AWS 리전에서 읽기 복제본을 생성하여 재해 복구를 설정할 수 있습니다.
다른 선택지의 문제점
A: Oracle 데이터베이스를 Amazon EC2 인스턴스로 마이그레이션하면 운영 오버헤드가 증가할 수 있으며, 관리형 서비스의 이점을 누리지 못합니다.
B: Amazon RDS for Oracle은 기본 운영 체제에 대한 접근을 제공하지 않습니다.
D: Amazon RDS for Oracle은 기본 운영 체제에 대한 접근을 제공하지 않으며, 다른 가용 영역에 대기 데이터베이스를 생성하는 것은 재해 복구를 위한 최적의 솔루션이 아닙니다.
따라서, C 선택지가 요구사항을 충족하는 가장 적합한 솔루션입니다.


### 134번
문제 번역
회사는 애플리케이션을 서버리스 솔루션으로 이전하고자 합니다. 서버리스 솔루션은 기존 데이터와 새로운 데이터를 분석해야 합니다. 회사는 데이터를 Amazon S3 버킷에 저장하고 있습니다. 데이터는 암호화가 필요하며, 다른 AWS 리전으로 복제되어야 합니다. 가장 적은 운영 오버헤드로 이러한 요구사항을 충족하는 솔루션은 무엇입니까?

정답
A. Create a new S3 bucket. Load the data into the new S3 bucket. Use S3 Cross-Region Replication (CRR) to replicate encrypted objects to an S3 bucket in another Region. Use server-side encryption with AWS KMS multi-Region keys (SSE-KMS). Use Amazon Athena to query the data.

해설
A: 새로운 S3 버킷을 생성하고 데이터를 로드한 후, S3 Cross-Region Replication (CRR)을 사용하여 암호화된 객체를 다른 리전의 S3 버킷으로 복제합니다. AWS KMS 다중 리전 키(SSE-KMS)를 사용하여 서버 측 암호화를 적용합니다. Amazon Athena를 사용하여 데이터를 쿼리하면 서버리스 환경에서 데이터를 분석할 수 있습니다. 이 솔루션은 최소한의 운영 오버헤드로 요구사항을 충족합니다.
다른 선택지의 문제점
B: Amazon RDS는 서버리스 솔루션이 아니며, 운영 오버헤드가 증가할 수 있습니다.
C: Amazon S3 관리 암호화 키(SSE-S3)는 다중 리전 키를 제공하지 않으므로, 요구사항을 완전히 충족하지 못합니다.
D: Amazon RDS는 서버리스 솔루션이 아니며, 운영 오버헤드가 증가할 수 있습니다. 또한, SSE-S3는 다중 리전 키를 제공하지 않습니다.
따라서, A 선택지가 요구사항을 충족하는 가장 적합한 솔루션입니다.


### 135번
문제 번역
회사는 AWS에서 워크로드를 실행하고 있습니다. 회사는 외부 제공자의 서비스에 연결해야 합니다. 이 서비스는 제공자의 VPC에 호스팅되어 있습니다. 회사의 보안 팀에 따르면, 연결은 사설이어야 하며 대상 서비스로 제한되어야 합니다. 연결은 회사의 VPC에서만 시작되어야 합니다. 이 요구사항을 충족하는 솔루션은 무엇입니까?

정답
D. Ask the provider to create a VPC endpoint for the target service. Use AWS PrivateLink to connect to the target service.

해설
D: AWS PrivateLink를 사용하면 VPC 간에 사설 연결을 설정할 수 있으며, 특정 서비스에 대한 접근을 제한할 수 있습니다. 제공자가 대상 서비스에 대한 VPC 엔드포인트를 생성하면, 회사의 VPC에서만 시작되는 사설 연결을 통해 서비스에 접근할 수 있습니다. 이는 보안 요구사항을 충족하면서도 사설 연결을 보장합니다.
다른 선택지의 문제점
A: VPC 피어링은 VPC 간의 사설 연결을 제공하지만, 특정 서비스로의 접근을 제한하는 데 적합하지 않습니다.
B: 가상 프라이빗 게이트웨이는 VPN 연결을 설정하는 데 사용되며, AWS PrivateLink를 통한 특정 서비스 접근을 보장하지 않습니다.
C: NAT 게이트웨이는 인터넷을 통해 연결을 설정하므로, 사설 연결을 보장하지 않습니다.
따라서, D 선택지가 요구사항을 충족하는 가장 적합한 솔루션입니다.

### 136번
문제 번역
회사는 온프레미스 PostgreSQL 데이터베이스를 Amazon Aurora PostgreSQL로 마이그레이션하고 있습니다. 마이그레이션 중에도 온프레미스 데이터베이스는 온라인 상태를 유지하고 접근 가능해야 합니다. Aurora 데이터베이스는 온프레미스 데이터베이스와 동기화 상태를 유지해야 합니다. 솔루션 아키텍트는 이러한 요구사항을 충족하기 위해 어떤 조치를 취해야 합니까? (두 가지를 선택하십시오.)

정답
A. Create an ongoing replication task.

C. Create an AWS Database Migration Service (AWS DMS) replication server.

해설
A: 지속적인 복제 작업을 생성하면 온프레미스 데이터베이스와 Amazon Aurora PostgreSQL 간의 데이터 동기화를 유지할 수 있습니다.
C: AWS Database Migration Service (AWS DMS) 복제 서버를 생성하면 온프레미스 데이터베이스에서 Amazon Aurora PostgreSQL로의 데이터 마이그레이션을 관리할 수 있습니다. DMS는 데이터베이스를 마이그레이션하면서도 소스 데이터베이스를 온라인 상태로 유지할 수 있습니다.
다른 선택지의 문제점
B: 데이터베이스 백업을 생성하는 것은 초기 데이터 전송에 유용할 수 있지만, 지속적인 동기화를 보장하지 않습니다.
D: AWS Schema Conversion Tool (AWS SCT)은 데이터베이스 스키마 변환에 사용되며, 지속적인 데이터 동기화를 보장하지 않습니다.
E: Amazon EventBridge (Amazon CloudWatch Events) 규칙은 모니터링에 유용할 수 있지만, 데이터 동기화를 직접적으로 관리하지 않습니다.
따라서, A와 C 선택지가 요구사항을 충족하는 가장 적합한 솔루션입니다.

### 137번
문제 번역
회사는 각 비즈니스 유닛을 위해 전용 AWS 계정을 생성하고, 각 비즈니스 유닛의 계정을 독립적으로 관리할 수 있도록 AWS Organizations를 사용하고 있습니다. 루트 이메일 수신자가 한 계정의 루트 사용자 이메일 주소로 전송된 알림을 놓쳤습니다. 회사는 향후 모든 알림이 놓치지 않도록 하고자 합니다. 향후 알림은 계정 관리자에게만 제한되어야 합니다. 이 요구사항을 충족하는 솔루션은 무엇입니까?

정답
B. Configure all AWS account root user email addresses as distribution lists that go to a few administrators who can respond to alerts. Configure AWS account alternate contacts in the AWS Organizations console or programmatically.

해설
B: 모든 AWS 계정 루트 사용자 이메일 주소를 몇 명의 관리자에게 전달되는 배포 목록으로 구성하면, 알림이 놓치지 않도록 할 수 있습니다. 또한, AWS Organizations 콘솔 또는 프로그래밍 방식으로 AWS 계정 대체 연락처를 구성하여 알림을 받을 수 있는 추가적인 보안을 제공합니다.
다른 선택지의 문제점
A: 회사의 이메일 서버를 구성하여 알림 이메일 메시지를 조직의 모든 사용자에게 전달하는 것은 보안 위험이 있으며, 알림이 너무 많은 사람에게 전달될 수 있습니다.
C: 모든 알림을 한 명의 관리자에게 보내는 것은 단일 실패 지점을 만들 수 있으며, 알림이 적절한 그룹에 전달되지 않을 수 있습니다.
D: 모든 계정에 동일한 루트 사용자 이메일 주소를 사용하는 것은 관리 및 보안 측면에서 비효율적이며, 각 계정의 독립성을 유지하지 못합니다.
따라서, B 선택지가 요구사항을 충족하는 가장 적합한 솔루션입니다.

### 138번
문제 번역
회사는 AWS에서 전자상거래 애플리케이션을 운영하고 있습니다. 새로운 주문이 들어올 때마다 RabbitMQ 큐에 메시지가 게시되며, 이 큐는 단일 가용 영역의 Amazon EC2 인스턴스에서 실행됩니다. 이러한 메시지는 별도의 EC2 인스턴스에서 실행되는 다른 애플리케이션에 의해 처리되며, 이 애플리케이션은 세부 정보를 또 다른 EC2 인스턴스에서 실행되는 PostgreSQL 데이터베이스에 저장합니다. 모든 EC2 인스턴스는 동일한 가용 영역에 있습니다. 회사는 가장 높은 가용성을 제공하고 운영 오버헤드를 최소화하기 위해 아키텍처를 재설계해야 합니다. 솔루션 아키텍트는 이러한 요구사항을 충족하기 위해 무엇을 해야 합니까?

정답
B. Migrate the queue to a redundant pair (active/standby) of RabbitMQ instances on Amazon MQ. Create a Multi-AZ Auto Scaling group for EC2 instances that host the application. Migrate the database to run on a Multi-AZ deployment of Amazon RDS for PostgreSQL.

해설
B: RabbitMQ 큐를 Amazon MQ의 활성/대기 페어로 마이그레이션하면 높은 가용성을 제공할 수 있습니다. 애플리케이션을 호스팅하는 EC2 인스턴스에 대해 다중 가용 영역(AZ) Auto Scaling 그룹을 생성하면 애플리케이션의 가용성을 높일 수 있습니다. PostgreSQL 데이터베이스를 Amazon RDS for PostgreSQL의 다중 AZ 배포로 마이그레이션하면 데이터베이스의 가용성과 관리 오버헤드를 최소화할 수 있습니다.
다른 선택지의 문제점
A: PostgreSQL 데이터베이스를 EC2 인스턴스에서 호스팅하는 것은 관리 오버헤드를 증가시키며, RDS를 사용하는 것보다 가용성이 낮을 수 있습니다.
C: RabbitMQ 큐를 EC2 인스턴스에서 호스팅하는 것은 관리 오버헤드를 증가시키며, Amazon MQ를 사용하는 것보다 가용성이 낮을 수 있습니다.
D: PostgreSQL 데이터베이스를 EC2 인스턴스에서 호스팅하는 것은 관리 오버헤드를 증가시키며, RDS를 사용하는 것보다 가용성이 낮을 수 있습니다.
따라서, B 선택지가 요구사항을 충족하는 가장 적합한 솔루션입니다.

### 139번
문제 번역
리포팅 팀은 매일 Amazon S3 버킷에 파일을 받습니다. 리포팅 팀은 매일 같은 시간에 이 초기 S3 버킷에서 파일을 검토하고 분석 S3 버킷으로 복사하여 Amazon QuickSight에서 사용합니다. 추가 팀들이 더 많은 파일을 더 큰 크기로 초기 S3 버킷에 보내기 시작하고 있습니다. 리포팅 팀은 파일이 초기 S3 버킷에 들어올 때 자동으로 분석 S3 버킷으로 파일을 이동시키고 싶습니다. 또한, 리포팅 팀은 AWS Lambda 함수를 사용하여 복사된 데이터에서 패턴 매칭 코드를 실행하고 싶습니다. 추가로, 리포팅 팀은 데이터 파일을 Amazon SageMaker Pipelines의 파이프라인으로 보내고 싶습니다. 운영 오버헤드를 최소화하면서 이러한 요구사항을 충족하기 위해 솔루션 아키텍트는 무엇을 해야 합니까?

정답
C. Configure S3 replication between the S3 buckets. Create an S3 event notification for the analysis S3 bucket. Configure Lambda and SageMaker Pipelines as destinations of the event notification. Configure s3:ObjectCreated:Put as the event type.

해설
C: S3 버킷 간의 복제를 구성하면 파일이 초기 S3 버킷에 들어올 때 자동으로 분석 S3 버킷으로 복사됩니다. 그런 다음, 분석 S3 버킷에 대한 S3 이벤트 알림을 생성하여 Lambda 함수와 SageMaker Pipelines를 이벤트 알림의 대상으로 구성합니다. s3:ObjectCreated:Put 이벤트 유형을 구성하면 파일이 분석 S3 버킷에 복사될 때 Lambda 함수와 SageMaker Pipelines가 트리거됩니다. 이는 운영 오버헤드를 최소화하면서 요구사항을 충족하는 가장 적합한 솔루션입니다.
다른 선택지의 문제점
A: Lambda 함수를 사용하여 파일을 복사하는 것은 가능하지만, S3 복제를 사용하는 것보다 운영 오버헤드가 더 큽니다.
B: EventBridge를 사용하여 이벤트를 처리하는 것은 가능하지만, S3 복제를 사용하는 것보다 운영 오버헤드가 더 큽니다.
D: EventBridge를 사용하여 이벤트를 처리하는 것은 가능하지만, S3 이벤트 알림을 사용하는 것보다 운영 오버헤드가 더 큽니다.


### 140번
문제 번역
솔루션 아키텍트는 회사가 AWS에서 애플리케이션을 실행하는 비용을 최적화하도록 도와야 합니다. 애플리케이션은 Amazon EC2 인스턴스, AWS Fargate, AWS Lambda를 사용하여 컴퓨팅을 수행합니다. EC2 인스턴스는 애플리케이션의 데이터 수집 계층을 실행합니다. EC2 사용은 간헐적이고 예측할 수 없습니다. EC2 인스턴스에서 실행되는 워크로드는 언제든지 중단될 수 있습니다. 애플리케이션 프론트 엔드는 Fargate에서 실행되며, Lambda는 API 계층을 제공합니다. 프론트 엔드 사용률과 API 계층 사용률은 향후 1년 동안 예측 가능합니다. 이 애플리케이션을 호스팅하는 데 가장 비용 효율적인 솔루션을 제공하는 구매 옵션의 조합은 무엇입니까? (두 가지를 선택하십시오.)

정답
A. Use Spot Instances for the data ingestion layer

C. Purchase a 1-year Compute Savings Plan for the front end and API layer.

해설
A: Spot Instances는 간헐적이고 예측할 수 없는 사용 패턴에 적합하며, 비용을 크게 절감할 수 있습니다. 데이터 수집 계층이 중단될 수 있는 워크로드를 실행하므로 Spot Instances를 사용하는 것이 비용 효율적입니다.
C: 1년 Compute Savings Plan은 Fargate와 Lambda와 같은 다양한 컴퓨팅 옵션에 대해 비용 절감을 제공합니다. 프론트 엔드와 API 계층의 사용률이 예측 가능하므로, Savings Plan을 구매하는 것이 비용 효율적입니다.
다른 선택지의 문제점
B: On-Demand Instances는 예측할 수 없는 사용 패턴에 적합하지만, Spot Instances보다 비용이 더 높습니다.
D: Reserved Instances는 특정 인스턴스 유형에 대해 예약된 용량을 제공하지만, 데이터 수집 계층의 간헐적이고 예측할 수 없는 사용 패턴에는 적합하지 않습니다.
E: EC2 instance Savings Plan은 특정 EC2 인스턴스에 대해 비용 절감을 제공하지만, Fargate와 Lambda를 포함한 다양한 컴퓨팅 옵션에 대해 비용 절감을 제공하는 Compute Savings Plan이 더 적합합니다.
따라서, A와 C 선택지가 요구사항을 충족하는 가장 적합한 솔루션입니다.