# 3번
**정답: A. Add the aws PrincipalOrgID global condition key with a reference to the organization ID to the S3 bucket policy.**

**해설:**
- **aws:PrincipalOrgID 글로벌 조건 키:**
  - **조직 내 접근 제한:** `aws:PrincipalOrgID` 글로벌 조건 키를 사용하면 특정 AWS Organizations ID에 속한 계정만 S3 버킷에 접근할 수 있도록 제한할 수 있습니다. 이는 조직 내의 모든 계정을 포함하므로, 각 계정의 사용자들이 접근할 수 있습니다.
  - **운영 오버헤드 최소화:** 이 방법은 S3 버킷 정책에 단일 조건을 추가하는 것만으로 구현할 수 있어, 운영 오버헤드가 최소화됩니다. 추가적인 관리 작업이 필요하지 않습니다.

**다른 보기가 정답이 될 수 없는 이유:**
- **B. aws:PrincipalOrgPaths 글로벌 조건 키:** `aws:PrincipalOrgPaths`는 조직 경로를 기반으로 접근을 제어할 수 있지만, 각 부서별로 조직 단위를 생성하고 관리해야 하므로 운영 오버헤드가 증가할 수 있습니다.
- **C. AWS CloudTrail 모니터링:** CloudTrail을 사용하여 계정 생성 및 조직 변경 이벤트를 모니터링하고 S3 버킷 정책을 업데이트하는 것은 복잡하고 운영 오버헤드가 큽니다. 실시간으로 정책을 업데이트하는 것도 어려울 수 있습니다.
- **D. aws:PrincipalTag 글로벌 조건 키:** 각 사용자에게 태그를 추가하고 이를 기반으로 접근을 제어하는 것은 많은 관리 작업이 필요합니다. 특히, 새로운 사용자가 추가될 때마다 태그를 관리해야 하므로 운영 오버헤드가 큽니다.

**출제 의도:**
이 문제는 AWS Organizations를 사용하여 여러 AWS 계정을 관리할 때, 특정 S3 버킷에 대한 접근을 조직 내의 계정으로 제한하는 방법을 평가합니다. 특히, 운영 오버헤드를 최소화하면서 접근 제어를 구현하는 방법을 이해하는 것이 목적입니다.

**공부해야 하는 부분:**
1. **AWS Organizations:**
   - AWS Organizations의 기본 개념과 사용 사례
   - 조직 ID와 조직 단위(OU)의 역할

2. **S3 버킷 정책:**
   - S3 버킷 정책의 기본 개념과 사용 사례
   - 글로벌 조건 키(`aws:PrincipalOrgID`, `aws:PrincipalOrgPaths`, `aws:PrincipalTag`)를 사용하여 접근을 제어하는 방법

3. **AWS CloudTrail:**
   - CloudTrail의 기본 개념과 사용 사례
   - CloudTrail을 사용하여 조직 이벤트를 모니터링하는 방법

이 부분들을 공부하면, AWS에서 조직 내의 계정으로 접근을 제한하는 방법을 더 잘 이해할 수 있습니다.

# 16번

## 정답
- B. Create an analysis in Amazon QuickSight. Connect all the data sources and create new datasets. Publish dashboards to visualize the data. Share the dashboards with the appropriate users and groups.**

**해설:**
- **Amazon QuickSight:**
  - **데이터 시각화:** QuickSight는 다양한 데이터 소스를 연결하여 대시보드를 생성하고 데이터를 시각화할 수 있는 서비스입니다. Amazon S3와 Amazon RDS for PostgreSQL을 포함한 여러 데이터 소스를 연결할 수 있습니다.
  - **사용자 및 그룹 공유:** QuickSight는 대시보드를 특정 사용자 및 그룹과 공유할 수 있는 기능을 제공합니다. 이를 통해 관리 팀에게는 전체 접근 권한을 부여하고, 나머지 직원들에게는 제한된 접근 권한을 부여할 수 있습니다.
  - **IAM 통합:** QuickSight는 AWS IAM과 통합되어, 사용자 및 그룹 기반의 접근 제어를 쉽게 설정할 수 있습니다.

**다른 보기가 정답이 될 수 없는 이유:**
- **A. IAM 역할 공유:** IAM 역할을 사용하여 대시보드를 공유하는 것은 가능하지만, QuickSight의 사용자 및 그룹 기반 공유 기능이 더 적합합니다. 사용자 및 그룹을 통해 더 세밀한 접근 제어를 설정할 수 있습니다.
- **C. AWS Glue 및 S3:** Glue를 사용하여 데이터를 처리하고 S3에 보고서를 게시하는 것은 가능하지만, 데이터 시각화 및 대시보드 생성 기능이 부족합니다. 또한, S3 버킷 정책을 사용하여 접근을 제한하는 것은 관리 오버헤드가 큽니다.
- **D. AWS Glue 및 Athena:** Glue와 Athena를 사용하여 데이터를 처리하고 보고서를 생성하는 것은 가능하지만, 데이터 시각화 및 대시보드 생성 기능이 부족합니다. 또한, S3 버킷 정책을 사용하여 접근을 제한하는 것은 관리 오버헤드가 큽니다.

**출제 의도:**
이 문제는 AWS에서 데이터 시각화 및 보고 솔루션을 구현하는 방법을 평가합니다. 특히, Amazon QuickSight를 사용하여 다양한 데이터 소스를 연결하고, 대시보드를 생성하며, 사용자 및 그룹 기반의 접근 제어를 설정하는 방법을 이해하는 것이 목적입니다.

**공부해야 하는 부분:**
1. **Amazon QuickSight:**
   - QuickSight의 기본 개념과 사용 사례
   - QuickSight를 사용하여 데이터 소스를 연결하고 대시보드를 생성하는 방법
   - QuickSight에서 사용자 및 그룹과 대시보드를 공유하는 방법

2. **AWS Glue:**
   - Glue의 기본 개념과 사용 사례
   - Glue를 사용하여 데이터를 처리하고 ETL 작업을 수행하는 방법

3. **Amazon Athena:**
   - Athena의 기본 개념과 사용 사례
   - Athena를 사용하여 데이터를 쿼리하고 보고서를 생성하는 방법

4. **Amazon S3:**
   - S3의 기본 개념과 사용 사례
   - S3 버킷 정책을 사용하여 접근을 제어하는 방법

이 부분들을 공부하면, AWS에서 데이터 시각화 및 보고 솔루션을 효율적으로 구현하는 방법을 더 잘 이해할 수 있습니다.

# 18번
**정답: A. Create an Amazon Simple Queue Service (Amazon SQS) queue. Configure the S3 bucket to send a notification to the SQS queue when an image is uploaded to the S3 bucket.**
**정답: B. Configure the Lambda function to use the Amazon Simple Queue Service (Amazon SQS) queue as the invocation source. When the SQS message is successfully processed, delete the message in the queue.**

**해설:**
- **Amazon SQS와 Lambda 통합:**
  - **내구성 및 무상태 컴포넌트:** SQS는 내구성 있는 메시지 큐잉 서비스로, 메시지를 안전하게 저장하고 전달할 수 있습니다. Lambda 함수는 무상태 컴퓨팅 서비스로, SQS 큐에서 메시지를 읽어와 이미지를 처리할 수 있습니다.
  - **자동 처리:** S3 버킷에 이미지가 업로드되면 SQS 큐에 알림을 보내고, Lambda 함수가 SQS 큐에서 메시지를 읽어와 이미지를 처리하고 압축된 이미지를 다른 S3 버킷에 저장할 수 있습니다.

**다른 보기가 정답이 될 수 없는 이유:**
- **C. Lambda 함수가 S3 버킷을 모니터링:** Lambda 함수가 직접 S3 버킷을 모니터링하는 것은 가능하지만, 파일 이름을 메모리에 저장하고 추적하는 것은 내구성이 부족하고, 무상태 컴포넌트의 장점을 활용하지 못합니다.
- **D. EC2 인스턴스 사용:** EC2 인스턴스를 사용하여 SQS 큐를 모니터링하고 Lambda 함수를 호출하는 것은 불필요하게 복잡하며, 무상태 컴포넌트의 장점을 활용하지 못합니다.
- **E. EventBridge와 SNS 사용:** EventBridge와 SNS를 사용하여 알림을 보내는 것은 가능하지만, 이는 이미지 처리를 자동화하는 데 적합하지 않습니다. 이메일 알림은 추가적인 수동 작업이 필요할 수 있습니다.

**출제 의도:**
이 문제는 AWS에서 내구성 있고 무상태 컴포넌트를 사용하여 이미지를 자동으로 처리하는 솔루션을 설계하는 방법을 평가합니다. 특히, SQS와 Lambda를 사용하여 이미지를 처리하고 압축하는 방법을 이해하는 것이 목적입니다.

**공부해야 하는 부분:**
1. **Amazon SQS:**
   - SQS의 기본 개념과 사용 사례
   - SQS를 사용하여 메시지를 큐잉하고 전달하는 방법

2. **AWS Lambda:**
   - Lambda의 기본 개념과 사용 사례
   - Lambda를 사용하여 SQS 메시지를 처리하는 방법

3. **Amazon S3:**
   - S3의 기본 개념과 사용 사례
   - S3 이벤트 알림을 설정하여 SQS 큐로 알림을 보내는 방법

이 부분들을 공부하면, AWS에서 내구성 있고 무상태 컴포넌트를 사용하여 이미지를 자동으로 처리하는 방법을 더 잘 이해할 수 있습니다.

# 19번
**정답: D. Deploy a Gateway Load Balancer in the inspection VPC. Create a Gateway Load Balancer endpoint to receive the incoming packets and forward the packets to the appliance.**

**해설:**
- **Gateway Load Balancer:**
  - **트래픽 검사:** Gateway Load Balancer는 트래픽을 가로채고, 가상 어플라이언스(예: 방화벽)로 전달하여 트래픽을 검사할 수 있도록 설계되었습니다. 이는 트래픽을 검사하는 데 최적화된 솔루션입니다.
  - **운영 오버헤드 최소화:** Gateway Load Balancer는 자동으로 확장되고, 고가용성을 제공하며, 관리 오버헤드가 적습니다. 또한, Gateway Load Balancer 엔드포인트를 사용하여 VPC 간에 트래픽을 쉽게 전달할 수 있습니다.
  - **통합:** Gateway Load Balancer는 AWS Marketplace에서 제공되는 가상 어플라이언스와 쉽게 통합할 수 있습니다.

**다른 보기가 정답이 될 수 없는 이유:**
- **A. Network Load Balancer:** Network Load Balancer는 트래픽을 분산시키는 데 사용되지만, 트래픽을 검사하는 데 최적화되지 않았습니다. 또한, 트래픽을 가상 어플라이언스로 전달하는 기능이 부족합니다.
- **B. Application Load Balancer:** Application Load Balancer는 HTTP/HTTPS 트래픽을 분산시키는 데 사용되며, 트래픽을 검사하는 데 최적화되지 않았습니다. 또한, 트래픽을 가상 어플라이언스로 전달하는 기능이 부족합니다.
- **C. Transit Gateway:** Transit Gateway는 VPC 간의 트래픽을 라우팅하는 데 사용되지만, 트래픽을 검사하는 데 최적화되지 않았습니다. 또한, 관리 오버헤드가 높을 수 있습니다.

**출제 의도:**
이 문제는 AWS에서 트래픽을 검사하고, 운영 오버헤드를 최소화하는 방법을 평가합니다. 특히, Gateway Load Balancer를 사용하여 트래픽을 가상 어플라이언스로 전달하고 검사하는 방법을 이해하는 것이 목적입니다.

**공부해야 하는 부분:**
1. **Gateway Load Balancer:**
   - Gateway Load Balancer의 기본 개념과 사용 사례
   - Gateway Load Balancer를 사용하여 트래픽을 가상 어플라이언스로 전달하고 검사하는 방법

2. **Network Load Balancer:**
   - Network Load Balancer의 기본 개념과 사용 사례
   - Network Load Balancer를 사용하여 트래픽을 분산시키는 방법

3. **Application Load Balancer:**
   - Application Load Balancer의 기본 개념과 사용 사례
   - Application Load Balancer를 사용하여 HTTP/HTTPS 트래픽을 분산시키는 방법

4. **Transit Gateway:**
   - Transit Gateway의 기본 개념과 사용 사례
   - Transit Gateway를 사용하여 VPC 간의 트래픽을 라우팅하는 방법

이 부분들을 공부하면, AWS에서 트래픽을 검사하고 운영 오버헤드를 최소화하는 방법을 더 잘 이해할 수 있습니다.


# 20번
**정답: D. Take EBS snapshots of the production EBS volumes. Turn on the EBS fast snapshot restore feature on the EBS snapshots. Restore the snapshots into new EBS volumes. Attach the new EBS volumes to EC2 instances in the test environment.**

**해설:**
- **EBS Fast Snapshot Restore:**
  - **빠른 복원:** EBS Fast Snapshot Restore(FSR) 기능을 사용하면 스냅샷에서 EBS 볼륨을 빠르게 복원할 수 있습니다. 이는 복원 시간을 최소화하여 테스트 환경을 신속하게 설정할 수 있습니다.
  - **일관된 성능:** FSR을 사용하면 복원된 볼륨이 즉시 사용 가능하며, 일관된 높은 I/O 성능을 제공합니다. 이는 테스트 환경에서 소프트웨어가 요구하는 성능을 충족할 수 있습니다.
  - **독립된 데이터:** 스냅샷을 사용하여 새로운 EBS 볼륨을 생성하므로, 테스트 환경에서의 데이터 수정이 프로덕션 환경에 영향을 미치지 않습니다.

**다른 보기가 정답이 될 수 없는 이유:**
- **A. EC2 인스턴스 스토어 볼륨:** 인스턴스 스토어 볼륨은 일시적 스토리지로, 인스턴스가 중지되거나 종료되면 데이터가 손실됩니다. 또한, 스냅샷을 인스턴스 스토어 볼륨으로 복원하는 것은 적절하지 않습니다.
- **B. EBS Multi-Attach:** EBS Multi-Attach 기능은 여러 인스턴스에서 동일한 EBS 볼륨을 동시에 연결할 수 있지만, 이는 데이터 일관성 문제를 일으킬 수 있으며, 프로덕션 데이터에 영향을 미칠 수 있습니다.
- **C. 새로운 EBS 볼륨 초기화:** 새로운 EBS 볼륨을 생성하고 초기화한 후 스냅샷에서 복원하는 것은 시간이 많이 걸릴 수 있습니다. FSR을 사용하면 이 과정을 크게 단축할 수 있습니다.

**출제 의도:**
이 문제는 AWS에서 프로덕션 데이터를 테스트 환경으로 신속하게 복제하는 방법을 평가합니다. 특히, EBS Fast Snapshot Restore 기능을 사용하여 복원 시간을 최소화하고 일관된 성능을 제공하는 방법을 이해하는 것이 목적입니다.

**공부해야 하는 부분:**
1. **Amazon EBS Snapshots:**
   - EBS 스냅샷의 기본 개념과 사용 사례
   - EBS 스냅샷을 사용하여 볼륨을 복원하는 방법

2. **EBS Fast Snapshot Restore (FSR):**
   - FSR의 기본 개념과 사용 사례
   - FSR을 사용하여 스냅샷에서 볼륨을 빠르게 복원하는 방법

3. **EBS Multi-Attach:**
   - Multi-Attach의 기본 개념과 사용 사례
   - Multi-Attach를 사용하여 여러 인스턴스에서 동일한 볼륨을 연결하는 방법과 한계

4. **EC2 Instance Store:**
   - 인스턴스 스토어의 기본 개념과 사용 사례
   - 인스턴스 스토어를 사용하여 데이터를 저장하는 방법과 한계

이 부분들을 공부하면, AWS에서 프로덕션 데이터를 테스트 환경으로 신속하게 복제하는 방법을 더 잘 이해할 수 있습니다.



# 25번
**정답: D. Set up two Lambda functions. Configure one function to receive the information. Configure the other function to load the information into the database. Integrate the Lambda functions by using an Amazon Simple Queue Service (Amazon SQS) queue.**

**해설:**
- **AWS Lambda와 SQS 통합:**
  - **비동기 처리:** SQS를 사용하면 데이터를 비동기적으로 처리할 수 있습니다. 첫 번째 Lambda 함수가 데이터를 수신하고 SQS 큐에 메시지를 넣으면, 두 번째 Lambda 함수가 큐에서 메시지를 읽어와 데이터를 데이터베이스에 로드합니다. 이는 시스템의 확장성을 높이고, 데이터 처리량이 증가할 때도 안정적으로 작동할 수 있습니다.
  - **확장성:** SQS는 자동으로 확장되어 높은 트래픽을 처리할 수 있습니다. Lambda 함수도 자동으로 확장되어 SQS 큐에서 메시지를 처리할 수 있습니다.
  - **구성 노력 최소화:** SQS와 Lambda를 사용하면 서버를 관리할 필요 없이 자동으로 확장되는 서버리스 아키텍처를 구현할 수 있습니다. 이는 구성 노력을 최소화합니다.

**다른 보기가 정답이 될 수 없는 이유:**
- **A. Apache Tomcat과 EC2:** Lambda 함수를 EC2 인스턴스에서 실행되는 Tomcat 코드로 리팩토링하는 것은 운영 오버헤드가 크고, 서버 관리를 필요로 합니다. 이는 구성 노력을 증가시킵니다.
- **B. DynamoDB와 DAX:** Aurora PostgreSQL에서 DynamoDB로 플랫폼을 변경하는 것은 데이터베이스 구조와 API 호출 방식을 완전히 변경해야 하므로, 이는 큰 리팩토링 작업이 필요합니다. 또한, DynamoDB는 관계형 데이터베이스가 아니므로, 기존 데이터베이스 구조와 호환되지 않을 수 있습니다.
- **C. Lambda와 SNS 통합:** SNS는 주로 메시지 브로커 역할을 하며, SQS와 달리 메시지를 큐에 저장하지 않습니다. 이는 비동기 데이터 처리를 구현하는 데 적합하지 않습니다.

**출제 의도:**
이 문제는 AWS에서 높은 데이터 처리량을 효율적으로 처리하고, 구성 노력을 최소화하는 방법을 평가합니다. 특히, Lambda와 SQS를 사용하여 비동기 데이터 처리를 구현하는 방법을 이해하는 것이 목적입니다.

**공부해야 하는 부분:**
1. **AWS Lambda:**
   - Lambda의 기본 개념과 사용 사례
   - Lambda를 사용하여 서버리스 아키텍처를 구현하는 방법

2. **Amazon SQS:**
   - SQS의 기본 개념과 사용 사례
   - SQS를 사용하여 비동기 데이터 처리를 구현하는 방법

3. **Amazon SNS:**
   - SNS의 기본 개념과 사용 사례
   - SNS를 사용하여 메시지를 브로커하는 방법

4. **Amazon Aurora 및 DynamoDB:**
   - Aurora와 DynamoDB의 기본 개념과 사용 사례
   - 각 데이터베이스의 장단점과 사용 사례

이 부분들을 공부하면, AWS에서 높은 데이터 처리량을 효율적으로 처리하고, 구성 노력을 최소화하는 방법을 더 잘 이해할 수 있습니다.

# 28번
이 문제의 정답은 **A**입니다.

### 정답: A. 
**Enable AWS Single Sign-On (AWS SSO) from the AWS SSO console. Create a one-way forest trust or a one-way domain trust to connect the company's self-managed Microsoft Active Directory with AWS SSO by using AWS Directory Service for Microsoft Active Directory.**

### 해설:
1. **요구사항 이해**:
   - 회사는 여러 AWS 계정에서 애플리케이션을 운영하고 있으며, AWS Organizations를 사용하여 중앙에서 계정을 관리하고 있습니다.
   - 보안 팀은 모든 계정에서 단일 로그인(SSO) 솔루션이 필요합니다.
   - 사용자는 온프레미스에서 관리되는 Microsoft Active Directory를 통해 계속 관리되어야 합니다.

2. **옵션 분석**:
   - **A**는 AWS SSO를 사용하여 SSO 기능을 활성화하고, 온프레미스 Active Directory와 연결하기 위해 일방향 트러스트를 설정하는 방법입니다. 이렇게 하면 온프레미스 AD의 사용자 및 그룹을 AWS SSO에서 사용할 수 있습니다.
   - **B**는 양방향 트러스트를 설정하라고 제안하는데, 이는 불필요하며 관리 복잡성을 증가시킵니다. AWS SSO는 일방향 트러스트로도 충분히 기능합니다.
   - **C**는 AWS Directory Service를 사용하여 양방향 트러스트 관계를 설정하는 방법으로, SSO 솔루션을 적극적으로 활용하지 않기 때문에 최선의 선택이 아닙니다.
   - **D**는 온프레미스 IdP를 배포하고 SSO를 활성화하는 방법인데, 이는 운영 및 유지보수의 복잡성을 증가시킬 수 있습니다.

3. **정답의 장점**:
   - A 옵션은 AWS SSO와 AWS Directory Service의 통합을 통해 중앙에서 사용자 관리 및 SSO 기능을 제공할 수 있게 하여 운영 효율성을 높입니다.
   - 또한, 회사의 기존 Active Directory를 활용하여 사용자 관리가 일관되게 유지됩니다.

결론적으로, 옵션 A가 이 회사의 요구 사항을 가장 잘 충족하며, AWS SSO의 기능을 효과적으로 활용할 수 있는 최선의 선택입니다.

# 30번
**정답: A. Stop the DB instance when tests are completed. Restart the DB instance when required.**

**해설:**
- **RDS 인스턴스 중지 및 시작:**
  - **비용 절감:** RDS 인스턴스를 중지하면 스토리지 비용만 발생하고, 인스턴스 사용 비용은 발생하지 않습니다. 이는 테스트가 끝난 후 인스턴스를 중지하고, 필요할 때 다시 시작함으로써 비용을 절감할 수 있습니다.
  - **구성 유지:** 인스턴스를 중지하고 다시 시작해도 기존의 컴퓨팅 및 메모리 속성은 유지됩니다. 이는 테스트 요구 사항을 충족하면서 비용을 절감할 수 있는 방법입니다.

**다른 보기가 정답이 될 수 없는 이유:**
- **B. Auto Scaling 정책 사용:** RDS 인스턴스는 Auto Scaling을 지원하지 않습니다. 또한, Auto Scaling은 주로 EC2 인스턴스에 적용됩니다.
- **C. 스냅샷 생성 및 인스턴스 종료:** 스냅샷을 생성하고 인스턴스를 종료한 후 다시 복원하는 것은 시간이 많이 걸리고, 운영 오버헤드가 큽니다. 또한, 스냅샷 복원 시 데이터베이스 설정을 다시 구성해야 할 수 있습니다.
- **D. 인스턴스 용량 조정:** 인스턴스 용량을 낮추고 다시 높이는 것은 운영 오버헤드가 크며, 인스턴스 크기를 변경하는 동안 다운타임이 발생할 수 있습니다. 이는 테스트 요구 사항을 충족하지 못할 수 있습니다.

**출제 의도:**
이 문제는 AWS RDS 인스턴스를 사용하여 비용을 절감하면서도 성능 요구 사항을 충족하는 방법을 평가합니다. 특히, RDS 인스턴스를 중지하고 다시 시작하여 비용을 절감하는 방법을 이해하는 것이 목적입니다.

**공부해야 하는 부분:**
1. **Amazon RDS:**
   - RDS의 기본 개념과 사용 사례
   - RDS 인스턴스를 중지하고 다시 시작하는 방법

2. **비용 절감 전략:**
   - AWS에서 비용을 절감하는 다양한 전략
   - 인스턴스를 중지하고 다시 시작하여 비용을 절감하는 방법

이 부분들을 공부하면, AWS에서 RDS 인스턴스를 효율적으로 관리하고 비용을 절감하는 방법을 더 잘 이해할 수 있습니다.

# 33번
**정답: C. Stream the transactions data into Amazon Kinesis Data Streams. Use AWS Lambda integration to remove sensitive data from every transaction and then store the transactions data in Amazon DynamoDB. Other applications can consume the transactions data off the Kinesis data stream.**

**해설:**
- **Amazon Kinesis Data Streams:**
  - **실시간 데이터 스트리밍:** Kinesis Data Streams는 실시간으로 데이터를 스트리밍할 수 있는 서비스로, 수백만 건의 트랜잭션 데이터를 처리하는 데 적합합니다.
  - **확장성:** Kinesis Data Streams는 자동으로 확장되어 높은 트래픽을 처리할 수 있습니다.

- **AWS Lambda 통합:**
  - **데이터 처리:** Lambda 함수를 사용하여 Kinesis Data Streams에서 데이터를 읽고, 민감한 데이터를 제거한 후, 데이터를 DynamoDB에 저장할 수 있습니다. 이는 데이터 처리와 저장을 자동화하고, 민감한 데이터를 안전하게 제거할 수 있습니다.
  - **비용 효율성:** Lambda는 서버리스 아키텍처로, 사용한 만큼만 비용을 지불하므로 비용 효율적입니다.

- **Amazon DynamoDB:**
  - **저지연 데이터베이스:** DynamoDB는 저지연 데이터베이스로, 빠른 데이터 검색이 필요한 경우에 적합합니다.
  - **내구성 및 확장성:** DynamoDB는 높은 내구성과 확장성을 제공하여, 대규모 트랜잭션 데이터를 효율적으로 저장하고 검색할 수 있습니다.

**다른 보기가 정답이 될 수 없는 이유:**
- **A. DynamoDB와 DynamoDB Streams:** DynamoDB는 데이터 저장에 적합하지만, 데이터 처리(민감한 데이터 제거)를 위한 규칙을 설정하는 기능이 부족합니다. 또한, DynamoDB Streams는 실시간 데이터 스트리밍에 적합하지 않습니다.
- **B. Kinesis Data Firehose:** Kinesis Data Firehose는 주로 데이터를 S3, Redshift, Elasticsearch로 전송하는 데 사용됩니다. DynamoDB와의 통합이 제한적이며, 실시간 데이터 처리에 적합하지 않습니다.
- **D. S3와 Lambda:** S3에 데이터를 배치로 저장하고 Lambda를 사용하여 처리하는 것은 실시간 데이터 처리에 적합하지 않습니다. 또한, S3는 저지연 데이터베이스로 사용하기에 적합하지 않습니다.

**출제 의도:**
이 문제는 AWS에서 실시간으로 대규모 트랜잭션 데이터를 처리하고, 민감한 데이터를 제거한 후, 저지연 데이터베이스에 저장하는 방법을 평가합니다. 특히, Kinesis Data Streams와 Lambda를 사용하여 실시간 데이터 처리를 구현하는 방법을 이해하는 것이 목적입니다.

**공부해야 하는 부분:**
1. **Amazon Kinesis Data Streams:**
   - Kinesis Data Streams의 기본 개념과 사용 사례
   - Kinesis Data Streams를 사용하여 실시간 데이터를 스트리밍하는 방법

2. **AWS Lambda:**
   - Lambda의 기본 개념과 사용 사례
   - Lambda를 사용하여 데이터를 처리하고, 다른 서비스와 통합하는 방법

3. **Amazon DynamoDB:**
   - DynamoDB의 기본 개념과 사용 사례
   - DynamoDB를 사용하여 데이터를 저장하고, 저지연으로 검색하는 방법

이 부분들을 공부하면, AWS에서 실시간으로 대규모 트랜잭션 데이터를 처리하고, 민감한 데이터를 제거한 후, 저지연 데이터베이스에 저장하는 방법을 더 잘 이해할 수 있습니다.

# 34번
이 문제에서는 AWS 리소스의 구성 변경 사항을 추적하고 API 호출 기록을 기록하는 방법에 대한 요구 사항이 제시되고 있습니다. 각 선택지를 살펴보면:

A. **Use AWS CloudTrail to track configuration changes and AWS Config to record API calls.**  
   - 잘못된 조합입니다. AWS CloudTrail은 API 호출을 기록하는 데 사용되며, AWS Config는 리소스 구성 변경을 추적하는 데 사용됩니다.

B. **Use AWS Config to track configuration changes and AWS CloudTrail to record API calls.**  
   - 올바른 조합입니다. AWS Config는 AWS 리소스의 구성 변경을 추적하며, AWS CloudTrail은 AWS 리소스에 대한 API 호출을 기록합니다.

C. **Use AWS Config to track configuration changes and Amazon CloudWatch to record API calls.**  
   - 잘못된 조합입니다. Amazon CloudWatch는 모니터링 및 로깅에 사용되지만, API 호출 기록에는 사용되지 않습니다.

D. **Use AWS CloudTrail to track configuration changes and Amazon CloudWatch to record API calls.**  
   - 잘못된 조합입니다. AWS CloudTrail은 API 호출을 기록하는 데 사용되며, 구성 변경을 추적하지 않습니다.

따라서, 주어진 요구 사항을 충족하기 위한 올바른 해결책은 **B. Use AWS Config to track configuration changes and AWS CloudTrail to record API calls.**입니다.

# 36번
이 시나리오에서는 애플리케이션이 AWS 클라우드에서 데이터를 Amazon S3 버킷에 저장하고, **AWS Key Management Service (AWS KMS)**의 고객 관리 키를 사용하여 모든 데이터를 암호화해야 합니다. 중요한 요구 사항은 두 개의 AWS 리전에서 동일한 KMS 키를 사용하여 데이터를 암호화하고 복호화하는 것입니다. 

### 옵션 분석

#### **A. Create an S3 bucket in each Region. Configure the S3 buckets to use server-side encryption with Amazon S3 managed encryption keys (SSE-S3). Configure replication between the S3 buckets.**
- **SSE-S3**는 Amazon S3에서 관리하는 암호화 키를 사용하므로, 고객 관리 KMS 키 사용 요구 사항을 충족하지 않습니다.
- 또한, 복제 시 KMS 키를 사용하지 않으므로 요구 사항에 부합하지 않습니다.

#### **B. Create a customer managed multi-Region KMS key. Create an S3 bucket in each Region. Configure replication between the S3 buckets. Configure the application to use the KMS key with client-side encryption.**
- **다중 리전 KMS 키**를 사용하는 것은 좋은 접근이지만, 클라이언트 측 암호화를 설정하는 것은 **운영 오버헤드**가 커질 수 있습니다. 
- 또한, KMS 키를 사용하여 서버 측 암호화를 직접 구현하지 않으므로 운영 오버헤드가 증가합니다.

#### **C. Create a customer managed KMS key and an S3 bucket in each Region. Configure the S3 buckets to use server-side encryption with Amazon S3 managed encryption keys (SSE-S3). Configure replication between the S3 buckets.**
- 고객 관리 KMS 키를 설정하는 것은 좋은 접근이지만, 여전히 SSE-S3를 사용하여 Amazon S3가 관리하는 키를 사용하고 있어 KMS 키 사용 요구 사항을 충족하지 않습니다.

#### **D. Create a customer managed KMS key and an S3 bucket in each Region. Configure the S3 buckets to use server-side encryption with AWS KMS keys (SSE-KMS). Configure replication between the S3 buckets.**
- 이 옵션은 고객 관리 KMS 키를 생성하고, 각 리전의 S3 버킷에서 **서버 측 암호화(AWS KMS 키 사용)**를 설정합니다.
- 두 버킷이 동일한 KMS 키로 암호화 및 복호화되어 요구 사항을 충족합니다.
- 또한, S3 버킷 간의 복제 설정이 가능하므로, 운영 오버헤드가 가장 적습니다.

### **결론**
**정답은 D. Create a customer managed KMS key and an S3 bucket in each Region. Configure the S3 buckets to use server-side encryption with AWS KMS keys (SSE-KMS). Configure replication between the S3 buckets.**입니다. 이 방법은 고객 관리 KMS 키를 사용하여 데이터 암호화를 수행하고, 두 리전에서 데이터를 동일한 KMS 키로 관리하여 최소한의 운영 오버헤드로 요구 사항을 충족합니다.

# 38번
이 문제에서 요구하는 것은 전 세계적으로 증가하는 트래픽에 대해 정적 웹사이트의 대기 시간을 줄이는 것입니다. 여러 옵션이 있지만 가장 비용 효과적인 솔루션을 찾아야 합니다. 각 옵션을 살펴보겠습니다.

**A. S3 버킷을 모든 AWS 리전에 복제하고 Route 53 지리적 라우팅 항목 추가하기.**
- 모든 리전에 S3 버킷을 복제하면 데이터가 중복되어 관리해야 할 리소스가 많아지며, 비용이 증가할 수 있습니다. 지리적 라우팅은 각 지역의 사용자에게 가장 가까운 리전으로 트래픽을 라우팅할 수 있지만, S3 버킷을 복제하는 것 자체가 비효율적이고 비용이 많이 듭니다.

**B. AWS Global Accelerator에서 가속기를 프로비저닝하고, 제공된 IP 주소를 S3 버킷과 연결하기. Route 53 항목을 가속기의 IP 주소로 수정하기.**
- Global Accelerator는 여러 리전에서 리소스에 대한 요청을 최적화할 수 있지만, S3에 대한 액세스는 IP 주소로 직접 연결할 수 없으므로 이 옵션은 비현실적입니다. 또한, Global Accelerator는 추가 비용이 발생합니다.

**C. Amazon CloudFront 배포를 S3 버킷 앞에 추가하고, Route 53 항목을 CloudFront 배포를 가리키도록 수정하기.**
- CloudFront는 전 세계에 분산된 엣지 로케이션을 사용하여 콘텐츠를 캐싱하므로 사용자에게 더 가까운 위치에서 데이터를 제공합니다. 이를 통해 대기 시간이 줄어들고 성능이 향상됩니다. 이 방법은 정적 웹사이트에 특히 효과적이며, 비용도 비교적 저렴합니다.

**D. S3 Transfer Acceleration을 버킷에서 활성화하고, Route 53 항목을 새 엔드포인트로 수정하기.**
- Transfer Acceleration은 업로드 속도를 향상시키는 기능이지만, 전반적인 웹사이트 성능 개선에는 한계가 있습니다. Transfer Acceleration은 주로 데이터 전송 속도를 개선하기 위해 설계되었으며, CloudFront와 같은 캐싱 솔루션보다는 효과적이지 않을 수 있습니다.

결론적으로, 전 세계적으로 증가하는 트래픽에 대해 정적 웹사이트의 대기 시간을 줄이고자 할 때 가장 비용 효과적인 솔루션은 **C. Amazon CloudFront 배포를 S3 버킷 앞에 추가하고, Route 53 항목을 CloudFront 배포를 가리키도록 수정하기**입니다. CloudFront는 콘텐츠 전송 네트워크(CDN) 기능을 제공하여 지연 시간을 줄이고 사용자 경험을 개선하는 데 도움이 됩니다.

# 43번
**정답: B. Establish a new AWS Direct Connect connection and direct backup traffic through this new connection.**

**해설:**
- **AWS Direct Connect:**
  - **전용 네트워크 연결:** AWS Direct Connect는 온프레미스 데이터 센터와 AWS 간의 전용 네트워크 연결을 제공합니다. 이는 인터넷을 거치지 않으므로, 인터넷 대역폭에 영향을 주지 않고 안정적이고 빠른 데이터 전송을 가능하게 합니다.
  - **대용량 데이터 전송:** Direct Connect는 대용량 데이터 전송에 적합하며, 시간에 민감한 데이터를 신속하게 백업할 수 있습니다. 이는 인터넷 대역폭 제한 문제를 해결할 수 있습니다.

**다른 보기가 정답이 될 수 없는 이유:**
- **A. AWS VPN 연결:** VPN 연결은 인터넷을 통해 데이터를 전송하므로, 인터넷 대역폭 제한 문제를 해결하지 못합니다. 또한, 대용량 데이터 전송에 적합하지 않습니다.
- **C. AWS Snowball:** Snowball은 대용량 데이터를 물리적으로 전송하는 데 사용되지만, 매일 장치를 주문하고 데이터를 로드하여 반환하는 것은 비효율적이며, 장기적인 솔루션으로 적합하지 않습니다.
- **D. S3 서비스 한도 제거 요청:** S3 서비스 한도 제거는 데이터 전송 속도나 인터넷 대역폭 문제를 해결하지 못합니다. 이는 문제의 근본 원인을 해결하지 않습니다.

**출제 의도:**
이 문제는 AWS에서 온프레미스 데이터 센터와 AWS 간의 대용량 데이터 전송을 효율적으로 관리하고, 인터넷 대역폭에 미치는 영향을 최소화하는 방법을 평가합니다. 특히, AWS Direct Connect를 사용하여 안정적이고 빠른 데이터 전송을 구현하는 방법을 이해하는 것이 목적입니다.

**공부해야 하는 부분:**
1. **AWS Direct Connect:**
   - Direct Connect의 기본 개념과 사용 사례
   - Direct Connect를 사용하여 온프레미스 데이터 센터와 AWS 간의 전용 네트워크 연결을 설정하는 방법

2. **AWS VPN:**
   - VPN의 기본 개념과 사용 사례
   - VPN을 사용하여 온프레미스 데이터 센터와 AWS 간의 연결을 설정하는 방법

3. **AWS Snowball:**
   - Snowball의 기본 개념과 사용 사례
   - Snowball을 사용하여 대용량 데이터를 물리적으로 전송하는 방법

이 부분들을 공부하면, AWS에서 온프레미스 데이터 센터와 AWS 간의 대용량 데이터 전송을 효율적으로 관리하고, 인터넷 대역폭에 미치는 영향을 최소화하는 방법을 더 잘 이해할 수 있습니다.

# 47번 
**정답: D. Create an On-Demand Capacity Reservation that specifies the Region and three Availability Zones needed.**

**해설:**
- **On-Demand Capacity Reservation:**
  - **즉시 용량 확보:** On-Demand Capacity Reservation을 사용하면 특정 리전과 가용 영역에서 EC2 인스턴스 용량을 즉시 확보할 수 있습니다. 이는 특정 기간 동안 필요한 용량을 보장합니다.
  - **단기 이벤트:** Capacity Reservation은 단기 이벤트에 적합하며, 예약된 기간 동안 용량을 보장합니다. 이는 1주일 동안 지속되는 이벤트에 적합합니다.
  - **가용 영역 지정:** Capacity Reservation을 생성할 때 특정 가용 영역을 지정할 수 있으므로, 세 개의 특정 가용 영역에서 용량을 보장할 수 있습니다.

**다른 보기가 정답이 될 수 없는 이유:**
- **A. 리전을 지정한 예약 인스턴스 구매:** 예약 인스턴스는 특정 리전에서 할인된 요금으로 인스턴스를 사용할 수 있게 하지만, 용량을 보장하지 않습니다.
- **B. 리전을 지정한 On-Demand Capacity Reservation:** 리전만 지정한 Capacity Reservation은 특정 가용 영역에서의 용량을 보장하지 않습니다.
- **C. 리전과 가용 영역을 지정한 예약 인스턴스 구매:** 예약 인스턴스는 특정 가용 영역에서 할인된 요금으로 인스턴스를 사용할 수 있게 하지만, 용량을 보장하지 않습니다.

**출제 의도:**
이 문제는 AWS에서 특정 기간 동안 특정 가용 영역에서 EC2 인스턴스 용량을 보장하는 방법을 평가합니다. 특히, On-Demand Capacity Reservation을 사용하여 용량을 보장하는 방법을 이해하는 것이 목적입니다.

**공부해야 하는 부분:**
1. **On-Demand Capacity Reservation:**
   - Capacity Reservation의 기본 개념과 사용 사례
   - Capacity Reservation을 사용하여 특정 리전과 가용 영역에서 용량을 보장하는 방법

2. **Reserved Instances:**
   - 예약 인스턴스의 기본 개념과 사용 사례
   - 예약 인스턴스를 사용하여 비용을 절감하는 방법과 용량 보장의 차이점

이 부분들을 공부하면, AWS에서 특정 기간 동안 특정 가용 영역에서 EC2 인스턴스 용량을 보장하는 방법을 더 잘 이해할 수 있습니다.**정답: D. Create an On-Demand Capacity Reservation that specifies the Region and three Availability Zones needed.**

**해설:**
- **On-Demand Capacity Reservation:**
  - **즉시 용량 확보:** On-Demand Capacity Reservation을 사용하면 특정 리전과 가용 영역에서 EC2 인스턴스 용량을 즉시 확보할 수 있습니다. 이는 특정 기간 동안 필요한 용량을 보장합니다.
  - **단기 이벤트:** Capacity Reservation은 단기 이벤트에 적합하며, 예약된 기간 동안 용량을 보장합니다. 이는 1주일 동안 지속되는 이벤트에 적합합니다.
  - **가용 영역 지정:** Capacity Reservation을 생성할 때 특정 가용 영역을 지정할 수 있으므로, 세 개의 특정 가용 영역에서 용량을 보장할 수 있습니다.

**다른 보기가 정답이 될 수 없는 이유:**
- **A. 리전을 지정한 예약 인스턴스 구매:** 예약 인스턴스는 특정 리전에서 할인된 요금으로 인스턴스를 사용할 수 있게 하지만, 용량을 보장하지 않습니다.
- **B. 리전을 지정한 On-Demand Capacity Reservation:** 리전만 지정한 Capacity Reservation은 특정 가용 영역에서의 용량을 보장하지 않습니다.
- **C. 리전과 가용 영역을 지정한 예약 인스턴스 구매:** 예약 인스턴스는 특정 가용 영역에서 할인된 요금으로 인스턴스를 사용할 수 있게 하지만, 용량을 보장하지 않습니다.

**출제 의도:**
이 문제는 AWS에서 특정 기간 동안 특정 가용 영역에서 EC2 인스턴스 용량을 보장하는 방법을 평가합니다. 특히, On-Demand Capacity Reservation을 사용하여 용량을 보장하는 방법을 이해하는 것이 목적입니다.

**공부해야 하는 부분:**
1. **On-Demand Capacity Reservation:**
   - Capacity Reservation의 기본 개념과 사용 사례
   - Capacity Reservation을 사용하여 특정 리전과 가용 영역에서 용량을 보장하는 방법

2. **Reserved Instances:**
   - 예약 인스턴스의 기본 개념과 사용 사례
   - 예약 인스턴스를 사용하여 비용을 절감하는 방법과 용량 보장의 차이점

이 부분들을 공부하면, AWS에서 특정 기간 동안 특정 가용 영역에서 EC2 인스턴스 용량을 보장하는 방법을 더 잘 이해할 수 있습니다.

# 48번
**정답: D. Move the catalog to an Amazon Elastic File System (Amazon EFS) file system.**

**해설:**
- **Amazon Elastic File System (EFS):**
  - **고가용성 및 내구성:** Amazon EFS는 여러 가용 영역에 걸쳐 데이터를 저장하여 고가용성과 내구성을 제공합니다. 이는 데이터 손실 위험을 줄이고, 데이터가 항상 접근 가능하도록 보장합니다.
  - **확장성:** EFS는 자동으로 확장되므로, 데이터 양이 증가해도 별도의 관리 없이 확장할 수 있습니다.
  - **공유 파일 시스템:** EFS는 여러 EC2 인스턴스에서 동시에 접근할 수 있는 공유 파일 시스템을 제공하므로, 웹사이트의 카탈로그 데이터를 여러 인스턴스에서 사용할 수 있습니다.

**다른 보기가 정답이 될 수 없는 이유:**
- **A. ElastiCache for Redis:** ElastiCache for Redis는 주로 캐싱을 위한 인메모리 데이터 저장소로, 내구성 있는 데이터 저장소로 사용하기에는 적합하지 않습니다.
- **B. 더 큰 인스턴스 스토어:** 더 큰 인스턴스 스토어를 사용하는 것은 내구성을 보장하지 않습니다. 인스턴스 스토어는 인스턴스가 종료되면 데이터가 손실될 수 있습니다.
- **C. S3 Glacier Deep Archive:** S3 Glacier Deep Archive는 장기 보관을 위한 저비용 스토리지로, 자주 접근해야 하는 데이터에는 적합하지 않습니다. 또한, 데이터 복구 시간이 길어질 수 있습니다.

**출제 의도:**
이 문제는 AWS에서 데이터를 고가용성 및 내구성을 보장하는 위치에 저장하는 방법을 평가합니다. 특히, Amazon EFS를 사용하여 데이터를 안전하게 저장하고, 여러 인스턴스에서 접근할 수 있도록 하는 방법을 이해하는 것이 목적입니다.

**공부해야 하는 부분:**
1. **Amazon Elastic File System (EFS):**
   - EFS의 기본 개념과 사용 사례
   - EFS를 사용하여 데이터를 고가용성 및 내구성을 보장하는 방법

2. **Amazon ElastiCache:**
   - ElastiCache의 기본 개념과 사용 사례
   - ElastiCache를 사용하여 데이터를 캐싱하는 방법

3. **Amazon S3 Glacier Deep Archive:**
   - S3 Glacier Deep Archive의 기본 개념과 사용 사례
   - S3 Glacier Deep Archive를 

# 49번
**정답: B. Store individual files in Amazon S3 Intelligent-Tiering. Use S3 Lifecycle policies to move the files to S3 Glacier Flexible Retrieval after 1 year. Query and retrieve the files that are in Amazon S3 by using Amazon Athena. Query and retrieve the files that are in S3 Glacier by using S3 Glacier Select.**

**해설:**
- **Amazon S3 Intelligent-Tiering:**
  - **비용 최적화:** S3 Intelligent-Tiering은 데이터 액세스 패턴에 따라 자동으로 데이터를 가장 비용 효율적인 스토리지 클래스로 이동시킵니다. 이는 자주 액세스되는 데이터와 드물게 액세스되는 데이터를 자동으로 구분하여 비용을 절감할 수 있습니다.
  - **빠른 액세스:** 1년 이내에 자주 액세스되는 파일은 S3 Intelligent-Tiering의 표준 또는 인빈티드 액세스 계층에 저장되어 빠르게 액세스할 수 있습니다.

- **S3 Glacier Flexible Retrieval:**
  - **장기 보관:** 1년 이후에 드물게 액세스되는 파일은 S3 Glacier Flexible Retrieval로 이동하여 비용을 절감할 수 있습니다. 이 스토리지 클래스는 저렴한 비용으로 데이터를 장기 보관할 수 있으며, 액세스 지연이 허용되는 경우에 적합합니다.

- **Amazon Athena 및 S3 Glacier Select:**
  - **데이터 쿼리:** Athena를 사용하여 S3에 저장된 데이터를 쿼리하고, S3 Glacier Select를 사용하여 Glacier에 저장된 데이터를 쿼리할 수 있습니다. 이는 데이터를 효율적으로 검색하고, 필요한 경우에만 데이터를 복원할 수 있게 합니다.

**다른 보기가 정답이 될 수 없는 이유:**
- **A. S3 Glacier Instant Retrieval:** S3 Glacier Instant Retrieval은 빠른 액세스를 제공하지만, 비용이 더 높을 수 있습니다. 또한, 1년 이내에 자주 액세스되는 데이터를 위한 최적의 솔루션이 아닙니다.
- **C. S3 Standard 및 S3 Glacier Instant Retrieval:** S3 Standard는 비용이 더 높을 수 있으며, S3 Glacier Instant Retrieval은 비용 효율적이지 않습니다. 또한, 메타데이터를 별도로 저장하고 쿼리하는 것은 복잡성을 증가시킵니다.
- **D. S3 Standard 및 S3 Glacier Deep Archive:** S3 Glacier Deep Archive는 매우 저렴한 비용으로 데이터를 장기 보관할 수 있지만, 데이터 복구 시간이 길어질 수 있습니다. 이는 1년 이내에 자주 액세스되는 데이터를 위한 최적의 솔루션이 아닙니다.

**출제 의도:**
이 문제는 AWS에서 데이터를 비용 효율적으로 저장하고, 액세스 패턴에 따라 최적화하는 방법을 평가합니다. 

# 50번
**정답: D. Use AWS Systems Manager Run Command to run a custom command that applies the patch to all EC2 instances.**

**해설:**
- **AWS Systems Manager Run Command:**
  - **즉시 실행:** Run Command를 사용하면 EC2 인스턴스에 명령을 즉시 실행할 수 있습니다. 이는 긴급한 패치 작업을 빠르게 수행하는 데 적합합니다.
  - **대규모 인스턴스 관리:** Run Command는 여러 인스턴스에 동시에 명령을 실행할 수 있으므로, 1,000개의 EC2 인스턴스에 패치를 빠르게 적용할 수 있습니다.
  - **커스텀 명령:** Run Command를 사용하여 특정 패치 명령을 정의하고 실행할 수 있습니다. 이는 특정 소프트웨어 패치를 적용하는 데 유연성을 제공합니다.

**다른 보기가 정답이 될 수 없는 이유:**
- **A. AWS Lambda 함수 생성:** Lambda 함수는 짧은 실행 시간과 제한된 리소스를 가지므로, 1,000개의 EC2 인스턴스에 패치를 적용하는 데 적합하지 않습니다.
- **B. AWS Systems Manager Patch Manager 구성:** Patch Manager는 주로 운영 체제 패치를 관리하는 데 사용됩니다. 특정 서드파티 소프트웨어 패치를 적용하는 데는 적합하지 않을 수 있습니다.
- **C. AWS Systems Manager 유지 관리 창 스케줄링:** 유지 관리 창을 사용하면 패치를 예약할 수 있지만, 긴급한 패치 작업을 즉시 수행하는 데는 적합하지 않습니다.

**출제 의도:**
이 문제는 AWS에서 대규모 EC2 인스턴스에 긴급한 패치를 빠르게 적용하는 방법을 평가합니다. 특히, AWS Systems Manager Run Command를 사용하여 커스텀 명령을 실행하고, 패치를 빠르게 적용하는 방법을 이해하는 것이 목적입니다.

**공부해야 하는 부분:**
1. **AWS Systems Manager Run Command:**
   - Run Command의 기본 개념과 사용 사례
   - Run Command를 사용하여 여러 인스턴스에 명령을 실행하는 방법

2. **AWS Systems Manager Patch Manager:**
   - Patch Manager의 기본 개념과 사용 사례
   - Patch Manager를 사용하여 운영 체제 패치를 관리하는 방법

3. **AWS Lambda:**
   - Lambda의 기본 개념과 사용 사례
   - Lambda를 사용하여 짧은 실행 시간의 작업을 수행하는 방법

4. **AWS Systems Manager Maintenance Window:**
   - Maintenance Window의 기본 개념과 사용 사례
   - Maintenance Window를 사용하여 유지 관리 작업을 예약하는 방법

이 부분들을 공부하면, AWS에서 대규모 EC2 인스턴스에 긴급한 패치를 빠르게 적용하는 방법을 더 잘 이해할 수 있습니다.

# 51번
이 문제는 매일 아침 REST API를 통해 주문 배송 통계를 추출하고, 이 데이터를 읽기 쉬운 HTML 형식으로 정리한 후 여러 이메일 주소로 보고서를 보내는 애플리케이션을 개발하는 것과 관련이 있습니다. 요구 사항을 충족하기 위해 적절한 두 가지 단계를 선택해야 합니다.

각 옵션을 검토해 보겠습니다.

**A. Configure the application to send the data to Amazon Kinesis Data Firehose.**  
- Kinesis Data Firehose는 실시간 데이터 스트리밍을 위한 서비스로, 주로 데이터 스트림을 저장하고 처리하는 데 사용됩니다. 이 경우, 데이터 추출 및 이메일 발송과는 직접적으로 관련이 없습니다.

**B. Use Amazon Simple Email Service (Amazon SES) to format the data and to send the report by email.**  
- Amazon SES는 이메일을 발송하기 위한 서비스입니다. 보고서를 이메일로 발송하기 위해서는 필요한 서비스입니다. 그러나 SES는 HTML 형식으로 데이터를 포맷하는 기능을 제공하지 않으므로, 다른 방법으로 데이터를 포맷해야 할 것입니다.

**C. Create an Amazon EventBridge (Amazon CloudWatch Events) scheduled event that invokes an AWS Glue job to query the application's API for the data.**  
- AWS Glue는 ETL(Extract, Transform, Load) 작업을 수행하는 데 사용되며, API를 쿼리하는 데 적합하지 않습니다. 따라서 이 옵션은 요구 사항을 충족하지 않습니다.

**D. Create an Amazon EventBridge (Amazon CloudWatch Events) scheduled event that invokes an AWS Lambda function to query the application's API for the data.**  
- 이 옵션은 매일 특정 시간에 Lambda 함수를 호출하여 API에서 데이터를 쿼리하는 것을 가능하게 합니다. Lambda는 데이터를 처리하고 HTML 형식으로 변환할 수 있는 유연성을 제공하므로 이 요구 사항을 충족하는 좋은 선택입니다.

**E. Store the application data in Amazon S3. Create an Amazon Simple Notification Service (Amazon SNS) topic as an S3 event destination to send the report by email.**  
- Amazon S3는 데이터를 저장하는 데 사용할 수 있지만, SNS를 사용하여 S3 이벤트에 따라 이메일을 보내는 것은 이번 경우와 직접적인 연관이 없습니다. 데이터 포맷팅 및 이메일 발송을 처리하는 데 있어 적절한 방식은 아닙니다.

따라서, 이 요구 사항을 충족하기 위한 적절한 두 가지 단계를 선택하면 다음과 같습니다:

- **D. Create an Amazon EventBridge (Amazon CloudWatch Events) scheduled event that invokes an AWS Lambda function to query the application's API for the data.**
- **B. Use Amazon Simple Email Service (Amazon SES) to format the data and to send the report by email.**

이 조합을 통해 매일 아침 API에서 데이터를 쿼리하고, Amazon SES를 사용하여 이메일로 보고서를 발송할 수 있습니다.

# 54
**C. Extend the file share environment to Amazon FSx for Windows File Server with a Multi-AZ configuration. Migrate all the data to FSx for Windows File Server.**

# 57번
**정답: B. Use Amazon Rekognition to detect inappropriate content. Use human review for low-confidence predictions.**

**해설:**
- **Amazon Rekognition:**
  - **이미지 분석:** Amazon Rekognition은 이미지와 비디오에서 객체, 사람, 텍스트, 장면 및 활동을 식별할 수 있는 완전 관리형 서비스입니다. 특히, 부적절한 콘텐츠를 감지하는 데 사용될 수 있는 내장된 기능을 제공합니다.
  - **개발 노력 최소화:** Rekognition은 사전 훈련된 모델을 제공하므로, 별도의 모델을 훈련하거나 배포할 필요가 없습니다. 이는 개발 노력을 최소화합니다.
  - **인간 검토:** Rekognition은 낮은 신뢰도의 예측에 대해 인간 검토를 추가할 수 있는 기능을 제공합니다. 이는 부적절한 콘텐츠를 더 정확하게 필터링하는 데 도움이 됩니다.

**다른 보기가 정답이 될 수 없는 이유:**
- **A. Amazon Comprehend:** Comprehend는 주로 텍스트 분석을 위한 서비스로, 이미지에서 부적절한 콘텐츠를 감지하는 데 적합하지 않습니다.
- **C. Amazon SageMaker:** SageMaker는 맞춤형 머신 러닝 모델을 훈련하고 배포하는 데 사용됩니다. 이는 개발 노력이 많이 들며, 사전 훈련된 모델을 제공하지 않으므로 부적절한 콘텐츠 감지에 적합하지 않습니다.
- **D. AWS Fargate:** Fargate는 컨테이너를 배포하고 관리하는 데 사용됩니다. 맞춤형 머신 러닝 모델을 배포하려면 많은 개발 노력이 필요하며, 사전 훈련된 모델을 제공하지 않으므로 부적절한 콘텐츠 감지에 적합하지 않습니다.

**출제 의도:**
이 문제는 AWS에서 부적절한 콘텐츠를 감지하고, 개발 노력을 최소화하는 방법을 평가합니다. 특히, Amazon Rekognition을 사용하여 이미지에서 부적절한 콘텐츠를 감지하고, 낮은 신뢰도의 예측에 대해 인간 검토를 추가하는 방법을 이해하는 것이 목적입니다.

**공부해야 하는 부분:**
1. **Amazon Rekognition:**
   - Rekognition의 기본 개념과 사용 사례
   - Rekognition을 사용하여 이미지에서 부적절한 콘텐츠를 감지하는 방법

2. **Amazon Comprehend:**
   - Comprehend의 기본 개념과 사용 사례
   - Comprehend를 사용하여 텍스트를 분석하는 방법

3. **Amazon SageMaker:**
   - SageMaker의 기본 개념과 사용 사례
   - SageMaker를 사용하여 맞춤형 머신 러닝 모델을 훈련하고 배포하는 방법

4. **AWS Fargate:**
   - Fargate의 기본 개념과 사용 사례
   - Fargate를 사용하여 컨테이너를 배포하고 관리하는 방법

이 부분들을 공부하면, AWS에서 부적절한 콘텐츠를 감지하고, 개발 노력을 최소화하는 방법을 더 잘 이해할 수 있습니다.

**정답: C. Create an S3 bucket lifecycle policy to move files from S3 Standard to S3 Standard-Infrequent Access (S3 Standard-IA) 30 days from object creation. Delete the files 4 years after object creation.**

**해설:**
- **S3 Standard-Infrequent Access (S3 Standard-IA):**
  - **비용 효율성:** S3 Standard-IA는 자주 접근하지 않는 데이터를 저장하는 데 적합하며, S3 Standard보다 저렴한 비용으로 데이터를 저장할 수 있습니다.
  - **즉시 접근 가능:** S3 Standard-IA는 데이터를 즉시 접근할 수 있도록 보장하므로, 중요한 비즈니스 데이터를 저장하는 데 적합합니다.
  - **사용 패턴:** 문제에서 주어진 사용 패턴(처음 30일 동안 자주 접근, 이후 드물게 접근)에 적합합니다.

**다른 보기가 정답이 될 수 없는 이유:**
- **A. S3 Glacier:** S3 Glacier는 장기 보관을 위한 저비용 스토리지로, 데이터 접근 시간이 길어질 수 있습니다. 즉시 접근이 필요한 데이터에는 적합하지 않습니다.
- **B. S3 One Zone-IA:** S3 One Zone-IA는 단일 가용 영역에 데이터를 저장하므로, 내구성이 낮아질 수 있습니다. 중요한 비즈니스 데이터를 저장하는 데 적합하지 않습니다.
- **D. S3 Standard-IA에서 S3 Glacier로 이동:** S3 Glacier로 이동하면 데이터 접근 시간이 길어질 수 있습니다. 즉시 접근이 필요한 데이터에는 적합하지 않습니다.

**출제 의도:**
이 문제는 AWS에서 데이터를 비용 효율적으로 저장하고, 즉시 접근 가능성을 보장하는 방법을 평가합니다. 특히, S3 Standard-IA를 사용하여 자주 접근하지 않는 데이터를 저장하고, S3 Lifecycle 정책을 사용하여 데이터를 관리하는 방법을 이해하는 것이 목적입니다.

**공부해야 하는 부분:**
1. **Amazon S3 Storage Classes:**
   - S3 Standard, S3 Standard-IA, S3 One Zone-IA, S3 Glacier의 기본 개념과 사용 사례
   - 각 스토리지 클래스의 비용 및 접근 시간

2. **S3 Lifecycle Policies:**
   - S3 Lifecycle 정책의 기본 개념과 사용 사례
   - S3 Lifecycle 정책을 사용하여 데이터를 자동으로 이동하고 삭제하는 방법

이 부분들을 공부하면, AWS에서 데이터를 비용 효율적으로 저장하고, 즉시 접근 가능성을 보장하는 방법을 더 잘 이해할 수 있습니다.

# 64번
정답: **D. Deploy and configure Amazon FSx for Windows File Server on AWS. Deploy and configure an Amazon FSx File Gateway on premises. Move the on-premises file data to the FSx File Gateway. Configure the cloud workloads to use FSx for Windows File Server on AWS. Configure the on-premises workloads to use the FSx File Gateway.**

### 해설:

**옵션 D가 정답인 이유**:
이 시나리오에서는 회사가 온프레미스에서 AWS로 점진적으로 Windows 워크로드를 이전하고 있으며, AWS와 온프레미스 모두에서 파일 데이터에 대한 접근이 필요합니다. 이 경우 **Amazon FSx for Windows File Server**와 **FSx File Gateway**의 조합이 가장 적합한 솔루션입니다.

- **Amazon FSx for Windows File Server**는 Windows 기반 파일 스토리지를 AWS에서 제공하며, SMB 프로토콜을 지원하여 기존 Windows 파일 서버와 호환됩니다.
- **FSx File Gateway**는 온프레미스에서 Amazon FSx for Windows File Server로의 원활한 연결을 제공하여, 온프레미스에서도 Amazon FSx의 데이터를 빠르고 효율적으로 접근할 수 있습니다.

이 솔루션은 다음과 같은 이점을 제공합니다:
1. **기존 파일 액세스 패턴 유지**: FSx File Gateway는 온프레미스 애플리케이션이 기존 파일 서버처럼 Amazon FSx에 액세스할 수 있도록 하므로 파일 액세스 패턴의 큰 변경 없이도 사용 가능합니다.
2. **운영 오버헤드 최소화**: AWS 관리 서비스인 FSx for Windows File Server와 FSx File Gateway는 사용자가 직접 서버를 관리할 필요가 없도록 해 운영 오버헤드를 줄입니다.
3. **데이터 동기화 및 낮은 지연 시간**: 온프레미스에서 AWS로 점진적으로 이전하는 동안 FSx File Gateway를 통해 데이터를 빠르게 접근할 수 있으며, AWS로 이전된 데이터와의 동기화도 원활히 지원됩니다.

**다른 옵션에 대한 해설**:

- **옵션 A**: Amazon FSx for Windows File Server만을 사용하는 경우 온프레미스에서 직접 AWS에 있는 FSx 파일 시스템에 접근해야 하므로 지연 시간이 발생할 수 있으며, 파일 서버 접근 패턴을 유지하기 어렵습니다.

- **옵션 B**: Amazon S3 File Gateway는 Amazon S3에 파일을 저장하는 데 최적화되어 있지만, Windows 워크로드에서 사용하는 SMB 프로토콜을 지원하지 않으므로 기존 파일 액세스 패턴에 맞지 않습니다.

- **옵션 C**: S3 File Gateway와 Amazon S3 조합도 SMB 프로토콜을 지원하지 않으며, Windows 파일 시스템의 경우 적합하지 않습니다.

따라서 **옵션 D**가 운영 오버헤드를 최소화하면서 온프레미스와 AWS 간 파일 시스템 접근을 원활하게 하는 최적의 솔루션입니다.

# 68번
**정답: A. Provision an AWS Direct Connect connection to a Region. Provision a VPN connection as a backup if the primary Direct Connect connection fails.**

**해설:**
- **AWS Direct Connect:**
  - **고가용성 및 저지연:** Direct Connect는 AWS와 온프레미스 데이터 센터 간의 전용 네트워크 연결을 제공하여, 일관된 저지연과 높은 가용성을 보장합니다.
  - **비용 효율성:** Direct Connect는 대규모 데이터 전송에 대해 비용 효율적입니다.

- **VPN 연결 백업:**
  - **비용 절감:** VPN 연결은 Direct Connect에 비해 저렴하며, 백업 연결로 사용하기에 적합합니다.
  - **자동 페일오버:** Direct Connect 연결이 실패할 경우, VPN 연결을 통해 트래픽을 전송할 수 있습니다. 이는 트래픽이 느려질 수 있지만, 비용을 절감하면서 고가용성을 유지할 수 있습니다.

**다른 보기가 정답이 될 수 없는 이유:**
- **B. 두 개의 VPN 터널:** 두 개의 VPN 터널을 사용하는 것은 비용이 저렴하지만, 일관된 저지연을 제공하지 못합니다. 이는 고가용성과 저지연 요구 사항을 충족하지 못합니다.
- **C. 두 개의 Direct Connect 연결:** 두 개의 Direct Connect 연결을 사용하는 것은 고가용성을 보장하지만, 비용이 많이 듭니다. 비용을 최소화하려는 요구 사항을 충족하지 못합니다.
- **D. Direct Connect 페일오버 속성:** Direct Connect 페일오버 속성은 자동 백업 연결을 생성하지 않습니다. 백업 연결을 수동으로 설정해야 합니다.

**출제 의도:**
이 문제는 AWS에서 온프레미스 인프라를 확장하고, 고가용성과 저지연을 보장하면서 비용을 최소화하는 방법을 평가합니다. 특히, Direct Connect와 VPN 연결을 조합하여 고가용성과 비용 효율성을 유지하는 방법을 이해하는 것이 목적입니다.

**공부해야 하는 부분:**
1. **AWS Direct Connect:**
   - Direct Connect의 기본 개념과 사용 사례
   - Direct Connect를 사용하여 고가용성과 저지연을 보장하는 방법

2. **AWS VPN:**
   - VPN의 기본 개념과 사용 사례
   - VPN을 백업 연결로 사용하는 방법

3. **하이브리드 아키텍처:**
   - 온프레미스 인프라와 AWS 간의 하이브리드 아키텍처 설계 방법
   - 고가용성과 비용 효율성을 유지하는 방법

이 부분들을 공부하면, AWS에서 온프레미스 인프라를 확장하고, 고가용성과 저지연을 보장하면서 비용을 최소화하는 방법을 더 잘 이해할 수 있습니다.

# 72번
**정답: D. Deploy an S3 VPC gateway endpoint into the VPC and attach an endpoint policy that allows access to the S3 buckets.**

**해설:**
- **S3 VPC Gateway Endpoint:**
  - **내부 네트워크 트래픽:** S3 VPC Gateway Endpoint를 사용하면 VPC 내에서 Amazon S3에 직접 연결할 수 있습니다. 이는 인터넷을 통해 트래픽을 라우팅할 필요가 없으므로 데이터 전송 비용을 줄일 수 있습니다.
  - **비용 절감:** VPC Endpoint를 사용하면 인터넷 게이트웨이, NAT 게이트웨이 또는 다른 네트워크 장치를 통해 트래픽을 라우팅할 필요가 없으므로 데이터 전송 비용을 절감할 수 있습니다.
  - **보안:** VPC Endpoint를 사용하면 트래픽이 AWS 네트워크 내에서 유지되므로 보안이 강화됩니다.

**다른 보기가 정답이 될 수 없는 이유:**
- **A. API Gateway 사용:** API Gateway는 주로 API 관리를 위해 사용되며, S3와의 데이터 전송 비용을 줄이는 데 적합하지 않습니다.
- **B. NAT Gateway 사용:** NAT Gateway를 사용하면 인터넷을 통해 트래픽이 라우팅되므로 데이터 전송 비용이 발생합니다.
- **C. 인터넷 게이트웨이 사용:** 인터넷 게이트웨이를 통해 S3에 접근하면 데이터 전송 비용이 발생합니다.

**출제 의도:**
이 문제는 AWS에서 데이터 전송 비용을 줄이기 위해 S3 VPC Gateway Endpoint를 사용하는 방법을 평가합니다. 특히, VPC Endpoint를 사용하여 VPC 내에서 S3에 직접 연결하고, 데이터 전송 비용을 절감하는 방법을 이해하는 것이 목적입니다.

**공부해야 하는 부분:**
1. **Amazon S3 VPC Gateway Endpoint:**
   - S3 VPC Gateway Endpoint의 기본 개념과 사용 사례
   - VPC Endpoint를 사용하여 데이터 전송 비용을 절감하는 방법

2. **AWS 네트워킹:**
   - VPC, 서브넷, 인터넷 게이트웨이, NAT 게이트웨이의 기본 개념과 사용 사례
   - 각 네트워킹 구성 요소의 비용 및 보안 고려 사항

이 부분들을 공부하면, AWS에서 데이터 전송 비용을 줄이기 위해 S3 VPC Gateway Endpoint를 사용하는 방법을 더 잘 이해할 수 있습니다.


# 82번
이 문제에서는 AWS Certificate Manager (ACM)에서 관리하는 인증서의 만료 30일 전에 보안 팀에게 알림을 제공해야 합니다. 이를 해결하기 위한 최적의 솔루션을 선택해야 합니다.

### 옵션 분석

#### **A. Add a rule in ACM to publish a custom message to an Amazon Simple Notification Service (Amazon SNS) topic every day, beginning 30 days before any certificate will expire.**
- ACM은 인증서 만료에 대한 알림을 직접 관리하지 않습니다. 따라서 이 옵션은 실현 가능하지 않습니다.

#### **B. Create an AWS Config rule that checks for certificates that will expire within 30 days. Configure Amazon EventBridge (Amazon CloudWatch Events) to invoke a custom alert by way of Amazon Simple Notification Service (Amazon SNS) when AWS Config reports a noncompliant resource.**
- AWS Config 규칙을 사용하여 인증서 만료 상태를 확인하고, EventBridge를 통해 알림을 설정할 수 있지만, 이 방식은 추가적인 복잡성을 요구하고, Config의 주기적 검사에 의존하게 됩니다. 

#### **C. Use AWS Trusted Advisor to check for certificates that will expire within 30 days. Create an Amazon CloudWatch alarm that is based on Trusted Advisor metrics for check status changes. Configure the alarm to send a custom alert by way of Amazon Simple Notification Service (Amazon SNS).**
- AWS Trusted Advisor는 유용한 도구이지만, 인증서 만료를 위한 자동 알림을 설정하기 위한 솔루션으로 적합하지 않습니다. Trusted Advisor 체크는 정기적으로 실행되며, 직접적인 알림 기능을 제공하지 않습니다.

#### **D. Create an Amazon EventBridge (Amazon CloudWatch Events) rule to detect any certificates that will expire within 30 days. Configure the rule to invoke an AWS Lambda function. Configure the Lambda function to send a custom alert by way of Amazon Simple Notification Service (Amazon SNS).**
- EventBridge를 사용하여 인증서 만료를 감지하는 규칙을 생성하고, 이를 AWS Lambda 함수와 연결하여 SNS를 통해 알림을 보낼 수 있습니다. 이 방법은 인증서 만료 알림을 효율적으로 처리할 수 있으며, 즉각적인 반응이 가능합니다.

### **결론**
**정답은 D. Create an Amazon EventBridge (Amazon CloudWatch Events) rule to detect any certificates that will expire within 30 days. Configure the rule to invoke an AWS Lambda function. Configure the Lambda function to send a custom alert by way of Amazon Simple Notification Service (Amazon SNS).**입니다.

이 방법은 AWS Lambda를 통해 유연하게 처리할 수 있고, EventBridge를 사용하여 만료 인증서를 감지할 수 있어 보안 팀에게 필요한 알림을 신속하게 제공하는 데 적합합니다.

# 93번
**정답: B. Use Amazon Aurora MySQL with Multi-AZ Aurora Replicas for production. Use database cloning to create the staging database on-demand.**

**해설:**
- **Amazon Aurora MySQL:**
  - **고가용성 및 확장성:** Aurora MySQL은 고가용성과 확장성을 제공하며, Multi-AZ Aurora Replicas를 사용하여 읽기 성능을 향상시킬 수 있습니다.
  - **Aurora Replicas:** Aurora Replicas는 읽기 작업을 분산시켜 데이터베이스의 부하를 줄이고 성능을 향상시킵니다.

- **Database Cloning:**
  - **빠른 복제:** 데이터베이스 클로닝을 사용하면 전체 데이터베이스를 빠르게 복제할 수 있습니다. 이는 스테이징 환경을 신속하게 설정할 수 있도록 합니다.
  - **운영 오버헤드 최소화:** 클로닝은 백업 및 복원 과정보다 훨씬 빠르고 효율적이며, 운영 오버헤드를 최소화합니다.

**다른 보기가 정답이 될 수 없는 이유:**
- **A. mysqldump 사용:** mysqldump를 사용한 백업 및 복원 과정은 시간이 많이 걸리며, 여전히 애플리케이션 지연 문제를 해결하지 못할 수 있습니다.
- **C. 스탠바이 인스턴스 사용:** 스탠바이 인스턴스는 장애 복구를 위해 사용되며, 스테이징 데이터베이스로 사용하는 것은 적절하지 않습니다.
- **D. mysqldump 사용:** mysqldump를 사용한 백업 및 복원 과정은 시간이 많이 걸리며, 여전히 애플리케이션 지연 문제를 해결하지 못할 수 있습니다.

**출제 의도:**
이 문제는 AWS에서 MySQL 데이터베이스를 고가용성과 확장성을 갖춘 아키텍처로 마이그레이션하고, 애플리케이션 지연 문제를 해결하는 방법을 평가합니다. 특히, Amazon Aurora MySQL과 데이터베이스 클로닝을 사용하여 스테이징 환경을 신속하게 설정하고, 운영 오버헤드를 최소화하는 방법을 이해하는 것이 목적입니다.

**공부해야 하는 부분:**
1. **Amazon Aurora MySQL:**
   - Aurora MySQL의 기본 개념과 사용 사례
   - Multi-AZ Aurora Replicas를 사용하여 읽기 성능을 향상시키는 방법

2. **Database Cloning:**
   - 데이터베이스 클로닝의 기본 개념과 사용 사례
   - 클로닝을 사용하여 스테이징 환경을 신속하게 설정하는 방법

이 부분들을 공부하면, AWS에서 MySQL 데이터베이스를 고가용성과 확장성을 갖춘 아키텍처로 마이그레이션하고, 애플리케이션 지연 문제를 해결하는 방법을 더 잘 이해할 수 있습니다.

# 95번
- Creating read replicas allows the application to offload read traffic from the source database, improving its performance. The read replicas should be configured with the same compute and storage resources as the source database to ensure that they can handle the read workload effectively.

- 오프로딩(offloading): 컴퓨팅 자원 및 계산 속도의 한계를 극복하기 위해 로컬 컴퓨터에서 수행하는 어플리케이션 의 일부를 컴퓨팅 자원과 처리능력이 우수한 원격지 컴퓨터에 전달하여 처리한 후 결과를 반환받는 방식

### 정답
D. Create read replicas for the database. Configure the read replicas with the same compute and storage resources as the source database.

### 해설
애플리케이션 성능 저하 문제를 해결하기 위해 읽기 트래픽과 쓰기 트래픽을 분리하는 것이 필요합니다. Amazon RDS MySQL에서 읽기 복제본을 생성하면 읽기 작업을 복제본으로 분산시켜 기본 데이터베이스의 부하를 줄일 수 있습니다. 읽기 복제본을 원본 데이터베이스와 동일한 컴퓨팅 및 스토리지 리소스로 구성하면 성능을 최적화할 수 있습니다.

각 옵션을 자세히 살펴보면:

- **A. Change the existing database to a Multi-AZ deployment. Serve the read requests from the primary Availability Zone.**
  - Multi-AZ 배포는 고가용성을 제공하지만, 읽기 트래픽을 분리하는 데는 적합하지 않습니다. 기본 가용 영역에서 읽기 요청을 처리하면 성능 저하 문제가 해결되지 않습니다.

- **B. Change the existing database to a Multi-AZ deployment. Serve the read requests from the secondary Availability Zone.**
  - Multi-AZ 배포의 보조 가용 영역은 장애 조치 용도로만 사용되며, 읽기 요청을 처리할 수 없습니다.

- **C. Create read replicas for the database. Configure the read replicas with half of the compute and storage resources as the source database.**
  - 읽기 복제본을 생성하는 것은 적절한 접근 방식이지만, 원본 데이터베이스의 절반 리소스로 구성하면 성능이 저하될 수 있습니다.

- **D. Create read replicas for the database. Configure the read replicas with the same compute and storage resources as the source database.**
  - 읽기 복제본을 생성하고 원본 데이터베이스와 동일한 컴퓨팅 및 스토리지 리소스로 구성하면 성능을 최적화할 수 있습니다. 이는 읽기 트래픽을 분리하고 애플리케이션 성능을 빠르게 최적화하는 데 가장 적합한 솔루션입니다.

따라서, 회사의 요구 사항을 가장 효율적으로 충족하는 솔루션은 옵션 D입니다.

### 필요한 학습 내용

1. **Amazon RDS 읽기 복제본**
   - 읽기 복제본은 데이터베이스의 읽기 작업을 분산시켜 성능을 최적화할 수 있습니다.
   - 원본 데이터베이스와 동일한 컴퓨팅 및 스토리지 리소스로 구성하면 성능을 최적화할 수 있습니다.

2. **Amazon RDS Multi-AZ 배포**
   - Multi-AZ 배포는 고가용성을 제공하지만, 읽기 트래픽을 분리하는 데는 적합하지 않습니다.
   - 보조 가용 영역은 장애 조치 용도로만 사용됩니다.

### 추가 학습 자료
- [Amazon RDS 읽기 복제본 공식 문서](https://docs.aws.amazon.com/ko_kr/AmazonRDS/latest/UserGuide/USER_ReadRepl.html)
- [Amazon RDS Multi-AZ 배포 공식 문서](https://docs.aws.amazon.com/ko_kr/AmazonRDS/latest/UserGuide/Concepts.MultiAZ.html)

이 자료들을 통해 읽기 복제본과 Multi-AZ 배포의 다양한 기능과 설정 방법을 이해하고, 특정 시나리오에서 최적의 솔루션을 선택하는 능력을 키울 수 있습니다.

# 96번
### 정답
C. Users can terminate an EC2 instance in the us-east-1 Region when the user's source IP is 10.100.100.254.

### 해설
이 정책은 두 가지 주요 조건을 포함하고 있습니다:

1. **Allow 조건**: 특정 IP 주소 범위(10.100.100.0/24)에서 `ec2:TerminateInstances` 작업을 허용합니다.
2. **Deny 조건**: `ec2:*` 작업을 us-east-1 리전이 아닌 모든 리전에서 거부합니다.

이 정책의 효과를 분석해보면:

- 첫 번째 조건은 특정 IP 주소 범위(10.100.100.0/24)에서 `ec2:TerminateInstances` 작업을 허용합니다. 예를 들어, IP 주소가 10.100.100.254인 사용자는 이 작업을 수행할 수 있습니다.
- 두 번째 조건은 us-east-1 리전이 아닌 모든 리전에서 `ec2:*` 작업을 거부합니다. 즉, us-east-1 리전에서는 이 거부 조건이 적용되지 않습니다.

따라서, 사용자가 us-east-1 리전에서 특정 IP 주소 범위(10.100.100.0/24) 내에서 `ec2:TerminateInstances` 작업을 수행할 수 있습니다. 이는 옵션 C와 일치합니다.

### 필요한 학습 내용

1. **IAM 정책 조건**
   - IAM 정책에서 조건을 사용하여 특정 상황에서만 권한을 허용하거나 거부할 수 있습니다.
   - [`IpAddress`](command:_github.copilot.openSymbolFromReferences?%5B%22%22%2C%5B%7B%22uri%22%3A%7B%22scheme%22%3A%22file%22%2C%22authority%22%3A%22%22%2C%22path%22%3A%22%2Fe%3A%2FStudy%2FTheory-oriented%2FAmazon%2FExamTopics%20SAA-C03%20%EB%AC%B8%EC%A0%9C%2F91-100.md%22%2C%22query%22%3A%22%22%2C%22fragment%22%3A%22%22%7D%2C%22pos%22%3A%7B%22line%22%3A60%2C%22character%22%3A17%7D%7D%5D%2C%22f7ec7572-e7bb-495a-bf8e-45e56902ff28%22%5D "Go to definition") 조건은 특정 IP 주소 범위에서만 작업을 허용하거나 거부할 수 있습니다.
   - [`StringNotEquals`](command:_github.copilot.openSymbolFromReferences?%5B%22%22%2C%5B%7B%22uri%22%3A%7B%22scheme%22%3A%22file%22%2C%22authority%22%3A%22%22%2C%22path%22%3A%22%2Fe%3A%2FStudy%2FTheory-oriented%2FAmazon%2FExamTopics%20SAA-C03%20%EB%AC%B8%EC%A0%9C%2F91-100.md%22%2C%22query%22%3A%22%22%2C%22fragment%22%3A%22%22%7D%2C%22pos%22%3A%7B%22line%22%3A70%2C%22character%22%3A17%7D%7D%5D%2C%22f7ec7572-e7bb-495a-bf8e-45e56902ff28%22%5D "Go to definition") 조건은 특정 문자열 값이 일치하지 않을 때 작업을 허용하거나 거부할 수 있습니다.

2. **IAM 정책의 허용 및 거부**
   - IAM 정책에서 명시적으로 허용된 작업은 조건이 충족될 때만 허용됩니다.
   - 명시적으로 거부된 작업은 조건이 충족될 때 항상 거부됩니다.

### 추가 학습 자료
- [IAM 정책 조건 공식 문서](https://docs.aws.amazon.com/IAM/latest/UserGuide/reference_policies_elements_condition.html)
- [IAM 정책의 허용 및 거부 공식 문서](https://docs.aws.amazon.com/IAM/latest/UserGuide/reference_policies_evaluation-logic.html)

이 자료들을 통해 IAM 정책 조건과 허용 및 거부의 다양한 기능과 설정 방법을 이해하고, 특정 시나리오에서 최적의 솔루션을 선택하는 능력을 키울 수 있습니다.


# 98번
**정답: B. Change the SQS standard queue to an SQS FIFO queue. Use the message deduplication ID to discard duplicate messages.**

**해설:**
- **SQS FIFO Queue:**
  - **메시지 중복 제거:** SQS FIFO 큐는 메시지 중복 제거 기능을 제공하여 동일한 메시지가 여러 번 처리되는 것을 방지할 수 있습니다. 메시지 중복 제거 ID를 사용하면 동일한 메시지가 여러 번 처리되지 않도록 할 수 있습니다.
  - **순서 보장:** FIFO 큐는 메시지의 순서를 보장하므로, 메시지가 올바른 순서로 처리됩니다.

**다른 보기가 정답이 될 수 없는 이유:**
- **A. Long Polling:** Long Polling은 메시지를 더 효율적으로 수신하는 데 도움이 되지만, 메시지 중복 문제를 해결하지는 않습니다.
- **C. Visibility Timeout 증가:** Visibility Timeout을 증가시키면 메시지가 다시 처리되는 것을 방지할 수 있지만, 이는 메시지 처리 시간이 길어질 수 있는 경우에만 유효합니다. 또한, 이는 메시지 중복 문제를 완전히 해결하지 못할 수 있습니다.
- **D. Lambda 함수 수정:** Lambda 함수에서 메시지를 읽은 후 즉시 삭제하는 것은 메시지가 성공적으로 처리되었는지 확인하기 전에 삭제하는 것이므로, 데이터 손실의 위험이 있습니다.

**출제 의도:**
이 문제는 AWS에서 SQS와 Lambda를 사용하여 이벤트 기반 처리를 구현할 때 메시지 중복 문제를 해결하는 방법을 평가합니다. 특히, SQS FIFO 큐를 사용하여 메시지 중복 제거 기능을 활용하는 방법을 이해하는 것이 목적입니다.

**공부해야 하는 부분:**
1. **Amazon SQS FIFO Queue:**
   - FIFO 큐의 기본 개념과 사용 사례
   - 메시지 중복 제거 ID를 사용하여 메시지 중복을 방지하는 방법

2. **Visibility Timeout:**
   - Visibility Timeout의 기본 개념과 사용 사례
   - Visibility Timeout을 적절히 설정하여 메시지 중복 처리를 방지하는 방법

이 부분들을 공부하면, AWS에서 SQS와 Lambda를 사용하여 이벤트 기반 처리를 구현할 때 메시지 중복 문제를 해결하는 방법을 더 잘 이해할 수 있습니다.

# 102번
**정답: B. Install an AWS DataSync agent in the on-premises data center. E. Use AWS DataSync to create a suitable location configuration for the on-premises SFTP server.**

**해설:**
- **AWS DataSync:**
  - **데이터 전송 자동화:** DataSync는 온프레미스 데이터 센터와 AWS 간의 데이터 전송을 자동화하고 가속화하는 서비스입니다. 이를 통해 200GB의 데이터를 효율적으로 전송할 수 있습니다.
  - **NFS 지원:** DataSync는 NFS 기반 파일 시스템을 지원하므로, 온프레미스 SFTP 서버의 데이터를 EFS로 쉽게 전송할 수 있습니다.

- **B. DataSync 에이전트 설치:**
  - **온프레미스 데이터 센터:** DataSync 에이전트를 온프레미스 데이터 센터에 설치하여, 데이터를 AWS로 전송할 수 있습니다.

- **E. 위치 구성:**
  - **적절한 위치 구성:** DataSync를 사용하여 온프레미스 SFTP 서버의 위치 구성을 생성하고, 데이터를 EFS로 전송할 수 있습니다.

**다른 보기가 정답이 될 수 없는 이유:**
- **A. 동일한 가용 영역:** EC2 인스턴스를 EFS 파일 시스템과 동일한 가용 영역에 배치하는 것은 성능에 도움이 될 수 있지만, 데이터 전송을 자동화하는 데는 직접적인 관련이 없습니다.
- **C. EBS 볼륨 생성:** EBS 볼륨을 생성하는 것은 EFS를 사용하는 요구 사항과 맞지 않습니다.
- **D. 수동 복사:** 수동으로 데이터를 복사하는 것은 자동화된 솔루션이 아니며, 운영 오버헤드가 큽니다.

**출제 의도:**
이 문제는 AWS에서 온프레미스 데이터 센터의 데이터를 자동으로 AWS로 전송하는 방법을 평가합니다. 특히, AWS DataSync를 사용하여 데이터를 효율적으로 전송하고, 운영 오버헤드를 최소화하는 방법을 이해하는 것이 목적입니다.

**공부해야 하는 부분:**
1. **AWS DataSync:**
   - DataSync의 기본 개념과 사용 사례
   - DataSync를 사용하여 온프레미스 데이터 센터와 AWS 간의 데이터를 전송하는 방법

2. **Amazon EFS:**
   - EFS의 기본 개념과 사용 사례
   - EFS를 사용하여 데이터를 저장하고, EC2 인스턴스와 통합하는 방법

이 부분들을 공부하면, AWS에서 온프레미스 데이터 센터의 데이터를 자동으로 AWS로 전송하는 방법을 더 잘 이해할 수 있습니다.

# 104번
- B: GuardDuty는 공격자를 블락할 수 없으며, 데이터 소스나 이벤트 로그를 모니터링하고, 멀웨어 탐지 및 결과를 생성할 뿐임


# 107번
### 정답
D. Use Amazon API Gateway with Amazon Kinesis Data Analytics.

### 해설
자전거 공유 회사는 자전거 위치 데이터를 추적하고, 이 데이터를 기존 분석 플랫폼에서 사용할 수 있도록 해야 합니다. 또한, 데이터는 REST API를 통해 접근 가능해야 합니다. Amazon Kinesis Data Analytics는 실시간 데이터 스트리밍 분석을 제공하며, Amazon API Gateway는 REST API를 통해 데이터를 노출할 수 있습니다. 이 조합은 실시간 위치 데이터를 효율적으로 수집하고 분석하는 데 적합합니다.

각 옵션을 자세히 살펴보면:

- **A. Use Amazon Athena with Amazon S3.**
  - Amazon Athena는 S3에 저장된 데이터를 쿼리하는 데 사용되며, 실시간 데이터 스트리밍 분석에는 적합하지 않습니다.

- **B. Use Amazon API Gateway with AWS Lambda.**
  - API Gateway와 Lambda는 REST API를 제공하고 서버리스 컴퓨팅을 제공하지만, 실시간 데이터 스트리밍 분석에는 적합하지 않습니다.

- **C. Use Amazon QuickSight with Amazon Redshift.**
  - QuickSight는 데이터 시각화 도구이고, Redshift는 데이터 웨어하우징 솔루션입니다. 실시간 데이터 스트리밍 분석에는 적합하지 않습니다.

- **D. Use Amazon API Gateway with Amazon Kinesis Data Analytics.**
  - API Gateway는 REST API를 제공하고, Kinesis Data Analytics는 실시간 데이터 스트리밍 분석을 제공합니다. 이 조합은 실시간 위치 데이터를 효율적으로 수집하고 분석하는 데 적합합니다.

따라서, 회사의 요구 사항을 가장 효율적으로 충족하는 솔루션은 옵션 D입니다.

### 필요한 학습 내용

1. **Amazon Kinesis Data Analytics**
   - Kinesis Data Analytics는 실시간 데이터 스트리밍 분석을 제공하는 서비스입니다.
   - 실시간 위치 데이터를 효율적으로 수집하고 분석할 수 있습니다.

2. **Amazon API Gateway**
   - API Gateway는 REST API를 제공하는 서비스입니다.
   - 데이터를 노출하고 접근할 수 있는 인터페이스를 제공합니다.

3. **Amazon Athena**
   - Athena는 S3에 저장된 데이터를 쿼리하는 서비스입니다.
   - 실시간 데이터 스트리밍 분석에는 적합하지 않습니다.

4. **AWS Lambda**
   - Lambda는 서버리스 컴퓨팅을 제공하는 서비스입니다.
   - 실시간 데이터 스트리밍 분석에는 적합하지 않습니다.

5. **Amazon QuickSight**
   - QuickSight는 데이터 시각화 도구입니다.
   - 실시간 데이터 스트리밍 분석에는 적합하지 않습니다.

6. **Amazon Redshift**
   - Redshift는 데이터 웨어하우징 솔루션입니다.
   - 실시간 데이터 스트리밍 분석에는 적합하지 않습니다.

### 추가 학습 자료
- [Amazon Kinesis Data Analytics 공식 문서](https://docs.aws.amazon.com/ko_kr/kinesisanalytics/latest/dev/what-is.html)
- [Amazon API Gateway 공식 문서](https://docs.aws.amazon.com/ko_kr/apigateway/latest/developerguide/welcome.html)
- [Amazon Athena 공식 문서](https://docs.aws.amazon.com/ko_kr/athena/latest/ug/what-is.html)
- [AWS Lambda 공식 문서](https://docs.aws.amazon.com/ko_kr/lambda/latest/dg/welcome.html)
- [Amazon QuickSight 공식 문서](https://docs.aws.amazon.com/ko_kr/quicksight/latest/user/welcome.html)
- [Amazon Redshift 공식 문서](https://docs.aws.amazon.com/ko_kr/redshift/latest/mgmt/welcome.html)

이 자료들을 통해 Kinesis Data Analytics, API Gateway, Athena, Lambda, QuickSight, Redshift의 다양한 기능과 설정 방법을 이해하고, 특정 시나리오에서 최적의 솔루션을 선택하는 능력을 키울 수 있습니다.

# 108번
- Amazon SNS는 Pub/Sub의 브로드캐스트 모델이고, Amazon SQS 큐잉 모델
- 브로드캐스트 모델은 단순히 전달만 할 뿐, 정상적으로 전달되었는지 여부는 상관하지 않음
- 반면 큐잉 모델은 데이터가 전달되어야 하는 정상 상태의 처리자가 반드시 필요하며, 데이터를 받을 처리자가 없으면 해당 데이터는 큐에 보관됨
- 이 문제에서 회사는 Multiple target systems를 보유하므로, SNS를 통해 갱신 정보를 브로드캐스팅하여 각각의 시스템이 개별적으로 람다를 실행시키는 것이 효과적임
- A의 문제점은 단일 SQS를 사용하는 점인데, 하나의 SQS는 곧 여러 시스템에 의한 중복 소비를 발생시키는데 이를 방지하기 위한 처리가 상당히 까다롭고 복잡함

### 정답
D. Subscribe to an RDS event notification and send an Amazon Simple Notification Service (Amazon SNS) topic fanned out to multiple Amazon Simple Queue Service (Amazon SQS) queues. Use AWS Lambda functions to update the targets.

### 해설
자동차 판매 웹사이트에서 자동차가 판매될 때, 해당 목록을 웹사이트에서 제거하고 데이터를 여러 대상 시스템으로 전송해야 합니다. 이를 위해 RDS 이벤트 알림을 구독하고, Amazon SNS 주제를 사용하여 여러 Amazon SQS 큐로 데이터를 팬아웃(fan-out)하는 것이 가장 적합한 솔루션입니다. 각 SQS 큐는 대상 시스템으로 데이터를 전송하는 AWS Lambda 함수를 트리거할 수 있습니다.

각 옵션을 자세히 살펴보면:

- **A. Create an AWS Lambda function triggered when the database on Amazon RDS is updated to send the information to an Amazon Simple Queue Service (Amazon SQS) queue for the targets to consume.**
  - Lambda 함수를 사용하여 RDS 업데이트 시 SQS 큐로 데이터를 전송하는 것은 가능하지만, 여러 대상 시스템으로 데이터를 팬아웃하는 기능이 부족합니다.

- **B. Create an AWS Lambda function triggered when the database on Amazon RDS is updated to send the information to an Amazon Simple Queue Service (Amazon SQS) FIFO queue for the targets to consume.**
  - FIFO 큐를 사용하는 것은 순서 보장이 필요한 경우에 적합하지만, 이 시나리오에서는 필요하지 않습니다. 또한, 팬아웃 기능이 부족합니다.

- **C. Subscribe to an RDS event notification and send an Amazon Simple Queue Service (Amazon SQS) queue fanned out to multiple Amazon Simple Notification Service (Amazon SNS) topics. Use AWS Lambda functions to update the targets.**
  - SQS 큐에서 SNS 주제로 팬아웃하는 것은 일반적인 패턴이 아니며, SNS 주제에서 SQS 큐로 팬아웃하는 것이 더 적합합니다.

- **D. Subscribe to an RDS event notification and send an Amazon Simple Notification Service (Amazon SNS) topic fanned out to multiple Amazon Simple Queue Service (Amazon SQS) queues. Use AWS Lambda functions to update the targets.**
  - RDS 이벤트 알림을 구독하고, SNS 주제를 사용하여 여러 SQS 큐로 데이터를 팬아웃하는 것은 가장 적합한 솔루션입니다. 각 SQS 큐는 대상 시스템으로 데이터를 전송하는 Lambda 함수를 트리거할 수 있습니다.

따라서, 회사의 요구 사항을 가장 효율적으로 충족하는 솔루션은 옵션 D입니다.

### 필요한 학습 내용

1. **Amazon RDS 이벤트 알림**
   - RDS 이벤트 알림을 사용하여 데이터베이스 이벤트를 감지하고, 이를 기반으로 작업을 트리거할 수 있습니다.

2. **Amazon SNS**
   - SNS는 메시지를 여러 구독자에게 팬아웃할 수 있는 메시징 서비스입니다.
   - SNS 주제를 사용하여 여러 SQS 큐로 메시지를 팬아웃할 수 있습니다.

3. **Amazon SQS**
   - SQS는 메시지를 큐에 저장하고, 이를 소비자에게 전달하는 메시징 서비스입니다.
   - 여러 SQS 큐를 사용하여 데이터를 여러 대상 시스템으로 분산시킬 수 있습니다.

4. **AWS Lambda**
   - Lambda는 서버리스 컴퓨팅 서비스로, 특정 이벤트에 따라 코드를 실행할 수 있습니다.
   - SQS 큐에서 메시지를 소비하고, 대상 시스템으로 데이터를 전송하는 데 사용할 수 있습니다.

### 추가 학습 자료
- [Amazon RDS 이벤트 알림 공식 문서](https://docs.aws.amazon.com/ko_kr/AmazonRDS/latest/UserGuide/USER_Events.html)
- [Amazon SNS 공식 문서](https://docs.aws.amazon.com/ko_kr/sns/latest/dg/welcome.html)
- [Amazon SQS 공식 문서](https://docs.aws.amazon.com/ko_kr/AWSSimpleQueueService/latest/SQSDeveloperGuide/welcome.html)
- [AWS Lambda 공식 문서](https://docs.aws.amazon.com/ko_kr/lambda/latest/dg/welcome.html)

이 자료들을 통해 RDS 이벤트 알림, SNS, SQS, Lambda의 다양한 기능과 설정 방법을 이해하고, 특정 시나리오에서 최적의 솔루션을 선택하는 능력을 키울 수 있습니다.

# 113번
- AWS Snowball Edge Storage Optimized는 대용량 데이터를 효율적으로 전송할 수 있는 장치로, 네트웤크 대역폭이 부족한 상황에서도 사용 가능
- A: AWS DataSync는 네트워크를 통한 데이터 전송 서비스로, 추가적인 대역폭이 없음
- B: AWS Snowcones는 소규모 데이터 전송에 적합
- D: AWS Snowball Edge Storage Optimized 장치에 EC2 컴퓨팅 기능 포함 가능하지만, 데이터 전송 후에 AWS Glue를 사용하는 것이 더 효율적이며 운영 오버헤드가 적음

### 정답
C. Order an AWS Snowball Edge Storage Optimized device. Copy the data to the device. Create a custom transformation job by using AWS Glue.

### 해설
회사는 50TB의 데이터를 온프레미스에서 AWS로 이동해야 하며, 네트워크 대역폭이 부족하여 추가 작업을 수행할 수 없습니다. AWS Snowball Edge Storage Optimized 장치를 사용하면 대량의 데이터를 물리적으로 AWS로 전송할 수 있습니다. AWS Glue를 사용하여 데이터 변환 작업을 수행하면 관리 오버헤드가 최소화됩니다.

각 옵션을 자세히 살펴보면:

- **A. Use AWS DataSync to move the data. Create a custom transformation job by using AWS Glue.**
  - DataSync는 네트워크를 통해 데이터를 전송하므로, 네트워크 대역폭이 부족한 상황에서는 적합하지 않습니다.

- **B. Order an AWS Snowcone device to move the data. Deploy the transformation application to the device.**
  - Snowcone는 소규모 데이터 전송에 적합하며, 50TB의 데이터를 전송하는 데는 적합하지 않습니다.

- **C. Order an AWS Snowball Edge Storage Optimized device. Copy the data to the device. Create a custom transformation job by using AWS Glue.**
  - Snowball Edge Storage Optimized 장치는 대량의 데이터를 물리적으로 전송하는 데 적합합니다. AWS Glue를 사용하여 데이터 변환 작업을 수행하면 관리 오버헤드가 최소화됩니다.

- **D. Order an AWS Snowball Edge Storage Optimized device that includes Amazon EC2 compute. Copy the data to the device. Create a new EC2 instance on AWS to run the transformation application.**
  - Snowball Edge Storage Optimized 장치에 EC2 컴퓨팅을 포함시키는 것은 가능하지만, AWS Glue를 사용하는 것이 더 간단하고 관리 오버헤드가 적습니다.

따라서, 회사의 요구 사항을 가장 효율적으로 충족하는 솔루션은 옵션 C입니다.

### 필요한 학습 내용

1. **AWS Snowball Edge Storage Optimized**
   - Snowball Edge Storage Optimized 장치는 대량의 데이터를 물리적으로 전송하는 데 적합합니다.
   - 네트워크 대역폭이 부족한 상황에서도 데이터를 전송할 수 있습니다.

2. **AWS Glue**
   - AWS Glue는 완전 관리형 ETL(Extract, Transform, Load) 서비스로, 데이터 변환 작업을 자동화할 수 있습니다.
   - 관리 오버헤드가 최소화됩니다.

3. **AWS DataSync**
   - DataSync는 네트워크를 통해 데이터를 전송하는 서비스입니다.
   - 네트워크 대역폭이 부족한 상황에서는 적합하지 않습니다.

4. **AWS Snowcone**
   - Snowcone은 소규모 데이터 전송에 적합한 장치입니다.
   - 50TB의 데이터를 전송하는 데는 적합하지 않습니다.

### 추가 학습 자료
- [AWS Snowball Edge Storage Optimized 공식 문서](https://docs.aws.amazon.com/ko_kr/snowball/latest/developer-guide/what-is-snowball.html)
- [AWS Glue 공식 문서](https://docs.aws.amazon.com/ko_kr/glue/latest/dg/what-is-glue.html)
- [AWS DataSync 공식 문서](https://docs.aws.amazon.com/ko_kr/datasync/latest/userguide/what-is-datasync.html)
- [AWS Snowcone 공식 문서](https://docs.aws.amazon.com/ko_kr/snowcone/latest/developer-guide/what-is-snowcone.html)

이 자료들을 통해 Snowball Edge Storage Optimized, Glue, DataSync, Snowcone의 다양한 기능과 설정 방법을 이해하고, 특정 시나리오에서 최적의 솔루션을 선택하는 능력을 키울 수 있습니다.

# 116번
**정답: A. Configure Amazon CloudFront in front of the website to use HTTPS functionality. D. Create the new website and an Amazon S3 bucket. Deploy the website on the S3 bucket with static website hosting enabled.**

**해설:**
- **Amazon S3 with Static Website Hosting:**
  - **저비용 및 고확장성:** S3는 정적 웹사이트 호스팅을 지원하며, 저비용으로 높은 확장성을 제공합니다. 정적 콘텐츠를 저장하고 제공하는 데 적합합니다.
  - **운영 오버헤드 최소화:** S3는 관리형 서비스로, 패치 및 유지 관리가 필요하지 않습니다. 이는 운영 오버헤드를 최소화합니다.

- **Amazon CloudFront:**
  - **콘텐츠 전송 네트워크 (CDN):** CloudFront는 전 세계에 분산된 엣지 로케이션을 통해 콘텐츠를 제공하므로, 웹사이트의 성능과 가용성을 향상시킵니다.
  - **HTTPS 지원:** CloudFront는 HTTPS를 지원하여, 웹사이트의 보안을 강화할 수 있습니다.

**다른 보기가 정답이 될 수 없는 이유:**
- **B. AWS WAF:** WAF는 웹 애플리케이션 방화벽으로, HTTPS 기능을 제공하지 않습니다. 보안 강화에는 도움이 되지만, HTTPS를 설정하는 데는 적합하지 않습니다.
- **C. AWS Lambda:** Lambda는 서버리스 컴퓨팅 서비스로, 정적 콘텐츠를 제공하는 데는 적합하지 않습니다. 또한, 운영 오버헤드가 증가할 수 있습니다.
- **E. EC2와 Auto Scaling:** EC2 인스턴스를 사용하여 웹사이트를 호스팅하는 것은 운영 오버헤드가 크며, 정적 콘텐츠를 제공하는 데는 과도한 솔루션입니다.

**출제 의도:**
이 문제는 AWS에서 정적 웹사이트를 호스팅하고, 높은 확장성과 보안을 제공하는 방법을 평가합니다. 특히, Amazon S3와 CloudFront를 사용하여 정적 웹사이트를 호스팅하고, HTTPS를 통해 보안을 강화하는 방법을 이해하는 것이 목적입니다.

**공부해야 하는 부분:**
1. **Amazon S3 Static Website Hosting:**
   - S3의 정적 웹사이트 호스팅 기능과 사용 사례
   - S3를 사용하여 정적 웹사이트를 호스팅하는 방법

2. **Amazon CloudFront:**
   - CloudFront의 기본 개념과 사용 사례
   - CloudFront를 사용하여 콘텐츠를 전송하고, HTTPS를 통해 보안을 강화하는 방법

이 부분들을 공부하면, AWS에서 정적 웹사이트를 호스팅하고, 높은 확장성과 보안을 제공하는 방법을 더 잘 이해할 수 있습니다.

# 119번
**정답: B. Set up AWS Firewall Manager in both Regions. Centrally configure AWS WAF rules.**

**해설:**
- **AWS Firewall Manager:**
  - **중앙 관리:** Firewall Manager는 여러 계정과 리전에서 AWS WAF 규칙을 중앙에서 관리할 수 있습니다. 이는 관리 오버헤드를 줄이고, 일관된 보안 정책을 적용하는 데 도움이 됩니다.
  - **자동 적용:** Firewall Manager는 새로운 리소스가 생성될 때 자동으로 WAF 규칙을 적용할 수 있어, 관리 작업을 최소화합니다.

- **AWS WAF:**
  - **웹 애플리케이션 방화벽:** WAF는 SQL 인젝션 및 크로스 사이트 스크립팅(XSS) 공격을 방어할 수 있는 규칙을 제공합니다. API Gateway와 통합하여 REST API를 보호할 수 있습니다.

**다른 보기가 정답이 될 수 없는 이유:**
- **A. AWS WAF in both Regions:** 각 리전에 별도로 WAF를 설정하고 관리하는 것은 관리 오버헤드가 큽니다. 중앙에서 관리할 수 있는 Firewall Manager를 사용하는 것이 더 효율적입니다.
- **C. AWS Shield:** AWS Shield는 주로 DDoS 공격을 방어하는 데 사용되며, SQL 인젝션 및 XSS 공격을 방어하는 데는 적합하지 않습니다.
- **D. AWS Shield in one Region:** AWS Shield는 DDoS 공격 방어에 적합하며, SQL 인젝션 및 XSS 공격을 방어하는 데는 적합하지 않습니다. 또한, 한 리전에만 설정하는 것은 글로벌 보호를 제공하지 않습니다.

**출제 의도:**
이 문제는 AWS에서 여러 계정과 리전에 걸쳐 API Gateway를 보호하는 방법을 평가합니다. 특히, AWS Firewall Manager와 WAF를 사용하여 중앙에서 보안 규칙을 관리하고, SQL 인젝션 및 XSS 공격을 방어하는 방법을 이해하는 것이 목적입니다.

**공부해야 하는 부분:**
1. **AWS Firewall Manager:**
   - Firewall Manager의 기본 개념과 사용 사례
   - Firewall Manager를 사용하여 여러 계정과 리전에서 WAF 규칙을 중앙에서 관리하는 방법

2. **AWS WAF:**
   - WAF의 기본 개념과 사용 사례
   - WAF를 사용하여 SQL 인젝션 및 XSS 공격을 방어하는 방법

이 부분들을 공부하면, AWS에서 여러 계정과 리전에 걸쳐 API Gateway를 보호하는 방법을 더 잘 이해할 수 있습니다.

# 121번
**정답: A. Encrypt a copy of the latest DB snapshot. Replace existing DB instance by restoring the encrypted snapshot.**

**해설:**
- **RDS 스냅샷 암호화:**
  - **스냅샷 암호화:** RDS 인스턴스가 암호화되지 않은 경우, 직접적으로 인스턴스를 암호화할 수 없습니다. 대신, 최신 스냅샷을 암호화된 스냅샷으로 복사한 후, 이 암호화된 스냅샷을 사용하여 새로운 암호화된 RDS 인스턴스를 생성할 수 있습니다.
  - **기존 인스턴스 교체:** 암호화된 스냅샷을 복원하여 새로운 암호화된 RDS 인스턴스를 생성한 후, 기존의 암호화되지 않은 인스턴스를 교체할 수 있습니다.

**다른 보기가 정답이 될 수 없는 이유:**
- **B. EBS 볼륨 암호화:** RDS 인스턴스의 스냅샷을 EBS 볼륨으로 복사하는 것은 적절한 방법이 아닙니다. RDS 스냅샷은 RDS 인스턴스와 직접적으로 연관되어 있어야 합니다.
- **C. 기존 인스턴스에 복원:** 암호화된 스냅샷을 기존의 암호화되지 않은 인스턴스에 복원할 수 없습니다. 새로운 암호화된 인스턴스를 생성해야 합니다.
- **D. S3로 복사:** 스냅샷을 S3로 복사하는 것은 백업 목적으로는 유용할 수 있지만, RDS 인스턴스를 암호화하는 데는 적합하지 않습니다.

**출제 의도:**
이 문제는 AWS에서 RDS 인스턴스와 스냅샷을 암호화하는 방법을 평가합니다. 특히, 암호화되지 않은 RDS 인스턴스를 암호화된 인스턴스로 교체하는 방법을 이해하는 것이 목적입니다.

**공부해야 하는 부분:**
1. **Amazon RDS 스냅샷 암호화:**
   - RDS 스냅샷을 암호화하는 방법
   - 암호화된 스냅샷을 사용하여 새로운 암호화된 RDS 인스턴스를 생성하는 방법

2. **AWS Key Management Service (KMS):**
   - KMS의 기본 개념과 사용 사례
   - KMS를 사용하여 RDS 스냅샷을 암호화하는 방법

이 부분들을 공부하면, AWS에서 RDS 인스턴스와 스냅샷을 암호화하는 방법을 더 잘 이해할 수 있습니다.

# 122번
문제: 회사는 개발자가 애플리케이션에서 데이터를 암호화할 수 있도록 지원하는 확장 가능한 키 관리 인프라를 구축하고자 합니다. 운영 부담을 줄이기 위해 솔루션 아키텍트는 무엇을 해야 합니까?

해설
B: AWS Key Management Service (AWS KMS)는 암호화 키를 생성, 관리 및 보호하는 완전 관리형 서비스입니다. KMS를 사용하면 키 관리와 관련된 많은 운영 부담을 AWS가 대신 처리해주므로, 운영 부담을 크게 줄일 수 있습니다. 또한, KMS는 자동으로 키를 회전하고, 키 사용을 모니터링하며, 다양한 AWS 서비스와 통합되어 사용이 편리합니다.

다른 선택지의 문제점
A: 다중 요소 인증(MFA)은 보안 강화를 위해 유용하지만, 키 관리 인프라의 운영 부담을 줄이는 데 직접적인 도움이 되지 않습니다.
C: AWS Certificate Manager (ACM)는 SSL/TLS 인증서를 관리하는 서비스로, 암호화 키 관리와는 다른 목적을 가지고 있습니다.
D: IAM 정책을 사용하여 사용자 접근 권한

### 정답
B. Use AWS Key Management Service (AWS KMS) to protect the encryption keys.

### 해설
AWS Key Management Service (AWS KMS)는 암호화 키를 생성, 관리 및 보호하는 완전 관리형 서비스입니다. KMS를 사용하면 키 관리의 운영 부담을 줄이고, 개발자가 애플리케이션에서 데이터를 암호화하는 데 필요한 인프라를 쉽게 구축할 수 있습니다. KMS는 자동 키 회전, 키 정책 관리, 감사 로그 생성 등 다양한 기능을 제공하여 운영 부담을 최소화합니다.

각 옵션을 자세히 살펴보면:

- **A. Use multi-factor authentication (MFA) to protect the encryption keys.**
  - MFA는 보안 강화를 위한 방법이지만, 키 관리 인프라를 구축하고 운영 부담을 줄이는 데 직접적인 도움이 되지 않습니다.

- **B. Use AWS Key Management Service (AWS KMS) to protect the encryption keys.**
  - AWS KMS는 암호화 키를 생성, 관리 및 보호하는 완전 관리형 서비스로, 키 관리의 운영 부담을 줄이는 데 가장 적합한 솔루션입니다.

- **C. Use AWS Certificate Manager (ACM) to create, store, and assign the encryption keys.**
  - ACM은 SSL/TLS 인증서를 관리하는 서비스로, 암호화 키 관리에는 적합하지 않습니다.

- **D. Use an IAM policy to limit the scope of users who have access permissions to protect the encryption keys.**
  - IAM 정책을 사용하여 사용자 접근 권한을 제한하는 것은 보안 강화를 위한 방법이지만, 키 관리 인프라를 구축하고 운영 부담을 줄이는 데 직접적인 도움이 되지 않습니다.

따라서, 회사의 요구 사항을 가장 효율적으로 충족하는 솔루션은 옵션 B입니다.

### 필요한 학습 내용

1. **AWS Key Management Service (KMS)**
   - KMS는 암호화 키를 생성, 관리 및 보호하는 완전 관리형 서비스입니다.
   - 자동 키 회전, 키 정책 관리, 감사 로그 생성 등 다양한 기능을 제공합니다.

2. **Multi-Factor Authentication (MFA)**
   - MFA는 보안 강화를 위한 방법으로, 추가적인 인증 단계를 요구합니다.
   - 키 관리 인프라를 구축하는 데 직접적인 도움이 되지 않습니다.

3. **AWS Certificate Manager (ACM)**
   - ACM은 SSL/TLS 인증서를 관리하는 서비스입니다.
   - 암호화 키 관리에는 적합하지 않습니다.

4. **IAM 정책**
   - IAM 정책을 사용하여 사용자 접근 권한을 제한할 수 있습니다.
   - 키 관리 인프라를 구축하는 데 직접적인 도움이 되지 않습니다.

### 추가 학습 자료
- [AWS Key Management Service (KMS) 공식 문서](https://docs.aws.amazon.com/ko_kr/kms/latest/developerguide/overview.html)
- [Multi-Factor Authentication (MFA) 공식 문서](https://docs.aws.amazon.com/ko_kr/IAM/latest/UserGuide/id_credentials_mfa.html)
- [AWS Certificate Manager (ACM) 공식 문서](https://docs.aws.amazon.com/ko_kr/acm/latest/userguide/acm-overview.html)
- [IAM 정책 공식 문서](https://docs.aws.amazon.com/ko_kr/IAM/latest/UserGuide/access_policies.html)

이 자료들을 통해 KMS, MFA, ACM, IAM 정책의 다양한 기능과 설정 방법을 이해하고, 특정 시나리오에서 최적의 솔루션을 선택하는 능력을 키울 수 있습니다.

# 124번
문제 번역
회사는 많은 Amazon EC2 인스턴스를 사용하여 완료하는 매우 동적인 배치 처리 작업을 가지고 있습니다. 이 작업은 상태가 없으며, 언제든지 시작하고 중지할 수 있으며, 총 완료 시간은 보통 60분 이상 걸립니다. 회사는 솔루션 아키텍트에게 이 작업의 요구사항을 충족하는 확장 가능하고 비용 효율적인 솔루션을 설계해 달라고 요청했습니다. 솔루션 아키텍트는 무엇을 추천해야 합니까?

정답
A. Implement EC2 Spot Instances.

해설
A: EC2 Spot Instances는 AWS의 미사용 EC2 용량을 활용하여 최대 90%까지 비용을 절감할 수 있는 옵션입니다. 이 작업은 상태가 없고 언제든지 중지 및 시작할 수 있으므로, Spot Instances의 일시적인 중단 가능성에도 불구하고 적합합니다. 이는 확장 가능하고 비용 효율적인 솔루션입니다.
다른 선택지의 문제점
B: EC2 Reserved Instances는 장기적으로 특정 용량을 예약하여 비용을 절감할 수 있지만, 동적인 배치 처리 작업에는 유연성이 부족합니다.
C: EC2 On-Demand Instances는 유연하지만, 비용이 더 높을 수 있습니다. 상태가 없는 작업에는 Spot Instances가 더 비용 효율적입니다.
D: AWS Lambda는 짧은 실행 시간의 이벤트 기반 작업에 적합하지만, 60분 이상 걸리는 배치 처리 작업에는 적합하지 않습니다.
따라서, A 선택지가 확장 가능하고 비용 효율적인 솔루션을 제공하는 데 가장 적합합니다.

# 125번
**정답: A. Use an Auto Scaling group to launch the EC2 instances in private subnets. Deploy an RDS Multi-AZ DB instance in private subnets. E. Configure a VPC with two public subnets, two private subnets, and two NAT gateways across two Availability Zones. Deploy an Application Load Balancer in the public subnets.**

**해설:**
- **A. EC2 인스턴스와 RDS 인스턴스를 프라이빗 서브넷에 배치:**
  - **보안:** EC2 인스턴스와 RDS 인스턴스를 프라이빗 서브넷에 배치하면, 이 인스턴스들이 공용 인터넷에 노출되지 않으므로 보안이 강화됩니다.
  - **고가용성:** Auto Scaling 그룹을 사용하여 EC2 인스턴스를 관리하면, 인스턴스의 가용성을 높일 수 있습니다. RDS Multi-AZ 배포는 데이터베이스의 고가용성을 보장합니다.

- **E. VPC 구성:**
  - **공용 및 프라이빗 서브넷:** 두 개의 공용 서브넷과 두 개의 프라이빗 서브넷을 사용하여, 애플리케이션의 웹 계층과 데이터베이스 계층을 분리할 수 있습니다.
  - **NAT 게이트웨이:** 두 개의 NAT 게이트웨이를 사용하여, 프라이빗 서브넷의 EC2 인스턴스가 인터넷에 접근할 수 있도록 합니다. 이는 EC2 인스턴스가 결제 처리와 같은 외부 웹 서비스를 사용할 수 있도록 합니다.
  - **Application Load Balancer:** ALB를 공용 서브넷에 배치하여, 외부 트래픽을 EC2 인스턴스로 라우팅할 수 있습니다.

**다른 보기가 정답이 될 수 없는 이유:**
- **B. ALB를 프라이빗 서브넷에 배치:** ALB를 프라이빗 서브넷에 배치하면, 외부 트래픽을 수신할 수 없으므로 적합하지 않습니다.
- **C. EC2 인스턴스를 공용 서브넷에 배치:** EC2 인스턴스를 공용 서브넷에 배치하면, 인스턴스가 공용 인터넷에 노출되므로 보안 요구 사항을 충족하지 않습니다.
- **D. 하나의 공용 서브넷과 하나의 프라이빗 서브넷:** 하나의 공용 서브넷과 하나의 프라이빗 서브넷만 사용하는 것은 고가용성을 보장하지 않습니다.

**출제 의도:**
이 문제는 AWS에서 이중 계층 아키텍처를 사용하여 웹 애플리케이션을 배포하고, 보안과 고가용성을 보장하는 방법을 평가합니다. 특히, VPC 서브넷 구성, NAT 게이트웨이 사용, Auto Scaling 그룹 및 RDS Multi-AZ 배포를 이해하는 것이 목적입니다.

**공부해야 하는 부분:**
1. **VPC 서브넷 구성:**
   - 공용 서브넷과 프라이빗 서브넷의 차이점과 사용 사례
   - NAT 게이트웨이를 사용하여 프라이빗 서브넷의 인스턴스가 인터넷에 접근하는 방법

2. **Auto Scaling 그룹:**
   - Auto Scaling 그룹의 기본 개념과 사용 사례
   - Auto Scaling 그룹을 사용하여 EC2 인스턴스의 가용성을 높이는 방법

3. **RDS Multi-AZ 배포:**
   - RDS Multi-AZ 배포의 기본 개념과 사용 사례
   - RDS Multi-AZ 배포를 사용하여 데이터베이스의 고가용성을 보장하는 방법

이 부분들을 공부하면, AWS에서 이중 계층 아키텍처를 사용하여 웹 애플리케이션을 배포하고, 보안과 고가용성을 보장하는 방법을 더 잘 이해할 수 있습니다.

# 127번
문제 번역
미디어 회사가 시스템을 AWS 클라우드로 이전할 가능성을 평가하고 있습니다. 회사는 비디오 처리에 최대한의 I/O 성능을 제공하는 최소 10TB의 스토리지, 미디어 콘텐츠를 저장하기 위한 300TB의 매우 내구성 있는 스토리지, 더 이상 사용되지 않는 아카이브 미디어를 위한 900TB의 스토리지가 필요합니다. 솔루션 아키텍트는 이러한 요구사항을 충족하기 위해 어떤 서비스 세트를 추천해야 합니까?

정답
A. Amazon EBS for maximum performance, Amazon S3 for durable data storage, and Amazon S3 Glacier for archival storage

해설
Amazon EBS (Elastic Block Store): EBS는 고성능 I/O를 제공하는 블록 스토리지 서비스로, 비디오 처리와 같은 고성능 작업에 적합합니다.
Amazon S3 (Simple Storage Service): S3는 높은 내구성과 가용성을 제공하는 객체 스토리지 서비스로, 미디어 콘텐츠와 같은 데이터를 저장하는 데 적합합니다.
Amazon S3 Glacier: S3 Glacier는 장기 아카이브 스토리지 서비스로, 자주 접근하지 않는 데이터를 비용 효율적으로 저장하는 데 적합합니다.
다른 선택지의 문제점
B: Amazon EFS는 파일 스토리지 서비스로, 대규모 데이터 저장에는 적합하지만, S3보다 비용이 높을 수 있습니다.
C: Amazon EC2 instance store는 인스턴스가 종료되면 데이터가 사라지므로, 내구성 있는 데이터 저장에는 적합하지 않습니다.
D: Amazon EC2 instance store는 내구성 있는 데이터 저장에 적합하지 않으며, S3는 아카이브 스토리지로 사용하기에는 비용이 높을 수 있습니다.
따라서, A 선택지가 요구사항을 충족하는 가장 적합한 솔루션입니다.

# 128번
문제 번역
회사는 AWS 클라우드에서 컨테이너로 애플리케이션을 실행하고자 합니다. 이 애플리케이션들은 상태가 없으며, 기본 인프라의 중단을 견딜 수 있습니다. 회사는 비용과 운영 오버헤드를 최소화하는 솔루션이 필요합니다. 솔루션 아키텍트는 이러한 요구사항을 충족하기 위해 무엇을 해야 합니까?

정답
B. Use Spot Instances in an Amazon Elastic Kubernetes Service (Amazon EKS) managed node group.

해설
B: Amazon EKS는 관리형 Kubernetes 서비스로, 컨테이너 오케스트레이션을 자동화하여 운영 오버헤드를 줄입니다. Spot Instances를 사용하면 비용을 크게 절감할 수 있으며, 애플리케이션이 상태가 없고 중단을 견딜 수 있으므로 적합합니다. EKS 관리 노드 그룹을 사용하면 Kubernetes 클러스터의 노드 관리를 AWS가 대신 처리해주므로 운영 오버헤드가 최소화됩니다.
다른 선택지의 문제점
A: EC2 Auto Scaling 그룹을 사용하여 컨테이너를 실행하는 것은 가능하지만, EKS를 사용하면 Kubernetes 관리가 자동화되어 운영 오버헤드가 더 낮습니다.
C: On-Demand Instances는 유연하지만 비용이 더 높을 수 있습니다. 상태가 없는 애플리케이션에는 Spot Instances가 더 비용 효율적입니다.
D: On-Demand Instances는 비용이 더 높을 수 있으며, 상태가 없는 애플리케이션에는 Spot Instances가 더 적합합니다.
따라서, B 선택지가 요구사항을 충족하는 가장 적합한 솔루션입니다.

# 130번
문제 번역
애플리케이션이 여러 가용 영역에 걸쳐 Amazon EC2 인스턴스에서 실행됩니다. 인스턴스는 Application Load Balancer 뒤에 있는 Amazon EC2 Auto Scaling 그룹에서 실행됩니다. 애플리케이션은 EC2 인스턴스의 CPU 사용률이 40%에 가깝거나 그 이하일 때 최상의 성능을 발휘합니다. 솔루션 아키텍트는 그룹의 모든 인스턴스에서 원하는 성능을 유지하기 위해 무엇을 해야 합니까?

정답
B. Use a target tracking policy to dynamically scale the Auto Scaling group.

해설
B: 타겟 추적 정책(Target Tracking Policy)은 Auto Scaling 그룹의 평균 CPU 사용률을 특정 목표(이 경우 40%)로 유지하도록 자동으로 조정합니다. 이는 CPU 사용률이 목표 수준에 도달하도록 인스턴스를 동적으로 추가하거나 제거하여 원하는 성능을 유지하는 데 가장 적합한 방법입니다.
다른 선택지의 문제점
A: 단순 스케일링 정책(Simple Scaling Policy)은 특정 조건이 충족될 때만 인스턴스를 추가하거나 제거합니다. 이는 CPU 사용률을 일정하게 유지하는 데 충분하지 않을 수 있습니다.
C: AWS Lambda 함수를 사용하여 Auto Scaling 그룹의 용량을 업데이트하는 것은 복잡하고 유지 관리가 어려울 수 있습니다.
D: 예약된 스케일링 작업(Scheduled Scaling Actions)은 특정 시간에만 스케일링을 수행하므로, 실시간으로 변동하는 CPU 사용률을 효과적으로 관리하지 못할 수 있습니다.
따라서, B 선택지가 그룹의 모든 인스턴스에서 원하는 성능을 유지하는 데 가장 적합한 솔루션입니다.


# 131번
문제 번역
회사는 파일 공유 애플리케이션을 개발 중이며, Amazon S3 버킷을 스토리지로 사용할 예정입니다. 회사는 모든 파일을 Amazon CloudFront 배포를 통해 제공하고자 합니다. 회사는 파일이 S3 URL을 통해 직접 접근되지 않도록 하고 싶습니다. 솔루션 아키텍트는 이러한 요구사항을 충족하기 위해 무엇을 해야 합니까?

정답
D. Create an origin access identity (OAI). Assign the OAI to the CloudFront distribution. Configure the S3 bucket permissions so that only the OAI has read permission.

해설
D: Origin Access Identity (OAI)를 생성하고 이를 CloudFront 배포에 할당하면, CloudFront를 통해서만 S3 버킷의 객체에 접근할 수 있습니다. S3 버킷 권한을 설정하여 OAI만 읽기 권한을 가지도록 구성하면, S3 URL을 통한 직접 접근을 방지할 수 있습니다.
다른 선택지의 문제점
A: 각 S3 버킷에 대해 개별 정책을 작성하는 것은 복잡하고 관리하기 어렵습니다. 또한, CloudFront에 대한 접근 권한을 효과적으로 제어하지 못할 수 있습니다.
B: IAM 사용자를 생성하고 읽기 권한을 부여하는 것은 CloudFront와의 통합을 보장하지 않으며, S3 URL을 통한 직접 접근을 방지하지 못합니다.
C: S3 버킷 정책에 CloudFront 배포 ID를 Principal로 지정하는 것은 일반적인 접근 제어 방법이 아니며, OAI를 사용하는 것이 더 적합합니다.
따라서, D 선택지가 요구사항을 충족하는 가장 적합한 솔루션입니다.

# 133번
cerulean85
A company runs an Oracle database on premises. As part of the company’s migration to AWS, the company wants to upgrade the database to the most recent available version. The company also wants to set up disaster recovery (DR) for the database. The company needs to minimize the operational overhead for normal operations and DR setup. The company also needs to maintain access to the database's underlying operating system. Which solution will meet these requirements?

A. Migrate the Oracle database to an Amazon EC2 instance. Set up database replication to a different AWS Region. B. Migrate the Oracle database to Amazon RDS for Oracle. Activate Cross-Region automated backups to replicate the snapshots to another AWS Region. C. Migrate the Oracle database to Amazon RDS Custom for Oracle. Create a read replica for the database in another AWS Region. D. Migrate the Oracle database to Amazon RDS for Oracle. Create a standby database in another Availability Zone.

GitHub Copilot
문제 번역
회사는 온프레미스에서 Oracle 데이터베이스를 운영하고 있습니다. 회사의 AWS로의 마이그레이션의 일환으로, 회사는 데이터베이스를 최신 버전으로 업그레이드하고자 합니다. 또한, 회사는 데이터베이스에 대한 재해 복구(DR)를 설정하고자 합니다. 회사는 정상 운영과 DR 설정에 대한 운영 오버헤드를 최소화해야 하며, 데이터베이스의 기본 운영 체제에 대한 접근을 유지해야 합니다. 이 요구사항을 충족하는 솔루션은 무엇입니까?

정답
C. Migrate the Oracle database to Amazon RDS Custom for Oracle. Create a read replica for the database in another AWS Region.

해설
C: Amazon RDS Custom for Oracle는 사용자가 데이터베이스의 기본 운영 체제에 접근할 수 있도록 허용하는 관리형 데이터베이스 서비스입니다. 이는 운영 오버헤드를 줄이면서도 데이터베이스의 기본 운영 체제에 대한 접근을 유지할 수 있습니다. 또한, 다른 AWS 리전에서 읽기 복제본을 생성하여 재해 복구를 설정할 수 있습니다.
다른 선택지의 문제점
A: Oracle 데이터베이스를 Amazon EC2 인스턴스로 마이그레이션하면 운영 오버헤드가 증가할 수 있으며, 관리형 서비스의 이점을 누리지 못합니다.
B: Amazon RDS for Oracle은 기본 운영 체제에 대한 접근을 제공하지 않습니다.
D: Amazon RDS for Oracle은 기본 운영 체제에 대한 접근을 제공하지 않으며, 다른 가용 영역에 대기 데이터베이스를 생성하는 것은 재해 복구를 위한 최적의 솔루션이 아닙니다.
따라서, C 선택지가 요구사항을 충족하는 가장 적합한 솔루션입니다.


# 134번
**정답: A. Create a new S3 bucket. Load the data into the new S3 bucket. Use S3 Cross-Region Replication (CRR) to replicate encrypted objects to an S3 bucket in another Region. Use server-side encryption with AWS KMS multi-Region keys (SSE-KMS). Use Amazon Athena to query the data.**

**해설:**
- **Amazon S3 Cross-Region Replication (CRR):**
  - **데이터 복제:** CRR을 사용하면 S3 버킷 간에 데이터를 자동으로 복제할 수 있습니다. 이는 데이터의 가용성과 내구성을 높이는 데 도움이 됩니다.
  - **암호화:** CRR은 암호화된 객체를 다른 리전의 S3 버킷으로 복제할 수 있습니다.

- **AWS KMS Multi-Region Keys (SSE-KMS):**
  - **보안:** KMS를 사용하여 데이터를 암호화하면, 강력한 보안과 키 관리 기능을 제공받을 수 있습니다. Multi-Region Keys를 사용하면 여러 리전에 걸쳐 일관된 암호화 키를 사용할 수 있습니다.

- **Amazon Athena:**
  - **서버리스 분석:** Athena는 S3에 저장된 데이터를 SQL을 사용하여 분석할 수 있는 서버리스 쿼리 서비스입니다. 이는 운영 오버헤드를 최소화하면서 데이터를 분석하는 데 적합합니다.

**다른 보기가 정답이 될 수 없는 이유:**
- **B. Amazon RDS:** RDS는 관리형 관계형 데이터베이스 서비스로, 서버리스 솔루션이 아니며, 운영 오버헤드가 증가할 수 있습니다.
- **C. SSE-S3:** SSE-S3는 S3 관리형 키를 사용하여 데이터를 암호화하지만, KMS를 사용하는 것보다 보안과 관리 기능이 제한적입니다.
- **D. Amazon RDS:** RDS는 서버리스 솔루션이 아니며, 운영 오버헤드가 증가할 수 있습니다.

**출제 의도:**
이 문제는 AWS에서 서버리스 솔루션을 사용하여 데이터를 분석하고, 데이터의 암호화와 리전 간 복제를 설정하는 방법을 평가합니다. 특히, Amazon S3, AWS KMS, Amazon Athena를 사용하여 운영 오버헤드를 최소화하면서 요구 사항을 충족하는 방법을 이해하는 것이 목적입니다.

**공부해야 하는 부분:**
1. **Amazon S3 Cross-Region Replication (CRR):**
   - CRR의 기본 개념과 사용 사례
   - CRR을 사용하여 데이터를 다른 리전의 S3 버킷으로 복제하는 방법

2. **AWS KMS Multi-Region Keys (SSE-KMS):**
   - KMS의 기본 개념과 사용 사례
   - Multi-Region Keys를 사용하여 데이터를 암호화하고, 여러 리전에 걸쳐 일관된 키를 사용하는 방법

3. **Amazon Athena:**
   - Athena의 기본 개념과 사용 사례
   - Athena를 사용하여 S3에 저장된 데이터를 SQL을 사용하여 분석하는 방법

이 부분들을 공부하면, AWS에서 서버리스 솔루션을 사용하여 데이터를 분석하고, 데이터의 암호화와 리전 간 복제를 설정하는 방법을 더 잘 이해할 수 있습니다.



# 136번
문제 번역
회사는 온프레미스 PostgreSQL 데이터베이스를 Amazon Aurora PostgreSQL로 마이그레이션하고 있습니다. 마이그레이션 중에도 온프레미스 데이터베이스는 온라인 상태를 유지하고 접근 가능해야 합니다. Aurora 데이터베이스는 온프레미스 데이터베이스와 동기화 상태를 유지해야 합니다. 솔루션 아키텍트는 이러한 요구사항을 충족하기 위해 어떤 조치를 취해야 합니까? (두 가지를 선택하십시오.)

정답
A. Create an ongoing replication task.

C. Create an AWS Database Migration Service (AWS DMS) replication server.

해설
A: 지속적인 복제 작업을 생성하면 온프레미스 데이터베이스와 Amazon Aurora PostgreSQL 간의 데이터 동기화를 유지할 수 있습니다.
C: AWS Database Migration Service (AWS DMS) 복제 서버를 생성하면 온프레미스 데이터베이스에서 Amazon Aurora PostgreSQL로의 데이터 마이그레이션을 관리할 수 있습니다. DMS는 데이터베이스를 마이그레이션하면서도 소스 데이터베이스를 온라인 상태로 유지할 수 있습니다.
다른 선택지의 문제점
B: 데이터베이스 백업을 생성하는 것은 초기 데이터 전송에 유용할 수 있지만, 지속적인 동기화를 보장하지 않습니다.
D: AWS Schema Conversion Tool (AWS SCT)은 데이터베이스 스키마 변환에 사용되며, 지속적인 데이터 동기화를 보장하지 않습니다.
E: Amazon EventBridge (Amazon CloudWatch Events) 규칙은 모니터링에 유용할 수 있지만, 데이터 동기화를 직접적으로 관리하지 않습니다.
따라서, A와 C 선택지가 요구사항을 충족하는 가장 적합한 솔루션입니다.

# 137번
문제 번역
회사는 각 비즈니스 유닛을 위해 전용 AWS 계정을 생성하고, 각 비즈니스 유닛의 계정을 독립적으로 관리할 수 있도록 AWS Organizations를 사용하고 있습니다. 루트 이메일 수신자가 한 계정의 루트 사용자 이메일 주소로 전송된 알림을 놓쳤습니다. 회사는 향후 모든 알림이 놓치지 않도록 하고자 합니다. 향후 알림은 계정 관리자에게만 제한되어야 합니다. 이 요구사항을 충족하는 솔루션은 무엇입니까?

정답
B. Configure all AWS account root user email addresses as distribution lists that go to a few administrators who can respond to alerts. Configure AWS account alternate contacts in the AWS Organizations console or programmatically.

해설
B: 모든 AWS 계정 루트 사용자 이메일 주소를 몇 명의 관리자에게 전달되는 배포 목록으로 구성하면, 알림이 놓치지 않도록 할 수 있습니다. 또한, AWS Organizations 콘솔 또는 프로그래밍 방식으로 AWS 계정 대체 연락처를 구성하여 알림을 받을 수 있는 추가적인 보안을 제공합니다.
다른 선택지의 문제점
A: 회사의 이메일 서버를 구성하여 알림 이메일 메시지를 조직의 모든 사용자에게 전달하는 것은 보안 위험이 있으며, 알림이 너무 많은 사람에게 전달될 수 있습니다.
C: 모든 알림을 한 명의 관리자에게 보내는 것은 단일 실패 지점을 만들 수 있으며, 알림이 적절한 그룹에 전달되지 않을 수 있습니다.
D: 모든 계정에 동일한 루트 사용자 이메일 주소를 사용하는 것은 관리 및 보안 측면에서 비효율적이며, 각 계정의 독립성을 유지하지 못합니다.
따라서, B 선택지가 요구사항을 충족하는 가장 적합한 솔루션입니다.

# 138번
문제 번역
회사는 AWS에서 전자상거래 애플리케이션을 운영하고 있습니다. 새로운 주문이 들어올 때마다 RabbitMQ 큐에 메시지가 게시되며, 이 큐는 단일 가용 영역의 Amazon EC2 인스턴스에서 실행됩니다. 이러한 메시지는 별도의 EC2 인스턴스에서 실행되는 다른 애플리케이션에 의해 처리되며, 이 애플리케이션은 세부 정보를 또 다른 EC2 인스턴스에서 실행되는 PostgreSQL 데이터베이스에 저장합니다. 모든 EC2 인스턴스는 동일한 가용 영역에 있습니다. 회사는 가장 높은 가용성을 제공하고 운영 오버헤드를 최소화하기 위해 아키텍처를 재설계해야 합니다. 솔루션 아키텍트는 이러한 요구사항을 충족하기 위해 무엇을 해야 합니까?

정답
B. Migrate the queue to a redundant pair (active/standby) of RabbitMQ instances on Amazon MQ. Create a Multi-AZ Auto Scaling group for EC2 instances that host the application. Migrate the database to run on a Multi-AZ deployment of Amazon RDS for PostgreSQL.

해설
B: RabbitMQ 큐를 Amazon MQ의 활성/대기 페어로 마이그레이션하면 높은 가용성을 제공할 수 있습니다. 애플리케이션을 호스팅하는 EC2 인스턴스에 대해 다중 가용 영역(AZ) Auto Scaling 그룹을 생성하면 애플리케이션의 가용성을 높일 수 있습니다. PostgreSQL 데이터베이스를 Amazon RDS for PostgreSQL의 다중 AZ 배포로 마이그레이션하면 데이터베이스의 가용성과 관리 오버헤드를 최소화할 수 있습니다.
다른 선택지의 문제점
A: PostgreSQL 데이터베이스를 EC2 인스턴스에서 호스팅하는 것은 관리 오버헤드를 증가시키며, RDS를 사용하는 것보다 가용성이 낮을 수 있습니다.
C: RabbitMQ 큐를 EC2 인스턴스에서 호스팅하는 것은 관리 오버헤드를 증가시키며, Amazon MQ를 사용하는 것보다 가용성이 낮을 수 있습니다.
D: PostgreSQL 데이터베이스를 EC2 인스턴스에서 호스팅하는 것은 관리 오버헤드를 증가시키며, RDS를 사용하는 것보다 가용성이 낮을 수 있습니다.
따라서, B 선택지가 요구사항을 충족하는 가장 적합한 솔루션입니다.

# 139번 ---
**정답: C. Configure S3 replication between the S3 buckets. Create an S3 event notification for the analysis S3 bucket. Configure Lambda and SageMaker Pipelines as destinations of the event notification. Configure s3:ObjectCreated:Put as the event type.**

**해설:**
- **S3 Replication:**
  - **자동 복제:** S3 복제를 설정하면, 초기 S3 버킷에 파일이 업로드될 때 자동으로 분석 S3 버킷으로 복제됩니다. 이는 수동 작업을 자동화하고 운영 오버헤드를 줄이는 데 도움이 됩니다.
  - **고가용성:** S3 복제는 데이터를 다른 버킷으로 자동으로 복제하여 고가용성을 제공합니다.

- **S3 Event Notification:**
  - **이벤트 기반 처리:** 분석 S3 버킷에 이벤트 알림을 설정하여, 파일이 복제될 때 Lambda 함수와 SageMaker Pipelines를 트리거할 수 있습니다. 이는 파일이 복제될 때마다 자동으로 패턴 매칭 코드와 데이터 파이프라인을 실행할 수 있도록 합니다.
  - **s3:ObjectCreated:Put 이벤트:** 이 이벤트 유형을 사용하면, 객체가 생성될 때마다 이벤트 알림이 트리거됩니다.

**다른 보기가 정답이 될 수 없는 이유:**
- **A. Lambda 함수로 파일 복사:** Lambda 함수를 사용하여 파일을 복사하는 것은 가능하지만, S3 복제를 사용하는 것보다 운영 오버헤드가 큽니다.
- **B. EventBridge 사용:** EventBridge를 사용하여 이벤트를 처리하는 것은 가능하지만, S3 이벤트 알림을 직접 사용하는 것이 더 간단하고 운영 오버헤드가 적습니다.
- **D. EventBridge 사용:** EventBridge를 사용하여 이벤트를 처리하는 것은 가능하지만, S3 이벤트 알림을 직접 사용하는 것이 더 간단하고 운영 오버헤드가 적습니다.

**출제 의도:**
이 문제는 AWS에서 S3 버킷 간의 데이터 복제를 자동화하고, 이벤트 기반 처리를 설정하는 방법을 평가합니다. 특히, S3 복제와 S3 이벤트 알림을 사용하여 운영 오버헤드를 최소화하면서 요구 사항을 충족하는 방법을 이해하는 것이 목적입니다.

**공부해야 하는 부분:**
1. **Amazon S3 Replication:**
   - S3 복제의 기본 개념과 사용 사례
   - S3 복제를 설정하여 데이터를 자동으로 복제하는 방법

2. **S3 Event Notification:**
   - S3 이벤트 알림의 기본 개념과 사용 사례
   - S3 이벤트 알림을 설정하여 특정 이벤트가 발생할 때 Lambda 함수와 SageMaker Pipelines를 트리거하는 방법

이 부분들을 공부하면, AWS에서 S3 버킷 간의 데이터 복제를 자동화하고, 이벤트 기반 처리를 설정하는 방법을 더 잘 이해할 수 있습니다.

# 140번
**정답: A. Use Spot Instances for the data ingestion layer C. Purchase a 1-year Compute Savings Plan for the front end and API layer.**

**해설:**
- **Spot Instances:**
  - **비용 절감:** Spot Instances는 사용하지 않는 EC2 용량을 활용하여 최대 90%까지 비용을 절감할 수 있습니다. 이는 데이터 수집 계층의 스포라딕하고 예측 불가능한 사용 패턴에 적합합니다.
  - **중단 가능성:** Spot Instances는 언제든지 중단될 수 있지만, 데이터 수집 계층의 작업이 중단을 견딜 수 있으므로 적합합니다.

- **Compute Savings Plan:**
  - **비용 절감:** Compute Savings Plan은 특정 인스턴스 유형에 구애받지 않고, EC2, Fargate, Lambda 등 다양한 컴퓨팅 옵션에 대해 비용을 절감할 수 있습니다.
  - **예측 가능한 사용:** 프론트엔드와 API 계층의 사용량이 예측 가능하므로, 1년 Compute Savings Plan을 구매하면 비용을 절감할 수 있습니다.

**다른 보기가 정답이 될 수 없는 이유:**
- **B. On-Demand Instances:** On-Demand Instances는 비용이 더 높으며, 스포라딕하고 예측 불가능한 사용 패턴에 적합하지 않습니다.
- **D. Reserved Instances:** 데이터 수집 계층의 사용 패턴이 예측 불가능하므로, Reserved Instances는 적합하지 않습니다.
- **E. EC2 instance Savings Plan:** EC2 instance Savings Plan은 특정 인스턴스 패밀리와 리전에만 적용되므로, Compute Savings Plan이 더 유연하고 비용 효율적입니다.

**출제 의도:**
이 문제는 AWS에서 다양한 컴퓨팅 옵션을 사용하여 비용을 최적화하는 방법을 평가합니다. 특히, Spot Instances와 Compute Savings Plan을 사용하여 비용을 절감하고, 예측 가능한 사용 패턴에 맞는 구매 옵션을 선택하는 방법을 이해하는 것이 목적입니다.

**공부해야 하는 부분:**
1. **Spot Instances:**
   - Spot Instances의 기본 개념과 사용 사례
   - Spot Instances를 사용하여 비용을 절감하고, 중단 가능성을 관리하는 방법

2. **Savings Plans:**
   - Compute Savings Plan과 EC2 instance Savings Plan의 차이점과 사용 사례
   - Savings Plan을 사용하여 비용을 절감하는 방법

이 부분들을 공부하면, AWS에서 다양한 컴퓨팅 옵션을 사용하여 비용을 최적화하는 방법을 더 잘 이해할 수 있습니다.


# 141번
**정답: B. Deploy the application stack in two AWS Regions. Use an Amazon Route 53 latency routing policy to serve all content from the ALB in the closest Region.**

**해설:**
- **다중 리전 배포:**
  - **고가용성:** 두 개의 AWS 리전에 애플리케이션 스택을 배포하면, 하나의 리전에서 장애가 발생하더라도 다른 리전에서 서비스를 계속 제공할 수 있습니다.
  - **지연 시간 최소화:** 여러 리전에 배포하면, 사용자가 가장 가까운 리전에서 콘텐츠를 제공받을 수 있어 지연 시간을 최소화할 수 있습니다.

- **Amazon Route 53 Latency Routing Policy:**
  - **지연 시간 기반 라우팅:** Route 53의 지연 시간 라우팅 정책을 사용하면, 사용자가 가장 낮은 지연 시간을 제공하는 리전의 ALB에서 콘텐츠를 제공받을 수 있습니다. 이는 전 세계 사용자에게 최적의 성능을 제공합니다.

**다른 보기가 정답이 될 수 없는 이유:**
- **A. 단일 리전 배포 및 CloudFront:** 단일 리전에 배포하면, 해당 리전에서 장애가 발생할 경우 서비스가 중단될 수 있습니다. 또한, CloudFront는 정적 콘텐츠 캐싱에 적합하지만, 동적 콘텐츠의 지연 시간을 최소화하는 데는 한계가 있습니다.
- **C. 단일 리전 배포 및 CloudFront:** 단일 리전에 배포하면, 해당 리전에서 장애가 발생할 경우 서비스가 중단될 수 있습니다. 또한, 동적 콘텐츠를 ALB에서 직접 제공하면 지연 시간이 증가할 수 있습니다.
- **D. 지리적 라우팅 정책:** 지리적 라우팅 정책은 사용자의 지리적 위치에 따라 라우팅하지만, 지연 시간을 최적화하는 데는 적합하지 않습니다.

**출제 의도:**
이 문제는 AWS에서 전 세계 사용자에게 최적의 성능을 제공하기 위해 애플리케이션을 설계하는 방법을 평가합니다. 특히, 다중 리전 배포와 Route 53 지연 시간 라우팅 정책을 사용하여 지연 시간을 최소화하고, 고가용성을 제공하는 방법을 이해하는 것이 목적입니다.

**공부해야 하는 부분:**
1. **다중 리전 배포:**
   - 여러 리전에 애플리케이션을 배포하여 고가용성과 성능을 최적화하는 방법
   - 다중 리전 배포의 장단점

2. **Amazon Route 53 라우팅 정책:**
   - Route 53의 다양한 라우팅 정책(지연 시간, 지리적, 가중치 등)의 기본 개념과 사용 사례
   - 지연 시간 라우팅 정책을 사용하여 사용자에게 최적의 성능을 제공하는 방법

이 부분들을 공부하면, AWS에서 전 세계 사용자에게 최적의 성능을 제공하기 위해 애플리케이션을 설계하는 방법을 더 잘 이해할 수 있습니다.  


# 143번
이 문제는 AWS로 기존의 온프레미스 모놀리식 애플리케이션을 마이그레이션하려는 회사의 요구사항을 다루고 있습니다. 회사는 가능한 한 많은 프론트엔드 코드와 백엔드 코드를 유지하면서 애플리케이션을 더 작은 애플리케이션으로 나누고 싶어합니다. 각 애플리케이션은 다른 팀에서 관리하며, **고가용성**과 **운영 오버헤드 최소화**를 목표로 하는 **확장 가능한 솔루션**이 필요합니다. 

각 선택지의 설명과 정답을 분석해 보겠습니다.

### 선택지 분석

**A. Host the application on AWS Lambda. Integrate the application with Amazon API Gateway.**
- **설명**: AWS Lambda는 서버리스 컴퓨팅 서비스를 제공하여 자동으로 확장할 수 있으며, 운영 오버헤드가 적습니다. Amazon API Gateway를 사용하여 API를 생성하고 관리할 수 있습니다. 
- **장점**: 
  - 서버리스 아키텍처로 인해 운영 관리가 최소화됩니다.
  - Lambda는 요청 수에 따라 자동으로 확장됩니다.
  - API Gateway와의 통합이 간편하여 애플리케이션을 마이크로서비스로 분리할 수 있습니다.
- **단점**: 모놀리식 애플리케이션에서 Lambda 기반으로 이전할 때 기존 코드를 완전히 재작성해야 할 수 있습니다.

---

**B. Host the application with AWS Amplify. Connect the application to an Amazon API Gateway API that is integrated with AWS Lambda.**
- **설명**: AWS Amplify는 풀스택 애플리케이션을 쉽게 구축하고 배포할 수 있도록 돕는 플랫폼입니다. API Gateway와 AWS Lambda와 통합하여 프론트엔드를 서버리스로 구축할 수 있습니다.
- **장점**: 
  - Amplify는 프론트엔드 및 백엔드 개발을 간편하게 관리할 수 있습니다.
  - 서버리스 아키텍처를 통해 확장성과 운영 오버헤드를 최소화할 수 있습니다.
- **단점**: AWS Amplify는 주로 정적 웹사이트 및 서버리스 애플리케이션에 적합합니다. 모놀리식 애플리케이션을 완전히 재작성해야 할 수 있습니다.

---

**C. Host the application on Amazon EC2 instances. Set up an Application Load Balancer with EC2 instances in an Auto Scaling group as targets.**
- **설명**: Amazon EC2에서 애플리케이션을 호스팅하고, Auto Scaling 그룹과 함께 Application Load Balancer를 설정하여 트래픽을 분산합니다.
- **장점**: 
  - 기존의 EC2 기반 아키텍처로 쉽게 마이그레이션할 수 있습니다.
  - EC2 인스턴스는 높은 커스터마이징을 제공하고, 부하에 따라 확장할 수 있습니다.
- **단점**: 운영 관리가 상대적으로 많으며, 모놀리식 구조로 인해 애플리케이션을 마이크로서비스로 분할하는 데 어려움이 있을 수 있습니다.

---

**D. Host the application on Amazon Elastic Container Service (Amazon ECS). Set up an Application Load Balancer with Amazon ECS as the target.**
- **설명**: Amazon ECS를 사용하여 컨테이너화된 애플리케이션을 호스팅하고, Application Load Balancer를 설정하여 트래픽을 분산합니다.
- **장점**: 
  - ECS는 컨테이너 관리 서비스로, 마이크로서비스 아키텍처를 지원하며, 애플리케이션을 더 작은 서비스로 나누는 데 유리합니다.
  - 자동 확장 기능을 제공하며, 운영 오버헤드가 적습니다.
  - 애플리케이션의 개별 구성 요소를 각 팀이 독립적으로 관리할 수 있도록 합니다.
- **단점**: 컨테이너 환경에 대한 학습 곡선이 있을 수 있습니다.

---

### **정답 및 해설**
**정답: D. Host the application on Amazon Elastic Container Service (Amazon ECS). Set up an Application Load Balancer with Amazon ECS as the target.**

**해설**:
- **모놀리식 애플리케이션을 더 작은 서비스로 분할**하는 데 유리한 컨테이너 기반 아키텍처를 제공합니다. 
- **ECS를 사용하면** 여러 팀이 각각의 서비스를 관리할 수 있으며, **각 서비스는 독립적으로 배포되고 확장**될 수 있습니다. 
- **운영 오버헤드가 적고, 자동 확장 기능을 통해** 고가용성과 높은 트래픽 처리 능력을 제공하므로 기업의 요구 사항에 가장 적합합니다.

따라서 **ECS와 Application Load Balancer** 조합은 주어진 조건을 모두 충족하며, **기존 코드를 최대한 유지하면서** 마이크로서비스 아키텍처로 이전할 수 있는 최적의 선택입니다.


# 145번
**정답: A. Migrate the database to an Amazon RDS for MySQL DB instance. Create an AMI of the web application. Use the AMI to launch a second EC2 On-Demand Instance. Use an Application Load Balancer to distribute the load to each EC2 instance.**

**해설:**
- **Amazon RDS for MySQL:**
  - **데이터베이스 분리:** RDS를 사용하여 데이터베이스를 EC2 인스턴스에서 분리하면, 데이터베이스 관리와 성능 최적화가 쉬워집니다. 이는 애플리케이션의 성능을 향상시키는 데 도움이 됩니다.
  - **관리형 서비스:** RDS는 관리형 서비스로, 백업, 복구, 소프트웨어 패치 등을 자동으로 처리하여 운영 오버헤드를 줄입니다.

- **Application Load Balancer (ALB):**
  - **로드 밸런싱:** ALB를 사용하여 여러 EC2 인스턴스 간에 트래픽을 분산시키면, 애플리케이션의 가용성과 성능을 향상시킬 수 있습니다.
  - **확장성:** ALB와 Auto Scaling을 결합하면, 트래픽 증가에 따라 자동으로 인스턴스를 추가하여 확장할 수 있습니다.

**다른 보기가 정답이 될 수 없는 이유:**
- **B. Route 53 weighted routing:** Route 53의 가중치 라우팅은 로드 밸런싱을 제공할 수 있지만, ALB를 사용하는 것이 더 일반적이고 효율적입니다.
- **C. Lambda와 CloudWatch:** Lambda와 CloudWatch를 사용하여 인스턴스 유형을 변경하는 것은 성능 문제를 해결할 수 있지만, 이는 자동 확장과 로드 밸런싱을 제공하지 않습니다.
- **D. Aurora와 Spot Fleet:** Aurora는 고성능 데이터베이스를 제공하지만, Spot Fleet을 사용하는 것은 비용 효율적일 수 있지만, 인스턴스가 중단될 수 있어 안정적인 서비스 제공에 문제가 있을 수 있습니다.

**출제 의도:**
이 문제는 AWS에서 웹 애플리케이션의 성능 문제를 해결하고, 비용 효율적으로 확장 가능한 아키텍처를 설계하는 방법을 평가합니다. 특히, Amazon RDS와 Application Load Balancer를 사용하여 데이터베이스를 분리하고, 로드 밸런싱을 통해 애플리케이션의 성능을 향상시키는 방법을 이해하는 것이 목적입니다.

**공부해야 하는 부분:**
1. **Amazon RDS:**
   - RDS의 기본 개념과 사용 사례
   - RDS를 사용하여 데이터베이스를 관리하고 성능을 최적화하는 방법

2. **Application Load Balancer (ALB):**
   - ALB의 기본 개념과 사용 사례
   - ALB를 사용하여 트래픽을 분산시키고, 애플리케이션의 가용성과 성능을 향상시키는 방법

이 부분들을 공부하면, AWS에서 웹 애플리케이션의 성능 문제를 해결하고, 비용 효율적으로 확장 가능한 아키텍처를 설계하는 방법을 더 잘 이해할 수 있습니다.


# 150번
**정답: A. Create Amazon CloudWatch composite alarms where possible.**

**해설:**
- **Amazon CloudWatch Composite Alarms:**
  - **복합 조건:** Composite Alarms는 여러 개의 단일 알람을 결합하여, 특정 조건이 모두 충족될 때만 알람을 발생시킬 수 있습니다. 이는 CPU 사용률이 50%를 초과하고 동시에 디스크의 읽기 IOPS가 높은 경우에만 알람을 발생시키는 데 적합합니다.
  - **거짓 알람 감소:** Composite Alarms를 사용하면, 단일 조건이 충족될 때 발생하는 거짓 알람을 줄일 수 있습니다. 이는 CPU 사용률이 일시적으로 50%를 초과하는 경우와 같은 상황에서 불필요한 알람을 방지합니다.

**다른 보기가 정답이 될 수 없는 이유:**
- **B. CloudWatch Dashboards:** 대시보드는 메트릭을 시각화하고 문제를 빠르게 파악하는 데 유용하지만, 자동으로 알람을 발생시키는 기능은 없습니다.
- **C. CloudWatch Synthetics Canaries:** Synthetics Canaries는 애플리케이션의 엔드포인트를 모니터링하고 가용성을 테스트하는 데 사용되며, 인프라 메트릭 알람을 설정하는 데 적합하지 않습니다.
- **D. Single Metric Alarms:** 단일 메트릭 알람은 여러 메트릭 조건을 결합할 수 없으므로, CPU 사용률과 디스크 읽기 IOPS를 동시에 모니터링하는 데 적합하지 않습니다.

**출제 의도:**
이 문제는 AWS에서 인프라 메트릭을 모니터링하고, 특정 조건이 충족될 때만 알람을 발생시키는 방법을 평가합니다. 특히, Amazon CloudWatch Composite Alarms를 사용하여 거짓 알람을 줄이고, 필요한 경우에만 알람을 발생시키는 방법을 이해하는 것이 목적입니다.

**공부해야 하는 부분:**
1. **Amazon CloudWatch Composite Alarms:**
   - Composite Alarms의 기본 개념과 사용 사례
   - Composite Alarms를 사용하여 여러 메트릭 조건을 결합하고, 특정 조건이 충족될 때만 알람을 발생시키는 방법

2. **Amazon CloudWatch Alarms:**
   - CloudWatch Alarms의 기본 개념과 사용 사례
   - 단일 메트릭 알람과 복합 알람의 차이점과 사용 사례

이 부분들을 공부하면, AWS에서 인프라 메트릭을 모니터링하고, 특정 조건이 충족될 때만 알람을 발생시키는 방법을 더 잘 이해할 수 있습니다.


# 151번
**정답: A. Use AWS Control Tower to implement data residency guardrails to deny internet access and deny access to all AWS Regions except ap-northeast-3. C. Use AWS Organizations to configure service control policies (SCPS) that prevent VPCs from gaining internet access. Deny access to all AWS Regions except ap-northeast-3.**

**해설:**
- **AWS Control Tower:**
  - **데이터 거주성 가드레일:** Control Tower는 데이터 거주성 가드레일을 사용하여 특정 리전 외의 리전에 대한 접근을 차단하고, 인터넷 접근을 차단할 수 있습니다. 이는 컴플라이언스 요구 사항을 충족하는 데 도움이 됩니다.

- **AWS Organizations와 SCPs:**
  - **서비스 제어 정책 (SCPs):** SCPs를 사용하여 특정 리전 외의 리전에 대한 접근을 차단하고, VPC가 인터넷에 접근하지 못하도록 설정할 수 있습니다. 이는 중앙에서 관리할 수 있는 강력한 보안 정책을 제공합니다.

**다른 보기가 정답이 될 수 없는 이유:**
- **B. AWS WAF:** WAF는 웹 애플리케이션 방화벽으로, 인터넷 접근을 차단하는 데 적합하지 않습니다. 또한, AWS 계정 설정에서 리전 접근을 차단하는 기능이 없습니다.
- **D. 네트워크 ACL 및 IAM 정책:** 네트워크 ACL을 사용하여 인터넷 접근을 차단할 수 있지만, 이는 각 VPC마다 설정해야 하므로 관리 오버헤드가 큽니다. 또한, IAM 정책으로 리전 접근을 차단하는 것은 적절하지 않습니다.
- **E. AWS Config:** AWS Config는 리소스 변경을 감지하고 알림을 제공하는 데 유용하지만, 인터넷 접근을 차단하거나 리전 접근을 차단하는 데 직접적인 역할을 하지 않습니다.

**출제 의도:**
이 문제는 AWS에서 특정 리전으로의 데이터 마이그레이션을 설정하고, 인터넷 접근을 차단하는 방법을 평가합니다. 특히, AWS Control Tower와 AWS Organizations의 SCPs를 사용하여 중앙에서 관리할 수 있는 보안 정책을 설정하는 방법을 이해하는 것이 목적입니다.

**공부해야 하는 부분:**
1. **AWS Control Tower:**
   - Control Tower의 기본 개념과 사용 사례
   - Control Tower를 사용하여 데이터 거주성 가드레일을 설정하는 방법

2. **AWS Organizations와 SCPs:**
   - AWS Organizations의 기본 개념과 사용 사례
   - SCPs를 사용하여 특정 리전 외의 리전에 대한 접근을 차단하고, 인터넷 접근을 차단하는 방법

이 부분들을 공부하면, AWS에서 특정 리전으로의 데이터 마이그레이션을 설정하고, 인터넷 접근을 차단하는 방법을 더 잘 이해할 수 있습니다.

# 152번
**정답: D. Create AWS Lambda functions to start and stop the DB instance. Create Amazon EventBridge (Amazon CloudWatch Events) scheduled rules to invoke the Lambda functions. Configure the Lambda functions as event targets for the rules.**

**해설:**
- **AWS Lambda와 EventBridge:**
  - **자동화:** Lambda 함수를 사용하여 RDS 인스턴스를 시작하고 중지하는 작업을 자동화할 수 있습니다. 이는 수동 작업을 줄이고 운영 오버헤드를 최소화합니다.
  - **스케줄링:** EventBridge (이전의 CloudWatch Events)를 사용하여 정기적인 스케줄을 설정하고, 특정 시간에 Lambda 함수를 트리거하여 RDS 인스턴스를 시작하거나 중지할 수 있습니다. 이는 애플리케이션이 사용되지 않는 시간 동안 비용을 절감하는 데 도움이 됩니다.

**다른 보기가 정답이 될 수 없는 이유:**
- **A. IAM 정책과 Systems Manager Session Manager:** 이 방법은 RDS 인스턴스를 자동으로 시작하고 중지하는 데 적합하지 않습니다.
- **B. ElastiCache for Redis:** ElastiCache를 사용하여 데이터를 캐싱하는 것은 가능하지만, RDS 인스턴스를 중지하는 동안 데이터를 캐싱하는 것은 복잡하고 비용 효율적이지 않습니다.
- **C. EC2 인스턴스와 cron job:** EC2 인스턴스를 사용하여 스케줄링 작업을 설정하는 것은 가능하지만, Lambda와 EventBridge를 사용하는 것이 더 간단하고 비용 효율적입니다.

**출제 의도:**
이 문제는 AWS에서 RDS 인스턴스를 자동으로 시작하고 중지하여 비용을 절감하는 방법을 평가합니다. 특히, AWS Lambda와 EventBridge를 사용하여 스케줄링 작업을 자동화하는 방법을 이해하는 것이 목적입니다.

**공부해야 하는 부분:**
1. **AWS Lambda:**
   - Lambda의 기본 개념과 사용 사례
   - Lambda를 사용하여 RDS 인스턴스를 시작하고 중지하는 방법

2. **Amazon EventBridge (CloudWatch Events):**
   - EventBridge의 기본 개념과 사용 사례
   - EventBridge를 사용하여 정기적인 스케줄을 설정하고, Lambda 함수를 트리거하는 방법

이 부분들을 공부하면, AWS에서 RDS 인스턴스를 자동으로 시작하고 중지하여 비용을 절감하는 방법을 더 잘 이해할 수 있습니다.



# 156번
**정답: A. Use Amazon Athena for one-time queries. Use Amazon QuickSight to create dashboards for KPIs. E. Use blueprints in AWS Lake Formation to identify the data that can be ingested into a data lake. Use AWS Glue to crawl the source, extract the data, and load the data into Amazon S3 in Apache Parquet format.**

**해설:**
- **Amazon Athena와 Amazon QuickSight:**
  - **Athena:** Athena는 S3에 저장된 데이터를 SQL을 사용하여 쿼리할 수 있는 서버리스 쿼리 서비스입니다. 이는 일회성 쿼리에 적합하며, 운영 오버헤드가 적습니다.
  - **QuickSight:** QuickSight는 비즈니스 인텔리전스 도구로, Athena에서 쿼리한 데이터를 시각화하고 대시보드를 생성하는 데 사용할 수 있습니다. 이는 KPI를 표시하는 데 적합합니다.

- **AWS Lake Formation과 AWS Glue:**
  - **Lake Formation:** Lake Formation은 데이터 레이크를 쉽게 설정하고 관리할 수 있도록 도와줍니다. 블루프린트를 사용하여 데이터를 식별하고, 데이터 레이크에 적재할 수 있습니다.
  - **AWS Glue:** Glue는 ETL(추출, 변환, 로드) 작업을 자동화하는 관리형 서비스입니다. Glue 크롤러를 사용하여 소스 데이터를 크롤링하고, 데이터를 S3에 Apache Parquet 형식으로 적재할 수 있습니다. 이는 다양한 데이터 소스를 통합하고, 데이터를 분석하기 쉽게 만듭니다.

**다른 보기가 정답이 될 수 없는 이유:**
- **B. Kinesis Data Analytics:** Kinesis Data Analytics는 실시간 데이터 스트림을 분석하는 데 적합하지만, 일회성 쿼리에는 적합하지 않습니다.
- **C. Lambda와 Redshift:** Lambda 함수를 사용하여 데이터를 Redshift로 이동하는 것은 가능하지만, 이는 운영 오버헤드가 크고, 요구 사항에 비해 복잡합니다.
- **D. Glue와 OpenSearch Service:** OpenSearch Service는 검색 및 분석 엔진으로, 데이터 레이크와 비즈니스 인텔리전스 도구로 사용하기에는 적합하지 않습니다.

**출제 의도:**
이 문제는 AWS에서 다양한 데이터 소스를 통합하고, 비즈니스 인텔리전스를 위해 데이터를 분석하는 방법을 평가합니다. 특히, Amazon Athena와 QuickSight를 사용하여 데이터를 쿼리하고 시각화하는 방법과, AWS Lake Formation과 Glue를 사용하여 데이터를 통합하고 적재하는 방법을 이해하는 것이 목적입니다.

**공부해야 하는 부분:**
1. **Amazon Athena와 QuickSight:**
   - Athena의 기본 개념과 사용 사례
   - QuickSight를 사용하여 데이터를 시각화하고 대시보드를 생성하는 방법

2. **AWS Lake Formation과 AWS Glue:**
   - Lake Formation의 기본 개념과 사용 사례
   - Glue를 사용하여 데이터를 크롤링하고, ETL 작업을 자동화하는 방법

이 부분들을 공부하면, AWS에서 다양한 데이터 소스를 통합하고, 비즈니스 인텔리전스를 위해 데이터를 분석하는 방법을 더 잘 이해할 수 있습니다.


# 157번
**정답: D. Configure an Amazon CloudWatch Logs export for the DB cluster. E. Use AWS Backup to take the backups and to keep the backups for 5 years.**

**해설:**
- **Amazon CloudWatch Logs Export:**
  - **감사 로그 보관:** CloudWatch Logs를 사용하여 데이터베이스에서 수행된 작업의 감사 로그를 무기한으로 보관할 수 있습니다. 이는 감사 로그를 영구적으로 보관해야 하는 요구 사항을 충족합니다.

- **AWS Backup:**
  - **백업 보존:** AWS Backup을 사용하여 Aurora DB 클러스터의 백업을 자동으로 생성하고, 백업 보존 기간을 5년으로 설정할 수 있습니다. 이는 데이터를 5년 동안 보관하고, 5년 후에 삭제해야 하는 요구 사항을 충족합니다.
  - **자동화:** AWS Backup은 백업 작업을 자동화하여 운영 오버헤드를 줄이고, 백업 보존 정책을 쉽게 관리할 수 있습니다.

**다른 보기가 정답이 될 수 없는 이유:**
- **A. Manual Snapshot:** 수동 스냅샷은 백업을 수동으로 관리해야 하므로, 운영 오버헤드가 증가합니다. 또한, 수동 스냅샷은 자동으로 삭제되지 않으므로, 5년 후에 데이터를 자동으로 삭제하는 요구 사항을 충족하지 않습니다.
- **B. Lifecycle Policy for Automated Backups:** Aurora는 기본적으로 자동 백업에 대한 수명 주기 정책을 지원하지 않습니다.
- **C. Automated Backup Retention:** Aurora의 자동 백업 보존 기간은 최대 35일로 제한되므로, 5년 동안 데이터를 보관하는 요구 사항을 충족하지 않습니다.

**출제 의도:**
이 문제는 AWS에서 데이터베이스 백업과 감사 로그를 관리하고, 특정 보존 기간 동안 데이터를 안전하게 보관하는 방법을 평가합니다. 특히, AWS Backup과 CloudWatch Logs를 사용하여 데이터를 자동으로 백업하고, 감사 로그를 영구적으로 보관하는 방법을 이해하는 것이 목적입니다.

**공부해야 하는 부분:**
1. **AWS Backup:**
   - AWS Backup의 기본 개념과 사용 사례
   - AWS Backup을 사용하여 데이터베이스 백업을 자동화하고, 보존 기간을 설정하는 방법

2. **Amazon CloudWatch Logs:**
   - CloudWatch Logs의 기본 개념과 사용 사례
   - CloudWatch Logs를 사용하여 데이터베이스 감사 로그를 무기한으로 보관하는 방법

이 부분들을 공부하면, AWS에서 데이터베이스 백업과 감사 로그를 관리하고, 특정 보존 기간 동안 데이터를 안전하게 보관하는 방법을 더 잘 이해할 수 있습니다.


# 162번
**정답: A. Amazon FSx for Lustre integrated with Amazon S3**

**해설:**
- **Amazon FSx for Lustre:**
  - **고성능 파일 시스템:** FSx for Lustre는 고성능 컴퓨팅(HPC) 워크로드에 최적화된 파일 시스템으로, 높은 처리량과 낮은 지연 시간을 제공합니다. 이는 금융 리스크 모델링과 같은 HPC 워크로드에 적합합니다.
  - **S3 통합:** FSx for Lustre는 Amazon S3와 통합되어, 데이터를 S3에 저장하고 필요할 때 FSx for Lustre 파일 시스템으로 가져올 수 있습니다. 이는 장기 보관 및 분석을 위한 데이터를 효율적으로 관리할 수 있게 합니다.

**다른 보기가 정답이 될 수 없는 이유:**
- **B. Amazon FSx for Windows File Server:** FSx for Windows File Server는 Windows 기반 워크로드에 최적화되어 있으며, Linux 기반 HPC 워크로드에는 적합하지 않습니다.
- **C. Amazon S3 Glacier와 EBS:** S3 Glacier는 장기 보관을 위한 저비용 스토리지로, 고성능 파일 시스템을 제공하지 않습니다. EBS는 블록 스토리지로, 파일 시스템으로 사용하기에는 적합하지 않습니다.
- **D. S3와 EBS:** S3와 EBS를 통합하여 사용할 수 있지만, 이는 고성능 파일 시스템을 제공하지 않으며, HPC 워크로드에 적합하지 않습니다.

**출제 의도:**
이 문제는 AWS에서 고성능 컴퓨팅(HPC) 워크로드를 위한 스토리지 솔루션을 선택하는 방법을 평가합니다. 특히, Amazon FSx for Lustre와 Amazon S3를 사용하여 고성능 파일 시스템과 장기 보관 스토리지를 통합하는 방법을 이해하는 것이 목적입니다.

**공부해야 하는 부분:**
1. **Amazon FSx for Lustre:**
   - FSx for Lustre의 기본 개념과 사용 사례
   - FSx for Lustre를 사용하여 고성능 컴퓨팅 워크로드를 처리하는 방법

2. **Amazon S3:**
   - S3의 기본 개념과 사용 사례
   - S3를 사용하여 데이터를 장기 보관하고, FSx for Lustre와 통합하는 방법

이 부분들을 공부하면, AWS에서 고성능 컴퓨팅(HPC) 워크로드를 위한 스토리지 솔루션을 선택하는 방법을 더 잘 이해할 수 있습니다.


# 179번
**정답: A. Create an IAM role that has read access to the Parameter Store parameter. Allow Decrypt access to an AWS Key Management Service (AWS KMS) key that is used to encrypt the parameter. Assign this IAM role to the EC2 instance.**

**해설:**
- **IAM Role 및 KMS 통합:**
  - **IAM Role:** EC2 인스턴스에 IAM 역할을 할당하여, 해당 역할이 Systems Manager Parameter Store의 매개변수에 대한 읽기 권한을 가지도록 설정합니다. 이는 보안 모범 사례에 부합하며, EC2 인스턴스가 필요한 권한만 가지도록 제한할 수 있습니다.
  - **KMS 키:** 매개변수를 암호화하는 데 사용된 AWS KMS 키에 대한 복호화 권한을 IAM 역할에 부여합니다. 이는 매개변수가 암호화된 상태로 저장되고, 필요한 경우에만 복호화할 수 있도록 보장합니다.

**다른 보기가 정답이 될 수 없는 이유:**
- **B. IAM Policy:** IAM 정책을 EC2 인스턴스에 직접 할당하는 것은 보안 모범 사례에 부합하지 않습니다. 대신 IAM 역할을 사용하여 권한을 부여하는 것이 더 안전하고 관리하기 쉽습니다.
- **C. IAM Trust Relationship:** Parameter Store와 EC2 인스턴스 간의 신뢰 관계를 설정하는 것은 적절한 접근 방식이 아닙니다. 또한, Amazon RDS를 주체로 지정하는 것은 이 시나리오와 관련이 없습니다.
- **D. IAM Trust Relationship:** DB 인스턴스와 EC2 인스턴스 간의 신뢰 관계를 설정하는 것은 적절한 접근 방식이 아닙니다. 또한, Systems Manager를 주체로 지정하는 것은 이 시나리오와 관련이 없습니다.

**출제 의도:**
이 문제는 AWS에서 보안 모범 사례를 따르면서 애플리케이션이 데이터베이스 자격 증명을 안전하게 저장하고 접근할 수 있도록 설정하는 방법을 평가합니다. 특히, IAM 역할과 KMS 키를 사용하여 Systems Manager Parameter Store의 매개변수를 안전하게 관리하는 방법을 이해하는 것이 목적입니다.

**공부해야 하는 부분:**
1. **AWS Systems Manager Parameter Store:**
   - Parameter Store의 기본 개념과 사용 사례
   - Parameter Store를 사용하여 애플리케이션 자격 증명을 안전하게 저장하고 관리하는 방법

2. **IAM Roles and Policies:**
   - IAM 역할과 정책의 기본 개념과 사용 사례
   - IAM 역할을 사용하여 EC2 인스턴스에 권한을 부여하는 방법

3. **AWS Key Management Service (KMS):**
   - KMS의 기본 개념과 사용 사례
   - KMS 키를 사용하여 데이터를 


# 184번
**정답: A. Configure the Lambda function to run in the VPC with the appropriate security group.**

**해설:**
- **Lambda 함수 VPC 설정:**
  - **VPC 내 실행:** Lambda 함수를 VPC 내에서 실행하도록 설정하면, VPC의 리소스에 접근할 수 있습니다. 이는 Lambda 함수가 VPC 내의 서브넷과 보안 그룹을 사용하여 네트워크 트래픽을 제어할 수 있게 합니다.
  - **보안 그룹:** 적절한 보안 그룹을 설정하여 Lambda 함수가 온프레미스 데이터 센터의 데이터베이스에 접근할 수 있도록 허용합니다. 보안 그룹은 인바운드 및 아웃바운드 트래픽을 제어합니다.

**다른 보기가 정답이 될 수 없는 이유:**
- **B. VPN 연결 설정:** 이미 Direct Connect를 통해 온프레미스 데이터 센터에 접근할 수 있으므로, 추가적인 VPN 연결을 설정할 필요가 없습니다.
- **C. 라우트 테이블 업데이트:** 라우트 테이블을 업데이트하는 것만으로는 Lambda 함수가 VPC 내에서 실행되지 않으면 온프레미스 데이터 센터에 접근할 수 없습니다.
- **D. Elastic IP 주소 사용:** Elastic IP 주소를 사용하여 트래픽을 라우팅하는 것은 적절한 방법이 아닙니다. Lambda 함수는 ENI(Elastic Network Interface)를 통해 VPC 내에서 실행되어야 합니다.

**출제 의도:**
이 문제는 AWS Lambda 함수를 VPC 내에서 실행하여 온프레미스 데이터 센터의 리소스에 접근할 수 있도록 설정하는 방법을 평가합니다. 특히, Lambda 함수를 VPC 내에서 실행하고, 적절한 보안 그룹을 설정하여 네트워크 트래픽을 제어하는 방법을 이해하는 것이 목적입니다.

**공부해야 하는 부분:**
1. **AWS Lambda와 VPC 통합:**
   - Lambda 함수를 VPC 내에서 실행하는 방법
   - Lambda 함수에 VPC 서브넷과 보안 그룹을 할당하는 방법

2. **AWS Direct Connect:**
   - Direct Connect의 기본 개념과 사용 사례
   - Direct Connect를 사용하여 온프레미스 데이터 센터와 AWS 간의 네트워크 연결을 설정하는 방법

이 부분들을 공부하면, AWS Lambda 함수를 VPC 내에서 실행하여 온프레미스 데이터 센터의 리소스에 접근할 수 있도록 설정하는 방법을 더 잘 이해할 수 있습니다.


# 186번
- 틀리지는 않았으나 FSx, Storage Gateway 차이점을 알 수 있음

**정답: B. Configure Amazon FSx for Windows File Server. Mount the Amazon FSx file system to each Windows instance.**

**해설:**
- **Amazon FSx for Windows File Server:**
  - **Windows 네이티브 파일 시스템:** Amazon FSx for Windows File Server는 완전 관리형 네이티브 Windows 파일 시스템을 제공하여, Windows 기반 애플리케이션에 적합합니다.
  - **다중 AZ 지원:** FSx for Windows File Server는 다중 가용 영역(AZ)에 걸쳐 배포할 수 있어, 고가용성과 내구성을 제공합니다.
  - **SMB 프로토콜 지원:** FSx for Windows File Server는 SMB 프로토콜을 지원하여, 여러 EC2 Windows 인스턴스에서 파일 시스템을 공유할 수 있습니다.

**다른 보기가 정답이 될 수 없는 이유:**
- **A. AWS Storage Gateway:** Storage Gateway는 온프레미스와 AWS 간의 하이브리드 클라우드 스토리지 솔루션으로, 다중 AZ에 걸친 Windows 파일 시스템을 제공하는 데 적합하지 않습니다.
- **C. Amazon EFS:** EFS는 Linux 기반 파일 시스템으로, Windows 기반 애플리케이션에는 적합하지 않습니다.
- **D. Amazon EBS:** EBS 볼륨은 단일 EC2 인스턴스에만 연결할 수 있으며, 여러 인스턴스에서 동시에 액세스할 수 없습니다.

**출제 의도:**
이 문제는 AWS에서 Windows 기반 애플리케이션을 마이그레이션하고, 다중 AZ에 걸쳐 여러 EC2 Windows 인스턴스에서 공유할 수 있는 파일 시스템을 설정하는 방법을 평가합니다. 특히, Amazon FSx for Windows File Server를 사용하여 Windows 네이티브 파일 시스템을 제공하는 방법을 이해하는 것이 목적입니다.

**공부해야 하는 부분:**
1. **Amazon FSx for Windows File Server:**
   - FSx for Windows File Server의 기본 개념과 사용 사례
   - FSx for Windows File Server를 사용하여 Windows 기반 애플리케이션에 적합한 파일 시스템을 설정하는 방법

2. **AWS Storage Gateway:**
   - Storage Gateway의 기본 개념과 사용 사례
   - Storage Gateway를 사용하여 온프레미스와 AWS 간의 하이브리드 클라우드 스토리지를 설정하는 방법

3. **Amazon Elastic File System (EFS):**
   - EFS의 기본 개념과 사용 사례
   - EFS를 사용하여 Linux 기반 파일 시스템을 설정하는 방법

4. **Amazon Elastic Block Store (EBS):**
   - EBS의 기본 개념과 사용 사례
   - EBS 볼륨을 사용하여 단일 EC2 인스턴스에 스토리지를 제공하는 방법

이 부분들을 공부하면, AWS에서 Windows 기반 애플리케이션을 마이그레이션하고, 다중 AZ에 걸쳐 여러 EC2 Windows 인스턴스에서 공유할 수 있는 파일 시스템을 설정하는 방법을 더 잘 이해할 수 있습니다.

# 200번
### 정답
D. Configure an Amazon Cognito user pool authorizer in API Gateway to allow Amazon Cognito to validate each request.

### 해설
Amazon Cognito를 이미 사용하여 사용자를 관리하고 있으므로, API Gateway에서 Cognito 사용자 풀(authorizer)을 사용하여 각 요청을 검증하는 것이 가장 적합한 솔루션입니다. 이는 AWS 관리형 솔루션으로, 개발 노력을 줄이고 운영 오버헤드를 최소화할 수 있습니다.

각 옵션을 자세히 살펴보면:

- **A. Configure an AWS Lambda function to be an authorizer in API Gateway to validate which user made the request.**
  - Lambda 함수를 사용하여 요청을 검증하는 것은 가능하지만, 이는 추가적인 개발 노력과 운영 오버헤드를 발생시킵니다.

- **B. For each user, create and assign an API key that must be sent with each request. Validate the key by using an AWS Lambda function.**
  - 각 사용자에 대해 API 키를 생성하고 검증하는 것은 복잡하며, 추가적인 개발 노력과 운영 오버헤드를 발생시킵니다.

- **C. Send the user’s email address in the header with every request. Invoke an AWS Lambda function to validate that the user with that email address has proper access.**
  - 이메일 주소를 헤더에 포함시키고 Lambda 함수를 사용하여 검증하는 것은 보안상 적절하지 않으며, 추가적인 개발 노력과 운영 오버헤드를 발생시킵니다.

- **D. Configure an Amazon Cognito user pool authorizer in API Gateway to allow Amazon Cognito to validate each request.**
  - Cognito 사용자 풀(authorizer)을 사용하면 AWS 관리형 솔루션으로, 개발 노력을 줄이고 운영 오버헤드를 최소화할 수 있습니다. Cognito는 이미 사용자를 관리하고 있으므로, 이를 활용하여 요청을 검증하는 것이 가장 적합합니다.

따라서, 회사의 요구 사항을 가장 효율적으로 충족하는 솔루션은 옵션 D입니다.

### 필요한 학습 내용

1. **Amazon Cognito**
   - Cognito는 사용자 인증, 권한 부여 및 사용자 관리 기능을 제공하는 서비스입니다.
   - 사용자 풀을 사용하여 사용자 인증을 관리할 수 있습니다.

2. **Amazon API Gateway**
   - API Gateway는 RESTful API를 생성, 배포 및 관리할 수 있는 서비스입니다.
   - Cognito 사용자 풀(authorizer)을 사용하여 요청을 검증할 수 있습니다.

3. **AWS Lambda**
   - Lambda는 서버리스 컴퓨팅을 제공하는 서비스로, 특정 이벤트에 따라 코드를 실행할 수 있습니다.
   - 요청을 검증하는 데 사용할 수 있지만, 추가적인 개발 노력과 운영 오버헤드를 발생시킵니다.

### 추가 학습 자료
- [Amazon Cognito 공식 문서](https://docs.aws.amazon.com/ko_kr/cognito/latest/developerguide/what-is-amazon-cognito.html)
- [Amazon API Gateway 공식 문서](https://docs.aws.amazon.com/ko_kr/apigateway/latest/developerguide/welcome.html)
- [AWS Lambda 공식 문서](https://docs.aws.amazon.com/ko_kr/lambda/latest/dg/welcome.html)

이 자료들을 통해 Cognito, API Gateway, Lambda의 다양한 기능과 설정 방법을 이해하고, 특정 시나리오에서 최적의 솔루션을 선택하는 능력을 키울 수 있습니다.


# 201번
**정답: B. Build an Amazon Pinpoint journey. Configure Amazon Pinpoint to send events to an Amazon Kinesis data stream for analysis and archiving.**

**해설:**
- **Amazon Pinpoint:**
  - **SMS 메시지 전송:** Amazon Pinpoint는 마케팅 커뮤니케이션 서비스로, SMS 메시지를 전송하는 데 적합합니다. Pinpoint는 사용자에게 SMS 메시지를 보내고, 사용자의 응답을 처리할 수 있습니다.
  - **이벤트 전송:** Pinpoint는 이벤트를 Amazon Kinesis 데이터 스트림으로 전송하여, 실시간으로 데이터를 분석하고 아카이빙할 수 있습니다. 이는 사용자의 응답을 1년 동안 저장하고 분석하는 요구 사항을 충족합니다.

**다른 보기가 정답이 될 수 없는 이유:**
- **A. Amazon Connect:** Amazon Connect는 주로 콜 센터 솔루션으로 사용되며, SMS 메시지 전송에 적합하지 않습니다.
- **C. Amazon SQS:** SQS는 메시지 큐잉 서비스로, SMS 메시지 전송에 적합하지 않습니다. 또한, SQS는 메시지의 장기 저장을 제공하지 않습니다.
- **D. Amazon SNS FIFO:** SNS는 주로 알림 전송에 사용되며, SMS 메시지 전송에 적합하지 않습니다. 또한, SNS FIFO 주제는 메시지 순서를 보장하지만, SMS 메시지 전송과 응답 처리에는 적합하지 않습니다.

**출제 의도:**
이 문제는 AWS에서 SMS 메시지를 전송하고, 사용자의 응답을 저장하고 분석하는 솔루션을 설계하는 방법을 평가합니다. 특히, Amazon Pinpoint를 사용하여 SMS 메시지를 전송하고, Kinesis 데이터 스트림을 사용하여 데이터를 실시간으로 분석하고 아카이빙하는 방법을 이해하는 것이 목적입니다.

**공부해야 하는 부분:**
1. **Amazon Pinpoint:**
   - Pinpoint의 기본 개념과 사용 사례
   - Pinpoint를 사용하여 SMS 메시지를 전송하고, 사용자의 응답을 처리하는 방법

2. **Amazon Kinesis:**
   - Kinesis 데이터 스트림의 기본 개념과 사용 사례
   - Kinesis를 사용하여 데이터를 실시간으로 분석하고 아카이빙하는 방법

이 부분들을 공부하면, AWS에서 SMS 메시지를 전송하고, 사용자의 응답을 저장하고 분석하는 솔루션을 설계하는 방법을 더 잘 이해할 수 있습니다.

# 203번
**정답: D. Add an Auto Scaling group for the application that sends meeting invitations. Configure the Auto Scaling group to scale based on the depth of the SQS queue.**

**해설:**
- **Auto Scaling Group:**
  - **자동 확장:** Auto Scaling 그룹을 사용하면 애플리케이션 인스턴스 수를 자동으로 조정할 수 있습니다. SQS 큐의 깊이에 따라 인스턴스를 확장하면, 대기 중인 메시지를 더 빠르게 처리할 수 있습니다.
  - **큐 기반 확장:** SQS 큐의 깊이를 모니터링하고, 큐에 쌓인 메시지 수에 따라 인스턴스를 확장하면, 고객의 미팅 초대장이 지연 없이 발송될 수 있습니다.

**다른 보기가 정답이 될 수 없는 이유:**
- **A. DynamoDB Accelerator (DAX):** DAX는 DynamoDB의 읽기 성능을 향상시키는 데 사용되며, 현재 문제는 미팅 초대장 발송 지연이므로 적합하지 않습니다.
- **B. Amazon API Gateway:** API Gateway는 웹 애플리케이션 앞에 API를 제공하는 데 사용되며, 현재 문제는 미팅 초대장 발송 지연이므로 적합하지 않습니다.
- **C. Amazon CloudFront:** CloudFront는 콘텐츠 전송 네트워크(CDN)로, 웹 애플리케이션의 성능을 향상시키는 데 사용됩니다. 현재 문제는 미팅 초대장 발송 지연이므로 적합하지 않습니다.

**출제 의도:**
이 문제는 AWS에서 SQS 큐를 사용하여 메시지를 처리하는 애플리케이션의 성능을 향상시키는 방법을 평가합니다. 특히, Auto Scaling 그룹을 사용하여 SQS 큐의 깊이에 따라 애플리케이션 인스턴스를 자동으로 확장하는 방법을 이해하는 것이 목적입니다.

**공부해야 하는 부분:**
1. **Amazon SQS:**
   - SQS의 기본 개념과 사용 사례
   - SQS 큐의 깊이를 모니터링하고, 큐 기반 확장을 설정하는 방법

2. **Auto Scaling Group:**
   - Auto Scaling 그룹의 기본 개념과 사용 사례
   - Auto Scaling 그룹을 사용하여 애플리케이션 인스턴스를 자동으로 확장하는 방법

이 부분들을 공부하면, AWS에서 SQS 큐를 사용하여 메시지를 처리하는 애플리케이션의 성능을 향상시키는 방법을 더 잘 이해할 수 있습니다.

# 204번
**정답: C. Create a data lake by using AWS Lake Formation. Create an AWS Glue JDBC connection to Amazon RDS. Register the S3 bucket in Lake Formation. Use Lake Formation access controls to limit access.**

**해설:**
- **AWS Lake Formation:**
  - **데이터 레이크 관리:** Lake Formation은 데이터 레이크를 쉽게 설정하고 관리할 수 있는 서비스입니다. S3에 저장된 데이터를 등록하고, 다양한 데이터 소스와 통합할 수 있습니다.
  - **세분화된 권한 관리:** Lake Formation은 세분화된 데이터 액세스 제어를 제공하여, 다양한 팀이 필요한 데이터에만 접근할 수 있도록 설정할 수 있습니다. 이는 데이터 보안을 강화하고, 운영 오버헤드를 최소화합니다.
  - **AWS Glue 통합:** AWS Glue를 사용하여 RDS와의 JDBC 연결을 설정하고, 데이터를 크롤링하여 카탈로그에 등록할 수 있습니다. 이를 통해 데이터에 대한 통합된 뷰를 제공할 수 있습니다.

**다른 보기가 정답이 될 수 없는 이유:**
- **A. Amazon RDS:** 모든 데이터를 RDS로 마이그레이션하는 것은 비효율적이며, RDS의 비용과 성능 문제를 초래할 수 있습니다. 또한, RDS는 데이터 레이크 기능을 제공하지 않습니다.
- **B. AWS Lambda와 Athena:** Lambda를 사용하여 데이터를 복사하고, Athena를 사용하여 데이터를 쿼리하는 것은 가능하지만, 세분화된 권한 관리를 제공하는 데 한계가 있습니다.
- **D. Amazon Redshift:** Redshift는 데이터 웨어하우스 솔루션으로, 대규모 데이터 분석에 적합하지만, 데이터 레이크 기능을 제공하지 않습니다. 또한, Redshift로 데이터를 복사하는 것은 운영 오버헤드를 증가시킬 수 있습니다.

**출제 의도:**
이 문제는 AWS에서 대규모 데이터를 관리하고, 다양한 팀이 데이터를 분석할 수 있도록 세분화된 권한 관리를 제공하는 솔루션을 설계하는 방법을 평가합니다. 특히, AWS Lake Formation을 사용하여 데이터 레이크를 설정하고, 세분화된 권한 관리를 제공하는 방법을 이해하는 것이 목적입니다.

**공부해야 하는 부분:**
1. **AWS Lake Formation:**
   - Lake Formation의 기본 개념과 사용 사례
   - Lake Formation을 사용하여 데이터 레이크를 설정하고, 세분화된 권한 관리를 제공하는 방법

2. **AWS Glue:**
   - Glue의 기본 개념과 사용 사례
   - Glue를 사용하여 다양한 데이터 소스와 통합하고, 데이터를 크롤링하여 카탈로그에 등록하는 방법

이 부분들을 공부하면, AWS에서 대규모 데이터를 관리하고, 다양한 팀이 데이터를 분석할 수 있도록 세분화된 권한 관리를 제공하는 솔루션을 설계하는 방법을 더 잘 이해할 수 있습니다.

# 205번
**정답: C. Create a private Amazon S3 bucket. Use an S3 bucket policy to allow access from a CloudFront origin access identity (OAI). Upload website content by using the AWS CLI.**

**해설:**
- **Amazon S3와 CloudFront:**
  - **비용 효율성:** S3는 정적 콘텐츠를 호스팅하는 데 매우 비용 효율적입니다. S3 버킷을 사용하면 서버를 관리할 필요가 없으며, 스토리지 비용만 지불하면 됩니다.
  - **내구성 및 가용성:** S3는 높은 내구성과 가용성을 제공하여, 웹사이트 콘텐츠를 안전하게 저장하고 제공할 수 있습니다.
  - **CloudFront 통합:** CloudFront와 S3를 통합하면, 전 세계 사용자에게 빠르고 안정적으로 콘텐츠를 제공할 수 있습니다. OAI를 사용하여 S3 버킷에 대한 액세스를 제어할 수 있습니다.

**다른 보기가 정답이 될 수 없는 이유:**
- **A. Amazon Lightsail:** Lightsail은 가상 서버를 제공하지만, S3를 사용하는 것보다 비용 효율적이지 않습니다. 또한, 서버를 관리해야 하는 오버헤드가 있습니다.
- **B. AWS Auto Scaling과 EC2:** EC2 인스턴스를 사용하고 Auto Scaling 그룹을 설정하는 것은 정적 웹사이트 호스팅에 비해 과도한 솔루션입니다. 비용이 많이 들고, 관리 오버헤드가 큽니다.
- **D. Public S3 bucket과 AWS Transfer for SFTP:** S3 버킷을 공개로 설정하는 것은 보안 위험이 있습니다. 또한, AWS Transfer for SFTP를 사용하는 것은 추가 비용이 발생할 수 있습니다.

**출제 의도:**
이 문제는 AWS에서 정적 웹사이트를 호스팅하고, 비용 효율적이고 내구성 있는 솔루션을 설계하는 방법을 평가합니다. 특히, Amazon S3와 CloudFront를 사용하여 정적 콘텐츠를 호스팅하고, OAI를 사용하여 S3 버킷에 대한 액세스를 제어하는 방법을 이해하는 것이 목적입니다.

**공부해야 하는 부분:**
1. **Amazon S3:**
   - S3의 기본 개념과 사용 사례
   - S3 버킷을 사용하여 정적 웹사이트를 호스팅하는 방법
   - S3 버킷 정책과 OAI를 사용하여 액세스를 제어하는 방법

2. **Amazon CloudFront:**
   - CloudFront의 기본 개념과 사용 사례
   - CloudFront를 사용하여 전 세계 사용자에게 콘텐츠를 빠르고 안정적으로 제공하는 방법

이 부분들을 공부하면, AWS에서 정적 웹사이트를 호스팅하고, 비용 효율적이고 내구성 있는 솔루션을 설계하는 방법을 더 잘 이해할 수 있습니다.

# 209번
**정답: A. Use Amazon ElastiCache to manage and store session data.**

**해설:**
- **Amazon ElastiCache:**
  - **분산 세션 관리:** ElastiCache는 Redis 또는 Memcached를 사용하여 세션 데이터를 관리하고 저장할 수 있습니다. 이는 분산 환경에서 세션 데이터를 중앙 집중식으로 관리할 수 있게 합니다.
  - **고성능:** ElastiCache는 인메모리 데이터 스토어로, 세션 데이터를 빠르게 읽고 쓸 수 있어 성능이 뛰어납니다.
  - **확장성:** ElastiCache는 자동으로 확장할 수 있어, EC2 인스턴스가 자주 스케일링되는 환경에서도 안정적으로 세션 데이터를 관리할 수 있습니다.

**다른 보기가 정답이 될 수 없는 이유:**
- **B. Session Affinity (Sticky Sessions):** ALB의 세션 어피니티(스티키 세션)는 세션 데이터를 특정 인스턴스에 고정시키는 방식으로, 인스턴스가 자주 스케일링되는 환경에서는 적합하지 않습니다. 또한, 인스턴스가 종료되면 세션 데이터가 손실될 수 있습니다.
- **C. Session Manager from AWS Systems Manager:** Session Manager는 EC2 인스턴스에 대한 원격 접속을 관리하는 도구로, 세션 데이터 관리를 위한 도구가 아닙니다.
- **D. GetSessionToken API in AWS STS:** GetSessionToken API는 임시 보안 자격 증명을 생성하는 데 사용되며, 세션 데이터 관리를 위한 도구가 아닙니다.

**출제 의도:**
이 문제는 AWS에서 분산 세션 데이터를 관리하고, 자동으로 확장되는 환경에서 안정적으로 세션 데이터를 관리하는 방법을 평가합니다. 특히, Amazon ElastiCache를 사용하여 세션 데이터를 중앙 집중식으로 관리하고, 성능과 확장성을 보장하는 방법을 이해하는 것이 목적입니다.

**공부해야 하는 부분:**
1. **Amazon ElastiCache:**
   - ElastiCache의 기본 개념과 사용 사례
   - ElastiCache를 사용하여 세션 데이터를 관리하고 저장하는 방법

2. **Application Load Balancer (ALB):**
   - ALB의 기본 개념과 사용 사례
   - ALB의 세션 어피니티(스티키 세션) 기능과 그 한계

이 부분들을 공부하면, AWS에서 분산 세션 데이터를 관리하고, 자동으로 확장되는 환경에서 안정적으로 세션 데이터를 관리하는 방법을 더 잘 이해할 수 있습니다.


# 215번
**정답: A. Order AWS Snowball devices to transfer the data. Use a lifecycle policy to transition the files to Amazon S3 Glacier Deep Archive.**

**해설:**
- **AWS Snowball:**
  - **대용량 데이터 전송:** AWS Snowball는 대용량 데이터를 물리적으로 전송하는 데 적합한 솔루션입니다. 700 TB의 데이터를 1개월 내에 전송해야 하는 경우, 인터넷 연결을 통한 전송은 시간이 많이 걸릴 수 있습니다.
  - **비용 효율성:** Snowball을 사용하면 대규모 데이터를 빠르고 안전하게 전송할 수 있으며, 인터넷 대역폭을 사용하지 않으므로 비용 효율적입니다.
  - **S3 Glacier Deep Archive:** 데이터를 S3로 전송한 후, 수명 주기 정책을 사용하여 데이터를 S3 Glacier Deep Archive로 전환하면, 장기 보관 비용을 최소화할 수 있습니다.

**다른 보기가 정답이 될 수 없는 이유:**
- **B. VPN과 AWS CLI:** VPN 연결을 통해 데이터를 전송하는 것은 500 Mbps의 대역폭으로는 700 TB의 데이터를 1개월 내에 전송하기 어렵습니다.
- **C. AWS Direct Connect:** Direct Connect를 통해 데이터를 전송하는 것은 가능하지만, 500 Mbps의 대역폭으로는 700 TB의 데이터를 1개월 내에 전송하기 어렵습니다. 또한, Direct Connect는 설정과 비용 측면에서 더 복잡할 수 있습니다.
- **D. AWS DataSync:** DataSync를 사용하여 데이터를 전송하는 것은 가능하지만, 500 Mbps의 대역폭으로는 700 TB의 데이터를 1개월 내에 전송하기 어렵습니다.

**출제 의도:**
이 문제는 AWS에서 대규모 데이터를 효율적으로 전송하고, 장기 보관 비용을 최소화하는 방법을 평가합니다. 특히, AWS Snowball을 사용하여 대규모 데이터를 빠르고 안전하게 전송하고, S3 Glacier Deep Archive를 사용하여 장기 보관 비용을 최소화하는 방법을 이해하는 것이 목적입니다.

**공부해야 하는 부분:**
1. **AWS Snowball:**
   - Snowball의 기본 개념과 사용 사례
   - Snowball을 사용하여 대규모 데이터를 전송하는 방법

2. **Amazon S3 Glacier Deep Archive:**
   - S3 Glacier Deep Archive의 기본 개념과 사용 사례
   - 수명 주기 정책을 사용하여 데이터를 S3 Glacier Deep Archive로 전환하는 방법

이 부분들을 공부하면, AWS에서 대규모 데이터를 효율적으로 전송하고, 장기 보관 비용을 최소화하는 방법을 더 잘 이해할 수 있습니다.


# 217번
**정답: A. Deploy the application with the required infrastructure elements in place. Use Amazon Route 53 to configure active-passive failover. Create an Aurora Replica in a second AWS Region.**

**해설:**
- **Active-Passive Failover:**
  - **Route 53 Active-Passive Failover:** Route 53을 사용하여 활성-수동 페일오버를 구성하면, 기본 인프라가 정상일 때는 트래픽을 기본 리전으로 라우팅하고, 장애가 발생하면 대기 리전으로 트래픽을 전환할 수 있습니다.
  - **Aurora Replica:** Aurora 복제본을 두 번째 AWS 리전에 생성하면, 데이터베이스의 복구 시간을 최소화할 수 있습니다. Aurora 복제본은 기본 인스턴스의 데이터를 실시간으로 복제하므로, 데이터 손실을 최소화할 수 있습니다.

**다른 보기가 정답이 될 수 없는 이유:**
- **B. Active-Active Failover:** 활성-활성 페일오버는 두 리전 모두에서 트래픽을 처리할 수 있도록 설정하는 방식으로, 현재 요구 사항(기본 인프라가 정상일 때는 대기 리전이 로드를 처리할 필요 없음)과 맞지 않습니다.
- **C. Snapshot 복구:** 스냅샷에서 복구된 Aurora 데이터베이스를 사용하는 것은 데이터 복구 시간이 길어질 수 있으며, 30분의 다운타임 요구 사항을 충족하지 못할 수 있습니다.
- **D. AWS Backup:** AWS Backup을 사용하여 데이터를 백업하고, 이를 사용하여 두 번째 리전에 인프라를 생성하는 것은 데이터 복구 시간이 길어질 수 있으며, 30분의 다운타임 요구 사항을 충족하지 못할 수 있습니다.

**출제 의도:**
이 문제는 AWS에서 재해 복구 솔루션을 설계하고, 특정 다운타임 및 데이터 손실 허용 범위 내에서 요구 사항을 충족하는 방법을 평가합니다. 특히, Route 53을 사용하여 활성-수동 페일오버를 구성하고, Aurora 복제본을 사용하여 데이터베이스 복구 시간을 최소화하는 방법을 이해하는 것이 목적입니다.

**공부해야 하는 부분:**
1. **Amazon Route 53:**
   - Route 53의 기본 개념과 사용 사례
   - Route 53을 사용하여 활성-수동 페일오버를 구성하는 방법

2. **Amazon Aurora:**
   - Aurora의 기본 개념과 사용 사례
   - Aurora 복제본을 생성하고, 이를 사용하여 데이터베이스 복구 시간을 최소화하는 방법

이 부분들을 공부하면, AWS에서 재해 복구 솔루션을 설계하고, 특정 다운타임 및 데이터 손실 허용 범위 내에서 요구 사항을 충족하는 방법을 더 잘 이해할 수 있습니다.


# 219번
**정답: D. Modify the CloudFormation templates. Replace the EC2 instances with R5 EC2 instances. Deploy the Amazon CloudWatch agent on the EC2 instances to generate custom application latency metrics for future capacity planning.**

**해설:**
- **R5 EC2 인스턴스:**
  - **메모리 최적화:** R5 인스턴스는 메모리 최적화 인스턴스로, 메모리 집약적인 작업을 수행하는 애플리케이션에 적합합니다. 현재 애플리케이션이 메모리 집약적인 작업을 수행하고 있으므로, R5 인스턴스로 교체하면 성능이 향상될 수 있습니다.
  
- **CloudWatch 에이전트:**
  - **커스텀 메트릭:** CloudWatch 에이전트를 사용하여 애플리케이션 지연 시간과 같은 커스텀 메트릭을 생성하면, 애플리케이션 성능을 모니터링하고 향후 용량 계획에 도움이 됩니다.

**다른 보기가 정답이 될 수 없는 이유:**
- **A. T3 인스턴스:** T3 인스턴스는 버스트 가능한 성능을 제공하지만, 지속적인 고성능이 필요한 메모리 집약적인 작업에는 적합하지 않습니다.
- **B. Auto Scaling 그룹:** Auto Scaling 그룹을 사용하여 인스턴스를 확장하는 것은 가능하지만, 상태 저장 애플리케이션의 경우 상태를 유지하는 데 어려움이 있을 수 있습니다. 또한, 메모리 최적화 인스턴스로 교체하는 것이 더 효과적입니다.
- **C. CloudWatch 메모리 메트릭:** CloudWatch의 기본 메모리 메트릭을 사용하는 것은 가능하지만, 애플리케이션 지연 시간과 같은 커스텀 메트릭을 생성하는 것이 더 유용합니다.

**출제 의도:**
이 문제는 AWS에서 메모리 집약적인 애플리케이션의 성능 문제를 해결하고, 운영 효율성을 극대화하는 방법을 평가합니다. 특히, 메모리 최적화 인스턴스로 교체하고, CloudWatch 에이전트를 사용하여 커스텀 메트릭을 생성하는 방법을 이해하는 것이 목적입니다.

**공부해야 하는 부분:**
1. **EC2 인스턴스 유형:**
   - M5, T3, R5 인스턴스의 기본 개념과 사용 사례
   - 메모리 최적화 인스턴스(R5)를 사용하여 메모리 집약적인 작업을 수행하는 방법

2. **Amazon CloudWatch:**
   - CloudWatch의 기본 개념과 사용 사례
   - CloudWatch 에이전트를 사용하여 커스텀 메트릭을 생성하고, 애플리케이션 성능을 모니터링하는 방법

이 부분들을 공부하면, AWS에서 메모리 집약적인 애플리케이션의 성능 문제를 해결하고, 운영 효율성을 극대화하는 방법을 더 잘 이해할 수 있습니다.

# 224번
**정답: C. Create an Amazon Route 53 multivalue answer routing policy. E. Launch four EC2 instances: two instances in one Availability Zone and two instances in another Availability Zone.**

**해설:**
- **Amazon Route 53 Multivalue Answer Routing Policy:**
  - **C. Multivalue Answer Routing Policy:** 이 라우팅 정책은 여러 IP 주소를 반환하여 트래픽을 무작위로 분산시킬 수 있습니다. 이는 모든 실행 중인 EC2 인스턴스에 트래픽을 무작위로 분산시키는 요구 사항을 충족합니다.

- **다중 가용 영역 배포:**
  - **E. Launch four EC2 instances:** 두 개의 가용 영역에 각각 두 개의 EC2 인스턴스를 배포하면, 고가용성과 장애 내성을 보장할 수 있습니다. 이는 하나의 가용 영역에 장애가 발생하더라도 다른 가용 영역의 인스턴스가 트래픽을 처리할 수 있도록 합니다.

**다른 보기가 정답이 될 수 없는 이유:**
- **A. Failover Routing Policy:** 이 라우팅 정책은 주로 장애 조치(failover)를 위해 사용되며, 트래픽을 무작위로 분산시키는 데 적합하지 않습니다.
- **B. Weighted Routing Policy:** 가중치 라우팅 정책은 트래픽을 특정 비율로 분산시키는 데 사용되며, 무작위 분산을 보장하지 않습니다.
- **D. Launch three EC2 instances:** 세 개의 인스턴스를 배포하는 것은 고가용성과 장애 내성을 보장하기에 충분하지 않을 수 있습니다. 두 개의 가용 영역에 각각 두 개의 인스턴스를 배포하는 것이 더 적합합니다.

**출제 의도:**
이 문제는 AWS에서 웹 애플리케이션의 아키텍처를 고가용성과 장애 내성을 갖추도록 설계하는 방법을 평가합니다. 특히, Route 53의 Multivalue Answer Routing Policy를 사용하여 트래픽을 무작위로 분산시키고, 다중 가용 영역에 인스턴스를 배포하여 고가용성을 보장하는 방법을 이해하는 것이 목적입니다.

**공부해야 하는 부분:**
1. **Amazon Route 53 Routing Policies:**
   - Route 53의 다양한 라우팅 정책(예: Multivalue Answer, Weighted, Failover)의 기본 개념과 사용 사례
   - Multivalue Answer Routing Policy를 사용하여 트래픽을 무작위로 분산시키는 방법

2. **고가용성과 장애 내성:**
   - 다중 가용 영역에 인스턴스를 배포하여 고가용성과 장애 내성을 보장하는 방법
   - AWS에서 고가용성과 장애 내성을 갖춘 아키텍처를 설계하는 모범 사례

이 부분들을 공부하면, AWS에서 웹 애플리케이션의 아키텍처를 고가용성과 장애 내성을 갖추도록 설계하는 방법을 더 잘 이해할 수 있습니다.


# 230번
**정답: C. Remove the two NAT instances and replace them with two NAT gateways in different Availability Zones.**

**해설:**
- **NAT 게이트웨이:**
  - **고가용성 및 장애 내성:** NAT 게이트웨이는 AWS에서 관리되는 서비스로, 고가용성과 장애 내성을 제공합니다. 서로 다른 가용 영역에 NAT 게이트웨이를 배포하면, 하나의 가용 영역에 장애가 발생하더라도 다른 가용 영역의 NAT 게이트웨이가 트래픽을 처리할 수 있습니다.
  - **자동 확장:** NAT 게이트웨이는 자동으로 확장되어 트래픽 증가를 처리할 수 있습니다. 이는 수동으로 인스턴스를 관리할 필요가 없으므로 운영 오버헤드를 줄여줍니다.

**다른 보기가 정답이 될 수 없는 이유:**
- **A. 동일한 가용 영역에 두 개의 NAT 게이트웨이:** 동일한 가용 영역에 두 개의 NAT 게이트웨이를 배포하는 것은 고가용성과 장애 내성을 제공하지 않습니다. 하나의 가용 영역에 장애가 발생하면 두 개의 NAT 게이트웨이 모두 사용할 수 없게 됩니다.
- **B. Auto Scaling 그룹과 Network Load Balancers:** NAT 인스턴스를 Auto Scaling 그룹과 Network Load Balancers로 관리하는 것은 가능하지만, NAT 게이트웨이를 사용하는 것이 더 간단하고 관리 오버헤드가 적습니다.
- **D. Spot Instances와 Network Load Balancer:** Spot Instances는 비용 효율적일 수 있지만, 인스턴스가 언제든지 종료될 수 있으므로 안정적인 NAT 솔루션으로 적합하지 않습니다. 또한, Network Load Balancer를 사용하는 것은 NAT 게이트웨이를 사용하는 것보다 복잡합니다.

**출제 의도:**
이 문제는 AWS에서 NAT 인스턴스를 NAT 게이트웨이로 교체하여 고가용성, 장애 내성, 자동 확장을 제공하는 방법을 평가합니다. 특히, 서로 다른 가용 영역에 NAT 게이트웨이를 배포하여 고가용성과 장애 내성을 보장하는 방법을 이해하는 것이 목적입니다.

**공부해야 하는 부분:**
1. **NAT 게이트웨이:**
   - NAT 게이트웨이의 기본 개념과 사용 사례
   - NAT 게이트웨이를 사용하여 고가용성, 장애 내성, 자동 확장을 제공하는 방법

2. **NAT 인스턴스:**
   - NAT 인스턴스의 기본 개념과 사용 사례
   - NAT 인스턴스를 NAT 게이트웨이로 교체하는 이유와 장점

이 부분들을 공부하면, AWS에서 NAT 인스턴스를 NAT 게이트웨이로 교체하여 고가용성, 장애 내성, 자동 확장을 제공하는 방법을 더 잘 이해할 수 있습니다.

# 232번
**정답: C. Publish VPC flow logs to Amazon CloudWatch Logs. Create required metric filters. Create an Amazon CloudWatch metric alarm with a notification action for when the alarm is in the ALARM state.**

**해설:**
- **VPC Flow Logs와 CloudWatch Logs:**
  - **VPC Flow Logs:** VPC Flow Logs를 사용하면 VPC 내의 네트워크 트래픽을 캡처하고 분석할 수 있습니다. RDP(포트 3389) 또는 SSH(포트 22) 트래픽을 감지할 수 있습니다.
  - **CloudWatch Logs:** VPC Flow Logs를 CloudWatch Logs로 전송하면, 로그 데이터를 기반으로 메트릭 필터를 생성할 수 있습니다.
  - **CloudWatch Metric Alarm:** 메트릭 필터를 사용하여 특정 조건(RDP 또는 SSH 트래픽 감지)에 대한 알람을 생성하고, 알람 상태가 ALARM일 때 알림을 보낼 수 있습니다.

**다른 보기가 정답이 될 수 없는 이유:**
- **A. CloudWatch Application Insights:** Application Insights는 애플리케이션 모니터링 도구로, RDP 또는 SSH 접근을 감지하는 데 적합하지 않습니다.
- **B. IAM Instance Profile:** IAM 인스턴스 프로파일과 AmazonSSMManagedInstanceCore 정책은 Systems Manager를 사용하여 인스턴스를 관리하는 데 사용됩니다. RDP 또는 SSH 접근을 감지하는 데 직접적인 도움이 되지 않습니다.
- **D. EventBridge Rule:** EC2 Instance State-change Notification은 인스턴스 상태 변경(예: 시작, 중지, 종료)에 대한 알림을 제공합니다. RDP 또는 SSH 접근을 감지하는 데 적합하지 않습니다.

**출제 의도:**
이 문제는 AWS에서 VPC 내의 네트워크 트래픽을 모니터링하고, 특정 조건(RDP 또는 SSH 접근)에 대한 알림을 설정하는 방법을 평가합니다. 특히, VPC Flow Logs와 CloudWatch Logs를 사용하여 네트워크 트래픽을 분석하고, CloudWatch Metric Alarm을 설정하는 방법을 이해하는 것이 목적입니다.

**공부해야 하는 부분:**
1. **VPC Flow Logs:**
   - VPC Flow Logs의 기본 개념과 사용 사례
   - VPC Flow Logs를 사용하여 네트워크 트래픽을 캡처하고 분석하는 방법

2. **Amazon CloudWatch Logs:**
   - CloudWatch Logs의 기본 개념과 사용 사례
   - CloudWatch Logs를 사용하여 로그 데이터를 분석하고, 메트릭 필터를 생성하는 방법

3. **Amazon CloudWatch Alarms:**
   - CloudWatch Alarms의 기본 개념과 사용 사례
   - CloudWatch Alarms를 사용하여 특정 조건에 대한 알림을 설정하는 방법

이 부분들을 공부하면, AWS에서 VPC 내의 네트워크 트래픽을 모니터링하고, 특정 조건에 대한 알림을 설정하는 방법을 더 잘 이해할 수 있습니다.

# 235번
**정답: C. Use the AWS Schema Conversion Tool with AWS Database Migration Service (AWS DMS) using a memory optimized replication instance. Create a full load plus change data capture (CDC) replication task and a table mapping to select all tables.**

**해설:**
- **AWS Schema Conversion Tool (SCT):**
  - **스키마 변환:** SCT는 Oracle 데이터베이스 스키마를 Aurora PostgreSQL로 변환하는 데 사용됩니다. 이는 데이터베이스 구조를 호환되게 만듭니다.
  
- **AWS Database Migration Service (DMS):**
  - **메모리 최적화 인스턴스:** 메모리 최적화 인스턴스를 사용하면, 높은 읽기 및 쓰기 트래픽을 처리하는 데 적합합니다.
  - **전체 로드 및 CDC:** 전체 로드와 변경 데이터 캡처(CDC)를 사용하면, 초기 데이터 로드 후에도 데이터베이스 간의 동기화를 유지할 수 있습니다. 이는 데이터가 계속해서 동기화된 상태로 유지되도록 합니다.

**다른 보기가 정답이 될 수 없는 이유:**
- **A. DataSync와 CDC:** DataSync는 파일 기반 데이터 전송에 적합하며, 데이터베이스 마이그레이션에는 적합하지 않습니다. 또한, 전체 로드 없이 CDC만 사용하는 것은 초기 데이터 로드를 처리하지 못합니다.
- **B. DataSync와 전체 로드 + CDC:** DataSync는 데이터베이스 마이그레이션에 적합하지 않습니다. SCT를 사용하여 스키마 변환을 수행하는 것이 더 적합합니다.
- **D. Compute 최적화 인스턴스와 일부 테이블 선택:** Compute 최적화 인스턴스는 메모리 최적화 인스턴스보다 높은 읽기 및 쓰기 트래픽을 처리하는 데 적합하지 않습니다. 또한, 일부 테이블만 선택하는 것은 전체 데이터 동기화를 보장하지 않습니다.

**출제 의도:**
이 문제는 AWS에서 데이터베이스를 마이그레이션하고, 높은 읽기 및 쓰기 트래픽을 처리하며, 데이터 동기화를 유지하는 방법을 평가합니다. 특히, AWS SCT와 DMS를 사용하여 스키마 변환과 데이터 마이그레이션을 수행하고, 메모리 최적화 인스턴스를 사용하여 높은 트래픽을 처리하는 방법을 이해하는 것이 목적입니다.

**공부해야 하는 부분:**
1. **AWS Schema Conversion Tool (SCT):**
   - SCT의 기본 개념과 사용 사례
   - SCT를 사용하여 Oracle 스키마를 Aurora PostgreSQL로 변환하는 방법

2. **AWS Database Migration Service (DMS):**
   - DMS의 기본 개념과 사용 사례
   - DMS를 사용하여 전체 로드 및 CDC를 통해 데이터베이스를 마이그레이션하고 동기화하는 방법
   - 메모리 최적화 인스턴스를 사용하여 높은 트래픽을 처리하는 방법

이 부분들을 공부하면, AWS에서 데이터베이스를 마이그레이션하고, 높은 읽기 및 쓰기 트래픽을 처리하며, 데이터 동기화를 유지하는 방법을 더 잘 이해할 수 있습니다.


# 237번
**정답: A. Set up a VPC peering connection between VPC-A and VPC-B.**

**해설:**
- **VPC Peering:**
  - **보안 및 성능:** VPC 피어링은 두 VPC 간의 트래픽을 안전하게 전송할 수 있는 방법입니다. 트래픽이 인터넷을 거치지 않고 AWS 네트워크 내에서 전송되므로 보안이 강화됩니다.
  - **고가용성:** VPC 피어링은 AWS 네트워크 인프라를 통해 고가용성과 높은 대역폭을 제공합니다. 이는 단일 장애 지점 없이 안정적인 연결을 보장합니다.
  - **다중 계정 지원:** VPC 피어링은 동일한 AWS 계정 내의 VPC뿐만 아니라, 서로 다른 AWS 계정 간의 VPC 간에도 설정할 수 있습니다.

**다른 보기가 정답이 될 수 없는 이유:**
- **B. VPC Gateway Endpoints:** VPC 게이트웨이 엔드포인트는 S3나 DynamoDB와 같은 특정 AWS 서비스에 대한 프라이빗 연결을 제공하는 데 사용됩니다. EC2 인스턴스 간의 연결에는 적합하지 않습니다.
- **C. Virtual Private Gateway:** 가상 프라이빗 게이트웨이는 온프레미스 네트워크와 VPC 간의 연결을 설정하는 데 사용됩니다. VPC 간의 연결에는 적합하지 않습니다.
- **D. Private Virtual Interface (VIF):** 프라이빗 VIF는 Direct Connect를 통해 온프레미스 네트워크와 VPC 간의 연결을 설정하는 데 사용됩니다. VPC 간의 연결에는 적합하지 않습니다.

**출제 의도:**
이 문제는 AWS에서 서로 다른 계정에 있는 두 VPC 간의 안전하고 고가용성 연결을 설정하는 방법을 평가합니다. 특히, VPC 피어링을 사용하여 두 VPC 간의 트래픽을 안전하게 전송하고, 단일 장애 지점 없이 안정적인 연결을 보장하는 방법을 이해하는 것이 목적입니다.

**공부해야 하는 부분:**
1. **VPC Peering:**
   - VPC 피어링의 기본 개념과 사용 사례
   - VPC 피어링을 설정하여 두 VPC 간의 트래픽을 안전하게 전송하는 방법
   - 서로 다른 AWS 계정 간의 VPC 피어링 설정 방법

2. **VPC Gateway Endpoints 및 Virtual Private Gateway:**
   - VPC 게이트웨이 엔드포인트와 가상 프라이빗 게이트웨이의 기본 개념과 사용 사례
   - 이들이 VPC 간의 연결에 적합하지 않은 이유

이 부분들을 공부하면, AWS에서 서로 다른 계정에 있는 두 VPC 간의 안전하고 고가용성 연결을 설정하는 방법을 더 잘 이해할 수 있습니다.


# 238번
**정답: C. Use AWS Budgets to create a cost budget for each account. Set the period to monthly. Set the scope to EC2 instances. Set an alert threshold for the budget. Configure an Amazon Simple Notification Service (Amazon SNS) topic to receive a notification when a threshold is exceeded.**

**해설:**
- **AWS Budgets:**
  - **비용 관리:** AWS Budgets는 비용 및 사용량을 추적하고, 특정 임계값을 초과할 때 알림을 설정할 수 있는 서비스입니다. 이는 비용 초과를 방지하고, 예산을 관리하는 데 유용합니다.
  - **알림 설정:** 예산을 설정하고, 특정 임계값을 초과할 때 Amazon SNS를 통해 알림을 받을 수 있습니다. 이는 비용 초과를 실시간으로 모니터링하고, 즉시 대응할 수 있도록 합니다.

**다른 보기가 정답이 될 수 없는 이유:**
- **A. Cost Explorer 일일 보고서:** Cost Explorer를 사용하여 일일 보고서를 생성하고, SES를 통해 알림을 설정하는 것은 가능하지만, AWS Budgets를 사용하는 것이 더 간단하고 비용 효율적입니다.
- **B. Cost Explorer 월간 보고서:** Cost Explorer를 사용하여 월간 보고서를 생성하고, SES를 통해 알림을 설정하는 것은 가능하지만, AWS Budgets를 사용하는 것이 더 간단하고 비용 효율적입니다.
- **D. Cost and Usage Reports와 Athena:** Cost and Usage Reports를 사용하여 시간별 보고서를 생성하고, Athena와 EventBridge를 사용하여 쿼리를 스케줄링하는 것은 가능하지만, 이는 복잡하고 관리 오버헤드가 큽니다. AWS Budgets를 사용하는 것이 더 간단하고 비용 효율적입니다.

**출제 의도:**
이 문제는 AWS에서 비용을 관리하고, 특정 임계값을 초과할 때 알림을 설정하는 방법을 평가합니다. 특히, AWS Budgets를 사용하여 비용을 추적하고, 알림을 설정하는 방법을 이해하는 것이 목적입니다.

**공부해야 하는 부분:**
1. **AWS Budgets:**
   - AWS Budgets의 기본 개념과 사용 사례
   - AWS Budgets를 사용하여 비용 및 사용량을 추적하고, 알림을 설정하는 방법

2. **Amazon SNS:**
   - Amazon SNS의 기본 개념과 사용 사례
   - SNS를 사용하여 알림을 설정하고, 알림을 수신하는 방법

이 부분들을 공부하면, AWS에서 비용을 관리하고, 특정 임계값을 초과할 때 알림을 설정하는 방법을 더 잘 이해할 수 있습니다.

# 239번
**정답: B. Create a Lambda function URL for the function. Specify AWS_IAM as the authentication type.**

**해설:**
- **Lambda Function URL:**
  - **운영 효율성:** Lambda Function URL은 Lambda 함수에 직접 HTTPS 엔드포인트를 제공하는 기능입니다. 이를 통해 API Gateway를 설정할 필요 없이 Lambda 함수에 직접 접근할 수 있습니다.
  - **IAM 인증:** Lambda Function URL은 AWS_IAM 인증 유형을 지원하므로, IAM을 사용하여 호출을 인증할 수 있습니다. 이는 보안 요구 사항을 충족합니다.

**다른 보기가 정답이 될 수 없는 이유:**
- **A. API Gateway:** API Gateway를 사용하여 Lambda 함수를 호출하는 것은 가능하지만, Lambda Function URL을 사용하는 것이 더 간단하고 운영 오버헤드가 적습니다.
- **C. Lambda@Edge:** Lambda@Edge는 CloudFront와 통합되어 엣지 로케이션에서 코드를 실행하는 데 사용됩니다. 이는 글로벌 콘텐츠 전송에 적합하지만, 단순한 마이크로서비스 호출에는 과도한 설정이 필요합니다.
- **D. CloudFront Functions:** CloudFront Functions는 CloudFront 배포와 통합되어 엣지에서 간단한 JavaScript 함수를 실행하는 데 사용됩니다. 이는 Lambda 함수를 호출하는 데 적합하지 않습니다.

**출제 의도:**
이 문제는 AWS에서 마이크로서비스를 배포하고, HTTPS 엔드포인트와 IAM 인증을 설정하는 방법을 평가합니다. 특히, Lambda Function URL을 사용하여 운영 오버헤드를 최소화하고, IAM 인증을 설정하는 방법을 이해하는 것이 목적입니다.

**공부해야 하는 부분:**
1. **Lambda Function URL:**
   - Lambda Function URL의 기본 개념과 사용 사례
   - Lambda Function URL을 사용하여 Lambda 함수에 직접 HTTPS 엔드포인트를 제공하는 방법
   - AWS_IAM 인증 유형을 사용하여 호출을 인증하는 방법

2. **Amazon API Gateway:**
   - API Gateway의 기본 개념과 사용 사례
   - API Gateway를 사용하여 Lambda 함수를 호출하고, IAM 인증을 설정하는 방법

이 부분들을 공부하면, AWS에서 마이크로서비스를 배포하고, HTTPS 엔드포인트와 IAM 인증을 설정하는 방법을 더 잘 이해할 수 있습니다.


# 240번
**정답: D. Host the visualization tool in the same AWS Region as the data warehouse and access it over a Direct Connect connection at a location in the same Region.**

**해설:**
- **Direct Connect 비용 절감:**
  - **Direct Connect:** Direct Connect는 AWS와 온프레미스 네트워크 간의 전용 네트워크 연결을 제공하여, 데이터 전송 비용을 절감할 수 있습니다. 특히, 동일한 AWS 리전 내에서 Direct Connect를 사용하는 경우, 인터넷을 통한 데이터 전송보다 비용이 저렴합니다.
  - **동일 리전 내 호스팅:** 시각화 도구를 데이터 웨어하우스와 동일한 AWS 리전에 호스팅하면, 데이터 전송이 AWS 네트워크 내에서 이루어지므로 추가적인 인터넷 데이터 전송 비용이 발생하지 않습니다.

**다른 보기가 정답이 될 수 없는 이유:**
- **A. 인터넷을 통한 쿼리:** 인터넷을 통해 데이터 웨어하우스를 쿼리하면, 데이터 전송 비용이 높아질 수 있습니다. 특히, 50MB 크기의 쿼리 결과를 자주 전송하는 경우, 비용이 크게 증가할 수 있습니다.
- **B. 인터넷을 통한 접근:** 시각화 도구를 AWS 리전에 호스팅하더라도, 인터넷을 통해 접근하면 데이터 전송 비용이 발생합니다. Direct Connect를 사용하는 것이 더 비용 효율적입니다.
- **C. 온프레미스에서 Direct Connect 사용:** 시각화 도구를 온프레미스에 호스팅하고 Direct Connect를 사용하는 것은 가능하지만, 데이터 웨어하우스와 시각화 도구 간의 데이터 전송이 여전히 발생하므로 비용이 더 높아질 수 있습니다.

**출제 의도:**
이 문제는 AWS에서 데이터 전송 비용을 최소화하는 방법을 평가합니다. 특히, Direct Connect를 사용하여 데이터 전송 비용을 절감하고, 동일한 AWS 리전 내에서 시각화 도구와 데이터 웨어하우스를 호스팅하여 추가적인 인터넷 데이터 전송 비용을 피하는 방법을 이해하는 것이 목적입니다.

**공부해야 하는 부분:**
1. **AWS Direct Connect:**
   - Direct Connect의 기본 개념과 사용 사례
   - Direct Connect를 사용하여 데이터 전송 비용을 절감하는 방법

2. **데이터 전송 비용:**
   - AWS에서 데이터 전송 비용 구조
   - 인터넷을 통한 데이터 전송과 Direct Connect를 통한 데이터 전송 비용 비교

이 부분들을 공부하면, AWS에서 데이터 전송 비용을 최소화하는 방법을 더 잘 이해할 수 있습니다.


# 241번
**정답: C. Migrate the PostgreSQL database to an Amazon RDS for PostgreSQL DB instance. Create a read replica in another Region.**

**해설:**
- **Amazon RDS Read Replica:**
  - **다중 리전 가용성:** RDS 읽기 복제본을 다른 리전에 생성하면, 데이터가 여러 리전에 걸쳐 복제되어 고가용성을 보장할 수 있습니다. 이는 데이터가 항상 온라인 상태로 유지되도록 합니다.
  - **운영 오버헤드 최소화:** RDS 읽기 복제본은 AWS에서 관리되므로, 수동으로 복제 설정을 관리할 필요가 없습니다. 이는 운영 오버헤드를 최소화합니다.

**다른 보기가 정답이 될 수 없는 이유:**
- **A. PostgreSQL cluster on EC2:** EC2 인스턴스에서 PostgreSQL 클러스터를 운영하는 것은 많은 관리 오버헤드가 발생합니다. 수동으로 복제를 설정하고 관리해야 하므로, 운영 오버헤드가 큽니다.
- **B. RDS Multi-AZ:** Multi-AZ 배포는 동일한 리전 내에서 고가용성을 제공하지만, 다중 리전 가용성을 제공하지 않습니다.
- **D. DB snapshots:** 스냅샷을 다른 리전에 복사하는 것은 데이터 백업을 위한 방법이며, 실시간 데이터 가용성을 보장하지 않습니다. 이는 데이터가 항상 온라인 상태로 유지되도록 하지 않습니다.

**출제 의도:**
이 문제는 AWS에서 다중 리전 가용성을 제공하고, 운영 오버헤드를 최소화하는 방법을 평가합니다. 특히, RDS 읽기 복제본을 사용하여 데이터가 여러 리전에 걸쳐 복제되고, 항상 온라인 상태로 유지되도록 하는 방법을 이해하는 것이 목적입니다.

**공부해야 하는 부분:**
1. **Amazon RDS Read Replica:**
   - RDS 읽기 복제본의 기본 개념과 사용 사례
   - RDS 읽기 복제본을 사용하여 다중 리전 가용성을 제공하는 방법

2. **Amazon RDS Multi-AZ:**
   - RDS Multi-AZ의 기본 개념과 사용 사례
   - RDS Multi-AZ가 다중 리전 가용성을 제공하지 않는 이유

이 부분들을 공부하면, AWS에서 다중 리전 가용성을 제공하고, 운영 오버헤드를 최소화하는 방법을 더 잘 이해할 수 있습니다.


# 242번
**정답: C. Multivalue routing policy**

**해설:**
- **Multivalue Routing Policy:**
  - **다중 IP 주소 반환:** Multivalue Answer Routing Policy는 여러 IP 주소를 반환할 수 있습니다. 이는 DNS 쿼리에 대해 여러 EC2 인스턴스의 IP 주소를 반환하여, 트래픽을 분산시킬 수 있습니다.
  - **헬스 체크:** Multivalue Answer Routing Policy는 헬스 체크를 지원하여, 건강한 인스턴스의 IP 주소만 반환할 수 있습니다. 이는 요청이 건강하지 않은 인스턴스로 라우팅되지 않도록 보장합니다.

**다른 보기가 정답이 될 수 없는 이유:**
- **A. Simple Routing Policy:** Simple Routing Policy는 단일 IP 주소를 반환합니다. 여러 IP 주소를 반환하는 요구 사항을 충족하지 않습니다.
- **B. Latency Routing Policy:** Latency Routing Policy는 지연 시간을 기준으로 트래픽을 라우팅합니다. 여러 IP 주소를 반환하는 요구 사항을 충족하지 않습니다.
- **D. Geolocation Routing Policy:** Geolocation Routing Policy는 사용자의 지리적 위치를 기준으로 트래픽을 라우팅합니다. 여러 IP 주소를 반환하는 요구 사항을 충족하지 않습니다.

**출제 의도:**
이 문제는 AWS Route 53에서 여러 IP 주소를 반환하고, 헬스 체크를 통해 건강한 인스턴스의 IP 주소만 반환하는 방법을 평가합니다. 특히, Multivalue Answer Routing Policy를 사용하여 이러한 요구 사항을 충족하는 방법을 이해하는 것이 목적입니다.

**공부해야 하는 부분:**
1. **Route 53 Routing Policies:**
   - Route 53의 다양한 라우팅 정책(예: Simple, Latency, Multivalue, Geolocation)의 기본 개념과 사용 사례
   - Multivalue Answer Routing Policy를 사용하여 여러 IP 주소를 반환하고, 헬스 체크를 통해 건강한 인스턴스의 IP 주소만 반환하는 방법

이 부분들을 공부하면, AWS Route 53에서 여러 IP 주소를 반환하고, 헬스 체크를 통해 건강한 인스턴스의 IP 주소만 반환하는 방법을 더 잘 이해할 수 있습니다.


# 246번
**정답: D. Create public subnets in each Availability Zone. Associate the public subnets with the ALB. Update the route tables for the public subnets with a route to the private subnets.**

**해설:**
- **인터넷 접근:** 인터넷에서 접근할 수 있는 ALB는 퍼블릭 서브넷에 배치되어야 합니다. 퍼블릭 서브넷은 인터넷 게이트웨이와 연결되어 있어야 하며, 이를 통해 인터넷 트래픽을 수신할 수 있습니다.
- **프라이빗 서브넷의 EC2 인스턴스:** EC2 인스턴스는 프라이빗 서브넷에 남아 있어도 됩니다. ALB가 퍼블릭 서브넷에 배치되고, 퍼블릭 서브넷의 라우팅 테이블이 프라이빗 서브넷으로의 경로를 포함하면, ALB는 프라이빗 서브넷의 EC2 인스턴스에 트래픽을 전달할 수 있습니다.

**다른 보기가 정답이 될 수 없는 이유:**
- **A. NAT 게이트웨이와 Network Load Balancer:** NAT 게이트웨이는 주로 프라이빗 서브넷의 인스턴스가 인터넷에 접근할 수 있도록 하는 데 사용됩니다. 인터넷에서 접근할 수 있는 ALB를 대체하는 데 적합하지 않습니다.
- **B. EC2 인스턴스를 퍼블릭 서브넷으로 이동:** EC2 인스턴스를 퍼블릭 서브넷으로 이동하는 것은 보안 위험이 있습니다. 프라이빗 서브넷에 인스턴스를 유지하면서 ALB를 퍼블릭 서브넷에 배치하는 것이 더 

# 247번
**정답: A. Enable binlog replication on the RDS primary node. C. Allow long-running transactions to complete on the source DB instance.**

**해설:**
- **A. Enable binlog replication on the RDS primary node:**
  - **Binlog 복제:** RDS MySQL에서 읽기 복제본을 생성하려면 바이너리 로그(binlog) 복제가 활성화되어 있어야 합니다. 이는 데이터 변경 사항을 기록하고, 읽기 복제본으로 복제하는 데 필요합니다.

- **C. Allow long-running transactions to complete on the source DB instance:**
  - **긴 트랜잭션 완료:** 읽기 복제본을 생성하기 전에 소스 DB 인스턴스에서 실행 중인 긴 트랜잭션이 완료되도록 해야 합니다. 이는 데이터 일관성을 보장하고, 복제본 생성 중에 데이터 손실을 방지합니다.

**다른 보기가 정답이 될 수 없는 이유:**
- **B. Choose a failover priority for the source DB instance:** 읽기 복제본을 생성하는 것과는 직접적인 관련이 없습니다. 이는 고가용성을 위한 설정입니다.
- **D. Create a global table and specify the AWS Regions where the table will be available:** 글로벌 테이블은 DynamoDB와 관련된 기능이며, RDS MySQL과는 관련이 없습니다.
- **E. Enable automatic backups on the source instance by setting the backup retention period to a value other than 0:** 자동 백업을 활성화하는 것은 좋은 관행이지만, 읽기 복제본을 생성하는 데 필수적인 단계는 아닙니다.

**출제 의도:**
이 문제는 AWS RDS MySQL에서 읽기 복제본을 생성하기 전에 수행해야 할 필수 작업을 평가합니다. 특히, binlog 복제를 활성화하고, 긴 트랜잭션이 완료되도록 하는 방법을 이해하는 것이 목적입니다.

**공부해야 하는 부분:**
1. **RDS MySQL Read Replica:**
   - 읽기 복제본의 기본 개념과 사용 사례
   - 읽기 복제본을 생성하기 전에 수행해야 할 필수 작업

2. **Binlog Replication:**
   - 바이너리 로그(binlog) 복제의 기본 개념과 사용 사례
   - binlog 복제를 활성화하는 방법

이 부분들을 공부하면, AWS RDS MySQL에서 읽기 복제본을 생성하기 전에 수행해야 할 필수 작업을 더 잘 이해할 수 있습니다.


# 263번
**정답: A. Deploy an Amazon Elastic Container Service (Amazon ECS) cluster. D. Deploy an Amazon Elastic Container Service (Amazon ECS) service with a Fargate launch type. Specify a desired task number level of greater than or equal to 2.**

**해설:**
- **Amazon ECS와 Fargate:**
  - **ECS 클러스터:** Amazon ECS는 AWS에서 컨테이너를 관리하는 서비스로, 클러스터를 사용하여 여러 컨테이너를 관리할 수 있습니다. ECS 클러스터를 사용하면 컨테이너 오케스트레이션을 쉽게 수행할 수 있습니다.
  - **Fargate 런치 타입:** Fargate는 서버리스 컨테이너 실행 환경으로, 인프라를 관리할 필요 없이 컨테이너를 실행할 수 있습니다. Fargate를 사용하면 EC2 인스턴스를 관리할 필요가 없으므로, 유지 관리와 확장에 대한 노력이 최소화됩니다.

**다른 보기가 정답이 될 수 없는 이유:**
- **B. Kubernetes control plane on EC2:** Kubernetes 제어 평면을 EC2 인스턴스에 배포하면, 추가 인프라를 관리해야 하므로 유지 관리 노력이 증가합니다.
- **C. ECS with EC2 launch type:** EC2 런치 타입을 사용하면 EC2 인스턴스를 관리해야 하므로, 추가 인프라를 관리해야 합니다. 이는 유지 관리 노력을 증가시킵니다.
- **E. Kubernetes worker nodes on EC2:** Kubernetes 워커 노드를 EC2 인스턴스에 배포하면, 추가 인프라를 관리해야 하므로 유지 관리 노력이 증가합니다.

**출제 의도:**
이 문제는 AWS에서 컨테이너 기술을 사용하여 마이크로서비스를 배포하고, 유지 관리와 확장에 대한 노력을 최소화하는 방법을 평가합니다. 특히, Amazon ECS와 Fargate를 사용하여 서버리스 컨테이너 실행 환경을 구성하는 방법을 이해하는 것이 목적입니다.

**공부해야 하는 부분:**
1. **Amazon ECS:**
   - ECS의 기본 개념과 사용 사례
   - ECS 클러스터를 사용하여 컨테이너를 관리하는 방법

2. **AWS Fargate:**
   - Fargate의 기본 개념과 사용 사례
   - Fargate를 사용하여 서버리스 컨테이너 실행 환경을 구성하는 방법

이 부분들을 공부하면, AWS에서 컨테이너 기술을 사용하여 마이크로서비스를 배포하고, 유지 관리와 확장에 대한 노력을 최소화하는 방법을 더 잘 이해할 수 있습니다.


# 276번
**정답: A. Configure storage Auto Scaling on the RDS for Oracle instance. D. Configure the Auto Scaling group to use the average CPU as the scaling metric.**

**해설:**
- **A. Configure storage Auto Scaling on the RDS for Oracle instance:**
  - **자동 스토리지 확장:** RDS for Oracle 인스턴스에 스토리지 자동 확장을 구성하면, 스토리지 용량이 부족할 때 자동으로 스토리지를 확장할 수 있습니다. 이는 RDS 인스턴스가 스토리지 부족으로 인해 중단되지 않도록 보장합니다.

- **D. Configure the Auto Scaling group to use the average CPU as the scaling metric:**
  - **CPU 기반 스케일링:** Auto Scaling 그룹에서 평균 CPU 사용률을 스케일링 메트릭으로 사용하면, 트래픽 증가에 따라 EC2 인스턴스를 자동으로 추가하거나 제거할 수 있습니다. 이는 EC2 인스턴스가 과부하되지 않도록 보장합니다.

**다른 보기가 정답이 될 수 없는 이유:**
- **B. Migrate the database to Amazon Aurora:** Amazon Aurora로 데이터베이스를 마이그레이션하는 것은 Oracle-specific PL/SQL 기능을 사용할 수 없게 만들 수 있으며, 이는 애플리케이션에 큰 변화를 요구할 수 있습니다.
- **C. Configure an alarm on the RDS for Oracle instance for low free storage space:** 알람을 구성하는 것은 스토리지 부족을 모니터링하는 데 도움이 되지만, 자동으로 스토리지를 확장하지는 않습니다.
- **E. Configure the Auto Scaling group to use the average free memory as the scaling metric:** 메모리 사용률을 스케일링 메트릭으로 사용하는 것은 가능하지만, 일반적으로 CPU 사용률이 더 적합한 스케일링 메트릭입니다. CPU 사용률은 트래픽 증가에 더 직접적으로 반응합니다.

**출제 의도:**
이 문제는 AWS에서 트래픽 증가에 따라 자동으로 확장할 수 있는 시스템을 설계하는 방법을 평가합니다. 특히, RDS 인스턴스의 스토리지 자동 확장과 Auto Scaling 그룹의 CPU 기반 스케일링을 구성하여 시스템이 자동으로 확장할 수 있도록 하는 방법을 이해하는 것이 목적입니다.

**공부해야 하는 부분:**
1. **Amazon RDS Auto Scaling:**
   - RDS의 스토리지 자동 확장의 기본 개념과 사용 사례
   - 스토리지 자동 확장을 구성하여 RDS 인스턴스가 스토리지 부족으로 인해 중단되지 않도록 하는 방법

2. **Auto Scaling Metrics:**
   - Auto Scaling 메트릭의 기본 개념과 사용 사례
   - CPU 사용률을 스케일링 메트릭으로 사용하여 트래픽 증가에 따라 EC2 인스턴스를 자동으로 추가하거나 제거하는 방법

이 부분들을 공부하면, AWS에서 트래픽 증가에 따라 자동으로 확장할 수 있는 시스템을 설계하는 방법을 더 잘 이해할 수 있습니다.

# 277번
### 정답: **D. Use Amazon S3 for storing the video content. Move the files temporarily over to an Amazon Elastic Block Store (Amazon EBS) volume attached to the server for processing.**

### 해설:

이 문제에서 **비용 효율적인 스토리지 솔루션**을 찾는 것이 핵심입니다. 현재 사용 중인 **Amazon EFS Standard**는 비용이 상대적으로 높기 때문에, 비용을 줄이면서도 애플리케이션의 기능 요구 사항을 충족할 수 있는 대안을 찾아야 합니다.

#### 각 선택지를 분석해보면:

- **A. AWS Storage Gateway for files**: 
  - Storage Gateway는 온프레미스 애플리케이션과 클라우드 간의 스토리지 통합을 위한 솔루션입니다. 여기서는 온프레미스 인프라와 AWS를 연결하는 시나리오가 아니기 때문에 적절하지 않습니다.

- **B. AWS Storage Gateway for volumes**: 
  - Storage Gateway 볼륨은 주로 백업, 복원, 재해 복구에 적합합니다. 이 또한 비디오 트랜스코딩 작업에 맞는 솔루션이 아니며 비용 절감 측면에서도 효과적이지 않습니다.

- **C. Amazon EFS + Amazon EBS**: 
  - EFS를 계속 사용하면서 처리 완료된 파일을 EBS로 전송하는 방식은 비용 절감에 한계가 있습니다. EFS는 상대적으로 비싸며, 비디오 저장에 비효율적일 수 있습니다.

- **D. Amazon S3 + Amazon EBS** (**정답**):
  - **Amazon S3**는 대규모 데이터 저장에 있어 **매우 저렴한 비용**을 제공합니다. 비디오 파일을 저장할 때 S3에 두고, 트랜스코딩을 위해 파일을 **일시적으로** EC2 인스턴스의 **EBS** 볼륨으로 옮겨 처리하는 방식이 가장 비용 효율적입니다. 
  - S3는 트랜스코딩이 끝난 후에도 **장기 저장**을 위해 매우 경제적이며, EBS는 처리 중일 때만 사용되므로 전체 운영 비용을 줄일 수 있습니다.
  
**정답 D**는 비디오 파일의 장기 보관에 대한 S3의 저비용 특성과, 처리할 때만 잠깐 사용하는 EBS의 효율성을 결합한 솔루션으로, **스토리지 비용을 줄이는** 동시에 트랜스코딩 작업도 수행할 수 있어 가장 적합한 선택입니다.

# 285번
**정답: B. Create an Amazon API Gateway endpoint with an AWS Lambda backend that makes a call to Amazon Simple Email Service (Amazon SES).**

**해설:**
- **Amazon API Gateway와 AWS Lambda:**
  - **서버리스 아키텍처:** API Gateway와 Lambda를 사용하면 서버를 관리할 필요 없이 동적 서버 측 컴포넌트를 구현할 수 있습니다. 이는 비용 효율적이며, 특히 트래픽이 적은 경우에 적합합니다.
  - **비용 효율성:** Lambda는 사용한 만큼만 비용을 지불하는 서버리스 컴퓨팅 서비스로, 월간 방문자가 100명 이하인 경우 매우 저렴하게 운영할 수 있습니다.
  - **Amazon SES 통합:** Lambda 함수에서 Amazon SES를 호출하여 이메일을 전송할 수 있습니다. 이는 이메일 전송을 간단하고 효율적으로 처리할 수 있습니다.

**다른 보기가 정답이 될 수 없는 이유:**
- **A. Amazon ECS:** ECS는 컨테이너 오케스트레이션 서비스로, 소규모 트래픽을 처리하는 데는 과도한 솔루션입니다. 비용이 더 많이 들 수 있습니다.
- **C. Amazon Lightsail:** Lightsail은 간단한 서버 호스팅 솔루션이지만, 서버를 관리해야 하므로 Lambda와 API Gateway를 사용하는 것보다 비용 효율적이지 않습니다.
- **D. Amazon EC2:** EC2 인스턴스를 사용하여 LAMP 스택을 배포하는 것은 소규모 트래픽을 처리하는 데 과도한 솔루션입니다. 서버를 관리해야 하므로 비용이 더 많이 들 수 있습니다.

**출제 의도:**
이 문제는 AWS에서 소규모 트래픽을 처리하는 동적 서버 측 컴포넌트를 구현하고, 비용 효율적으로 운영하는 방법을 평가합니다. 특히, Amazon API Gateway와 AWS Lambda를 사용하여 서버리스 아키텍처를 구현하고, Amazon SES를 사용하여 이메일을 전송하는 방법을 이해하는 것이 목적입니다.

**공부해야 하는 부분:**
1. **Amazon API Gateway:**
   - API Gateway의 기본 개념과 사용 사례
   - API Gateway를 사용하여 엔드포인트를 생성하고, Lambda와 통합하는 방법

2. **AWS Lambda:**
   - Lambda의 기본 개념과 사용 사례
   - Lambda 함수를 작성하고, API Gateway와 통합하여 서버리스 아키텍처를 구현하는 방법

3. **Amazon SES:**
   - SES의 기본 개념과 사용 사례
   - SES를 사용하여 이메일을 전송하는 방법

이 부분들을 공부하면, AWS에서 소규모 트래픽을 처리하는 동적 서버 측 컴포넌트를 구현하고, 비용 효율적으로 운영하는 방법을 더 잘 이해할 수 있습니다.

# 291번
**정답: B. Signed URLs, A. Signed cookies**

**해설:**
- **Signed URLs:**
  - **쿠키 미지원 클라이언트:** 일부 사용자가 쿠키를 지원하지 않는 커스텀 HTTP 클라이언트를 사용하고 있으므로, Signed URLs는 이러한 사용자를 지원하는 데 적합합니다. Signed URLs는 URL 자체에 만료 시간과 서명을 포함하여, 특정 시간 동안만 접근을 허용합니다.
  - **하드코딩된 URL:** 일부 사용자가 하드코딩된 URL을 변경할 수 없으므로, Signed URLs를 사용하면 기존 URL을 변경하지 않고도 접근 제어를 구현할 수 있습니다.

- **Signed Cookies:**
  - **쿠키 지원 클라이언트:** 쿠키를 지원하는 클라이언트의 경우, Signed Cookies를 사용하여 접근을 제어할 수 있습니다. 이는 여러 파일에 대한 접근을 제어하는 데 유용합니다.
  - **기존 URL 유지:** Signed Cookies를 사용하면 URL을 변경할 필요가 없으므로, 사용자에게 미치는 영향을 최소화할 수 있습니다.

**다른 보기가 정답이 될 수 없는 이유:**
- **C. AWS AppSync:** AppSync는 GraphQL API를 제공하는 서비스로, 이 시나리오에서는 적합하지 않습니다.
- **D. JSON Web Token (JWT):** JWT는 인증 및 권한 부여를 위한 토큰 기반 솔루션이지만, CloudFront와 S3의 접근 제어를 직접적으로 지원하지 않습니다.
- **E. AWS Secrets Manager:** Secrets Manager는 비밀 관리 서비스로, 이 시나리오에서는 적합하지 않습니다.

**출제 의도:**
이 문제는 AWS에서 CloudFront와 S3를 사용하여 공개적으로 제공되는 비디오 콘텐츠에 대한 접근을 제어하는 방법을 평가합니다. 특히, Signed URLs와 Signed Cookies를 사용하여 사용자에게 미치는 영향을 최소화하면서 접근을 제어하는 방법을 이해하는 것이 목적입니다.

**공부해야 하는 부분:**
1. **Signed URLs and Signed Cookies:**
   - Signed URLs와 Signed Cookies의 기본 개념과 사용 사례
   - Signed URLs와 Signed Cookies를 사용하여 CloudFront와 S3의 접근을 제어하는 방법

2. **AWS CloudFront and S3:**
   - CloudFront와 S3의 기본 개념과 사용 사례
   - CloudFront와 S3를 사용하여 비디오 콘텐츠를 제공하고, 접근을 제어하는 방법

이 부분들을 공부하면, AWS에서 CloudFront와 S3를 사용하여 공개적으로 제공되는 비디오 콘텐츠에 대한 접근을 제어하는 방법을 더 잘 이해할 수 있습니다.


# 293번
**정답: D. Use AWS Storage Gateway and configure a stored volume gateway. Run the Storage Gateway software appliance on premises and map the gateway storage volumes to on-premises storage. Mount the gateway storage volumes to provide local access to the data.**

**해설:**
- **AWS Storage Gateway (Stored Volume Gateway):**
  - **로컬 액세스:** Stored Volume Gateway는 온프레미스에서 데이터를 저장하고, 백업을 위해 AWS로 데이터를 전송합니다. 온프레미스 시스템은 로컬 스토리지에 직접 액세스할 수 있습니다.
  - **자동 및 안전한 전송:** Storage Gateway는 데이터를 자동으로 AWS로 전송하며, 전송 중에 데이터를 암호화하여 안전하게 보호합니다.
  - **백업 및 복구:** Stored Volume Gateway는 온프레미스 데이터의 백업 및 복구를 간편하게 관리할 수 있습니다.

**다른 보기가 정답이 될 수 없는 이유:**
- **A. AWS Snowball:** Snowball은 대량의 데이터를 물리적으로 AWS로 전송하는 데 사용되며, 지속적인 로컬 액세스를 제공하지 않습니다.
- **B. AWS Snowball Edge:** Snowball Edge는 일시적인 데이터 전송 및 로컬 컴퓨팅을 제공하지만, 지속적인 백업 솔루션으로는 적합하지 않습니다.
- **C. Cached Volume Gateway:** Cached Volume Gateway는 주로 AWS에 데이터를 저장하고, 자주 액세스하는 데이터를 로컬에 캐시합니다. 온프레미스에서 모든 데이터를 로컬로 유지하려는 요구 사항을 충족하지 않습니다.

**출제 의도:**
이 문제는 AWS에서 온프레미스 데이터의 백업 솔루션을 설계하고, 로컬 액세스를 유지하면서 데이터를 안전하게 전송하는 방법을 평가합니다. 특히, AWS Storage Gateway의 Stored Volume Gateway를 사용하여 이러한 요구 사항을 충족하는 방법을 이해하는 것이 목적입니다.

**공부해야 하는 부분:**
1. **AWS Storage Gateway:**
   - Storage Gateway의 기본 개념과 사용 사례
   - Stored Volume Gateway와 Cached Volume Gateway의 차이점
   - Stored Volume Gateway를 사용하여 온프레미스 데이터의 백업 및 로컬 액세스를 제공하는 방법

2. **AWS Snowball 및 Snowball Edge:**
   - Snowball과 Snowball Edge의 기본 개념과 사용 사례
   - Snowball과 Snowball Edge가 지속적인 백업 솔루션으로 적합하지 않은 이유

이 부분들을 공부하면, AWS에서 온프레미스 데이터의 백업 솔루션을 설계하고, 로컬 액세스를 유지하면서 데이터를 안전하게 전송하는 방법을 더 잘 이해할 수 있습니다.

# 296번
**정답: D. 10.0.1.0/24**

**해설:**
- **VPC Peering 조건:**
  - **CIDR 블록 중복 불가:** VPC 피어링 연결을 설정하려면 두 VPC의 CIDR 블록이 중복되지 않아야 합니다. 즉, 두 VPC의 IP 주소 범위가 겹치지 않아야 합니다.
  - **CIDR 블록 크기:** CIDR 블록의 크기는 /24, /16 등 다양한 크기로 설정할 수 있지만, 피어링 연결을 위해서는 중복되지 않는 범위 내에서 설정해야 합니다.

- **옵션 분석:**
  - **A. 10.0.1.0/32:** /32는 단일 IP 주소를 나타내며, VPC의 CIDR 블록으로는 너무 작습니다.
  - **B. 192.168.0.0/24:** 이 CIDR 블록은 이미 개발 VPC에서 사용 중이므로 중복됩니다.
  - **C. 192.168.1.0/32:** /32는 단일 IP 주소를 나타내며, VPC의 CIDR 블록으로는 너무 작습니다.
  - **D. 10.0.1.0/24:** 이 CIDR 블록은 개발 VPC의 CIDR 블록과 중복되지 않으며, VPC 피어링 연결을 설정하는 데 적합합니다.

**출제 의도:**
이 문제는 AWS에서 VPC 피어링 연결을 설정할 때 CIDR 블록을 올바르게 선택하는 방법을 평가합니다. 특히, 중복되지 않는 CIDR 블록을 선택하여 VPC 피어링 연결을 설정하는 방법을 이해하는 것이 목적입니다.

**공부해야 하는 부분:**
1. **VPC Peering:**
   - VPC 피어링의 기본 개념과 사용 사례
   - VPC 피어링 연결을 설정할 때 CIDR 블록이 중복되지 않도록 하는 방법

2. **CIDR 블록:**
   - CIDR 블록의 기본 개념과 사용 사례
   - 다양한 크기의 CIDR 블록을 이해하고, VPC에 적합한 CIDR 블록을 선택하는 방법

이 부분들을 공부하면, AWS에서 VPC 피어링 연결을 설정할 때 CIDR 블록을 올바르게 선택하는 방법을 더 잘 이해할 수 있습니다.

# 297번
**정답: B. Create an EC2 Auto Scaling group. Select the existing ALB as the load balancer and the existing target group as the target group. Set a target tracking scaling policy that is based on the ASGAverageCPUUtilization metric. Set the minimum instances to 2, the desired capacity to 3, the maximum instances to 6, and the target value to 50%. Add the EC2 instances to the Auto Scaling group.**

**해설:**
- **EC2 Auto Scaling Group:**
  - **자동 스케일링:** Auto Scaling 그룹을 사용하면 애플리케이션의 트래픽 변화에 따라 EC2 인스턴스의 수를 자동으로 조정할 수 있습니다. 이는 비용을 최적화하고, CPU 리소스가 필요한 경우 자동으로 확장할 수 있습니다.
  - **타겟 트래킹 스케일링 정책:** ASGAverageCPUUtilization 메트릭을 기반으로 하는 타겟 트래킹 스케일링 정책을 설정하면, CPU 사용률이 특정 값(예: 50%)을 목표로 자동으로 인스턴스를 추가하거나 제거할 수 있습니다. 이는 CPU 사용률이 낮을 때 비용을 절감하고, 사용률이 높을 때 성능을 보장합니다.

**다른 보기가 정답이 될 수 없는 이유:**
- **A. CloudWatch 알람과 Lambda:** CPU 사용률이 낮을 때 인스턴스를 종료하는 것은 비용 절감에 도움이 될 수 있지만, CPU 사용률이 높을 때 자동으로 인스턴스를 추가하지 않으므로 성능을 보장하지 못합니다.
- **C. Auto Scaling 그룹 (스케일링 정책 없음):** Auto Scaling 그룹을 설정하더라도 스케일링 정책이 없으면, 트래픽 변화에 따라 자동으로 인스턴스를 조정할 수 없습니다.
- **D. CloudWatch 알람과 SNS:** 알람을 설정하고 이메일을 통해 수동으로 인스턴스를 조정하는 것은 자동화되지 않으며, 운영 오버헤드가 큽니다.

**출제 의도:**
이 문제는 AWS에서 애플리케이션의 자동 스케일링을 설정하여 비용을 최적화하고 성능을 보장하는 방법을 평가합니다. 특히, EC2 Auto Scaling 그룹과 타겟 트래킹 스케일링 정책을 사용하여 CPU 사용률에 따라 인스턴스를 자동으로 조정하는 방법을 이해하는 것이 목적입니다.

**공부해야 하는 부분:**
1. **EC2 Auto Scaling:**
   - Auto Scaling 그룹의 기본 개념과 사용 사례
   - 타겟 트래킹 스케일링 정책을 설정하여 CPU 사용률에 따라 인스턴스를 자동으로 조정하는 방법

2. **CloudWatch Metrics:**
   - CloudWatch 메트릭의 기본 개념과 사용 사례
   - ASGAverageCPUUtilization 메트릭을 사용하여 스케일링 정책을 설정하는 방법

이 부분들을 공부하면, AWS에서 애플리케이션의 자동 스케일링을 설정하여 비용을 최적화하고 성능을 보장하는 방법을 더 잘 이해할 수 있습니다.

 
# 298번
**정답: C. Provision a subnet in each Availability Zone. Configure the Auto Scaling group to distribute the EC2 instances across both Availability Zones. Configure the DB instance for Multi-AZ deployment.**

**해설:**
- **다중 가용 영역 (Multi-AZ) 배포:**
  - **EC2 인스턴스:** Auto Scaling 그룹을 사용하여 EC2 인스턴스를 여러 가용 영역에 분산 배치하면, 한 가용 영역에 장애가 발생하더라도 애플리케이션이 계속 작동할 수 있습니다.
  - **RDS Multi-AZ:** RDS 인스턴스를 Multi-AZ 배포로 구성하면, 기본 인스턴스와 동기화된 스탠바이 인스턴스가 다른 가용 영역에 배치됩니다. 이는 데이터베이스의 고가용성을 보장합니다.

**다른 보기가 정답이 될 수 없는 이유:**
- **A. DB 인스턴스의 네트워크 연결:** RDS 인스턴스는 Multi-AZ 배포를 통해 고가용성을 제공해야 하며, 단순히 네트워크 연결을 설정하는 것으로는 충분하지 않습니다.
- **B. 두 개의 서브넷이 두 가용 영역에 걸쳐 있음:** 서브넷은 단일 가용 영역 내에 있어야 하며, 두 가용 영역에 걸쳐 있을 수 없습니다.
- **D. 서브넷이 두 가용 영역에 걸쳐 있음:** 서브넷은 단일 가용 영역 내에 있어야 하며, 두 가용 영역에 걸쳐 있을 수 없습니다.

**출제 의도:**
이 문제는 AWS에서 고가용성을 보장하기 위해 EC2 인스턴스와 RDS 인스턴스를 여러 가용 영역에 분산 배치하는 방법을 평가합니다. 특히, Auto Scaling 그룹과 RDS Multi-AZ 배포를 사용하여 애플리케이션의 고가용성을 보장하는 방법을 이해하는 것이 목적입니다.

**공부해야 하는 부분:**
1. **Auto Scaling Group:**
   - Auto Scaling 그룹의 기본 개념과 사용 사례
   - 여러 가용 영역에 EC2 인스턴스를 분산 배치하는 방법

2. **RDS Multi-AZ 배포:**
   - RDS Multi-AZ 배포의 기본 개념과 사용 사례
   - Multi-AZ 배포를 통해 데이터베이스의 고가용성을 보장하는 방법

이 부분들을 공부하면, AWS에서 고가용성을 보장하기 위해 EC2 인스턴스와 RDS 인스턴스를 여러 가용 영역에 분산 배치하는 방법을 더 잘 이해할 수 있습니다.

# 299번
**정답: B. Create an Amazon S3 bucket to store the raw data. Create an Amazon FSx for Lustre file system that uses persistent SSD storage. Select the option to import data from and export data to Amazon S3. Mount the file system on the EC2 instances.**

**해설:**
- **Amazon FSx for Lustre:**
  - **고성능:** FSx for Lustre는 고성능 파일 시스템으로, 특히 고성능 컴퓨팅(HPC) 워크로드에 적합합니다. SSD 스토리지를 사용하면 서브 밀리초 지연 시간과 높은 처리량을 제공합니다.
  - **데이터 통합:** S3와 통합하여 데이터를 가져오고 내보낼 수 있습니다. 이는 대규모 데이터 세트를 처리하는 데 유용합니다.

- **옵션 분석:**
  - **A. FSx for NetApp ONTAP (Tiering Policy: ALL):** NetApp ONTAP는 고성능 파일 시스템이지만, Lustre가 HPC 워크로드에 더 적합합니다. 또한, Tiering Policy를 ALL로 설정하면 성능이 저하될 수 있습니다.
  - **C. FSx for Lustre (Persistent HDD):** HDD 스토리지는 SSD보다 지연 시간이 길고 처리량이 낮습니다. 서브 밀리초 지연 시간과 높은 처리량 요구 사항을 충족하지 못합니다.
  - **D. FSx for NetApp ONTAP (Tiering Policy: NONE):** NetApp ONTAP는 고성능 파일 시스템이지만, Lustre가 HPC 워크로드에 더 적합합니다.

**출제 의도:**
이 문제는 AWS에서 고성능 컴퓨팅 워크로드를 처리하기 위해 적합한 스토리지 솔루션을 선택하는 방법을 평가합니다. 특히, FSx for Lustre를 사용하여 서브 밀리초 지연 시간과 높은 처리량 요구 사항을 충족하는 방법을 이해하는 것이 목적입니다.

**공부해야 하는 부분:**
1. **Amazon FSx for Lustre:**
   - FSx for Lustre의 기본 개념과 사용 사례
   - FSx for Lustre를 사용하여 고성능 컴퓨팅 워크로드를 처리하는 방법

2. **스토리지 성능:**
   - SSD와 HDD 스토리지의 차이점
   - 고성능 스토리지 솔루션을 선택하는 방법

이 부분들을 공부하면, AWS에서 고성능 컴퓨팅 워크로드를 처리하기 위해 적합한 스토리지 솔루션을 선택하는 방법을 더 잘 이해할 수 있습니다.


# 300번
**정답: C. Migrate the application layer to Amazon EC2 Reserved Instances. Migrate the data storage layer to Amazon Aurora Reserved Instances.**

**해설:**
- **Amazon EC2 Reserved Instances:**
  - **비용 절감:** Reserved Instances는 장기적인 약정을 통해 On-Demand Instances보다 비용을 절감할 수 있습니다. 애플리케이션이 24시간, 7일 내내 실행되므로 Reserved Instances가 비용 효율적입니다.
  
- **Amazon Aurora Reserved Instances:**
  - **확장성:** Amazon Aurora는 고성능, 고가용성, 자동 확장 기능을 제공하는 관계형 데이터베이스 서비스입니다. 데이터베이스 스토리지가 시간이 지남에 따라 계속 증가하는 요구 사항을 충족할 수 있습니다.
  - **비용 절감:** Aurora Reserved Instances를 사용하면 On-Demand Instances보다 비용을 절감할 수 있습니다.

**다른 보기가 정답이 될 수 없는 이유:**
- **A. EC2 Spot Instances와 S3:** Spot Instances는 언제든지 회수될 수 있으므로, 24/7 실행되는 애플리케이션에는 적합하지 않습니다. 또한, S3는 객체 스토리지로, 관계형 데이터베이스 요구 사항을 충족하지 않습니다.
- **B. EC2 Reserved Instances와 RDS On-Demand Instances:** RDS On-Demand Instances는 장기적인 비용 절감 측면에서 Reserved Instances보다 덜 효율적입니다.
- **D. EC2 On-Demand Instances와 RDS Reserved Instances:** EC2 On-Demand Instances는 장기적인 비용 절감 측면에서 Reserved Instances보다 덜 효율적입니다.

**출제 의도:**
이 문제는 AWS에서 24/7 실행되는 애플리케이션과 데이터베이스를 비용 효율적으로 마이그레이션하는 방법을 평가합니다. 특히, EC2 Reserved Instances와 Amazon Aurora Reserved Instances를 사용하여 비용을 절감하고, 데이터베이스 스토리지 요구 사항을 충족하는 방법을 이해하는 것이 목적입니다.

**공부해야 하는 부분:**
1. **Amazon EC2 Reserved Instances:**
   - Reserved Instances의 기본 개념과 사용 사례
   - Reserved Instances를 사용하여 비용을 절감하는 방법

2. **Amazon Aurora:**
   - Aurora의 기본 개념과 사용 사례
   - Aurora Reserved Instances를 사용하여 비용을 절감하고, 데이터베이스 스토리지 요구 사항을 충족하는 방법

이 부분들을 공부하면, AWS에서 24/7 실행되는 애플리케이션과 데이터베이스를 비용 효율적으로 마이그레이션하는 방법을 더 잘 이해할 수 있습니다.

# 308번
**정답: B. Use the Trusted Advisor recommendations from the consolidated billing account to see all RDS instance checks at the same time. C. Review the Trusted Advisor check for Amazon RDS Reserved Instance Optimization.**

**해설:**
- **B. Trusted Advisor recommendations from the consolidated billing account:**
  - **통합된 뷰:** 통합 결제 계정을 사용하면 모든 연결된 계정의 Trusted Advisor 권장 사항을 한 번에 볼 수 있습니다. 이는 여러 계정에서 실행 중인 RDS 인스턴스를 효율적으로 검토하는 데 도움이 됩니다.

- **C. Trusted Advisor check for Amazon RDS Reserved Instance Optimization:**
  - **비용 절감:** Reserved Instance Optimization 체크는 온디맨드 인스턴스를 예약 인스턴스로 전환하여 비용을 절감할 수 있는 기회를 제공합니다. 이는 RDS 비용을 줄이는 데 중요한 역할을 합니다.

**다른 보기가 정답이 될 수 없는 이유:**
- **A. Trusted Advisor recommendations from the account where the RDS instances are running:** 개별 계정에서 권장 사항을 확인하는 것은 가능하지만, 통합 결제 계정을 사용하면 모든 계정의 권장 사항을 한 번에 볼 수 있어 더 효율적입니다.
- **D. Trusted Advisor check for Amazon RDS Idle DB Instances:** 이 체크는 사용되지 않는 RDS 인스턴스를 식별하는 데 유용하지만, 고성능 RDS 인스턴스가 활성 상태로 실행 중이므로 이 체크는 덜 관련이 있습니다.
- **E. Trusted Advisor check for Amazon Redshift Reserved Node Optimization:** 이 체크는 Redshift에 대한 것이며, RDS 비용 절감과는 관련이 없습니다.

**출제 의도:**
이 문제는 AWS Trusted Advisor를 사용하여 여러 계정에서 실행 중인 RDS 인스턴스의 비용을 절감하는 방법을 평가합니다. 특히, 통합 결제 계정을 사용하여 모든 계정의 권장 사항을 한 번에 보고, RDS Reserved Instance Optimization 체크를 통해 비용 절감 기회를 식별하는 방법을 이해하는 것이 목적입니다.

**공부해야 하는 부분:**
1. **AWS Trusted Advisor:**
   - Trusted Advisor의 기본 개념과 사용 사례
   - 통합 결제 계정을 사용하여 여러 계정의 권장 사항을 확인하는 방법

2. **RDS 비용 최적화:**
   - RDS Reserved Instance Optimization 체크의 기본 개념과 사용 사례
   - RDS 비용을 절감하는 방법

이 부분들을 공부하면, AWS Trusted Advisor를 사용하여 여러 계정에서 실행 중인 RDS 인스턴스의 비용을 절감하는 방법을 더 잘 이해할 수 있습니다.


# 309번
### 정답
A. Analyze bucket access patterns by using the S3 Storage Lens dashboard for advanced activity metrics.

### 해설
Amazon S3 Storage Lens는 S3 스토리지 사용량 및 활동에 대한 포괄적인 메트릭과 인사이트를 제공하는 도구입니다. S3 Storage Lens 대시보드를 사용하면 S3 버킷의 액세스 패턴을 쉽게 분석할 수 있으며, 이는 운영 오버헤드를 최소화하면서 스토리지 비용을 최적화하는 데 도움이 됩니다.

각 옵션을 자세히 살펴보면:

- **A. Analyze bucket access patterns by using the S3 Storage Lens dashboard for advanced activity metrics.**
  - S3 Storage Lens는 S3 스토리지 사용량 및 활동에 대한 포괄적인 메트릭과 인사이트를 제공하며, 운영 오버헤드를 최소화하면서 S3 버킷의 액세스 패턴을 분석할 수 있습니다. 이는 가장 적은 운영 오버헤드로 목표를 달성할 수 있는 솔루션입니다.

- **B. Analyze bucket access patterns by using the S3 dashboard in the AWS Management Console.**
  - S3 대시보드는 기본적인 스토리지 정보를 제공하지만, S3 Storage Lens와 같은 고급 활동 메트릭을 제공하지 않습니다.

- **C. Turn on the Amazon CloudWatch BucketSizeBytes metric for buckets. Analyze bucket access patterns by using the metrics data with Amazon Athena.**
  - CloudWatch 메트릭과 Athena를 사용하여 데이터를 분석하는 것은 가능하지만, 설정 및 관리가 복잡할 수 있으며 운영 오버헤드가 증가할 수 있습니다.

- **D. Turn on AWS CloudTrail for S3 object monitoring. Analyze bucket access patterns by using CloudTrail logs that are integrated with Amazon CloudWatch Logs.**
  - CloudTrail 로그를 사용하여 S3 객체 모니터링을 설정하고 CloudWatch Logs와 통합하여 데이터를 분석하는 것은 가능하지만, 설정 및 관리가 복잡할 수 있으며 운영 오버헤드가 증가할 수 있습니다.

따라서, 회사의 요구 사항을 가장 효율적으로 충족하는 솔루션은 옵션 A입니다.

### 필요한 학습 내용

1. **Amazon S3 Storage Lens**
   - S3 Storage Lens는 S3 스토리지 사용량 및 활동에 대한 포괄적인 메트릭과 인사이트를 제공하는 도구입니다.
   - S3 버킷의 액세스 패턴을 쉽게 분석할 수 있습니다.

2. **Amazon S3 대시보드**
   - S3 대시보드는 기본적인 스토리지 정보를 제공하지만, 고급 활동 메트릭을 제공하지 않습니다.

3. **Amazon CloudWatch 및 Amazon Athena**
   - CloudWatch는 AWS 리소스 및 애플리케이션을 모니터링하는 서비스입니다.
   - Athena는 S3 데이터를 쿼리할 수 있는 서버리스 대화형 쿼리 서비스입니다.
   - 두 서비스를 결합하여 데이터를 분석할 수 있지만, 설정 및 관리가 복잡할 수 있습니다.

4. **AWS CloudTrail 및 CloudWatch Logs**
   - CloudTrail은 AWS 계정의 API 호출을 기록하는 서비스입니다.
   - CloudWatch Logs는 로그 데이터를 모니터링하고 분석할 수 있는 서비스입니다.
   - 두 서비스를 결합하여 데이터를 분석할 수 있지만, 설정 및 관리가 복잡할 수 있습니다.

### 추가 학습 자료
- [Amazon S3 Storage Lens 공식 문서](https://docs.aws.amazon.com/ko_kr/AmazonS3/latest/userguide/storage-lens.html)
- [Amazon CloudWatch 공식 문서](https://docs.aws.amazon.com/ko_kr/AmazonCloudWatch/latest/monitoring/WhatIsCloudWatch.html)
- [Amazon Athena 공식 문서](https://docs.aws.amazon.com/ko_kr/athena/latest/ug/what-is.html)
- [AWS CloudTrail 공식 문서](https://docs.aws.amazon.com/ko_kr/awscloudtrail/latest/userguide/cloudtrail-user-guide.html)

이 자료들을 통해 S3 Storage Lens, CloudWatch, Athena, CloudTrail의 다양한 기능과 설정 방법을 이해하고, 특정 시나리오에서 최적의 솔루션을 선택하는 능력을 키울 수 있습니다.

# 312번
**정답: B. Create a backup plan by using AWS Backup to perform nightly backups. Copy the backups to another Region. Add the application’s EC2 instances as resources.**

**해설:**
- **AWS Backup:**
  - **운영 효율성:** AWS Backup은 중앙 집중식 관리 콘솔을 통해 백업 작업을 자동화하고 관리할 수 있는 서비스입니다. 이를 통해 운영 오버헤드를 최소화할 수 있습니다.
  - **리소스 추가:** AWS Backup을 사용하면 EC2 인스턴스와 EBS 볼륨을 리소스로 추가하여 백업 계획을 설정할 수 있습니다. 이는 EC2 인스턴스의 구성과 데이터를 모두 백업할 수 있음을 의미합니다.
  - **Cross-Region 복사:** AWS Backup은 백업을 다른 리전으로 자동으로 복사할 수 있는 기능을 제공하여, 재해 복구 요구 사항을 충족할 수 있습니다.

**다른 보기가 정답이 될 수 없는 이유:**
- **A. AWS Lambda와 스냅샷:** Lambda 함수를 사용하여 스냅샷을 예약하고 다른 리전으로 복사할 수 있지만, 이는 추가적인 스크립팅과 관리 오버헤드를 요구합니다.
- **C. AWS Backup과 EBS 볼륨:** EBS 볼륨만을 리소스로 추가하면, EC2 인스턴스의 구성은 백업되지 않습니다. EC2 인스턴스 전체를 백업하는 것이 더 효율적입니다.
- **D. AWS Lambda와 스냅샷 (가용 영역):** 다른 가용 영역으로 스냅샷을 복사하는 것은 재해 복구 요구 사항을 충족하지 못합니다. 다른 리전으로 복사하는 것이 필요합니다.

**출제 의도:**
이 문제는 AWS에서 EC2 인스턴스와 EBS 볼륨을 효율적으로 백업하고, 재해 복구를 위해 다른 리전으로 복사하는 방법을 평가합니다. 특히, AWS Backup을 사용하여 운영 오버헤드를 최소화하면서 이러한 요구 사항을 충족하는 방법을 이해하는 것이 목적입니다.

**공부해야 하는 부분:**
1. **AWS Backup:**
   - AWS Backup의 기본 개념과 사용 사례
   - AWS Backup을 사용하여 EC2 인스턴스와 EBS 볼륨을 백업하고, 다른 리전으로 복사하는 방법

2. **재해 복구 (Disaster Recovery):**
   - 재해 복구 계획의 기본 개념과 사용 사례
   - Cross-Region 복사의 중요성과 구현 방법

이 부분들을 공부하면, AWS에서 EC2 인스턴스와 EBS 볼륨을 효율적으로 백업하고, 재해 복구를 위해 다른 리전으로 복사하는 방법을 더 잘 이해할 수 있습니다.


# 316번
**정답: C. Migrate the script on the EC2 instance to an AWS Lambda function with the appropriate runtime.**

**해설:**
- **AWS Lambda:**
  - **비용 절감:** Lambda는 서버리스 컴퓨팅 서비스로, 사용한 만큼만 비용을 지불합니다. EC2 인스턴스를 계속 실행하는 것보다 비용 효율적입니다.
  - **자동 확장:** Lambda는 자동으로 확장되므로, SQS 큐에 추가되는 메시지 수가 증가해도 처리할 수 있습니다. 이는 메시지 처리량이 증가할 때 유연하게 대응할 수 있습니다.
  - **운영 오버헤드 감소:** Lambda를 사용하면 인프라를 관리할 필요가 없으므로 운영 오버헤드가 줄어듭니다.

**다른 보기가 정답이 될 수 없는 이유:**
- **A. Increase the size of the EC2 instance:** EC2 인스턴스의 크기를 늘리는 것은 비용을 증가시키며, 메시지 수가 증가할 때 유연하게 대응하기 어렵습니다.
- **B. Use Amazon EventBridge:** EventBridge를 사용하여 EC2 인스턴스를 끄는 것은 비용 절감에 도움이 될 수 있지만, 메시지 처리량이 증가할 때 유연하게 대응하기 어렵습니다.
- **D. Use AWS Systems Manager Run Command:** Systems Manager Run Command를 사용하여 스크립트를 온디맨드로 실행하는 것은 메시지 처리량이 증가할 때 유연하게 대응하기 어렵습니다.

**출제 의도:**
이 문제는 AWS에서 SQS 큐의 메시지를 효율적으로 처리하고, 비용을 절감하며, 메시지 처리량이 증가할 때 유연하게 대응하는 방법을 평가합니다. 특히, AWS Lambda를 사용하여 이러한 요구 사항을 충족하는 방법을 이해하는 것이 목적입니다.

**공부해야 하는 부분:**
1. **AWS Lambda:**
   - Lambda의 기본 개념과 사용 사례
   - Lambda를 사용하여 SQS 큐의 메시지를 처리하는 방법

2. **비용 절감 및 자동 확장:**
   - 서버리스 컴퓨팅의 비용 절감 효과
   - 자동 확장을 통해 메시지 처리량 증가에 대응하는 방법

이 부분들을 공부하면, AWS에서 SQS 큐의 메시지를 효율적으로 처리하고, 비용을 절감하며, 메시지 처리량이 증가할 때 유연하게 대응하는 방법을 더 잘 이해할 수 있습니다.

# 318번
**정답: A. Enable AWS CloudTrail and use it for auditing. D. Enable AWS Config and create rules for auditing and compliance purposes.**

**해설:**
- **AWS CloudTrail:**
  - **감사 및 추적:** CloudTrail은 AWS 계정에서 API 호출을 기록하여, 누가 어떤 작업을 수행했는지 추적할 수 있습니다. 이를 통해 EC2 인스턴스 프로비저닝 및 보안 그룹 규칙 변경과 같은 활동을 감사할 수 있습니다.

- **AWS Config:**
  - **구성 관리 및 규정 준수:** AWS Config는 AWS 리소스의 구성을 평가, 감사 및 평가할 수 있는 서비스입니다. Config 규칙을 사용하여 리소스가 특정 규정 준수 요구 사항을 충족하는지 확인할 수 있습니다. 이를 통해 EC2 인스턴스 크기 및 보안 그룹 규칙 변경을 모니터링하고 규정 준수 상태를 유지할 수 있습니다.

**다른 보기가 정답이 될 수 없는 이유:**
- **B. 데이터 수명 주기 정책:** 데이터 수명 주기 정책은 주로 데이터 관리와 관련이 있으며, EC2 인스턴스 프로비저닝 및 보안 그룹 규칙 변경을 추적하는 데 적합하지 않습니다.
- **C. AWS Trusted Advisor:** Trusted Advisor는 비용 최적화, 보안, 성능, 내결함성 및 서비스 한도에 대한 권장 사항을 제공하지만, 실시간 구성 변경 추적 및 감사 기능을 제공하지 않습니다.
- **E. AWS CloudFormation:** CloudFormation은 인프라를 코드로 관리하는 도구로, 이전 리소스 구성을 복원할 수 있지만, 실시간 구성 변경 추적 및 감사 기능을 제공하지 않습니다.

**출제 의도:**
이 문제는 AWS에서 리소스 프로비저닝 및 구성 변경을 추적하고 감사하는 방법을 평가합니다. 특히, AWS CloudTrail과 AWS Config를 사용하여 이러한 요구 사항을 충족하는 방법을 이해하는 것이 목적입니다.

**공부해야 하는 부분:**
1. **AWS CloudTrail:**
   - CloudTrail의 기본 개념과 사용 사례
   - CloudTrail을 사용하여 API 호출을 기록하고 감사하는 방법

2. **AWS Config:**
   - Config의 기본 개념과 사용 사례
   - Config 규칙을 사용하여 리소스 구성을 평가하고 규정 준수 상태를 유지하는 방법

이 부분들을 공부하면, AWS에서 리소스 프로비저닝 및 구성 변경을 추적하고 감사하는 방법을 더 잘 이해할 수 있습니다.


# 324번
**정답: D. Provision an AWS Storage Gateway Volume Gateway stored volume with the same amount of disk space as the existing file storage volume. Mount the Volume Gateway stored volume to the existing file server by using iSCSI, and copy all files to the storage volume. Configure scheduled snapshots of the storage volume. To recover from a disaster, restore a snapshot to an Amazon Elastic Block Store (Amazon EBS) volume and attach the EBS volume to an Amazon EC2 instance.**

**해설:**
- **AWS Storage Gateway Volume Gateway (Stored Volumes):**
  - **기존 인프라 변경 최소화:** Stored Volumes는 온프레미스 파일 서버에 iSCSI를 통해 마운트되므로, 기존 인프라를 크게 변경할 필요가 없습니다.
  - **로컬 데이터 접근:** Stored Volumes는 모든 데이터를 로컬에 저장하고, 백업을 위해 AWS로 복제합니다. 이는 사용자가 로컬에서 데이터를 즉시 접근할 수 있도록 하여 지연 시간을 최소화합니다.
  - **재해 복구:** 스냅샷을 사용하여 데이터를 Amazon EBS 볼륨으로 복원하고, 이를 Amazon EC2 인스턴스에 연결하여 재해 복구를 수행할 수 있습니다.

**다른 보기가 정답이 될 수 없는 이유:**
- **A. Amazon S3 File Gateway:** S3 File Gateway는 NFS 프로토콜을 사용하므로, 기존 애플리케이션을 수정해야 합니다. 또한, 로컬 캐시가 제한적이므로 지연 시간이 발생할 수 있습니다.
- **B. AWS Storage Gateway Tape Gateway:** Tape Gateway는 주로 백업 및 아카이브 용도로 사용되며, 실시간 데이터 접근을 제공하지 않습니다.
- **C. AWS Storage Gateway Volume Gateway (Cached Volumes):** Cached Volumes는 자주 액세스되는 데이터를 로컬에 캐시하지만, 모든 데이터를 로컬에 저장하지 않으므로 지연 시간이 발생할 수 있습니다.

**출제 의도:**
이 문제는 AWS에서 온프레미스 파일 스토리지의 재해 복구 계획을 구현하고, 사용자가 지연 시간 없이 데이터를 접근할 수 있도록 하는 방법을 평가합니다. 특히, AWS Storage Gateway Volume Gateway (Stored Volumes)를 사용하여 이러한 요구 사항을 충족하는 방법을 이해하는 것이 목적입니다.

**공부해야 하는 부분:**
1. **AWS Storage Gateway:**
   - Storage Gateway의 기본 개념과 사용 사례
   - Volume Gateway (Stored Volumes)와 Volume Gateway (Cached Volumes)의 차이점

2. **재해 복구 계획:**
   - 재해 복구 계획의 기본 개념과 사용 사례
   - 스냅샷을 사용하여 데이터를 복원하고, Amazon EBS 볼륨으로 복원하는 방법

이 부분들을 공부하면, AWS에서 온프레미스 파일 스토리지의 재해 복구 계획을 구현하고, 사용자가 지연 시간 없이 데이터를 접근할 수 있도록 하는 방법을 더 잘 이해할 수 있습니다.

# 326번
**정답: A. Move assets to S3 Intelligent-Tiering after 30 days. B. Configure an S3 Lifecycle policy to clean up incomplete multipart uploads.**

**해설:**
- **A. S3 Intelligent-Tiering:**
  - **비용 최적화:** S3 Intelligent-Tiering은 객체의 접근 패턴에 따라 자동으로 비용을 최적화합니다. 자주 접근되는 객체는 빈번한 접근 계층에, 덜 자주 접근되는 객체는 드문 접근 계층에 저장됩니다. 이는 접근 패턴이 불규칙한 객체에 적합합니다.
  - **높은 가용성 및 내구성:** S3 Intelligent-Tiering은 S3 Standard와 동일한 높은 가용성과 내구성을 제공합니다.

- **B. Incomplete Multipart Uploads 정리:**
  - **비용 절감:** 불완전한 멀티파트 업로드는 스토리지 비용을 증가시킬 수 있습니다. S3 Lifecycle 정책을 사용하여 불완전한 멀티파트 업로드를 정리하면 비용을 절감할 수 있습니다.

**다른 보기가 정답이 될 수 없는 이유:**
- **C. Expired Object Delete Markers 정리:** 이 정책은 버전 관리를 사용하는 경우에만 유용하며, 비용 최적화와 직접적인 관련이 없습니다.
- **D. S3 Standard-IA:** S3 Standard-IA는 자주 접근되지 않는 객체에 적합하지만, 접근 패턴이 불규칙한 경우 비용이 증가할 수 있습니다.
- **E. S3 One Zone-IA:** S3 One Zone-IA는 단일 가용 영역에만 데이터를 저장하므로, 높은 가용성과 내구성을 요구하는 경우 적합하지 않습니다.

**출제 의도:**
이 문제는 AWS에서 S3 스토리지 비용을 최적화하면서 높은 가용성과 내구성을 유지하는 방법을 평가합니다. 특히, S3 Intelligent-Tiering과 S3 Lifecycle 정책을 사용하여 이러한 요구 사항을 충족하는 방법을 이해하는 것이 목적입니다.

**공부해야 하는 부분:**
1. **Amazon S3 Storage Classes:**
   - S3 Intelligent-Tiering, S3 Standard-IA, S3 One Zone-IA의 기본 개념과 사용 사례
   - 각 스토리지 클래스의 비용 최적화 및 가용성/내구성 특성

2. **S3 Lifecycle Policies:**
   - S3 Lifecycle 정책의 기본 개념과 사용 사례
   - 불완전한 멀티파트 업로드 및 만료된 객체 삭제 마커를 정리하는 방법

이 부분들을 공부하면, AWS에서 S3 스토리지 비용을 최적화하면서 높은 가용성과 내구성을 유지하는 방법을 더 잘 이해할 수 있습니다.


# 329번
**정답: D. Turn on Amazon Inspector in the account. Configure Amazon Inspector to scan the EC2 instances for software vulnerabilities. Set up AWS Systems Manager Patch Manager to patch the EC2 instances on a regular schedule.**

**해설:**
- **Amazon Inspector:**
  - **취약점 스캔:** Amazon Inspector는 EC2 인스턴스에서 실행되는 애플리케이션의 보안 취약점을 자동으로 스캔하는 서비스입니다. 이를 통해 정기적으로 보안 스캔을 수행할 수 있습니다.
  - **보고서 생성:** Inspector는 각 인스턴스의 취약점 상태에 대한 보고서를 제공합니다.

- **AWS Systems Manager Patch Manager:**
  - **자동 패치:** Patch Manager는 EC2 인스턴스를 정기적으로 패치할 수 있는 기능을 제공합니다. 이를 통해 인스턴스가 최신 보안 패치를 적용받도록 할 수 있습니다.
  - **상태 보고:** Patch Manager는 각 인스턴스의 패치 상태에 대한 보고서를 생성할 수 있습니다.

**다른 보기가 정답이 될 수 없는 이유:**
- **A. Amazon Macie:** Macie는 데이터 보호 및 개인정보 식별 서비스로, 소프트웨어 취약점 스캔을 수행하지 않습니다. 또한, 각 인스턴스에 cron job을 설정하는 것은 관리 오버헤드가 큽니다.
- **B. Amazon GuardDuty:** GuardDuty는 AWS 계정과 리소스에 대한 위협 탐지 서비스로, 소프트웨어 취약점 스캔을 수행하지 않습니다. Session Manager는 패치 관리 기능을 제공하지 않습니다.
- **C. Amazon Detective:** Detective는 보안 조사 및 분석 서비스로, 소프트웨어 취약점 스캔을 수행하지 않습니다. EventBridge는 패치 관리 기능을 제공하지 않습니다.

**출제 의도:**
이 문제는 AWS에서 EC2 인스턴스의 보안 취약점을 스캔하고, 정기적으로 패치를 적용하며, 각 인스턴스의 패치 상태를 보고하는 방법을 평가합니다. 특히, Amazon Inspector와 AWS Systems Manager Patch Manager를 사용하여 이러한 요구 사항을 충족하는 방법을 이해하는 것이 목적입니다.

**공부해야 하는 부분:**
1. **Amazon Inspector:**
   - Inspector의 기본 개념과 사용 사례
   - Inspector를 사용하여 EC2 인스턴스의 보안 취약점을 스캔하는 방법

2. **AWS Systems Manager Patch Manager:**
   - Patch Manager의 기본 개념과 사용 사례
   - Patch Manager를 사용하여 EC2 인스턴스를 정기적으로 패치하고, 패치 상태를 보고하는 방법

이 부분들을 공부하면, AWS에서 EC2 인스턴스의 보안 취약점을 스캔하고, 정기적으로 패치를 적용하며, 각 인스턴스의 패치 상태를 보고하는 방법을 더 잘 이해할 수 있습니다.


# 333번
**정답: C. Configure an EC2 Auto Scaling scheduled scaling policy based on the monthly schedule.**

**해설:**
- **EC2 Auto Scaling Scheduled Scaling Policy:**
  - **예측 가능한 트래픽 패턴:** 매월 첫날 자정에 월말 재무 계산 배치 작업이 실행될 때 애플리케이션의 CPU 사용률이 급증하는 패턴이 예측 가능합니다. 이러한 예측 가능한 트래픽 패턴에 대해 EC2 Auto Scaling의 예약된 스케일링 정책을 사용하여 미리 인스턴스를 추가할 수 있습니다.
  - **사전 준비:** 예약된 스케일링 정책을 사용하면 예상되는 트래픽 증가 전에 인스턴스를 추가하여 애플리케이션이 부하를 처리할 수 있도록 준비할 수 있습니다. 이는 CPU 사용률이 100%에 도달하여 애플리케이션이 중단되는 것을 방지합니다.

**다른 보기가 정답이 될 수 없는 이유:**
- **A. Amazon CloudFront:** CloudFront는 주로 정적 콘텐츠를 캐싱하여 성능을 향상시키는 데 사용됩니다. CPU 사용률 급증 문제를 해결하지 못합니다.
- **B. EC2 Auto Scaling Simple Scaling Policy:** 단순 스케일링 정책은 CPU 사용률이 이미 높은 상태에서 인스턴스를 추가하므로, 트래픽 급증에 대한 사전 준비가 부족할 수 있습니다.
- **D. Amazon ElastiCache:** ElastiCache는 데이터베이스 캐싱을 통해 성능을 향상시킬 수 있지만, CPU 사용률 급증 문제를 직접 해결하지는 못합니다.

**출제 의도:**
이 문제는 AWS에서 예측 가능한 트래픽 패턴에 대해 애플리케이션의 성능을 최적화하고, 중단을 방지하는 방법을 평가합니다. 특히, EC2 Auto Scaling의 예약된 스케일링 정책을 사용하여 이러한 요구 사항을 충족하는 방법을 이해하는 것이 목적입니다.

**공부해야 하는 부분:**
1. **EC2 Auto Scaling:**
   - Auto Scaling의 기본 개념과 사용 사례
   - 예약된 스케일링 정책을 사용하여 예측 가능한 트래픽 패턴에 대응하는 방법

2. **트래픽 관리 및 성능 최적화:**
   - 예측 가능한 트래픽 패턴에 대해 애플리케이션의 성능을 최적화하는 방법
   - CPU 사용률 급증 문제를 해결하는 방법

이 부분들을 공부하면, AWS에서 예측 가능한 트래픽 패턴에 대해 애플리케이션의 성능을 최적화하고, 중단을 방지하는 방법을 더 잘 이해할 수 있습니다.

# 335번
**정답: B. Enable Amazon Elastic Block Store (Amazon EBS) fast snapshot restore on a snapshot. Provision an AMI by using the snapshot. Replace the AMI in the Auto Scaling group with the new AMI.**

**해설:**
- **Amazon EBS Fast Snapshot Restore:**
  - **최소 초기화 지연:** EBS Fast Snapshot Restore(FSR)는 스냅샷에서 프로비저닝된 볼륨의 초기화 시간을 줄여줍니다. 이를 통해 EC2 인스턴스가 더 빠르게 시작될 수 있습니다.
  - **AMI 프로비저닝:** FSR을 사용하여 스냅샷에서 AMI를 프로비저닝하면, Auto Scaling 그룹에서 인스턴스를 시작할 때 초기화 지연이 최소화됩니다.

**다른 보기가 정답이 될 수 없는 이유:**
- **A. aws ec2 register-image:** 이 방법은 AMI를 생성하는 데 사용되지만, 초기화 지연을 줄이는 데 직접적인 도움이 되지 않습니다.
- **C. Amazon Data Lifecycle Manager (DLM):** DLM은 AMI와 스냅샷의 라이프사이클을 관리하는 데 유용하지만, 초기화 지연을 줄이는 데 직접적인 도움이 되지 않습니다.
- **D. AWS Backup lifecycle policies:** AWS Backup은 백업 및 복구를 관리하는 데 사용되며, 초기화 지연을 줄이는 데 직접적인 도움이 되지 않습니다.

**출제 의도:**
이 문제는 AWS에서 EC2 인스턴스를 빠르게 프로비저닝하고, 초기화 지연을 최소화하는 방법을 평가합니다. 특히, Amazon EBS Fast Snapshot Restore를 사용하여 이러한 요구 사항을 충족하는 방법을 이해하는 것이 목적입니다.

**공부해야 하는 부분:**
1. **Amazon EBS Fast Snapshot Restore:**
   - Fast Snapshot Restore의 기본 개념과 사용 사례
   - Fast Snapshot Restore를 사용하여 초기화 지연을 줄이는 방법

2. **Auto Scaling 그룹:**
   - Auto Scaling 그룹의 기본 개념과 사용 사례
   - Auto Scaling 그룹에서 AMI를 교체하는 방법

이 부분들을 공부하면, AWS에서 EC2 인스턴스를 빠르게 프로비저닝하고, 초기화 지연을 최소화하는 방법을 더 잘 이해할 수 있습니다.


# 338번
### 정답
D. Set up an Aurora global database for the DB cluster. Specify a minimum of one DB instance in the secondary Region.

### 해설
Amazon Aurora 글로벌 데이터베이스는 여러 AWS 리전에 걸쳐 데이터베이스를 복제할 수 있는 기능을 제공합니다. 이는 고가용성과 재해 복구를 위한 최적의 솔루션입니다. 글로벌 데이터베이스를 설정하면 데이터가 자동으로 여러 리전에 복제되며, 재해 발생 시 빠르게 장애 조치를 수행할 수 있습니다. 최소 하나의 DB 인스턴스를 보조 리전에 지정하면 데이터 복제가 지속적으로 이루어지며, 재해 복구 시 빠르게 활성화할 수 있습니다.

각 옵션을 자세히 살펴보면:

- **A. Use MySQL binary log replication to an Aurora cluster in the secondary Region. Provision one DB instance for the Aurora cluster in the secondary Region.**
  - MySQL 바이너리 로그 복제는 Aurora 글로벌 데이터베이스에 비해 설정 및 관리가 복잡할 수 있으며, 비용 효율적이지 않을 수 있습니다.

- **B. Set up an Aurora global database for the DB cluster. When setup is complete, remove the DB instance from the secondary Region.**
  - 보조 리전에서 DB 인스턴스를 제거하면 데이터 복제가 중단되며, 재해 복구 시 데이터 손실이 발생할 수 있습니다.

- **C. Use AWS Database Migration Service (AWS DMS) to continuously replicate data to an Aurora cluster in the secondary Region. Remove the DB instance from the secondary Region.**
  - AWS DMS는 데이터 마이그레이션에 적합하지만, 지속적인 데이터 복제 및 재해 복구를 위한 최적의 솔루션은 아닙니다. 또한, 보조 리전에서 DB 인스턴스를 제거하면 데이터 복제가 중단됩니다.

- **D. Set up an Aurora global database for the DB cluster. Specify a minimum of one DB instance in the secondary Region.**
  - Aurora 글로벌 데이터베이스는 여러 리전에 걸쳐 데이터베이스를 복제할 수 있는 기능을 제공하며, 최소 하나의 DB 인스턴스를 보조 리전에 지정하면 데이터 복제가 지속적으로 이루어집니다. 이는 고가용성과 재해 복구를 위한 최적의 솔루션입니다.

따라서, 회사의 요구 사항을 가장 효율적으로 충족하는 솔루션은 옵션 D입니다.

### 필요한 학습 내용

1. **Amazon Aurora 글로벌 데이터베이스**
   - Aurora 글로벌 데이터베이스는 여러 AWS 리전에 걸쳐 데이터베이스를 복제할 수 있는 기능을 제공합니다.
   - 고가용성과 재해 복구를 위한 최적의 솔루션입니다.

2. **MySQL 바이너리 로그 복제**
   - MySQL 바이너리 로그 복제는 데이터베이스 복제를 위한 방법 중 하나입니다.
   - 설정 및 관리가 복잡할 수 있으며, 비용 효율적이지 않을 수 있습니다.

3. **AWS Database Migration Service (DMS)**
   - DMS는 데이터베이스를 AWS로 마이그레이션하거나 AWS 내에서 데이터베이스를 복제하는 데 사용됩니다.
   - 지속적인 데이터 복제 및 재해 복구를 위한 최적의 솔루션은 아닙니다.

### 추가 학습 자료
- [Amazon Aurora 글로벌 데이터베이스 공식 문서](https://docs.aws.amazon.com/ko_kr/AmazonRDS/latest/AuroraUserGuide/aurora-global-database.html)
- [MySQL 바이너리 로그 복제 공식 문서](https://dev.mysql.com/doc/refman/8.0/en/replication.html)
- [AWS Database Migration Service (DMS) 공식 문서](https://docs.aws.amazon.com/ko_kr/dms/latest/userguide/Welcome.html)

이 자료들을 통해 Aurora 글로벌 데이터베이스, MySQL 바이너리 로그 복제, DMS의 다양한 기능과 설정 방법을 이해하고, 특정 시나리오에서 최적의 솔루션을 선택하는 능력을 키울 수 있습니다.

# 348번
정답은 **B. Use provisioned mode. Specify the read capacity units (RCUs) and write capacity units (WCUs).**

### 이유:
주어진 시나리오에서 데이터 워크로드는 **예측 가능하고 일정**하므로, **Provisioned 모드**가 가장 적합합니다. 또한, **Provisioned 모드**에서는 예측되는 워크로드에 맞춰 **읽기 및 쓰기 용량 단위(RCUs와 WCUs)**를 설정할 수 있어 비용을 최적화할 수 있습니다.

### 각 옵션에 대한 분석:
- **A. Use provisioned mode and DynamoDB Standard-Infrequent Access (DynamoDB Standard-IA). Reserve capacity for the forecasted workload**:
  - **DynamoDB Standard-IA**는 **주로 데이터 접근 빈도가 낮은 경우**에 적합하며, 주어진 시나리오에서는 **정기적이고 예측 가능한 데이터 워크로드**에 적합하지 않습니다.
  
- **B. Use provisioned mode. Specify the read capacity units (RCUs) and write capacity units (WCUs)**:
  - **Provisioned 모드**에서 예측된 읽기 및 쓰기 용량을 설정하면, **비용을 절감**하면서 예측 가능한 트래픽을 처리할 수 있습니다. 이 방식은 워크로드가 일정하고 예측 가능한 경우 가장 비용 효율적입니다.

- **C. Use on-demand mode. Set the read capacity units (RCUs) and write capacity units (WCUs) high enough to accommodate changes in the workload**:
  - **On-demand 모드**는 동적이고 예측할 수 없는 트래픽에 적합하지만, **고정된 예측 가능한 워크로드**에는 비용이 더 많이 발생할 수 있습니다. 이 방식은 비용 효율적이지 않을 수 있습니다.

- **D. Use on-demand mode. Specify the read capacity units (RCUs) and write capacity units (WCUs) with reserved capacity**:
  - **On-demand 모드**에서는 **RCU 및 WCU를 예약할 수 없**고, **정기적인 용량 예약**은 **Provisioned 모드**에서만 가능합니다. 따라서 이 옵션은 잘못된 선택입니다.

### 결론:
예측 가능한 일정한 워크로드에는 **Provisioned 모드**에서 **읽기 및 쓰기 용량 단위(RCUs, WCUs)**를 설정하는 방법이 가장 **비용 효율적**입니다.

# 351번
### 정답
D. Build out the workflow in AWS Step Functions. Use Step Functions to create a state machine. Use the state machine to invoke AWS Lambda functions to process the workflow steps.

### 해설
회사는 이벤트 기반 아키텍처로 전환하고, 서버리스 개념을 사용하여 워크플로우의 다양한 측면을 수행하면서 운영 오버헤드를 최소화하려고 합니다. AWS Step Functions는 서버리스 워크플로우 서비스로, 상태 머신을 사용하여 여러 AWS Lambda 함수를 조정하고 관리할 수 있습니다. 이를 통해 분산된 이벤트 기반 아키텍처를 구축하고, 운영 오버헤드를 최소화할 수 있습니다.

각 옵션을 자세히 살펴보면:

- **A. Build out the workflow in AWS Glue. Use AWS Glue to invoke AWS Lambda functions to process the workflow steps.**
  - AWS Glue는 데이터 통합 서비스로, ETL(Extract, Transform, Load) 작업에 적합합니다. 그러나 일반적인 워크플로우 관리에는 적합하지 않습니다.

- **B. Build out the workflow in AWS Step Functions. Deploy the application on Amazon EC2 instances. Use Step Functions to invoke the workflow steps on the EC2 instances.**
  - EC2 인스턴스를 사용하면 서버를 관리해야 하므로 운영 오버헤드가 증가합니다. 서버리스 개념을 사용하려는 요구 사항을 충족하지 않습니다.

- **C. Build out the workflow in Amazon EventBridge. Use EventBridge to invoke AWS Lambda functions on a schedule to process the workflow steps.**
  - EventBridge는 이벤트 기반 아키텍처를 구축하는 데 유용하지만, 복잡한 워크플로우 관리에는 적합하지 않습니다. Step Functions가 더 적합한 솔루션입니다.

- **D. Build out the workflow in AWS Step Functions. Use Step Functions to create a state machine. Use the state machine to invoke AWS Lambda functions to process the workflow steps.**
  - Step Functions는 상태 머신을 사용하여 여러 Lambda 함수를 조정하고 관리할 수 있습니다. 이를 통해 분산된 이벤트 기반 아키텍처를 구축하고, 운영 오버헤드를 최소화할 수 있습니다. 이는 회사의 요구 사항을 가장 효율적으로 충족하는 솔루션입니다.

따라서, 회사의 요구 사항을 가장 효율적으로 충족하는 솔루션은 옵션 D입니다.

### 필요한 학습 내용

1. **AWS Step Functions**
   - Step Functions는 서버리스 워크플로우 서비스로, 상태 머신을 사용하여 여러 AWS Lambda 함수를 조정하고 관리할 수 있습니다.
   - 복잡한 워크플로우를 시각적으로 설계하고, 상태 전환을 관리할 수 있습니다.

2. **AWS Lambda**
   - Lambda는 서버리스 컴퓨팅 서비스로, 이벤트에 응답하여 코드를 실행할 수 있습니다.
   - Step Functions와 통합하여 워크플로우의 각 단계를 처리할 수 있습니다.

3. **Amazon EventBridge**
   - EventBridge는 이벤트 기반 아키텍처를 구축할 수 있는 서비스입니다.
   - 이벤트를 기반으로 Lambda 함수를 호출할 수 있지만, 복잡한 워크플로우 관리에는 적합하지 않습니다.

4. **AWS Glue**
   - Glue는 데이터 통합 서비스로, ETL 작업에 적합합니다.
   - 일반적인 워크플로우 관리에는 적합하지 않습니다.

### 추가 학습 자료
- [AWS Step Functions 공식 문서](https://docs.aws.amazon.com/ko_kr/step-functions/latest/dg/welcome.html)
- [AWS Lambda 공식 문서](https://docs.aws.amazon.com/ko_kr/lambda/latest/dg/welcome.html)
- [Amazon EventBridge 공식 문서](https://docs.aws.amazon.com/ko_kr/eventbridge/latest/userguide/what-is-amazon-eventbridge.html)
- [AWS Glue 공식 문서](https://docs.aws.amazon.com/ko_kr/glue/latest/dg/what-is-glue.html)

이 자료들을 통해 Step Functions, Lambda, EventBridge, Glue의 다양한 기능과 설정 방법을 이해하고, 특정 시나리오에서 최적의 솔루션을 선택하는 능력을 키울 수 있습니다.

# 353번
### 정답
B. Use a Multi-AZ deployment of an Amazon RDS for MySQL DB instance with a General Purpose SSD (gp2) EBS volume.

### 해설
회사는 데이터베이스 계층을 완전 관리형 솔루션으로 이전하고, 고가용성과 장애 내성을 유지하면서 비용을 절감하고 성능을 안정화하려고 합니다. Amazon RDS는 완전 관리형 데이터베이스 서비스로, Multi-AZ 배포를 통해 고가용성과 장애 내성을 제공합니다. General Purpose SSD (gp2) EBS 볼륨은 비용 효율적이며, 1,000 IOPS의 읽기 및 쓰기 트래픽을 처리할 수 있습니다. 이는 회사의 요구 사항을 가장 비용 효율적으로 충족할 수 있는 솔루션입니다.

각 옵션을 자세히 살펴보면:

- **A. Use a Multi-AZ deployment of an Amazon RDS for MySQL DB instance with an io2 Block Express EBS volume.**
  - io2 Block Express EBS 볼륨은 높은 성능을 제공하지만, 비용이 더 많이 들 수 있습니다. 회사의 요구 사항을 충족할 수 있지만, 비용 효율적이지 않습니다.

- **B. Use a Multi-AZ deployment of an Amazon RDS for MySQL DB instance with a General Purpose SSD (gp2) EBS volume.**
  - gp2 EBS 볼륨은 비용 효율적이며, 1,000 IOPS의 읽기 및 쓰기 트래픽을 처리할 수 있습니다. Multi-AZ 배포를 통해 고가용성과 장애 내성을 제공하며, 회사의 요구 사항을 가장 비용 효율적으로 충족할 수 있습니다.

- **C. Use Amazon S3 Intelligent-Tiering access tiers.**
  - S3 Intelligent-Tiering은 객체 스토리지 솔루션으로, 데이터베이스 워크로드에 적합하지 않습니다.

- **D. Use two large EC2 instances to host the database in active-passive mode.**
  - 두 개의 EC2 인스턴스를 사용하여 데이터베이스를 호스팅하는 것은 관리 오버헤드가 증가하며, 비용 효율적이지 않습니다. 또한, 완전 관리형 솔루션이 아닙니다.

따라서, 회사의 요구 사항을 가장 효율적으로 충족하는 솔루션은 옵션 B입니다.

### 필요한 학습 내용

1. **Amazon RDS (Relational Database Service)**
   - RDS는 완전 관리형 관계형 데이터베이스 서비스로, 다양한 데이터베이스 엔진을 지원합니다.
   - Multi-AZ 배포를 통해 고가용성과 장애 내성을 제공합니다.

2. **EBS 볼륨 유형**
   - **General Purpose SSD (gp2)**: 비용 효율적이며, 다양한 워크로드에 적합합니다.
   - **Provisioned IOPS SSD (io2)**: 높은 성능을 제공하지만, 비용이 더 많이 들 수 있습니다.

3. **Amazon S3 Intelligent-Tiering**
   - S3 Intelligent-Tiering은 객체 스토리지 솔루션으로, 데이터베이스 워크로드에 적합하지 않습니다.

### 추가 학습 자료
- [Amazon RDS 공식 문서](https://docs.aws.amazon.com/ko_kr/AmazonRDS/latest/UserGuide/Welcome.html)
- [Amazon EBS 볼륨 유형 공식 문서](https://docs.aws.amazon.com/ko_kr/AWSEC2/latest/UserGuide/ebs-volume-types.html)
- [Amazon S3 Intelligent-Tiering 공식 문서](https://docs.aws.amazon.com/ko_kr/AmazonS3/latest/dev/storage-class-intro.html#sc-dynamic-data-access)

이 자료들을 통해 RDS, EBS 볼륨 유형, S3 Intelligent-Tiering의 다양한 기능과 설정 방법을 이해하고, 특정 시나리오에서 최적의 솔루션을 선택하는 능력을 키울 수 있습니다.


# 358번
### 정답: **C. Use a Lambda@Edge function with an external image management library. Associate the Lambda@Edge function with the CloudFront behaviors that serve the images.**

### 해설:

이 문제는 **이미지 동적 처리**와 **적절한 형식으로 클라이언트에게 제공**하는 요구 사항을 충족하는 솔루션을 찾는 것입니다. 회사는 **Amazon S3**에 저장된 이미지를 **동적으로 크기 조정**하고, 적절한 형식으로 클라이언트에게 제공하려고 합니다.

#### 각 옵션 분석:

- **A. Install an external image management library on an EC2 instance. Use the image management library to process the images.**
  - 이 옵션은 이미지를 **EC2 인스턴스에서 처리**하는 방법입니다. 그러나, EC2 인스턴스를 사용하면 **운영 오버헤드**가 커지며, 특히 대규모로 이미지를 처리하고 관리해야 하는 상황에서는 비효율적입니다. 서버 관리와 유지 보수 비용이 많이 들 수 있습니다.

- **B. Create a CloudFront origin request policy. Use the policy to automatically resize images and to serve the appropriate format based on the User-Agent HTTP header in the request.**
  - **CloudFront의 오리진 요청 정책**은 HTTP 요청에 따라 CloudFront가 오리진에 대한 요청을 어떻게 처리할지를 정의하지만, **이미지 크기 조정 및 형식 변환**을 자동으로 처리하지 않습니다. 따라서 이 옵션은 이미지를 처리하는 요구 사항을 충족하지 못합니다.

- **C. Use a Lambda@Edge function with an external image management library. Associate the Lambda@Edge function with the CloudFront behaviors that serve the images.**
  - **Lambda@Edge**는 **CloudFront** 배포와 연동하여 요청 및 응답을 처리할 수 있습니다. 이 솔루션은 **이미지 관리 라이브러리**를 Lambda@Edge 함수에 배포하여 이미지 크기 조정 및 형식 변환을 **클라우드 엣지에서 처리**할 수 있게 합니다. 이렇게 하면 **운영 오버헤드가 적고, 전 세계에 분산된 클라이언트들에게 빠르게 서비스를 제공**할 수 있습니다.
  - 이 방법은 EC2 인스턴스를 사용하지 않고도 이미지의 동적 처리를 **효율적으로** 할 수 있는 솔루션입니다.

- **D. Create a CloudFront response headers policy. Use the policy to automatically resize images and to serve the appropriate format based on the User-Agent HTTP header in the request.**
  - **CloudFront 응답 헤더 정책**은 응답 헤더를 관리하는 데 사용됩니다. 그러나 이미지를 **동적으로 크기 조정하거나 형식을 변환**하는 기능은 지원하지 않으므로 이 옵션은 요구 사항을 충족하지 않습니다.

### 결론:
**Lambda@Edge**를 사용하여 이미지 처리를 엣지에서 처리하는 것이 가장 효율적이며, 운영 오버헤드를 최소화하면서 요구 사항을 충족할 수 있습니다. **C** 옵션이 가장 적합한 솔루션입니다.



# 359번
### 정답
C. Use the aws:SecureTransport condition on S3 bucket policies to allow only encrypted connections over HTTPS (TLS). Configure default encryption for each S3 bucket to use server-side encryption with AWS KMS keys (SSE-KMS). Assign the compliance team to manage the KMS keys.

### 해설
병원의 요구 사항은 PHI(Protected Health Information)를 전송 중 및 저장 중에 암호화하고, 데이터 저장 시 암호화 키를 관리하는 것입니다. 이를 위해 S3 버킷 정책에서 `aws:SecureTransport` 조건을 사용하여 HTTPS(TLS)를 통한 암호화된 연결만 허용하고, 서버 측 암호화(SSE-KMS)를 사용하여 AWS KMS 키로 데이터를 암호화해야 합니다. KMS 키 관리를 병원의 컴플라이언스 팀에 할당하면 요구 사항을 충족할 수 있습니다.

각 옵션을 자세히 살펴보면:

- **A. Create a public SSL/TLS certificate in AWS Certificate Manager (ACM). Associate the certificate with Amazon S3. Configure default encryption for each S3 bucket to use server-side encryption with AWS KMS keys (SSE-KMS). Assign the compliance team to manage the KMS keys.**
  - ACM에서 SSL/TLS 인증서를 생성하고 S3에 연결하는 것은 적절하지 않습니다. S3 버킷 정책에서 `aws:SecureTransport` 조건을 사용하는 것이 더 적절합니다.

- **B. Use the aws:SecureTransport condition on S3 bucket policies to allow only encrypted connections over HTTPS (TLS). Configure default encryption for each S3 bucket to use server-side encryption with S3 managed encryption keys (SSE-S3). Assign the compliance team to manage the SSE-S3 keys.**
  - SSE-S3는 S3 관리형 키를 사용하므로, 컴플라이언스 팀이 키를 관리할 수 없습니다.

- **C. Use the aws:SecureTransport condition on S3 bucket policies to allow only encrypted connections over HTTPS (TLS). Configure default encryption for each S3 bucket to use server-side encryption with AWS KMS keys (SSE-KMS). Assign the compliance team to manage the KMS keys.**
  - `aws:SecureTransport` 조건을 사용하여 HTTPS(TLS)를 통한 암호화된 연결만 허용하고, SSE-KMS를 사용하여 KMS 키로 데이터를 암호화하면 요구 사항을 충족할 수 있습니다. KMS 키 관리를 컴플라이언스 팀에 할당할 수 있습니다.

- **D. Use the aws:SecureTransport condition on S3 bucket policies to allow only encrypted connections over HTTPS (TLS). Use Amazon Macie to protect the sensitive data that is stored in Amazon S3. Assign the compliance team to manage Macie.**
  - Amazon Macie는 민감한 데이터를 보호하는 데 유용하지만, 데이터 저장 시 암호화 키를 관리하는 데는 적합하지 않습니다.

따라서, 병원의 요구 사항을 가장 효율적으로 충족하는 솔루션은 옵션 C입니다.

### 필요한 학습 내용

1. **Amazon S3 버킷 정책**
   - S3 버킷 정책을 사용하여 버킷에 대한 접근을 제어할 수 있습니다.
   - `aws:SecureTransport` 조건을 사용하여 HTTPS(TLS)를 통한 암호화된 연결만 허용할 수 있습니다.

2. **AWS KMS (Key Management Service)**
   - KMS는 암호화 키를 생성하고 관리할 수 있는 서비스입니다.
   - SSE-KMS를 사용하여 데이터를 암호화하고, KMS 키 관리를 특정 사용자나 그룹에 할당할 수 있습니다.

3. **서버 측 암호화 (SSE)**
   - SSE는 S3에서 데이터를 저장할 때 자동으로 암호화하는 기능입니다.
   - SSE-KMS는 KMS 키를 사용하여 데이터를 암호화합니다.

### 추가 학습 자료
- [Amazon S3 버킷 정책 공식 문서](https://docs.aws.amazon.com/ko_kr/AmazonS3/latest/userguide/bucket-policies.html)
- [AWS KMS 공식 문서](https://docs.aws.amazon.com/ko_kr/kms/latest/developerguide/overview.html)
- [Amazon S3 서버 측 암호화 공식 문서](https://docs.aws.amazon.com/ko_kr/AmazonS3/latest/dev/serv-side-encryption.html)

이 자료들을 통해 S3 버킷 정책, KMS, 서버 측 암호화의 다양한 기능과 설정 방법을 이해하고, 특정 시나리오에서 최적의 솔루션을 선택하는 능력을 키울 수 있습니다.

# 362번
### 정답
B. Write the messages to an Amazon Kinesis data stream with the payment ID as the partition key.
E. Write the messages to an Amazon Simple Queue Service (Amazon SQS) FIFO queue. Set the message group to use the payment ID.

### 해설
메시지가 전송된 순서대로 수신되어야 하는 경우, Amazon Kinesis 데이터 스트림과 Amazon SQS FIFO 큐는 모두 메시지 순서를 보장하는 데 적합한 솔루션입니다.

각 옵션을 자세히 살펴보면:

- **A. Write the messages to an Amazon DynamoDB table with the payment ID as the partition key.**
  - DynamoDB는 메시지 순서를 보장하지 않습니다. 따라서 이 옵션은 적절하지 않습니다.

- **B. Write the messages to an Amazon Kinesis data stream with the payment ID as the partition key.**
  - Kinesis 데이터 스트림은 파티션 키를 사용하여 메시지를 분산시키며, 동일한 파티션 키를 가진 메시지의 순서를 보장합니다. 따라서 이 옵션은 적절합니다.

- **C. Write the messages to an Amazon ElastiCache for Memcached cluster with the payment ID as the key.**
  - ElastiCache for Memcached는 메시지 순서를 보장하지 않습니다. 따라서 이 옵션은 적절하지 않습니다.

- **D. Write the messages to an Amazon Simple Queue Service (Amazon SQS) queue. Set the message attribute to use the payment ID.**
  - SQS 표준 큐는 메시지 순서를 보장하지 않습니다. 따라서 이 옵션은 적절하지 않습니다.

- **E. Write the messages to an Amazon Simple Queue Service (Amazon SQS) FIFO queue. Set the message group to use the payment ID.**
  - SQS FIFO 큐는 메시지 그룹 ID를 사용하여 메시지의 순서를 보장합니다. 따라서 이 옵션은 적절합니다.

따라서, 회사의 요구 사항을 가장 효율적으로 충족하는 솔루션은 옵션 B와 E입니다.

### 필요한 학습 내용

1. **Amazon Kinesis 데이터 스트림**
   - Kinesis 데이터 스트림은 실시간으로 데이터를 수집하고 처리할 수 있는 서비스입니다.
   - 파티션 키를 사용하여 메시지를 분산시키며, 동일한 파티션 키를 가진 메시지의 순서를 보장합니다.

2. **Amazon SQS FIFO 큐**
   - SQS FIFO 큐는 메시지의 순서를 보장하며, 메시지 그룹 ID를 사용하여 메시지의 순서를 제어할 수 있습니다.
   - 메시지의 중복을 방지하고, 정확히 한 번만 처리되도록 보장합니다.

### 추가 학습 자료
- [Amazon Kinesis 데이터 스트림 공식 문서](https://docs.aws.amazon.com/ko_kr/streams/latest/dev/introduction.html)
- [Amazon SQS FIFO 큐 공식 문서](https://docs.aws.amazon.com/ko_kr/AWSSimpleQueueService/latest/SQSDeveloperGuide/FIFO-queues.html)

이 자료들을 통해 Kinesis 데이터 스트림과 SQS FIFO 큐의 다양한 기능과 설정 방법을 이해하고, 특정 시나리오에서 최적의 솔루션을 선택하는 능력을 키울 수 있습니다.

# 363번
### 정답
B. Amazon Simple Notification Service (Amazon SNS) FIFO topics

### 해설
Amazon SNS FIFO(First-In-First-Out) 주제는 메시지의 순서를 보장하면서 여러 구독자에게 메시지를 동시에 전달할 수 있는 기능을 제공합니다. 게임 시스템에서 리더보드, 매치메이킹, 인증 서비스와 같은 여러 서비스에 이벤트를 동시에 보내면서 이벤트의 순서를 보장해야 하는 경우, SNS FIFO 주제가 적합한 솔루션입니다.

각 옵션을 자세히 살펴보면:

- **A. Amazon EventBridge event bus**
  - EventBridge는 이벤트 기반 아키텍처를 구축할 수 있는 서비스로, 이벤트의 순서를 보장하지 않습니다.

- **B. Amazon Simple Notification Service (Amazon SNS) FIFO topics**
  - SNS FIFO 주제는 메시지의 순서를 보장하면서 여러 구독자에게 메시지를 동시에 전달할 수 있습니다. 이는 게임 시스템의 요구 사항을 충족하는 가장 적절한 솔루션입니다.

- **C. Amazon Simple Notification Service (Amazon SNS) standard topics**
  - SNS 표준 주제는 메시지의 순서를 보장하지 않습니다.

- **D. Amazon Simple Queue Service (Amazon SQS) FIFO queues**
  - SQS FIFO 큐는 메시지의 순서를 보장하지만, 메시지를 여러 구독자에게 동시에 전달하는 데 적합하지 않습니다.

따라서, 회사의 요구 사항을 가장 효율적으로 충족하는 솔루션은 옵션 B입니다.

### 필요한 학습 내용

1. **Amazon SNS FIFO 주제**
   - SNS FIFO 주제는 메시지의 순서를 보장하면서 여러 구독자에게 메시지를 동시에 전달할 수 있습니다.
   - 메시지 그룹 ID를 사용하여 메시지의 순서를 제어할 수 있습니다.

2. **Amazon EventBridge**
   - EventBridge는 이벤트 기반 아키텍처를 구축할 수 있는 서비스입니다.
   - 이벤트의 순서를 보장하지 않습니다.

3. **Amazon SNS 표준 주제**
   - SNS 표준 주제는 메시지를 여러 구독자에게 동시에 전달할 수 있지만, 메시지의 순서를 보장하지 않습니다.

4. **Amazon SQS FIFO 큐**
   - SQS FIFO 큐는 메시지의 순서를 보장하지만, 메시지를 여러 구독자에게 동시에 전달하는 데 적합하지 않습니다.

### 추가 학습 자료
- [Amazon SNS FIFO 주제 공식 문서](https://docs.aws.amazon.com/ko_kr/sns/latest/dg/fifo-topics.html)
- [Amazon EventBridge 공식 문서](https://docs.aws.amazon.com/ko_kr/eventbridge/latest/userguide/what-is-amazon-eventbridge.html)
- [Amazon SNS 표준 주제 공식 문서](https://docs.aws.amazon.com/ko_kr/sns/latest/dg/welcome.html)
- [Amazon SQS FIFO 큐 공식 문서](https://docs.aws.amazon.com/ko_kr/AWSSimpleQueueService/latest/SQSDeveloperGuide/FIFO-queues.html)

이 자료들을 통해 SNS FIFO 주제, EventBridge, SNS 표준 주제, SQS FIFO 큐의 다양한 기능과 설정 방법을 이해하고, 특정 시나리오에서 최적의 솔루션을 선택하는 능력을 키울 수 있습니다.


# 364번
### 정답
B. Turn on server-side encryption on the SNS components by using an AWS Key Management Service (AWS KMS) customer managed key. Apply a key policy to restrict key usage to a set of authorized principals.
D. Turn on server-side encryption on the SQS components by using an AWS Key Management Service (AWS KMS) customer managed key. Apply a key policy to restrict key usage to a set of authorized principals. Set a condition in the queue policy to allow only encrypted connections over TLS.

### 해설
병원의 요구 사항은 데이터가 전송 중 및 저장 중에 암호화되고, 병원의 승인된 인원만 데이터에 접근할 수 있도록 하는 것입니다. 이를 위해 SQS와 SNS 모두에서 서버 측 암호화를 활성화하고, AWS KMS 고객 관리 키를 사용하여 키 정책을 적용해야 합니다. 또한, TLS를 통해 암호화된 연결만 허용하도록 조건을 설정해야 합니다.

각 옵션을 자세히 살펴보면:

- **A. Turn on server-side encryption on the SQS components. Update the default key policy to restrict key usage to a set of authorized principals.**
  - SQS 구성 요소에 서버 측 암호화를 활성화하고 기본 키 정책을 업데이트하는 것은 적절하지만, TLS를 통한 암호화된 연결을 설정하는 조건이 포함되어 있지 않습니다.

- **B. Turn on server-side encryption on the SNS components by using an AWS Key Management Service (AWS KMS) customer managed key. Apply a key policy to restrict key usage to a set of authorized principals.**
  - SNS 구성 요소에 서버 측 암호화를 활성화하고, KMS 고객 관리 키를 사용하여 키 정책을 적용하는 것은 적절합니다.

- **C. Turn on encryption on the SNS components. Update the default key policy to restrict key usage to a set of authorized principals. Set a condition in the topic policy to allow only encrypted connections over TLS.**
  - SNS 구성 요소에 암호화를 활성화하고, 기본 키 정책을 업데이트하며, TLS를 통한 암호화된 연결을 설정하는 조건을 추가하는 것은 적절하지만, SQS 구성 요소에 대한 설정이 포함되어 있지 않습니다.

- **D. Turn on server-side encryption on the SQS components by using an AWS Key Management Service (AWS KMS) customer managed key. Apply a key policy to restrict key usage to a set of authorized principals. Set a condition in the queue policy to allow only encrypted connections over TLS.**
  - SQS 구성 요소에 서버 측 암호화를 활성화하고, KMS 고객 관리 키를 사용하여 키 정책을 적용하며, TLS를 통한 암호화된 연결을 설정하는 조건을 추가하는 것은 적절합니다.

- **E. Turn on server-side encryption on the SQS components by using an AWS Key Management Service (AWS KMS) customer managed key. Apply an IAM policy to restrict key usage to a set of authorized principals. Set a condition in the queue policy to allow only encrypted connections over TLS.**
  - SQS 구성 요소에 서버 측 암호화를 활성화하고, KMS 고객 관리 키를 사용하며, IAM 정책을 적용하는 것은 적절하지만, SNS 구성 요소에 대한 설정이 포함되어 있지 않습니다.

따라서, 회사의 요구 사항을 가장 효율적으로 충족하는 솔루션은 옵션 B와 D입니다.

### 필요한 학습 내용

1. **Amazon SQS**
   - SQS는 메시지 큐 서비스로, 메시지를 안전하게 전송하고 저장할 수 있습니다.
   - 서버 측 암호화를 활성화하여 데이터를 보호할 수 있습니다.

2. **Amazon SNS**
   - SNS는 메시지 전송 서비스로, 주제 기반의 메시지를 전송할 수 있습니다.
   - 서버 측 암호화를 활성화하여 데이터를 보호할 수 있습니다.

3. **AWS KMS (Key Management Service)**
   - KMS는 암호화 키를 생성하고 관리할 수 있는 서비스입니다.
   - 고객 관리 키를 사용하여 키 정책을 적용하고, 승인된 인원만 키를 사용할 수 있도록 제한할 수 있습니다.

4. **TLS (Transport Layer Security)**
   - TLS는 데이터 전송 중에 암호화를 제공하여 데이터를 보호합니다.
   - 정책 조건을 설정하여 TLS를 통한 암호화된 연결만 허용할 수 있습니다.

### 추가 학습 자료
- [Amazon SQS 공식 문서](https://docs.aws.amazon.com/ko_kr/AWSSimpleQueueService/latest/SQSDeveloperGuide/welcome.html)
- [Amazon SNS 공식 문서](https://docs.aws.amazon.com/ko_kr/sns/latest/dg/welcome.html)
- [AWS KMS 공식 문서](https://docs.aws.amazon.com/ko_kr/kms/latest/developerguide/overview.html)
- [TLS 공식 문서](https://tools.ietf.org/html/rfc5246)

이 자료들을 통해 SQS, SNS, KMS, TLS의 다양한 기능과 설정 방법을 이해하고, 특정 시나리오에서 최적의 솔루션을 선택하는 능력을 키울 수 있습니다.

# 365번
### 정답
C. Automated backups

### 해설
Amazon RDS의 자동 백업 기능은 데이터베이스를 특정 시점으로 복구할 수 있는 기능을 제공합니다. 자동 백업은 데이터베이스 인스턴스의 전체 스냅샷을 정기적으로 생성하고, 트랜잭션 로그를 지속적으로 백업하여 특정 시점으로 복구할 수 있도록 합니다. 이를 통해 데이터베이스를 5분 전의 상태로 복구할 수 있습니다.

각 옵션을 자세히 살펴보면:

- **A. Read replicas**
  - 읽기 전용 복제본은 데이터베이스의 읽기 성능을 향상시키기 위해 사용되며, 데이터 복구를 위한 기능은 제공하지 않습니다.

- **B. Manual snapshots**
  - 수동 스냅샷은 사용자가 직접 생성해야 하며, 지속적인 트랜잭션 로그 백업을 제공하지 않으므로 특정 시점으로 복구하는 데 적합하지 않습니다.

- **C. Automated backups**
  - 자동 백업은 정기적인 스냅샷과 지속적인 트랜잭션 로그 백업을 통해 특정 시점으로 데이터베이스를 복구할 수 있는 기능을 제공합니다. 이는 5분 전의 상태로 복구할 수 있는 요구 사항을 충족합니다.

- **D. Multi-AZ deployments**
  - Multi-AZ 배포는 고가용성과 장애 복구를 제공하지만, 데이터 복구를 위한 특정 시점 복구 기능은 제공하지 않습니다.

따라서, 회사의 요구 사항을 가장 효율적으로 충족하는 솔루션은 옵션 C입니다.

### 필요한 학습 내용

1. **Amazon RDS 자동 백업**
   - 자동 백업은 데이터베이스 인스턴스의 전체 스냅샷을 정기적으로 생성하고, 트랜잭션 로그를 지속적으로 백업하여 특정 시점으로 복구할 수 있도록 합니다.
   - 최대 35일 동안 백업을 보관할 수 있습니다.

2. **Amazon RDS 수동 스냅샷**
   - 수동 스냅샷은 사용자가 직접 생성해야 하며, 지속적인 트랜잭션 로그 백업을 제공하지 않습니다.

3. **Amazon RDS 읽기 전용 복제본**
   - 읽기 전용 복제본은 데이터베이스의 읽기 성능을 향상시키기 위해 사용됩니다.
   - 데이터 복구를 위한 기능은 제공하지 않습니다.

4. **Amazon RDS Multi-AZ 배포**
   - Multi-AZ 배포는 고가용성과 장애 복구를 제공하지만, 데이터 복구를 위한 특정 시점 복구 기능은 제공하지 않습니다.

### 추가 학습 자료
- [Amazon RDS 자동 백업 공식 문서](https://docs.aws.amazon.com/ko_kr/AmazonRDS/latest/UserGuide/USER_WorkingWithAutomatedBackups.html)
- [Amazon RDS 수동 스냅샷 공식 문서](https://docs.aws.amazon.com/ko_kr/AmazonRDS/latest/UserGuide/USER_CreateSnapshot.html)
- [Amazon RDS 읽기 전용 복제본 공식 문서](https://docs.aws.amazon.com/ko_kr/AmazonRDS/latest/UserGuide/USER_ReadRepl.html)
- [Amazon RDS Multi-AZ 배포 공식 문서](https://docs.aws.amazon.com/ko_kr/AmazonRDS/latest/UserGuide/Concepts.MultiAZ.html)

이 자료들을 통해 Amazon RDS의 다양한 기능과 설정 방법을 이해하고, 특정 시나리오에서 최적의 솔루션을 선택하는 능력을 키울 수 있습니다.



# 366번
### 정답
D. Implement API usage plans and API keys to limit the access of users who do not have a subscription.

### 해설
API Gateway의 API 사용 계획(API usage plans)과 API 키를 사용하면 구독이 없는 사용자의 접근을 제한할 수 있습니다. API 사용 계획을 통해 각 사용자에게 할당된 API 키를 기반으로 요청을 제한할 수 있으며, 구독이 있는 사용자에게만 특정 API 엔드포인트에 접근할 수 있는 권한을 부여할 수 있습니다. 이는 최소한의 운영 오버헤드로 구독 기반 접근 제어를 구현할 수 있는 방법입니다.

각 옵션을 자세히 살펴보면:

- **A. Enable API caching and throttling on the API Gateway API.**
  - API 캐싱과 스로틀링은 성능 최적화와 요청 제한을 위한 기능이지만, 구독 기반 접근 제어를 구현하는 데는 적합하지 않습니다.

- **B. Set up AWS WAF on the API Gateway API. Create a rule to filter users who have a subscription.**
  - AWS WAF는 웹 애플리케이션 방화벽으로, 보안 규칙을 설정하여 트래픽을 필터링할 수 있지만, 구독 기반 접근 제어를 구현하는 데는 적합하지 않습니다.

- **C. Apply fine-grained IAM permissions to the premium content in the DynamoDB table.**
  - 세밀한 IAM 권한을 적용하는 것은 가능하지만, 이는 DynamoDB 테이블 수준에서의 접근 제어로, API Gateway와 Lambda 함수의 접근 제어를 구현하는 데는 적합하지 않습니다.

- **D. Implement API usage plans and API keys to limit the access of users who do not have a subscription.**
  - API 사용 계획과 API 키를 사용하면 구독이 없는 사용자의 접근을 제한할 수 있습니다. 이는 최소한의 운영 오버헤드로 구독 기반 접근 제어를 구현할 수 있는 방법입니다.

따라서, 회사의 요구 사항을 가장 효율적으로 충족하는 솔루션은 옵션 D입니다.

### 필요한 학습 내용

1. **API Gateway API 사용 계획 (API Usage Plans)**
   - API 사용 계획을 통해 각 사용자에게 할당된 API 키를 기반으로 요청을 제한할 수 있습니다.
   - 구독이 있는 사용자에게만 특정 API 엔드포인트에 접근할 수 있는 권한을 부여할 수 있습니다.

2. **API 키 (API Keys)**
   - API 키를 사용하여 각 사용자의 요청을 식별하고, API 사용 계획과 연계하여 접근을 제어할 수 있습니다.

3. **Amazon Cognito**
   - Cognito 사용자 풀을 사용하여 애플리케이션의 개별 사용자를 식별할 수 있습니다.
   - 사용자 인증 및 권한 부여를 관리할 수 있습니다.

### 추가 학습 자료
- [Amazon API Gateway 사용 계획 공식 문서](https://docs.aws.amazon.com/ko_kr/apigateway/latest/developerguide/api-gateway-api-usage-plans.html)
- [Amazon API Gateway API 키 공식 문서](https://docs.aws.amazon.com/ko_kr/apigateway/latest/developerguide/api-gateway-api-key-source.html)
- [Amazon Cognito 공식 문서](https://docs.aws.amazon.com/ko_kr/cognito/latest/developerguide/what-is-amazon-cognito.html)

이 자료들을 통해 API Gateway 사용 계획과 API 키, Cognito의 다양한 기능과 설정 방법을 이해하고, 특정 시나리오에서 최적의 솔루션을 선택하는 능력을 키울 수 있습니다.


# 371번
### 출제 의도
이 문제는 Amazon EKS 클러스터와 Amazon EBS 볼륨을 사용하여 데이터를 암호화하는 방법을 이해하고, 최소한의 운영 오버헤드로 고객 관리 키를 사용하여 데이터를 암호화할 수 있는 능력을 평가합니다.

### 정답
C. Enable EBS encryption by default in the AWS Region where the EKS cluster will be created. Select the customer managed key as the default key.
D. Create the EKS cluster. Create an IAM role that has a policy that grants permission to the customer managed key. Associate the role with the EKS cluster.

### 해설
회사는 Amazon EKS 클러스터를 사용하여 디지털 미디어 스트리밍 애플리케이션을 호스팅하고, Amazon EBS 볼륨을 사용하여 데이터를 저장합니다. 모든 데이터를 고객 관리 키를 사용하여 암호화해야 합니다. 최소한의 운영 오버헤드로 이 요구 사항을 충족하려면 다음 두 가지 조치를 취해야 합니다:

- **C. Enable EBS encryption by default in the AWS Region where the EKS cluster will be created. Select the customer managed key as the default key.**
  - AWS 관리 콘솔에서 EBS 암호화를 기본값으로 설정하고, 고객 관리 키를 기본 키로 선택하면, 모든 새로 생성되는 EBS 볼륨이 자동으로 암호화됩니다. 이는 운영 오버헤드를 최소화하는 데 도움이 됩니다.

- **D. Create the EKS cluster. Create an IAM role that has a policy that grants permission to the customer managed key. Associate the role with the EKS cluster.**
  - EKS 클러스터를 생성하고, 고객 관리 키에 대한 권한을 부여하는 IAM 역할을 생성하여 클러스터에 연결하면, 클러스터 내에서 생성되는 모든 리소스가 해당 키를 사용할 수 있습니다.

다른 옵션을 살펴보면:

- **A. Use a Kubernetes plugin that uses the customer managed key to perform data encryption.**
  - Kubernetes 플러그인을 사용하는 것은 추가적인 설정과 관리가 필요하며, 운영 오버헤드를 증가시킬 수 있습니다.

- **B. After creation of the EKS cluster, locate the EBS volumes. Enable encryption by using the customer managed key.**
  - 클러스터 생성 후에 EBS 볼륨을 찾아 암호화를 활성화하는 것은 수동 작업이 필요하며, 운영 오버헤드를 증가시킵니다.

- **E. Store the customer managed key as a Kubernetes secret in the EKS cluster. Use the customer managed key to encrypt the EBS volumes.**
  - Kubernetes 시크릿을 사용하여 키를 저장하고 EBS 볼륨을 암호화하는 것은 복잡하며, 운영 오버헤드를 증가시킬 수 있습니다.

따라서, 최소한의 운영 오버헤드로 요구 사항을 충족하는 솔루션은 옵션 C와 D의 조합입니다.

### 필요한 학습 내용

1. **Amazon EKS (Elastic Kubernetes Service)**
   - EKS 클러스터 생성 및 관리 방법
   - EKS 클러스터와 IAM 역할 연동 방법

2. **Amazon EBS (Elastic Block Store)**
   - EBS 볼륨 암호화 방법
   - EBS 암호화를 기본값으로 설정하는 방법

3. **AWS Key Management Service (KMS)**
   - 고객 관리 키 (Customer Managed Key) 생성 및 관리 방법
   - KMS 키를 사용하여 EBS 볼륨 암호화 방법
   - IAM 역할을 통해 KMS 키에 대한 권한 부여 방법

### 추가 학습 자료
- [Amazon EKS 공식 문서](https://docs.aws.amazon.com/ko_kr/eks/latest/userguide/what-is-eks.html)
- [Amazon EBS 공식 문서](https://docs.aws.amazon.com/ko_kr/AWSEC2/latest/UserGuide/AmazonEBS.html)
- [AWS KMS 공식 문서](https://docs.aws.amazon.com/ko_kr/kms/latest/developerguide/overview.html)
- [EBS 암호화 기본값 설정](https://docs.aws.amazon.com/ko_kr/AWSEC2/latest/UserGuide/EBSEncryption.html#encryption-by-default)

이 자료들을 통해 EKS와 EBS의 다양한 기능과 보안 설정을 이해하고, 특정 시나리오에서 최적의 솔루션을 선택하는 능력을 키울 수 있습니다.


# 374
### 문제 분석
이 문제는 **세 개의 VPC**와 **단일 온프레미스 데이터 센터** 간의 **고속 데이터 전송**과 **VPC 간 통신**을 설계하는 것입니다. 또한, 요구사항에는 **비용 효율성**을 고려한 네트워크 연결 방식이 필요합니다. 

### 각 옵션 분석

#### A. Configure three AWS Site-to-Site VPN connections from the data center to AWS. Establish connectivity by configuring one VPN connection for each VPC.
- **장점**:
  - **AWS Site-to-Site VPN**은 비교적 **저렴한 비용**으로 연결을 설정할 수 있는 방법입니다.
- **단점**:
  - **각 VPC마다 별도의 VPN 연결**을 설정해야 하므로 **연결 관리가 복잡**해질 수 있습니다.
  - 대규모 데이터 전송이 필요한 상황에서 VPN 연결은 **성능상 한계**가 있을 수 있으며, **지연 시간**이 중요한 경우에는 적합하지 않습니다.
  - **속도**와 **대역폭** 측면에서 제한이 있을 수 있습니다.
  - **비용 효율성**은 있지만, **대규모 데이터 전송**에는 부적합할 수 있습니다.

#### B. Launch a third-party virtual network appliance in each VPC. Establish an IPsec VPN tunnel between the data center and each virtual appliance.
- **장점**:
  - 가상 네트워크 장비를 통해 **다양한 커스터마이징**이 가능할 수 있습니다.
- **단점**:
  - **복잡성**이 증가합니다. 각 VPC에 **가상 네트워크 장비**를 배포하고 이를 관리해야 합니다.
  - **IPsec VPN**을 사용하면 대규모 데이터 전송 시 **성능 문제**가 발생할 수 있습니다.
  - **비용**과 **관리의 복잡성**이 커질 수 있으며, 대규모 트래픽 전송에는 부적합합니다.

#### C. Set up three AWS Direct Connect connections from the data center to a Direct Connect gateway in us-east-1. Establish connectivity by configuring each VPC to use one of the Direct Connect connections.
- **장점**:
  - **Direct Connect**는 **전용 회선**을 이용하여 **고속 데이터 전송**과 **낮은 지연 시간**을 제공합니다.
  - **각 VPC에 대한 별도의 연결**을 설정하여 VPC 간에 효율적으로 데이터를 전송할 수 있습니다.
- **단점**:
  - **비용**이 상당히 높습니다. 각각의 VPC에 대해 **Direct Connect 연결**을 설정하는 것은 비용 면에서 비효율적일 수 있습니다.
  - **세 개의 Direct Connect 연결**을 관리하는 데는 관리의 복잡성과 비용이 증가합니다.

#### D. Set up one AWS Direct Connect connection from the data center to AWS. Create a transit gateway, and attach each VPC to the transit gateway. Establish connectivity between the Direct Connect connection and the transit gateway.
- **장점**:
  - **하나의 Direct Connect 연결**을 사용하여 **온프레미스 데이터 센터와 AWS** 간에 고속 연결을 제공합니다.
  - **Transit Gateway**를 사용하여 **세 개의 VPC**를 연결할 수 있습니다. 이를 통해 VPC 간 통신을 효율적으로 처리할 수 있습니다.
  - **비용 효율성**을 극대화할 수 있습니다. Direct Connect 연결을 한 번만 설정하고, Transit Gateway를 통해 VPC 간의 연결을 중앙 집중식으로 관리할 수 있습니다.
  - **고속 데이터 전송**과 **낮은 지연 시간**을 보장할 수 있습니다.
- **단점**:
  - **Transit Gateway** 설정에 대한 관리가 필요할 수 있지만, **비용 효율성**과 **성능** 면에서 우수한 솔루션입니다.

### 정답
**D. Set up one AWS Direct Connect connection from the data center to AWS. Create a transit gateway, and attach each VPC to the transit gateway. Establish connectivity between the Direct Connect connection and the transit gateway.**

### 해설
- 이 솔루션은 **하나의 Direct Connect 연결**을 사용하여 온프레미스 데이터 센터와 AWS 간의 고속 연결을 제공하고, **Transit Gateway**를 사용하여 **세 개의 VPC** 간에 효율적으로 데이터를 라우팅합니다.
- **비용 효율성**이 뛰어나며, 대규모 데이터 전송을 처리하는 데 적합합니다. 또한, **VPC 간 통신**과 **온프레미스와의 통신**을 최적화할 수 있습니다. **성능**과 **비용** 면에서 모두 우수한 선택입니다.

# 376번
### 출제 의도
이 문제는 Amazon RDS for MySQL 데이터베이스 인스턴스에 대한 연결 문제를 해결하고, 서버리스 애플리케이션의 트래픽 변동성을 처리할 수 있는 솔루션을 선택하는 능력을 평가합니다. 특히, 최소한의 운영 오버헤드로 데이터베이스 연결 거부 오류를 해결하는 방법을 찾는 것이 중요합니다.

### 정답
A. Create a proxy in RDS Proxy. Configure the users’ applications to use the DB instance through RDS Proxy.

### 해설
Amazon RDS Proxy는 데이터베이스 연결을 관리하고, 연결 풀링을 통해 데이터베이스에 대한 연결 수를 최적화하여 성능을 향상시킵니다. 이는 특히 서버리스 애플리케이션과 같이 트래픽 변동성이 큰 경우에 유용합니다. RDS Proxy를 사용하면 데이터베이스 연결 거부 오류를 줄이고, 최소한의 운영 오버헤드로 문제를 해결할 수 있습니다.

각 옵션을 자세히 살펴보면:

- **A. Create a proxy in RDS Proxy. Configure the users’ applications to use the DB instance through RDS Proxy.**
  - RDS Proxy는 데이터베이스 연결을 관리하고 최적화하여, 트래픽 변동성이 큰 경우에도 안정적인 연결을 제공합니다. 이는 최소한의 운영 오버헤드로 문제를 해결할 수 있는 솔루션입니다.

- **B. Deploy Amazon ElastiCache for Memcached between the users’ applications and the DB instance.**
  - ElastiCache는 캐싱 솔루션으로, 데이터베이스 부하를 줄이는 데 유용하지만, 연결 거부 오류를 직접적으로 해결하지는 않습니다.

- **C. Migrate the DB instance to a different instance class that has higher I/O capacity. Configure the users’ applications to use the new DB instance.**
  - 인스턴스 클래스를 업그레이드하는 것은 비용이 많이 들며, 트래픽 변동성 문제를 근본적으로 해결하지 못할 수 있습니다.

- **D. Configure Multi-AZ for the DB instance. Configure the users’ applications to switch between the DB instances.**
  - Multi-AZ 설정은 고가용성을 제공하지만, 연결 거부 오류를 해결하는 데 직접적인 도움이 되지 않습니다.

따라서, 회사의 요구 사항을 가장 비용 효율적으로 충족하는 솔루션은 옵션 A입니다.

### 필요한 학습 내용

1. **Amazon RDS Proxy**
   - RDS Proxy는 데이터베이스 연결을 관리하고 최적화하여, 트래픽 변동성이 큰 경우에도 안정적인 연결을 제공합니다.
   - 연결 풀링을 통해 데이터베이스에 대한 연결 수를 최적화하고, 성능을 향상시킵니다.

2. **Amazon ElastiCache**
   - ElastiCache는 인메모리 캐싱 서비스로, 데이터베이스 부하를 줄이는 데 유용합니다.
   - Memcached와 Redis를 지원하며, 데이터베이스 읽기 성능을 향상시킬 수 있습니다.

3. **Amazon RDS 인스턴스 클래스**
   - RDS 인스턴스 클래스는 데이터베이스 인스턴스의 성능을 결정합니다.
   - 더 높은 I/O 용량을 가진 인스턴스 클래스로 업그레이드하면 성능이 향상될 수 있지만, 비용이 증가합니다.

4. **Amazon RDS Multi-AZ**
   - Multi-AZ 배포는 고가용성을 제공하며, 장애 발생 시 자동으로 장애 조치를 수행합니다.
   - 데이터베이스 연결 거부 오류를 해결하는 데는 직접적인 도움이 되지 않습니다.

### 추가 학습 자료
- [Amazon RDS Proxy 공식 문서](https://docs.aws.amazon.com/ko_kr/AmazonRDS/latest/UserGuide/rds-proxy.html)
- [Amazon ElastiCache 공식 문서](https://docs.aws.amazon.com/ko_kr/AmazonElastiCache/latest/mem-ug/WhatIs.html)
- [Amazon RDS 인스턴스 클래스](https://docs.aws.amazon.com/ko_kr/AmazonRDS/latest/UserGuide/Concepts.DBInstanceClass.html)
- [Amazon RDS Multi-AZ 배포](https://docs.aws.amazon.com/ko_kr/AmazonRDS/latest/UserGuide/Concepts.MultiAZ.html)

이 자료들을 통해 RDS Proxy와 ElastiCache, RDS 인스턴스 클래스, Multi-AZ 배포의 다양한 기능과 설정 방법을 이해하고, 특정 시나리오에서 최적의 솔루션을 선택하는 능력을 키울 수 있습니다.


# 379번
### 출제 의도
이 문제는 Amazon API Gateway와 AWS Lambda를 사용하여 백엔드와 통합된 프론트엔드 애플리케이션의 응답 지연 시간을 최소화하는 방법을 평가합니다. 특히, 최소한의 운영 변경으로 응답 지연 시간을 줄이는 방법을 찾는 것이 중요합니다.

### 정답
B. Configure provisioned concurrency for the Lambda function that handles the requests.

### 해설
AWS Lambda 함수는 호출될 때마다 콜드 스타트 문제로 인해 지연 시간이 발생할 수 있습니다. 특히, 많은 라이브러리를 로드해야 하는 경우 이 지연 시간이 더 길어질 수 있습니다. 프로비저닝된 동시성(Provisioned Concurrency)을 사용하면 Lambda 함수가 항상 준비 상태를 유지하여 콜드 스타트 지연을 줄일 수 있습니다. 이는 최소한의 운영 변경으로 응답 지연 시간을 줄이는 가장 효과적인 방법입니다.

각 옵션을 자세히 살펴보면:

- **A. Establish a connection between the frontend application and the database to make queries faster by bypassing the API.**
  - 프론트엔드 애플리케이션이 직접 데이터베이스에 연결하는 것은 보안 및 아키텍처 측면에서 바람직하지 않습니다. 또한, API Gateway와 Lambda를 우회하는 것은 많은 변경이 필요합니다.

- **B. Configure provisioned concurrency for the Lambda function that handles the requests.**
  - 프로비저닝된 동시성을 사용하면 Lambda 함수가 항상 준비 상태를 유지하여 콜드 스타트 지연을 줄일 수 있습니다. 이는 최소한의 운영 변경으로 응답 지연 시간을 줄이는 가장 효과적인 방법입니다.

- **C. Cache the results of the queries in Amazon S3 for faster retrieval of similar datasets.**
  - 쿼리 결과를 S3에 캐시하는 것은 일부 경우에 유용할 수 있지만, 모든 요청에 대해 항상 최신 데이터를 제공하지 못할 수 있습니다. 또한, 캐시를 관리하는 추가적인 복잡성이 발생합니다.

- **D. Increase the size of the database to increase the number of connections Lambda can establish at one time.**
  - 데이터베이스 크기를 늘리는 것은 비용이 많이 들며, Lambda 함수의 콜드 스타트 문제를 해결하지 못합니다.

따라서, 회사의 요구 사항을 가장 효율적으로 충족하는 솔루션은 옵션 B입니다.

### 필요한 학습 내용

1. **AWS Lambda 프로비저닝된 동시성 (Provisioned Concurrency)**
   - 프로비저닝된 동시성을 사용하면 Lambda 함수가 항상 준비 상태를 유지하여 콜드 스타트 지연을 줄일 수 있습니다.
   - 이는 응답 지연 시간을 최소화하는 데 매우 효과적입니다.

2. **Amazon API Gateway**
   - API Gateway는 RESTful API를 생성, 배포 및 관리할 수 있는 서비스입니다.
   - Lambda 함수와 통합하여 백엔드 로직을 처리할 수 있습니다.

3. **Amazon RDS**
   - RDS는 관리형 관계형 데이터베이스 서비스로, 다양한 데이터베이스 엔진을 지원합니다.
   - Lambda 함수와 통합하여 데이터베이스 작업을 수행할 수 있습니다.

### 추가 학습 자료
- [AWS Lambda 프로비저닝된 동시성 공식 문서](https://docs.aws.amazon.com/ko_kr/lambda/latest/dg/configuration-concurrency.html)
- [Amazon API Gateway 공식 문서](https://docs.aws.amazon.com/ko_kr/apigateway/latest/developerguide/welcome.html)
- [Amazon RDS 공식 문서](https://docs.aws.amazon.com/ko_kr/AmazonRDS/latest/UserGuide/Welcome.html)

이 자료들을 통해 Lambda 프로비저닝된 동시성, API Gateway, RDS의 다양한 기능과 설정 방법을 이해하고, 특정 시나리오에서 최적의 솔루션을 선택하는 능력을 키울 수 있습니다.


# 383번
### 정답
A. Dedicated Reserved Hosts

### 해설
Dedicated Hosts는 물리적 서버를 전용으로 사용할 수 있는 옵션으로, 소켓과 코어 기반의 소프트웨어 라이선싱 모델을 지원합니다. 또한, Reserved Hosts는 예약된 용량을 제공하여 비용을 절감할 수 있습니다. 회사가 기존 라이선스를 사용하고, 예측 가능한 용량과 가동 시간 요구 사항이 있는 경우, Dedicated Reserved Hosts가 가장 비용 효율적인 선택입니다.

각 옵션을 자세히 살펴보면:

- **A. Dedicated Reserved Hosts**
  - Dedicated Hosts는 물리적 서버를 전용으로 사용할 수 있는 옵션으로, 소켓과 코어 기반의 소프트웨어 라이선싱 모델을 지원합니다. Reserved Hosts는 예약된 용량을 제공하여 비용을 절감할 수 있습니다. 이는 가장 비용 효율적인 선택입니다.

- **B. Dedicated On-Demand Hosts**
  - Dedicated On-Demand Hosts는 물리적 서버를 전용으로 사용할 수 있지만, 예약되지 않은 용량을 사용하므로 비용이 더 많이 들 수 있습니다.

- **C. Dedicated Reserved Instances**
  - Dedicated Reserved Instances는 물리적 서버를 전용으로 사용하지 않으며, 소켓과 코어 기반의 소프트웨어 라이선싱 모델을 지원하지 않습니다.

- **D. Dedicated On-Demand Instances**
  - Dedicated On-Demand Instances는 물리적 서버를 전용으로 사용하지 않으며, 예약되지 않은 용량을 사용하므로 비용이 더 많이 들 수 있습니다.

따라서, 회사의 요구 사항을 가장 효율적으로 충족하는 솔루션은 옵션 A입니다.

### 필요한 학습 내용

1. **Dedicated Hosts**
   - Dedicated Hosts는 물리적 서버를 전용으로 사용할 수 있는 옵션입니다.
   - 소켓과 코어 기반의 소프트웨어 라이선싱 모델을 지원합니다.

2. **Reserved Hosts**
   - Reserved Hosts는 예약된 용량을 제공하여 비용을 절감할 수 있습니다.
   - 예측 가능한 용량과 가동 시간 요구 사항이 있는 경우에 적합합니다.

3. **Dedicated Instances**
   - Dedicated Instances는 물리적 서버를 전용으로 사용하지 않으며, 소켓과 코어 기반의 소프트웨어 라이선싱 모델을 지원하지 않습니다.

4. **On-Demand Instances**
   - On-Demand Instances는 예약되지 않은 용량을 사용하므로, 비용이 더 많이 들 수 있습니다.

### 추가 학습 자료
- [Amazon EC2 Dedicated Hosts 공식 문서](https://docs.aws.amazon.com/ko_kr/AWSEC2/latest/UserGuide/dedicated-hosts-overview.html)
- [Amazon EC2 Reserved Instances 공식 문서](https://docs.aws.amazon.com/ko_kr/AWSEC2/latest/UserGuide/ec2-reserved-instances.html)
- [Amazon EC2 On-Demand Instances 공식 문서](https://docs.aws.amazon.com/ko_kr/AWSEC2/latest/UserGuide/ec2-on-demand-instances.html)

이 자료들을 통해 Dedicated Hosts, Reserved Hosts, Dedicated Instances, On-Demand Instances의 다양한 기능과 설정 방법을 이해하고, 특정 시나리오에서 최적의 솔루션을 선택하는 능력을 키울 수 있습니다.


# 390번
### 출제 의도
이 문제는 세션 데이터를 내구성 있게 저장하고, 고객 세션 관리를 최적화하는 방법을 평가합니다. 특히, 세션 데이터를 안전하게 저장하고, Auto Scaling 환경에서 세션 관리를 효율적으로 처리할 수 있는 솔루션을 선택하는 것이 중요합니다.

### 정답
B. Use an Amazon DynamoDB table to store customer session information.
D. Deploy an Amazon ElastiCache for Redis cluster to store customer session information.

### 해설
세션 데이터를 내구성 있게 저장하고, Auto Scaling 환경에서 세션 관리를 최적화하려면, 세션 데이터를 중앙 집중식으로 저장할 수 있는 솔루션이 필요합니다. DynamoDB와 ElastiCache for Redis는 모두 세션 데이터를 내구성 있게 저장하고, 빠르게 접근할 수 있는 솔루션을 제공합니다.

각 옵션을 자세히 살펴보면:

- **A. Turn on the sticky sessions feature (session affinity) on the ALB.**
  - ALB의 스티키 세션 기능은 세션 데이터를 내구성 있게 저장하지 않습니다. 이는 세션 데이터를 특정 인스턴스에 고정시키는 방법으로, 인스턴스가 종료되면 세션 데이터가 손실될 수 있습니다.

- **B. Use an Amazon DynamoDB table to store customer session information.**
  - DynamoDB는 완전 관리형 NoSQL 데이터베이스로, 세션 데이터를 내구성 있게 저장할 수 있습니다. 또한, 높은 가용성과 성능을 제공합니다.

- **C. Deploy an Amazon Cognito user pool to manage user session information.**
  - Amazon Cognito는 사용자 인증 및 관리에 적합하지만, 세션 데이터를 내구성 있게 저장하는 데는 적합하지 않습니다.

- **D. Deploy an Amazon ElastiCache for Redis cluster to store customer session information.**
  - ElastiCache for Redis는 인메모리 데이터 저장소로, 세션 데이터를 빠르게 저장하고 접근할 수 있습니다. 또한, Redis의 내구성 옵션을 사용하여 데이터를 안전하게 저장할 수 있습니다.

- **E. Use AWS Systems Manager Application Manager in the application to manage user session information.**
  - AWS Systems Manager Application Manager는 애플리케이션 관리를 위한 도구로, 세션 데이터를 내구성 있게 저장하는 데는 적합하지 않습니다.

따라서, 회사의 요구 사항을 가장 효율적으로 충족하는 솔루션은 옵션 B와 D입니다.

### 필요한 학습 내용

1. **Amazon DynamoDB**
   - 완전 관리형 NoSQL 데이터베이스로, 세션 데이터를 내구성 있게 저장할 수 있습니다.
   - 높은 가용성과 성능을 제공합니다.

2. **Amazon ElastiCache for Redis**
   - 인메모리 데이터 저장소로, 세션 데이터를 빠르게 저장하고 접근할 수 있습니다.
   - Redis의 내구성 옵션을 사용하여 데이터를 안전하게 저장할 수 있습니다.

3. **Application Load Balancer (ALB)**
   - ALB는 HTTP 및 HTTPS 트래픽을 로드 밸런싱할 수 있는 서비스입니다.
   - 스티키 세션 기능은 세션 데이터를 특정 인스턴스에 고정시키는 방법으로, 내구성 있는 세션 데이터 저장에는 적합하지 않습니다.

4. **Amazon Cognito**
   - 사용자 인증 및 관리를 위한 서비스로, 세션 데이터를 내구성 있게 저장하는 데는 적합하지 않습니다.

5. **AWS Systems Manager Application Manager**
   - 애플리케이션 관리를 위한 도구로, 세션 데이터를 내구성 있게 저장하는 데는 적합하지 않습니다.

### 추가 학습 자료
- [Amazon DynamoDB 공식 문서](https://docs.aws.amazon.com/ko_kr/amazondynamodb/latest/developerguide/Introduction.html)
- [Amazon ElastiCache for Redis 공식 문서](https://docs.aws.amazon.com/ko_kr/AmazonElastiCache/latest/red-ug/WhatIs.html)
- [Application Load Balancer 공식 문서](https://docs.aws.amazon.com/ko_kr/elasticloadbalancing/latest/application/introduction.html)
- [Amazon Cognito 공식 문서](https://docs.aws.amazon.com/ko_kr/cognito/latest/developerguide/what-is-amazon-cognito.html)
- [AWS Systems Manager Application Manager 공식 문서](https://docs.aws.amazon.com/ko_kr/systems-manager/latest/userguide/app-manager.html)

이 자료들을 통해 DynamoDB와 ElastiCache for Redis의 다양한 기능과 설정 방법을 이해하고, 특정 시나리오에서 최적의 솔루션을 선택하는 능력을 키울 수 있습니다.


# 391번
### 출제 의도
이 문제는 세 가지 계층으로 구성된 무상태 웹 애플리케이션의 백업 전략을 설계할 때, 확장성을 극대화하고 리소스 활용을 최적화하는 방법을 평가합니다. 특히, 2시간의 복구 시점 목표(RPO)를 충족하는 백업 전략을 선택하는 것이 중요합니다.

### 정답
C. Retain the latest Amazon Machine Images (AMIs) of the web and application tiers. Enable automated backups in Amazon RDS and use point-in-time recovery to meet the RPO.

### 해설
세 가지 계층으로 구성된 무상태 웹 애플리케이션의 경우, EC2 인스턴스는 상태를 유지하지 않으므로, 인스턴스 자체를 백업할 필요가 없습니다. 대신, 최신 Amazon Machine Images (AMIs)를 유지하여 필요할 때 인스턴스를 신속하게 재생성할 수 있습니다. 데이터베이스 계층의 경우, Amazon RDS의 자동 백업 기능을 사용하고, 포인트 인 타임 복구(Point-in-Time Recovery)를 통해 2시간의 RPO를 충족할 수 있습니다.

각 옵션을 자세히 살펴보면:

- **A. Take snapshots of Amazon Elastic Block Store (Amazon EBS) volumes of the EC2 instances and database every 2 hours to meet the RPO.**
  - EC2 인스턴스가 무상태이므로, EBS 볼륨 스냅샷을 2시간마다 찍는 것은 불필요한 리소스 낭비입니다. 데이터베이스의 경우, RDS의 자동 백업 기능을 사용하는 것이 더 효율적입니다.

- **B. Configure a snapshot lifecycle policy to take Amazon Elastic Block Store (Amazon EBS) snapshots. Enable automated backups in Amazon RDS to meet the RPO.**
  - EBS 스냅샷 라이프사이클 정책을 설정하는 것은 EC2 인스턴스가 무상태인 경우 불필요합니다. RDS의 자동 백업 기능을 사용하는 것은 적절하지만, EC2 인스턴스에 대한 백업 전략이 최적화되지 않았습니다.

- **C. Retain the latest Amazon Machine Images (AMIs) of the web and application tiers. Enable automated backups in Amazon RDS and use point-in-time recovery to meet the RPO.**
  - 최신 AMIs를 유지하면 EC2 인스턴스를 신속하게 재생성할 수 있으며, RDS의 자동 백업과 포인트 인 타임 복구를 통해 데이터베이스의 RPO를 충족할 수 있습니다. 이는 확장성을 극대화하고 리소스 활용을 최적화하는 가장 효율적인 방법입니다.

- **D. Take snapshots of Amazon Elastic Block Store (Amazon EBS) volumes of the EC2 instances every 2 hours. Enable automated backups in Amazon RDS and use point-in-time recovery to meet the RPO.**
  - EC2 인스턴스가 무상태이므로, EBS 볼륨 스냅샷을 2시간마다 찍는 것은 불필요한 리소스 낭비입니다. 데이터베이스의 경우, RDS의 자동 백업 기능을 사용하는 것이 더 효율적입니다.

따라서, 회사의 요구 사항을 가장 효율적으로 충족하는 솔루션은 옵션 C입니다.

### 필요한 학습 내용

1. **Amazon Machine Images (AMIs)**
   - AMI는 EC2 인스턴스를 생성하는 데 필요한 정보를 포함하는 템플릿입니다.
   - 최신 AMIs를 유지하면 EC2 인스턴스를 신속하게 재생성할 수 있습니다.

2. **Amazon RDS 자동 백업**
   - RDS는 자동으로 데이터베이스 백업을 생성하고, 포인트 인 타임 복구를 지원합니다.
   - 자동 백업을 사용하면 데이터베이스의 RPO를 충족할 수 있습니다.

3. **포인트 인 타임 복구 (Point-in-Time Recovery)**
   - RDS는 특정 시점으로 데이터베이스를 복구할 수 있는 기능을 제공합니다.
   - 이를 통해 데이터 손실을 최소화하고, RPO를 충족할 수 있습니다.

### 추가 학습 자료
- [Amazon Machine Images (AMIs) 공식 문서](https://docs.aws.amazon.com/ko_kr/AWSEC2/latest/UserGuide/AMIs.html)
- [Amazon RDS 자동 백업 공식 문서](https://docs.aws.amazon.com/ko_kr/AmazonRDS/latest/UserGuide/USER_WorkingWithAutomatedBackups.html)
- [포인트 인 타임 복구 공식 문서](https://docs.aws.amazon.com/ko_kr/AmazonRDS/latest/UserGuide/USER_PIT.html)

이 자료들을 통해 AMIs와 RDS 자동 백업, 포인트 인 타임 복구의 다양한 기능과 설정 방법을 이해하고, 특정 시나리오에서 최적의 솔루션을 선택하는 능력을 키울 수 있습니다.


# 393번
### 출제 의도
이 문제는 음성 파일에서 텍스트를 추출하고, 고객의 개인 식별 정보를 제거하는 방법을 평가합니다. 특히, AWS 서비스를 사용하여 이 작업을 자동화하고 효율적으로 수행하는 방법을 찾는 것이 중요합니다.

### 정답
C. Configure an Amazon Transcribe transcription job with PII redaction turned on. When an audio file is uploaded to the S3 bucket, invoke an AWS Lambda function to start the transcription job. Store the output in a separate S3 bucket.

### 해설
Amazon Transcribe는 음성 파일을 텍스트로 변환하는 서비스로, PII(개인 식별 정보) 제거 기능을 제공합니다. 이 기능을 사용하면 음성 파일에서 텍스트를 추출하면서 자동으로 PII를 제거할 수 있습니다. S3 버킷에 파일이 업로드될 때 Lambda 함수를 호출하여 Transcribe 작업을 시작하고, 결과를 별도의 S3 버킷에 저장하면 요구 사항을 충족할 수 있습니다.

각 옵션을 자세히 살펴보면:

- **A. Process the audio files by using Amazon Kinesis Video Streams. Use an AWS Lambda function to scan for known PII patterns.**
  - Kinesis Video Streams는 비디오 스트리밍 데이터를 처리하는 데 사용되며, 음성 파일을 처리하는 데 적합하지 않습니다. 또한, Lambda 함수를 사용하여 PII 패턴을 스캔하는 것은 복잡하고 비효율적일 수 있습니다.

- **B. When an audio file is uploaded to the S3 bucket, invoke an AWS Lambda function to start an Amazon Textract task to analyze the call recordings.**
  - Amazon Textract는 문서에서 텍스트와 데이터를 추출하는 서비스로, 음성 파일을 처리하는 데 적합하지 않습니다.

- **C. Configure an Amazon Transcribe transcription job with PII redaction turned on. When an audio file is uploaded to the S3 bucket, invoke an AWS Lambda function to start the transcription job. Store the output in a separate S3 bucket.**
  - Amazon Transcribe는 음성 파일을 텍스트로 변환하고, PII 제거 기능을 제공합니다. Lambda 함수를 사용하여 Transcribe 작업을 시작하고, 결과를 별도의 S3 버킷에 저장하면 요구 사항을 충족할 수 있습니다.

- **D. Create an Amazon Connect contact flow that ingests the audio files with transcription turned on. Embed an AWS Lambda function to scan for known PII patterns. Use Amazon EventBridge to start the contact flow when an audio file is uploaded to the S3 bucket.**
  - Amazon Connect는 콜 센터 솔루션으로, 음성 파일을 처리하는 데 적합하지 않습니다. 또한, Lambda 함수를 사용하여 PII 패턴을 스캔하는 것은 복잡하고 비효율적일 수 있습니다.

따라서, 회사의 요구 사항을 가장 효율적으로 충족하는 솔루션은 옵션 C입니다.

### 필요한 학습 내용

1. **Amazon Transcribe**
   - 음성 파일을 텍스트로 변환하는 서비스입니다.
   - PII 제거 기능을 제공하여, 개인 식별 정보를 자동으로 제거할 수 있습니다.

2. **AWS Lambda**
   - 서버리스 컴퓨팅 서비스로, 이벤트에 응답하여 코드를 실행할 수 있습니다.
   - S3 버킷에 파일이 업로드될 때 Lambda 함수를 호출하여 Transcribe 작업을 시작할 수 있습니다.

3. **Amazon S3**
   - 객체 스토리지 서비스로, 음성 파일과 변환된 텍스트를 저장할 수 있습니다.
   - S3 이벤트를 사용하여 파일 업로드 시 Lambda 함수를 호출할 수 있습니다.

### 추가 학습 자료
- [Amazon Transcribe 공식 문서](https://docs.aws.amazon.com/ko_kr/transcribe/latest/dg/what-is-transcribe.html)
- [AWS Lambda 공식 문서](https://docs.aws.amazon.com/ko_kr/lambda/latest/dg/welcome.html)
- [Amazon S3 공식 문서](https://docs.aws.amazon.com/ko_kr/AmazonS3/latest/userguide/Welcome.html)

이 자료들을 통해 Amazon Transcribe, AWS Lambda, Amazon S3의 다양한 기능과 설정 방법을 이해하고, 특정 시나리오에서 최적의 솔루션을 선택하는 능력을 키울 수 있습니다.

# 394번
1. **A. Replace the volume with a magnetic volume.**
   - **잘못된 선택**입니다. 마그네틱 볼륨은 낮은 IOPS 성능을 제공하므로 성능이 더 나빠질 수 있습니다.

2. **B. Increase the number of IOPS on the gp3 volume.**
   - **잘못된 선택**입니다. gp3 볼륨은 최대 IOPS가 16,000이므로, 문제의 요구 조건인 20,000 IOPS를 만족시킬 수 없습니다.

3. **C. Replace the volume with a Provisioned IOPS SSD (io2) volume.**
   - **정답**입니다. io2 볼륨은 gp3보다 높은 성능을 제공하며 최대 64,000 IOPS까지 지원합니다. 이를 통해 20,000 IOPS 이상을 요구하는 이 애플리케이션의 성능 문제를 해결할 수 있습니다.

4. **D. Replace the 2,000 GB gp3 volume with two 1,000 GB gp3 volumes.**
   - **잘못된 선택**입니다. Amazon RDS에서는 볼륨을 쪼개는 방식으로 IOPS를 늘릴 수 없으므로 성능 개선에 효과적이지 않습니다.

---

### 정답
**C. Replace the volume with a Provisioned IOPS SSD (io2) volume**

# 395번
### 정답
C. AWS CloudTrail

### 해설
AWS CloudTrail은 AWS 계정에서 이루어진 모든 API 호출 및 활동을 기록하는 서비스입니다. 이를 통해 누가 어떤 작업을 수행했는지 추적할 수 있습니다. 보안 그룹 규칙 변경과 같은 구성 변경 사항을 추적하고, 어떤 IAM 사용자가 이러한 변경을 수행했는지 확인할 수 있습니다.

각 옵션을 자세히 살펴보면:

- **A. Amazon GuardDuty**
  - GuardDuty는 AWS 계정과 워크로드를 모니터링하여 악의적인 활동과 비정상적인 동작을 탐지하는 서비스입니다. 그러나, 특정 구성 변경을 수행한 사용자를 추적하는 데는 적합하지 않습니다.

- **B. Amazon Inspector**
  - Inspector는 AWS 인프라의 보안 취약성을 평가하는 서비스입니다. 특정 구성 변경을 수행한 사용자를 추적하는 데는 적합하지 않습니다.

- **C. AWS CloudTrail**
  - CloudTrail은 AWS 계정에서 이루어진 모든 API 호출 및 활동을 기록합니다. 이를 통해 누가 어떤 작업을 수행했는지 추적할 수 있습니다. 보안 그룹 규칙 변경과 같은 구성 변경 사항을 추적하고, 어떤 IAM 사용자가 이러한 변경을 수행했는지 확인할 수 있습니다.

- **D. AWS Config**
  - Config는 AWS 리소스의 구성 상태를 평가, 감사 및 평가하는 서비스입니다. 리소스의 현재 및 과거 구성 상태를 추적할 수 있지만, 특정 구성 변경을 수행한 사용자를 추적하는 데는 CloudTrail이 더 적합합니다.

따라서, 회사의 요구 사항을 가장 효율적으로 충족하는 솔루션은 옵션 C입니다.

### 필요한 학습 내용

1. **AWS CloudTrail**
   - CloudTrail은 AWS 계정에서 이루어진 모든 API 호출 및 활동을 기록하는 서비스입니다.
   - 이를 통해 누가 어떤 작업을 수행했는지 추적할 수 있습니다.

2. **Amazon GuardDuty**
   - GuardDuty는 AWS 계정과 워크로드를 모니터링하여 악의적인 활동과 비정상적인 동작을 탐지하는 서비스입니다.

3. **Amazon Inspector**
   - Inspector는 AWS 인프라의 보안 취약성을 평가하는 서비스입니다.

4. **AWS Config**
   - Config는 AWS 리소스의 구성 상태를 평가, 감사 및 평가하는 서비스입니다.
   - 리소스의 현재 및 과거 구성 상태를 추적할 수 있습니다.

### 추가 학습 자료
- [AWS CloudTrail 공식 문서](https://docs.aws.amazon.com/ko_kr/awscloudtrail/latest/userguide/cloudtrail-user-guide.html)
- [Amazon GuardDuty 공식 문서](https://docs.aws.amazon.com/ko_kr/guardduty/latest/ug/what-is-guardduty.html)
- [Amazon Inspector 공식 문서](https://docs.aws.amazon.com/ko_kr/inspector/latest/userguide/inspector_introduction.html)
- [AWS Config 공식 문서](https://docs.aws.amazon.com/ko_kr/config/latest/developerguide/WhatIsConfig.html)

이 자료들을 통해 CloudTrail, GuardDuty, Inspector, Config의 다양한 기능과 설정 방법을 이해하고, 특정 시나리오에서 최적의 솔루션을 선택하는 능력을 

# 397번
### 출제 의도
이 문제는 최소한의 운영 노력으로 매일 예약된 작업을 실행하는 솔루션을 설계하는 능력을 평가합니다. 특히, 작업의 CPU 및 메모리 사용량이 일정하고, 작업이 최대 1시간 동안 실행될 수 있는 경우에 적합한 솔루션을 선택하는 것이 중요합니다.

### 정답
C. Create an Amazon Elastic Container Service (Amazon ECS) cluster with an AWS Fargate launch type. Create an Amazon EventBridge scheduled event that launches an ECS task on the cluster to run the job.

### 해설
Amazon ECS와 AWS Fargate를 사용하면 서버를 관리할 필요 없이 컨테이너를 실행할 수 있습니다. Fargate는 작업의 CPU 및 메모리 요구 사항을 기반으로 자동으로 리소스를 할당하므로, 운영 오버헤드를 최소화할 수 있습니다. 또한, Amazon EventBridge를 사용하여 작업을 예약할 수 있습니다. 이는 최소한의 운영 노력으로 작업을 실행할 수 있는 가장 적절한 솔루션입니다.

각 옵션을 자세히 살펴보면:

- **A. Create an AWS Lambda function that has an Amazon EventBridge notification. Schedule the EventBridge event to run once a day.**
  - Lambda 함수는 최대 15분 동안 실행될 수 있으므로, 최대 1시간이 걸리는 작업에는 적합하지 않습니다.

- **B. Create an AWS Lambda function. Create an Amazon API Gateway HTTP API, and integrate the API with the function. Create an Amazon EventBridge scheduled event that calls the API and invokes the function.**
  - Lambda 함수는 최대 15분 동안 실행될 수 있으므로, 최대 1시간이 걸리는 작업에는 적합하지 않습니다.

- **C. Create an Amazon Elastic Container Service (Amazon ECS) cluster with an AWS Fargate launch type. Create an Amazon EventBridge scheduled event that launches an ECS task on the cluster to run the job.**
  - Fargate는 서버를 관리할 필요 없이 컨테이너를 실행할 수 있으며, 작업의 CPU 및 메모리 요구 사항을 기반으로 자동으로 리소스를 할당합니다. 이는 최소한의 운영 노력으로 작업을 실행할 수 있는 가장 적절한 솔루션입니다.

- **D. Create an Amazon Elastic Container Service (Amazon ECS) cluster with an Amazon EC2 launch type and an Auto Scaling group with at least one EC2 instance. Create an Amazon EventBridge scheduled event that launches an ECS task on the cluster to run the job.**
  - EC2 인스턴스를 관리해야 하므로, 운영 오버헤드가 증가합니다. Fargate를 사용하는 것이 더 효율적입니다.

따라서, 회사의 요구 사항을 가장 효율적으로 충족하는 솔루션은 옵션 C입니다.

### 필요한 학습 내용

1. **Amazon ECS (Elastic Container Service)**
   - ECS는 컨테이너화된 애플리케이션을 실행하고 관리할 수 있는 서비스입니다.
   - Fargate와 EC2 런치 타입을 지원합니다.

2. **AWS Fargate**
   - Fargate는 서버를 관리할 필요 없이 컨테이너를 실행할 수 있는 서버리스 컴퓨팅 엔진입니다.
   - 작업의 CPU 및 메모리 요구 사항을 기반으로 자동으로 리소스를 할당합니다.

3. **Amazon EventBridge**
   - EventBridge는 이벤트 기반 아키텍처를 구축할 수 있는 서비스입니다.
   - 예약된 이벤트를 생성하여 작업을 자동으로 실행할 수 있습니다.

4. **AWS Lambda**
   - Lambda는 서버리스 컴퓨팅 서비스로, 이벤트에 응답하여 코드를 실행할 수 있습니다.
   - 최대 실행 시간이 15분으로 제한되어 있습니다.

### 추가 학습 자료
- [Amazon ECS 공식 문서](https://docs.aws.amazon.com/ko_kr/AmazonECS/latest/developerguide/Welcome.html)
- [AWS Fargate 공식 문서](https://docs.aws.amazon.com/ko_kr/AmazonECS/latest/developerguide/AWS_Fargate.html)
- [Amazon EventBridge 공식 문서](https://docs.aws.amazon.com/ko_kr/eventbridge/latest/userguide/what-is-amazon-eventbridge.html)
- [AWS Lambda 공식 문서](https://docs.aws.amazon.com/ko_kr/lambda/latest/dg/welcome.html)

이 자료들을 통해 ECS, Fargate, EventBridge, Lambda의 다양한 기능과 설정 방법을 이해하고, 특정 시나리오에서 최적의 솔루션을 선택하는 능력을 키울 수 있습니다.
# 399번
### 출제 의도
이 문제는 HTTP 플러드 공격으로부터 웹 애플리케이션을 보호하기 위해 최소한의 운영 오버헤드로 효과적인 솔루션을 설계하는 능력을 평가합니다.

### 정답
B. Create a Regional AWS WAF web ACL with a rate-based rule. Associate the web ACL with the API Gateway stage.

### 해설
AWS WAF (Web Application Firewall)은 웹 애플리케이션을 다양한 공격으로부터 보호할 수 있는 서비스입니다. WAF의 레이트 기반 규칙(rate-based rule)을 사용하면 특정 시간 동안의 요청 수를 기준으로 트래픽을 제어할 수 있습니다. 이를 통해 HTTP 플러드 공격을 효과적으로 방어할 수 있습니다. 또한, WAF는 API Gateway와 쉽게 통합할 수 있으며, 최소한의 운영 오버헤드로 설정할 수 있습니다.

각 옵션을 자세히 살펴보면:

- **A. Create an Amazon CloudFront distribution in front of the API Gateway Regional API endpoint with a maximum TTL of 24 hours.**
  - CloudFront는 콘텐츠 배포 네트워크(CDN)로, 캐싱을 통해 성능을 향상시킬 수 있지만, HTTP 플러드 공격을 직접적으로 방어하지는 않습니다.

- **B. Create a Regional AWS WAF web ACL with a rate-based rule. Associate the web ACL with the API Gateway stage.**
  - AWS WAF의 레이트 기반 규칙을 사용하면 HTTP 플러드 공격을 효과적으로 방어할 수 있습니다. 이는 최소한의 운영 오버헤드로 설정할 수 있는 솔루션입니다.

- **C. Use Amazon CloudWatch metrics to monitor the Count metric and alert the security team when the predefined rate is reached.**
  - CloudWatch를 사용하여 모니터링하고 경고를 설정하는 것은 유용하지만, 공격을 직접적으로 방어하지는 않습니다.

- **D. Create an Amazon CloudFront distribution with Lambda@Edge in front of the API Gateway Regional API endpoint. Create an AWS Lambda function to block requests from IP addresses that exceed the predefined rate.**
  - Lambda@Edge와 CloudFront를 사용하여 요청을 차단하는 것은 가능하지만, 설정과 관리가 복잡하며 운영 오버헤드가 증가할 수 있습니다.

따라서, 회사의 요구 사항을 가장 효율적으로 충족하는 솔루션은 옵션 B입니다.

### 필요한 학습 내용

1. **AWS WAF (Web Application Firewall)**
   - WAF는 웹 애플리케이션을 다양한 공격으로부터 보호할 수 있는 서비스입니다.
   - 레이트 기반 규칙을 사용하여 특정 시간 동안의 요청 수를 기준으로 트래픽을 제어할 수 있습니다.

2. **Amazon API Gateway**
   - API Gateway는 RESTful API를 생성, 배포 및 관리할 수 있는 서비스입니다.
   - WAF와 통합하여 API를 보호할 수 있습니다.

3. **Amazon CloudFront**
   - CloudFront는 콘텐츠 배포 네트워크(CDN)로, 캐싱을 통해 성능을 향상시킬 수 있습니다.
   - HTTP 플러드 공격을 직접적으로 방어하지는 않습니다.

4. **Amazon CloudWatch**
   - CloudWatch는 AWS 리소스와 애플리케이션을 모니터링할 수 있는 서비스입니다.
   - 모니터링과 경고 설정은 가능하지만, 공격을 직접적으로 방어하지는 않습니다.

### 추가 학습 자료
- [AWS WAF 공식 문서](https://docs.aws.amazon.com/ko_kr/waf/latest/developerguide/what-is-aws-waf.html)
- [Amazon API Gateway 공식 문서](https://docs.aws.amazon.com/ko_kr/apigateway/latest/developerguide/welcome.html)
- [Amazon CloudFront 공식 문서](https://docs.aws.amazon.com/ko_kr/AmazonCloudFront/latest/DeveloperGuide/Introduction.html)
- [Amazon CloudWatch 공식 문서](https://docs.aws.amazon.com/ko_kr/AmazonCloudWatch/latest/monitoring/WhatIsCloudWatch.html)

이 자료들을 통해 AWS WAF, API Gateway, CloudFront, CloudWatch의 다양한 기능과 설정 방법을 이해하고, 특정 시나리오에서 최적의 솔루션을 선택하는 능력을 키울 수 있습니다.

# 401번
### 문제 분석:

회사는 애플리케이션을 AWS 클라우드로 마이그레이션하고 싶어하며, 최근 데이터베이스 서버 장애로 인해 데이터 손실을 경험했습니다. 요구사항은 단일 장애 지점을 제거하고, 사용자 수요에 맞춰 확장 가능하며, 높은 가용성과 복원력을 제공하는 솔루션입니다.

### 각 선택지 분석:

#### A. 
**Amazon EC2 인스턴스를 여러 가용 영역(AZ)에 Auto Scaling 그룹으로 배포하고, Amazon RDS DB 인스턴스를 Multi-AZ 구성으로 사용한다.**

- **장점:** EC2 인스턴스가 여러 가용 영역에 걸쳐 분산되어 있고, Auto Scaling을 통해 수요에 맞게 인스턴스를 확장할 수 있습니다. Amazon RDS의 Multi-AZ 구성을 통해 데이터베이스 복제본이 자동으로 유지되며, 기본 인스턴스에 장애가 발생해도 자동으로 장애 조치가 이루어집니다.  
- **적합성:** 데이터베이스 가용성과 복원력, 확장성 요구를 충족시킵니다.
- **결론:** 이 선택지는 높은 가용성과 복원력을 제공하고, 요구사항을 완전히 충족합니다.

#### B. 
**Amazon EC2 인스턴스를 단일 가용 영역에서 Auto Scaling 그룹으로 배포하고, 데이터베이스를 EC2 인스턴스에 배포하며, EC2 Auto Recovery를 활성화한다.**

- **장점:** Auto Recovery를 통해 인스턴스 장애 시 복구가 가능하지만, 단일 가용 영역에서만 인스턴스를 운영하기 때문에 가용성에 문제가 있습니다.  
- **단점:** 데이터베이스는 단일 EC2 인스턴스에 배치되므로, 여전히 단일 장애 지점이 존재하며 복원력이 부족합니다.
- **결론:** 단일 가용 영역에 배포되어 있어 높은 가용성을 보장하지 못하므로 요구사항에 부적합합니다.

#### C. 
**Amazon EC2 인스턴스를 여러 가용 영역에 Auto Scaling 그룹으로 배포하고, 단일 가용 영역에서 읽기 복제본을 가진 Amazon RDS DB 인스턴스를 사용한다. 기본 DB 인스턴스가 실패하면 읽기 복제본을 승격한다.**

- **장점:** EC2 인스턴스는 다중 가용 영역에서 배포되어 가용성이 보장됩니다.
- **단점:** 읽기 복제본은 단일 가용 영역에만 존재하며, 장애가 발생하면 수동으로 복구해야 합니다. 자동 장애 조치가 없으므로 복원력이 떨어집니다.
- **결론:** 자동 장애 조치가 없는 구조이므로 요구사항에 적합하지 않습니다.

#### D. 
**Amazon EC2 인스턴스를 여러 가용 영역에 Auto Scaling 그룹으로 배포하고, 여러 가용 영역에 걸쳐 EC2 인스턴스에 기본 및 보조 데이터베이스 서버를 배포한다. Amazon EBS Multi-Attach를 사용하여 인스턴스 간 공유 스토리지를 생성한다.**

- **장점:** 여러 가용 영역에 걸친 데이터베이스 배포와 EBS Multi-Attach를 사용한 스토리지 공유.
- **단점:** EBS Multi-Attach는 데이터베이스의 가용성 문제를 완전히 해결하지 못할 수 있으며, Amazon RDS Multi-AZ 구성만큼 효율적이지 않습니다.
- **결론:** 이 솔루션은 복잡하고 관리 비용이 높을 수 있습니다. RDS Multi-AZ 구성을 사용하는 것이 더 나은 선택입니다.

### 정답:
**A.**

## EBS Multi-Attach란?
**EBS Multi-Attach**는 Amazon Elastic Block Store(EBS)에서 제공하는 기능으로, 하나의 EBS 볼륨을 여러 Amazon EC2 인스턴스에 동시에 연결할 수 있게 해줍니다. 이를 통해 동일한 데이터를 여러 EC2 인스턴스에서 동시에 읽고 쓸 수 있어, 고가용성이나 공유 스토리지가 필요한 애플리케이션에 유용합니다.

### 주요 특징:
1. **동시 연결:** 여러 EC2 인스턴스에서 하나의 EBS 볼륨을 동시에 연결하고 사용할 수 있습니다. 이는 최대 16개의 EC2 인스턴스까지 허용됩니다.
2. **읽기 및 쓰기 작업:** 각 인스턴스가 동일한 볼륨에 대해 읽기 및 쓰기 작업을 수행할 수 있지만, 파일 시스템의 일관성을 유지하기 위해 특정 애플리케이션(예: 클러스터 파일 시스템 또는 자체 동기화 메커니즘)을 사용해야 합니다.
3. **고가용성:** 인스턴스 중 하나가 장애를 일으키더라도 다른 인스턴스에서 볼륨을 계속 사용할 수 있어 고가용성을 보장합니다.
4. **제약 사항:** 표준 파일 시스템(Linux의 ext4, XFS 등)은 여러 인스턴스에서 동시에 쓰기 작업을 할 경우 데이터 손상이 발생할 수 있기 때문에, 일반적인 파일 시스템으로는 Multi-Attach를 사용할 수 없습니다. 대신 클러스터 파일 시스템(예: Oracle RAC나 IBM GPFS) 또는 애플리케이션 자체적으로 데이터 동기화 기능이 있어야 합니다.

### 사용 예시:
- **고가용성 애플리케이션:** 다중 인스턴스에서 동시에 동일한 데이터에 접근할 필요가 있는 애플리케이션(예: 데이터베이스 클러스터, 병렬 처리 시스템 등).
- **분산 애플리케이션:** 여러 인스턴스가 동일한 스토리지 리소스를 공유할 필요가 있는 경우.

단, EBS Multi-Attach를 사용하기 위해서는 애플리케이션이 이를 지원해야 하며, 데이터 일관성을 유지할 수 있는 메커니즘이 필요합니다. 일반적인 파일 시스템에서는 사용하지 않는 것이 좋습니다.

# 402번
### 정답
C. Update the number of Kinesis shards to handle the throughput of the data that is sent to Kinesis Data Streams.

### 해설
Amazon Kinesis Data Streams는 스트리밍 데이터를 실시간으로 처리할 수 있는 서비스입니다. 데이터가 S3 버킷에 모두 도달하지 않는 문제는 Kinesis Data Streams의 처리 용량이 부족하여 발생할 수 있습니다. Kinesis Data Streams는 샤드(shard) 단위로 데이터를 처리하며, 각 샤드는 초당 1MB의 쓰기 및 2MB의 읽기 용량을 제공합니다. 데이터의 양이 증가하면 샤드의 수를 늘려야 합니다. 따라서, Kinesis 샤드의 수를 늘려 데이터 처리 용량을 증가시키는 것이 적절한 해결책입니다.

각 옵션을 자세히 살펴보면:

- **A. Update the Kinesis Data Streams default settings by modifying the data retention period.**
  - 데이터 보존 기간을 늘리는 것은 데이터 손실을 방지하는 데 도움이 되지만, 처리 용량 문제를 해결하지는 않습니다.

- **B. Update the application to use the Kinesis Producer Library (KPL) to send the data to Kinesis Data Streams.**
  - KPL을 사용하면 데이터 전송을 최적화할 수 있지만, 처리 용량 문제를 직접적으로 해결하지는 않습니다.

- **C. Update the number of Kinesis shards to handle the throughput of the data that is sent to Kinesis Data Streams.**
  - Kinesis 샤드의 수를 늘리면 데이터 처리 용량이 증가하여 데이터 손실 문제를 해결할 수 있습니다.

- **D. Turn on S3 Versioning within the S3 bucket to preserve every version of every object that is ingested in the S3 bucket.**
  - S3 버킷 버전 관리는 데이터 손실 문제를 해결하지 않습니다.

따라서, 회사의 요구 사항을 가장 효율적으로 충족하는 솔루션은 옵션 C입니다.

### 필요한 학습 내용

1. **Amazon Kinesis Data Streams**
   - Kinesis Data Streams는 스트리밍 데이터를 실시간으로 처리할 수 있는 서비스입니다.
   - 샤드 단위로 데이터를 처리하며, 각 샤드는 초당 1MB의 쓰기 및 2MB의 읽기 용량을 제공합니다.

2. **Kinesis 샤드**
   - 샤드는 Kinesis Data Streams의 기본 단위로, 데이터 처리 용량을 결정합니다.
   - 데이터의 양이 증가하면 샤드의 수를 늘려야 합니다.

3. **Kinesis Producer Library (KPL)**
   - KPL은 Kinesis Data Streams에 데이터를 전송하는 애플리케이션을 최적화할 수 있는 라이브러리입니다.
   - 데이터 전송을 최적화할 수 있지만, 처리 용량 문제를 직접적으로 해결하지는 않습니다.

4. **Amazon S3 버전 관리**
   - S3 버전 관리는 객체의 모든 버전을 보존하여 데이터 손실을 방지할 수 있습니다.
   - 데이터 처리 용량 문제를 해결하지는 않습니다.

### 추가 학습 자료
- [Amazon Kinesis Data Streams 공식 문서](https://docs.aws.amazon.com/ko_kr/streams/latest/dev/introduction.html)
- [Kinesis 샤드 공식 문서](https://docs.aws.amazon.com/ko_kr/streams/latest/dev/key-concepts.html#shard)
- [Kinesis Producer Library (KPL) 공식 문서](https://docs.aws.amazon.com/ko_kr/streams/latest/dev/developing-producers-with-kpl.html)
- [Amazon S3 버전 관리 공식 문서](https://docs.aws.amazon.com/ko_kr/AmazonS3/latest/dev/ObjectVersioning.html)

이 자료들을 통해 Kinesis Data Streams, 샤드, KPL, S3 버전 관리의 다양한 기능과 설정 방법을 이해하고, 특정 시나리오에서 최적의 솔루션을 선택하는 능력을 키울 수 있습니다.


# 404번
### 정답
D. Create an Amazon Simple Queue Service (Amazon SQS) queue. Send the requests to the queue. Configure the queue as an event source for Lambda.

### 해설
마케팅 캠페인 후에 많은 문서가 처리되지 않은 문제는 Lambda 함수의 동시 실행 제한 또는 S3 이벤트 트리거의 제한으로 인해 발생할 수 있습니다. Amazon SQS를 사용하여 요청을 큐에 보내고, 큐를 Lambda 함수의 이벤트 소스로 구성하면, Lambda 함수가 큐에서 메시지를 처리할 수 있습니다. 이는 Lambda 함수의 동시 실행 제한을 우회하고, 문서가 손실되지 않도록 보장할 수 있습니다.


* **이벤트 소스(Event Source)**
   * Lambda 함수를 트리거하여 이벤트를 발생시키는 서비스나 리소스
   * Push-Based: API Gateway, S3, SNS, EventBridge
   * Poll-Based: SQS, Kinesis/DynamoDB Streams 
   * Event Source Mapping
      - SQS 큐와 Lambda 함수를 연결하여, Lambda 서비스가 자동으로 SQS 큐를 폴링하고 메시지를 Lambda 함수로 전달
      - create-event-source-mapping API를 사용하여 설정할 수 있음
* **Lambda 함수 동시 실행 제한**
   * 기본적으로 AWS 계정당 리전별로 1,000개의 제한이 설정


각 옵션을 자세히 살펴보면:

- **A. Set the Lambda function's runtime timeout value to 15 minutes.**
  - Lambda 함수의 실행 시간을 늘리는 것은 긴 실행 시간의 작업을 처리하는 데 도움이 될 수 있지만, 많은 문서가 처리되지 않는 문제를 해결하지는 않습니다.

- **B. Configure an S3 bucket replication policy. Stage the documents in the S3 bucket for later processing.**
  - S3 버킷 복제 정책을 구성하는 것은 데이터 복제에 도움이 될 수 있지만, 문서 처리 문제를 직접적으로 해결하지는 않습니다.

- **C. Deploy an additional Lambda function. Load balance the processing of the documents across the two Lambda functions.**
  - 추가 Lambda 함수를 배포하고 로드 밸런싱을 설정하는 것은 도움이 될 수 있지만, S3 이벤트 트리거의 제한을 해결하지는 않습니다.
  - Lambda의 동시 실행 한계에 도달하면 추가적인 Lambda 함수 실행이 이루어지지 않습니다. AWS Lambda는 기본적으로 계정당 동시에 실행할 수 있는 함수의 수에 제한이 있습니다. 이 제한은 동시 실행 한도(concurrent executions)라고 불리며, 기본적으로는 AWS 계정에 대해 1,000개의 동시 실행 제한이 있습니다(단, 이 값은 요청을 통해 증가시킬 수 있습니다). 만약 이 한도에 도달하면, 추가로 요청된 Lambda 함수는 대기 상태가 되거나 오류가 발생할 수 있습니다

- **D. Create an Amazon Simple Queue Service (Amazon SQS) queue. Send the requests to the queue. Configure the queue as an event source for Lambda.**
  - SQS 큐를 사용하여 요청을 큐에 보내고, 큐를 Lambda 함수의 이벤트 소스로 구성하면, Lambda 함수가 큐에서 메시지를 처리할 수 있습니다. 이는 Lambda 함수의 동시 실행 제한을 우회하고, 문서가 손실되지 않도록 보장할 수 있습니다. 이는 회사의 요구 사항을 가장 효율적으로 충족하는 솔루션입니다.

따라서, 회사의 요구 사항을 가장 효율적으로 충족하는 솔루션은 옵션 D입니다.

### 필요한 학습 내용

1. **Amazon SQS (Simple Queue Service)**
   - SQS는 메시지 큐 서비스로, 메시지를 안전하게 전송하고 저장할 수 있습니다.
   - Lambda 함수의 이벤트 소스로 구성하여 메시지를 처리할 수 있습니다.

2. **AWS Lambda**
   - Lambda는 서버리스 컴퓨팅 서비스로, 이벤트에 응답하여 코드를 실행할 수 있습니다.
   - SQS 큐를 이벤트 소스로 구성하여 메시지를 처리할 수 있습니다.

3. **Amazon S3**
   - S3는 객체 스토리지 서비스로, 데이터를 안전하게 저장하고 관리할 수 있습니다.
   - S3 이벤트 트리거를 사용하여 Lambda 함수를 호출할 수 있습니다.

### 추가 학습 자료
- [Amazon SQS 공식 문서](https://docs.aws.amazon.com/ko_kr/AWSSimpleQueueService/latest/SQSDeveloperGuide/welcome.html)
- [AWS Lambda 공식 문서](https://docs.aws.amazon.com/ko_kr/lambda/latest/dg/welcome.html)
- [Amazon S3 공식 문서](https://docs.aws.amazon.com/ko_kr/AmazonS3/latest/userguide/Welcome.html)



# 405번
### 정답
D. Use a target tracking scaling policy to scale the Auto Scaling group based on instance CPU utilization.
E. Use scheduled scaling to change the Auto Scaling group minimum, maximum, and desired capacity to zero for weekends. Revert to the default values at the start of the week.

### 해설
솔루션 아키텍트는 소프트웨어 데모 환경을 설계하고 있으며, 이 환경은 작업 시간 동안 트래픽이 크게 증가하지만 주말에는 운영할 필요가 없습니다. 이를 위해 Auto Scaling 그룹을 사용하여 EC2 인스턴스를 자동으로 확장하고 축소할 수 있도록 설정해야 합니다.

각 옵션을 자세히 살펴보면:

- **A. Use AWS Auto Scaling to adjust the ALB capacity based on request rate.**
  - ALB는 자체적으로 트래픽을 처리할 수 있으며, Auto Scaling 그룹과 함께 사용하여 EC2 인스턴스를 확장 및 축소하는 것이 더 적절합니다. ALB의 용량을 조정하는 것은 필요하지 않습니다.

- **B. Use AWS Auto Scaling to scale the capacity of the VPC internet gateway.**
  - VPC 인터넷 게이트웨이는 확장 가능한 서비스로, Auto Scaling을 통해 용량을 조정할 필요가 없습니다.

- **C. Launch the EC2 instances in multiple AWS Regions to distribute the load across Regions.**
  - 여러 리전에서 EC2 인스턴스를 실행하는 것은 복잡성을 증가시키며, 단일 리전 내에서 Auto Scaling을 사용하는 것이 더 적절합니다.

- **D. Use a target tracking scaling policy to scale the Auto Scaling group based on instance CPU utilization.**
  - 타겟 추적 스케일링 정책을 사용하여 인스턴스 CPU 사용률을 기준으로 Auto Scaling 그룹을 확장 및 축소할 수 있습니다. 이는 트래픽 증가에 따라 자동으로 인스턴스를 추가하거나 제거하는 데 유용합니다.

- **E. Use scheduled scaling to change the Auto Scaling group minimum, maximum, and desired capacity to zero for weekends. Revert to the default values at the start of the week.**
  - 예약된 스케일링을 사용하여 주말 동안 Auto Scaling 그룹의 최소, 최대 및 원하는 용량을 0으로 설정하고, 주 초에 기본 값으로 되돌릴 수 있습니다. 이는 주말 동안 리소스를 절약하는 데 유용합니다.

따라서, 회사의 요구 사항을 가장 효율적으로 충족하는 솔루션은 옵션 D와 E입니다.

### 필요한 학습 내용

1. **AWS Auto Scaling**
   - Auto Scaling은 EC2 인스턴스를 자동으로 확장 및 축소할 수 있는 기능을 제공합니다.
   - 타겟 추적 스케일링 정책을 사용하여 인스턴스 CPU 사용률을 기준으로 확장 및 축소할 수 있습니다.
   - 예약된 스케일링을 사용하여 특정 시간에 Auto Scaling 그룹의 용량을 조정할 수 있습니다.

2. **Application Load Balancer (ALB)**
   - ALB는 트래픽을 여러 EC2 인스턴스에 분산시켜 고가용성과 확장성을 제공합니다.
   - Auto Scaling 그룹과 함께 사용하여 트래픽 증가에 따라 인스턴스를 자동으로 추가하거나 제거할 수 있습니다.

### 추가 학습 자료
- [AWS Auto Scaling 공식 문서](https://docs.aws.amazon.com/ko_kr/autoscaling/ec2/userguide/what-is-amazon-ec2-auto-scaling.html)
- [Application Load Balancer 공식 문서](https://docs.aws.amazon.com/ko_kr/elasticloadbalancing/latest/application/introduction.html)

이 자료들을 통해 Auto Scaling과 ALB의 다양한 기능과 설정 방법을 이해하고, 특정 시나리오에서 최적의 솔루션을 선택하는 능력을 키울 수 있습니다.


# 408번
### 정답
B. Use AWS Global Accelerator. Create a Network Load Balancer (NLB) in each of the two Regions as an endpoint. Create an Amazon Elastic Container Service (Amazon ECS) cluster with the Fargate launch type. Create an ECS service on the cluster. Set the ECS service as the target for the NLB. Process the data in Amazon ECS.

### 해설
회사는 지리적으로 분산된 원격 장치에서 UDP 데이터를 수신하고, 데이터를 즉시 처리하며, 필요시 장치에 메시지를 다시 보내는 애플리케이션을 운영하고 있습니다. 이 솔루션은 데이터 전송의 지연 시간을 최소화하고, 다른 AWS 리전으로의 빠른 장애 조치를 제공해야 합니다.

각 옵션을 자세히 살펴보면:

- **A. Configure an Amazon Route 53 failover routing policy. Create a Network Load Balancer (NLB) in each of the two Regions. Configure the NLB to invoke an AWS Lambda function to process the data.**
  - NLB는 UDP 트래픽을 처리할 수 있지만, Lambda 함수는 짧은 실행 시간에 적합하며, 지속적인 데이터 처리를 위해서는 적합하지 않을 수 있습니다.

- **B. Use AWS Global Accelerator. Create a Network Load Balancer (NLB) in each of the two Regions as an endpoint. Create an Amazon Elastic Container Service (Amazon ECS) cluster with the Fargate launch type. Create an ECS service on the cluster. Set the ECS service as the target for the NLB. Process the data in Amazon ECS.**
  - AWS Global Accelerator는 전 세계적으로 최적의 경로를 통해 트래픽을 전달하여 지연 시간을 최소화합니다. NLB는 UDP 트래픽을 처리할 수 있으며, ECS와 Fargate를 사용하여 데이터를 처리할 수 있습니다. 이는 지연 시간을 최소화하고, 빠른 장애 조치를 제공하는 데 적합한 솔루션입니다.

- **C. Use AWS Global Accelerator. Create an Application Load Balancer (ALB) in each of the two Regions as an endpoint. Create an Amazon Elastic Container Service (Amazon ECS) cluster with the Fargate launch type. Create an ECS service on the cluster. Set the ECS service as the target for the ALB. Process the data in Amazon ECS.**
  - ALB는 UDP 트래픽을 처리할 수 없습니다. 따라서 이 옵션은 적절하지 않습니다.

- **D. Configure an Amazon Route 53 failover routing policy. Create an Application Load Balancer (ALB) in each of the two Regions. Create an Amazon Elastic Container Service (Amazon ECS) cluster with the Fargate launch type. Create an ECS service on the cluster. Set the ECS service as the target for the ALB. Process the data in Amazon ECS.**
  - ALB는 UDP 트래픽을 처리할 수 없습니다. 따라서 이 옵션은 적절하지 않습니다.

따라서, 회사의 요구 사항을 가장 효율적으로 충족하는 솔루션은 옵션 B입니다.

### 필요한 학습 내용

1. **AWS Global Accelerator**
   - Global Accelerator는 전 세계적으로 최적의 경로를 통해 트래픽을 전달하여 지연 시간을 최소화합니다.
   - 여러 리전 간의 빠른 장애 조치를 제공합니다.

2. **Network Load Balancer (NLB)**
   - NLB는 TCP 및 UDP 트래픽을 처리할 수 있는 고성능 로드 밸런서입니다.
   - ECS 서비스와 통합하여 데이터를 처리할 수 있습니다.

3. **Amazon Elastic Container Service (ECS)**
   - ECS는 컨테이너화된 애플리케이션을 관리할 수 있는 서비스입니다.
   - Fargate를 사용하여 서버를 관리하지 않고 컨테이너를 실행할 수 있습니다.

### 추가 학습 자료
- [AWS Global Accelerator 공식 문서](https://docs.aws.amazon.com/ko_kr/global-accelerator/latest/dg/what-is-global-accelerator.html)
- [Network Load Balancer 공식 문서](https://docs.aws.amazon.com/ko_kr/elasticloadbalancing/latest/network/introduction.html)
- [Amazon Elastic Container Service (ECS) 공식 문서](https://docs.aws.amazon.com/ko_kr/AmazonECS/latest/developerguide/Welcome.html)

이 자료들을 통해 Global Accelerator, NLB, ECS의 다양한 기능과 설정 방법을 이해하고, 특정 시나리오에서 최적의 솔루션을 선택하는 능력을 키울 수 있습니다.


# 410번
### 정답
B. Create the EBS volumes as encrypted volumes. Attach the EBS volumes to the EC2 instances.

### 해설
Amazon EBS 볼륨을 암호화된 볼륨으로 생성하면, 해당 볼륨에 기록되는 모든 데이터가 자동으로 암호화됩니다. 이는 EBS 볼륨의 데이터가 저장 중에 암호화되도록 보장하는 가장 직접적이고 확실한 방법입니다.

각 옵션을 자세히 살펴보면:

- **A. Create an IAM role that specifies EBS encryption. Attach the role to the EC2 instances.**
  -   용되지만, EBS 볼륨의 암호화를 직접적으로 설정하지는 않습니다.

- **B. Create the EBS volumes as encrypted volumes. Attach the EBS volumes to the EC2 instances.**
  - EBS 볼륨을 암호화된 볼륨으로 생성하면, 해당 볼륨에 기록되는 모든 데이터가 자동으로 암호화됩니다. 이는 데이터가 저장 중에 암호화되도록 보장하는 가장 직접적이고 확실한 방법입니다.

- **C. Create an EC2 instance tag that has a key of Encrypt and a value of True. Tag all instances that require encryption at the EBS level.**
  - 태그는 리소스를 식별하거나 관리하는 데 사용되지만, EBS 볼륨의 암호화를 직접적으로 설정하지는 않습니다.

- **D. Create an AWS Key Management Service (AWS KMS) key policy that enforces EBS encryption in the account. Ensure that the key policy is active.**
  - KMS 키 정책은 키 사용을 제어하는 데 사용되지만, EBS 볼륨의 암호화를 직접적으로 설정하지는 않습니다.

따라서, 회사의 요구 사항을 가장 효율적으로 충족하는 솔루션은 옵션 B입니다.

### 필요한 학습 내용

1. **Amazon EBS (Elastic Block Store)**
   - EBS는 EC2 인스턴스에 연결할 수 있는 블록 스토리지 서비스입니다.
   - EBS 볼륨을 암호화된 볼륨으로 생성하면, 해당 볼륨에 기록되는 모든 데이터가 자동으로 암호화됩니다.

2. **AWS Key Management Service (KMS)**
   - KMS는 암호화 키를 생성하고 관리할 수 있는 서비스입니다.
   - KMS 키를 사용하여 EBS 볼륨을 암호화할 수 있습니다.

3. **IAM 역할 (IAM Roles)**
   - IAM 역할은 AWS 리소스에 권한을 부여하는 데 사용됩니다.
   - EBS 볼륨의 암호화를 직접적으로 설정하지는 않습니다.

4. **EC2 인스턴스 태그**
   - 태그는 리소스를 식별하거나 관리하는 데 사용됩니다.
   - EBS 볼륨의 암호화를 직접적으로 설정하지는 않습니다.

### 추가 학습 자료
- [Amazon EBS 공식 문서](https://docs.aws.amazon.com/ko_kr/AWSEC2/latest/UserGuide/AmazonEBS.html)
- [AWS KMS 공식 문서](https://docs.aws.amazon.com/ko_kr/kms/latest/developerguide/overview.html)
- [IAM 역할 공식 문서](https://docs.aws.amazon.com/ko_kr/IAM/latest/UserGuide/id_roles.html)
- [EC2 인스턴스 태그 공식 문서](https://docs.aws.amazon.com/ko_kr/AWSEC2/latest/UserGuide/Using_Tags.html)

이 자료들을 통해 EBS, KMS, IAM 역할, EC2 인스턴스 태그의 다양한 기능과 설정 방법을 이해하고, 특정 시나리오에서 최적의 솔루션을 선택하는 능력을 키울 수 있습니다.



# 412번
### 정답
D. Use the S3 Block Public Access feature on the account level. Use AWS Organizations to create a service control policy (SCP) that prevents IAM users from changing the setting. Apply the SCP to the account.

### 해설
Amazon S3의 Block Public Access 기능을 사용하면 S3 버킷과 객체에 대한 공용 액세스를 차단할 수 있습니다. 이 설정을 계정 수준에서 적용하면, 계정 내 모든 S3 객체가 공용으로 노출되는 것을 방지할 수 있습니다. 또한, AWS Organizations의 서비스 제어 정책(SCP)을 사용하여 IAM 사용자가 이 설정을 변경하지 못하도록 할 수 있습니다. 이는 가장 효과적이고 관리 오버헤드가 적은 솔루션입니다.

각 옵션을 자세히 살펴보면:

- **A. Use Amazon GuardDuty to monitor S3 bucket policies. Create an automatic remediation action rule that uses an AWS Lambda function to remediate any change that makes the objects public.**
  - GuardDuty는 보안 위협을 모니터링하는 데 사용되며, S3 버킷 정책을 모니터링하는 데 적합하지 않습니다. 또한, Lambda 함수를 사용한 자동 수정은 복잡할 수 있습니다.

- **B. Use AWS Trusted Advisor to find publicly accessible S3 buckets. Configure email notifications in Trusted Advisor when a change is detected. Manually change the S3 bucket policy if it allows public access.**
  - Trusted Advisor는 공용으로 접근 가능한 S3 버킷을 찾는 데 유용하지만, 수동으로 변경하는 것은 관리 오버헤드가 큽니다.

- **C. Use AWS Resource Access Manager to find publicly accessible S3 buckets. Use Amazon Simple Notification Service (Amazon SNS) to invoke an AWS Lambda function when a change is detected. Deploy a Lambda function that programmatically remediates the change.**
  - Resource Access Manager는 주로 리소스 공유를 관리하는 데 사용됩니다. SNS와 Lambda를 사용한 자동 수정은 복잡할 수 있습니다.

- **D. Use the S3 Block Public Access feature on the account level. Use AWS Organizations to create a service control policy (SCP) that prevents IAM users from changing the setting. Apply the SCP to the account.**
  - S3 Block Public Access 기능을 계정 수준에서 사용하면 모든 S3 객체가 공용으로 노출되는 것을 방지할 수 있습니다. SCP를 사용하여 설정 변경을 방지하면 관리 오버헤드가 최소화됩니다.

따라서, 회사의 요구 사항을 가장 효율적으로 충족하는 솔루션은 옵션 D입니다.

### 필요한 학습 내용

1. **S3 Block Public Access**
   - S3 Block Public Access 기능을 사용하면 S3 버킷과 객체에 대한 공용 액세스를 차단할 수 있습니다.
   - 계정 수준에서 적용할 수 있습니다.

2. **AWS Organizations**
   - AWS Organizations는 여러 AWS 계정을 중앙에서 관리할 수 있는 서비스입니다.
   - 서비스 제어 정책(SCP)을 사용하여 특정 작업을 제한할 수 있습니다.

3. **IAM 정책**
   - IAM 정책은 특정 작업에 대한 권한을 부여하거나 거부할 수 있습니다.
   - SCP를 사용하여 IAM 사용자가 특정 설정을 변경하지 못하도록 할 수 있습니다.

### 추가 학습 자료
- [S3 Block Public Access 공식 문서](https://docs.aws.amazon.com/ko_kr/AmazonS3/latest/userguide/access-control-block-public-access.html)
- [AWS Organizations 공식 문서](https://docs.aws.amazon.com/ko_kr/organizations/latest/userguide/orgs_introduction.html)
- [IAM 정책 공식 문서](https://docs.aws.amazon.com/ko_kr/IAM/latest/UserGuide/access_policies.html)

이 자료들을 통해 S3 Block Public Access, AWS Organizations, IAM 정책의 다양한 기능과 설정 방법을 이해하고, 특정 시나리오에서 최적의 솔루션을 선택하는 능력을 키울 수 있습니다.

# 413번
### 정답
B. Configure the web instance to send email through Amazon Simple Email Service (Amazon SES).

### 해설
Amazon Simple Email Service (Amazon SES)는 대규모 이메일 전송을 위한 완전 관리형 서비스로, 이메일 전송의 복잡성을 줄이고 운영 오버헤드를 최소화할 수 있습니다. SES를 사용하면 이메일 전송 인프라를 관리할 필요가 없으며, 높은 신뢰성과 확장성을 제공합니다.

각 옵션을 자세히 살펴보면:

- **A. Create a separate application tier using EC2 instances dedicated to email processing.**
  - 별도의 EC2 인스턴스를 사용하여 이메일 처리를 전담하는 것은 가능하지만, 이는 추가적인 관리 오버헤드를 발생시킵니다.

- **B. Configure the web instance to send email through Amazon Simple Email Service (Amazon SES).**
  - Amazon SES는 이메일 전송을 위한 완전 관리형 서비스로, 이메일 전송의 복잡성을 줄이고 운영 오버헤드를 최소화할 수 있습니다. 이는 가장 적합한 솔루션입니다.

- **C. Configure the web instance to send email through Amazon Simple Notification Service (Amazon SNS).**
  - Amazon SNS는 주로 알림을 전송하는 데 사용되며, 이메일 전송을 위한 최적의 솔루션은 아닙니다.

- **D. Create a separate application tier using EC2 instances dedicated to email processing. Place the instances in an Auto Scaling group.**
  - 별도의 EC2 인스턴스를 사용하여 이메일 처리를 전담하는 것은 가능하지만, 이는 추가적인 관리 오버헤드를 발생시킵니다. Auto Scaling을 사용하더라도 SES를 사용하는 것이 더 적합합니다.

따라서, 회사의 요구 사항을 가장 효율적으로 충족하는 솔루션은 옵션 B입니다.

### 필요한 학습 내용

1. **Amazon Simple Email Service (SES)**
   - SES는 대규모 이메일 전송을 위한 완전 관리형 서비스입니다.
   - 높은 신뢰성과 확장성을 제공합니다.
   - 이메일 전송 인프라를 관리할 필요가 없습니다.

2. **Amazon Simple Notification Service (SNS)**
   - SNS는 주로 알림을 전송하는 데 사용됩니다.
   - 이메일 전송을 위한 최적의 솔루션은 아닙니다.

3. **EC2 인스턴스**
   - EC2 인스턴스를 사용하여 애플리케이션을 배포할 수 있습니다.
   - 별도의 인스턴스를 사용하여 이메일 처리를 전담하는 것은 추가적인 관리 오버헤드를 발생시킵니다.

### 추가 학습 자료
- [Amazon Simple Email Service (SES) 공식 문서](https://docs.aws.amazon.com/ko_kr/ses/latest/DeveloperGuide/Welcome.html)
- [Amazon Simple Notification Service (SNS) 공식 문서](https://docs.aws.amazon.com/ko_kr/sns/latest/dg/welcome.html)
- [Amazon EC2 공식 문서](https://docs.aws.amazon.com/ko_kr/AWSEC2/latest/UserGuide/concepts.html)

이 자료들을 통해 SES, SNS, EC2의 다양한 기능과 설정 방법을 이해하고, 특정 시나리오에서 최적의 솔루션을 선택하는 능력을 키울 수 있습니다.

# 416번
### 정답
B. Set up an Amazon CloudFront distribution.
D. Create a read replica for the RDS DB instance.

### 해설
웹 애플리케이션의 페이지 로드 속도를 개선하기 위해서는 정적 콘텐츠와 동적 콘텐츠 모두에 대한 최적화가 필요합니다. Amazon CloudFront는 전 세계적으로 콘텐츠를 캐시하여 정적 콘텐츠의 로드 시간을 줄일 수 있습니다. 또한, RDS DB 인스턴스에 대한 읽기 복제본을 생성하면 데이터베이스 읽기 작업을 분산시켜 데이터베이스 성능을 향상시킬 수 있습니다.

각 옵션을 자세히 살펴보면:

- **A. Configure an Amazon Redshift cluster.**
  - Amazon Redshift는 데이터 웨어하우징 솔루션으로, OLTP 데이터베이스 성능 문제를 해결하는 데 적합하지 않습니다.

- **B. Set up an Amazon CloudFront distribution.**
  - CloudFront는 전 세계적으로 콘텐츠를 캐시하여 정적 콘텐츠의 로드 시간을 줄일 수 있습니다. 이는 웹 애플리케이션의 페이지 로드 속도를 개선하는 데 도움이 됩니다.

- **C. Host the dynamic web content in Amazon S3.**
  - 동적 웹 콘텐츠는 서버 측에서 생성되므로 S3에 호스팅하는 것은 적절하지 않습니다. 정적 콘텐츠는 S3에 호스팅할 수 있지만, 동적 콘텐츠는 서버 측에서 처리해야 합니다.

- **D. Create a read replica for the RDS DB instance.**
  - RDS DB 인스턴스에 대한 읽기 복제본을 생성하면 데이터베이스 읽기 작업을 분산시켜 데이터베이스 성능을 향상시킬 수 있습니다. 이는 OLTP 데이터베이스의 성능 문제를 해결하는 데 도움이 됩니다.

- **E. Configure a Multi-AZ deployment for the RDS DB instance.**
  - Multi-AZ 배포는 고가용성을 제공하지만, 데이터베이스 성능을 직접적으로 향상시키지는 않습니다.

따라서, 회사의 요구 사항을 가장 효율적으로 충족하는 솔루션은 옵션 B와 D입니다.

### 필요한 학습 내용

1. **Amazon CloudFront**
   - CloudFront는 전 세계적으로 콘텐츠를 캐시하여 정적 콘텐츠의 로드 시간을 줄일 수 있는 콘텐츠 전송 네트워크(CDN)입니다.
   - 웹 애플리케이션의 페이지 로드 속도를 개선하는 데 도움이 됩니다.

2. **Amazon RDS 읽기 복제본**
   - RDS 읽기 복제본은 데이터베이스 읽기 작업을 분산시켜 데이터베이스 성능을 향상시킬 수 있습니다.
   - OLTP 데이터베이스의 성능 문제를 해결하는 데 도움이 됩니다.

3. **Amazon Redshift**
   - Redshift는 데이터 웨어하우징 솔루션으로, OLTP 데이터베이스 성능 문제를 해결하는 데 적합하지 않습니다.

4. **Amazon S3**
   - S3는 객체 스토리지 서비스로, 정적 콘텐츠를 호스팅하는 데 적합합니다.
   - 동적 콘텐츠는 서버 측에서 처리해야 합니다.

5. **Amazon RDS Multi-AZ 배포**
   - Multi-AZ 배포는 고가용성을 제공하지만, 데이터베이스 성능을 직접적으로 향상시키지는 않습니다.

### 추가 학습 자료
- [Amazon CloudFront 공식 문서](https://docs.aws.amazon.com/ko_kr/AmazonCloudFront/latest/DeveloperGuide/Introduction.html)
- [Amazon RDS 읽기 복제본 공식 문서](https://docs.aws.amazon.com/ko_kr/AmazonRDS/latest/UserGuide/USER_ReadRepl.html)
- [Amazon Redshift 공식 문서](https://docs.aws.amazon.com/ko_kr/redshift/latest/mgmt/welcome.html)
- [Amazon S3 공식 문서](https://docs.aws.amazon.com/ko_kr/AmazonS3/latest/userguide/Welcome.html)
- [Amazon RDS Multi-AZ 배포 공식 문서](https://docs.aws.amazon.com/ko_kr/AmazonRDS/latest/UserGuide/Concepts.MultiAZ.html)

이 자료들을 통해 CloudFront, RDS 읽기 복제본, Redshift, S3, RDS Multi-AZ 배포의 다양한 기능과 설정 방법을 이해하고, 특정 시나리오에서 최적의 솔루션을 선택하는 능력을 키울 수 있습니다.


# 417번 
### 정답
C. Purchase a Compute Savings Plan. Optimize the Lambda functions’ duration and memory usage, the number of invocations, and the amount of data that is transferred. Connect the Lambda functions to the private subnet that contains the EC2 instances.

### 해설
Compute Savings Plan은 EC2 인스턴스와 Lambda 함수 모두에 대해 비용 절감을 제공합니다. Lambda 함수의 실행 시간, 메모리 사용량, 호출 횟수 및 데이터 전송량을 최적화하면 비용을 더욱 절감할 수 있습니다. Lambda 함수를 EC2 인스턴스가 있는 프라이빗 서브넷에 연결하면 네트워크 지연 시간을 최소화할 수 있습니다.

각 옵션을 자세히 살펴보면:

- **A. Purchase an EC2 Instance Savings Plan. Optimize the Lambda functions’ duration and memory usage and the number of invocations. Connect the Lambda functions to the private subnet that contains the EC2 instances.**
  - EC2 Instance Savings Plan은 EC2 인스턴스에 대해서만 비용 절감을 제공합니다. Lambda 함수에 대한 비용 절감은 제공하지 않습니다.

- **B. Purchase an EC2 Instance Savings Plan. Optimize the Lambda functions' duration and memory usage, the number of invocations, and the amount of data that is transferred. Connect the Lambda functions to a public subnet in the same VPC where the EC2 instances run.**
  - Lambda 함수를 퍼블릭 서브넷에 연결하면 보안 문제가 발생할 수 있으며, EC2 Instance Savings Plan은 Lambda 함수에 대한 비용 절감을 제공하지 않습니다.

- **C. Purchase a Compute Savings Plan. Optimize the Lambda functions’ duration and memory usage, the number of invocations, and the amount of data that is transferred. Connect the Lambda functions to the private subnet that contains the EC2 instances.**
  - Compute Savings Plan은 EC2 인스턴스와 Lambda 함수 모두에 대해 비용 절감을 제공합니다. Lambda 함수를 프라이빗 서브넷에 연결하면 네트워크 지연 시간을 최소화할 수 있습니다.

- **D. Purchase a Compute Savings Plan. Optimize the Lambda functions’ duration and memory usage, the number of invocations, and the amount of data that is transferred. Keep the Lambda functions in the Lambda service VPC.**
  - Lambda 함수를 Lambda 서비스 VPC에 유지하면 네트워크 지연 시간이 증가할 수 있습니다.

* VPC 간 통신은 지연시간과 비용이 증가할 수 있음

# 418번 
### 정답
B. Add the development account as a principal in the trust policy of the role in the production account.

### 해설
원칙적으로 최소 권한 원칙을 준수하면서 두 개의 AWS 계정(개발 계정과 프로덕션 계정)에서 S3 버킷에 접근할 수 있도록 하기 위해서는, 개발 계정의 사용자들이 프로덕션 계정의 IAM 역할을 가정할 수 있도록 설정해야 합니다. 이를 위해서는 프로덕션 계정의 역할 신뢰 정책에 개발 계정을 주체로 추가해야 합니다.

각 옵션을 자세히 살펴보면:

- **A. Attach the Administrator Access policy to the development account users.**
  - 관리자 액세스 정책을 개발 계정 사용자에게 부여하면 과도한 권한이 부여되어 최소 권한 원칙을 위반하게 됩니다.

- **B. Add the development account as a principal in the trust policy of the role in the production account.**
  - 개발 계정을 프로덕션 계정의 역할 신뢰 정책에 주체로 추가하면, 개발 계정의 사용자들이 프로덕션 계정의 역할을 가정할 수 있게 되어 최소 권한 원칙을 준수하면서 접근을 허용할 수 있습니다.

- **C. Turn off the S3 Block Public Access feature on the S3 bucket in the production account.**
  - S3 퍼블릭 액세스 차단 기능을 끄는 것은 보안 위험을 초래할 수 있으며, 최소 권한 원칙을 준수하지 않습니다.

- **D. Create a user in the production account with unique credentials for each team member.**
  - 프로덕션 계정에 각 팀원을 위한 별도의 사용자를 생성하는 것은 관리 오버헤드가 증가하며, 최소 권한 원칙을 준수하지 않을 수 있습니다.

따라서, 회사의 요구 사항을 가장 효율적으로 충족하는 솔루션은 옵션 B입니다.

### 필요한 학습 내용

1. **IAM 역할 신뢰 정책**
   - IAM 역할 신뢰 정책은 어떤 주체(사용자, 그룹, 계정 등)가 역할을 가정할 수 있는지를 정의합니다.
   - 다른 계정의 사용자가 역할을 가정할 수 있도록 설정할 수 있습니다.

2. **최소 권한 원칙**
   - 최소 권한 원칙은 사용자가 작업을 수행하는 데 필요한 최소한의 권한만 부여하는 보안 원칙입니다.
   - 과도한 권한 부여를 방지하여 보안을 강화합니다.

### 추가 학습 자료
- [IAM 역할 신뢰 정책 공식 문서](https://docs.aws.amazon.com/ko_kr/IAM/latest/UserGuide/id_roles_manage_modify.html#roles-modify_trust-policy)
- [최소 권한 원칙 공식 문서](https://docs.aws.amazon.com/ko_kr/IAM/latest/UserGuide/best-practices.html#grant-least-privilege)

이 자료들을 통해 IAM 역할 신뢰 정책과 최소 권한 원칙의 다양한 기능과 설정 방법을 이해하고, 특정 시나리오에서 최적의 솔루션을 선택하는 능력을 키울 수 있습니다.


# 419번
### 정답
A. In the Amazon EC2 console, select the EBS encryption account attribute and define a default encryption key.
C. Create an SCP. Attach the SCP to the root organizational unit (OU). Define the SCP to deny the ec2:CreateVolume action when the ec2:Encrypted condition equals false.

### 해설
회사는 모든 데이터가 암호화된 상태로 저장되도록 보장하고, 새로운 EBS 볼륨이 암호화되지 않은 상태로 생성되지 않도록 해야 합니다. 이를 위해 기본 EBS 암호화 설정을 사용하고, 서비스 제어 정책(SCP)을 통해 암호화되지 않은 EBS 볼륨 생성을 방지할 수 있습니다.

각 옵션을 자세히 살펴보면:

- **A. In the Amazon EC2 console, select the EBS encryption account attribute and define a default encryption key.**
  - Amazon EC2 콘솔에서 EBS 암호화 계정 속성을 선택하고 기본 암호화 키를 정의하면, 새로 생성되는 모든 EBS 볼륨이 기본적으로 암호화됩니다. 이는 직원들에게 최소한의 영향을 미치면서 요구 사항을 충족합니다.

- **B. Create an IAM permission boundary. Attach the permission boundary to the root organizational unit (OU). Define the boundary to deny the ec2:CreateVolume action when the ec2:Encrypted condition equals false.**
  - IAM 권한 경계는 특정 사용자나 역할에 대한 권한을 제한하는 데 사용되며, 조직 전체에 적용하기에는 적합하지 않습니다.

- **C. Create an SCP. Attach the SCP to the root organizational unit (OU). Define the SCP to deny the ec2:CreateVolume action when the ec2:Encrypted condition equals false.**
  - SCP를 사용하여 조직 전체에 정책을 적용할 수 있습니다. ec2:CreateVolume 작업을 ec2:Encrypted 조건이 false일 때 거부하도록 정의하면, 암호화되지 않은 EBS 볼륨 생성을 방지할 수 있습니다.

- **D. Update the IAM policies for each account to deny the ec2:CreateVolume action when the ec2:Encrypted condition equals false.**
  - 각 계정의 IAM 정책을 업데이트하는 것은 관리 오버헤드가 크며, 조직 전체에 일관된 정책을 적용하기 어렵습니다.

- **E. In the Organizations management account, specify the Default EBS volume encryption setting.**
  - AWS Organizations 관리 계정에서 기본 EBS 볼륨 암호화 설정을 지정하는 옵션은 현재 존재하지 않습니다.

따라서, 회사의 요구 사항을 가장 효율적으로 충족하는 솔루션은 옵션 A와 C입니다.

### 필요한 학습 내용

1. **Amazon EC2 기본 EBS 암호화 설정**
   - 기본 EBS 암호화 설정을 사용하면 새로 생성되는 모든 EBS 볼륨이 자동으로 암호화됩니다.
   - 기본 암호화 키를 정의할 수 있습니다.

2. **서비스 제어 정책 (SCP)**
   - SCP는 AWS Organizations에서 조직 전체에 적용할 수 있는 정책입니다.
   - 특정 작업을 조건부로 허용하거나 거부할 수 있습니다.

### 추가 학습 자료
- [Amazon EC2 기본 EBS 암호화 공식 문서](https://docs.aws.amazon.com/ko_kr/AWSEC2/latest/UserGuide/EBSEncryption.html)
- [AWS Organizations 서비스 제어 정책 (SCP) 공식 문서](https://docs.aws.amazon.com/ko_kr/organizations/latest/userguide/orgs_manage_policies_scp.html)

이 자료들을 통해 기본 EBS 암호화 설정과 SCP의 다양한 기능과 설정 방법을 이해하고, 특정 시나리오에서 최적의 솔루션을 선택하는 능력을 키울 수 있습니다.


# 420번
### 정답
D. Use an Amazon RDS Multi-AZ DB cluster deployment. Point the read workload to the reader endpoint.

### 해설
Amazon RDS Multi-AZ DB 클러스터 배포는 고가용성과 자동 장애 조치 기능을 제공하며, 읽기 작업을 오프로드할 수 있는 리더 엔드포인트를 제공합니다. 이는 고가용성을 보장하고, 읽기 작업을 기본 인스턴스에서 분리하여 성능을 최적화할 수 있습니다. 또한, 리더 엔드포인트를 사용하면 읽기 작업을 자동으로 분산시킬 수 있어 관리 오버헤드가 줄어듭니다.

각 옵션을 자세히 살펴보면:

- **A. Use an Amazon RDS Multi-AZ DB instance deployment. Create one read replica and point the read workload to the read replica.**
  - Multi-AZ DB 인스턴스 배포는 고가용성을 제공하지만, 읽기 복제본을 추가로 생성해야 하므로 비용이 증가할 수 있습니다.

- **B. Use an Amazon RDS Multi-AZ DB cluster deployment. Create two read replicas and point the read workload to the read replicas.**
  - Multi-AZ DB 클러스터 배포는 고가용성을 제공하지만, 두 개의 읽기 복제본을 추가로 생성하면 비용이 증가할 수 있습니다.

- **C. Use an Amazon RDS Multi-AZ DB instance deployment. Point the read workload to the secondary instances in the Multi-AZ pair.**
  - Multi-AZ DB 인스턴스 배포에서 보조 인스턴스는 장애 조치 용도로만 사용되며, 읽기 작업을 처리할 수 없습니다.

- **D. Use an Amazon RDS Multi-AZ DB cluster deployment. Point the read workload to the reader endpoint.**
  - Multi-AZ DB 클러스터 배포는 고가용성과 자동 장애 조치 기능을 제공하며, 리더 엔드포인트를 사용하여 읽기 작업을 오프로드할 수 있습니다. 이는 비용을 최소화하면서 요구 사항을 충족하는 최적의 솔루션입니다.

따라서, 회사의 요구 사항을 가장 효율적으로 충족하는 솔루션은 옵션 D입니다.

### 필요한 학습 내용

1. **Amazon RDS Multi-AZ DB 클러스터**
   - Multi-AZ DB 클러스터는 고가용성과 자동 장애 조치 기능을 제공하는 RDS 배포 옵션입니다.
   - 리더 엔드포인트를 사용하여 읽기 작업을 오프로드할 수 있습니다.

2. **Amazon RDS 읽기 복제본**
   - 읽기 복제본은 데이터베이스의 읽기 작업을 분산시켜 성능을 최적화할 수 있습니다.
   - 추가 비용이 발생할 수 있습니다.

3. **Amazon RDS Multi-AZ DB 인스턴스**
   - Multi-AZ DB 인스턴스 배포는 고가용성을 제공하지만, 보조 인스턴스는 장애 조치 용도로만 사용됩니다.

### 추가 학습 자료
- [Amazon RDS Multi-AZ DB 클러스터 공식 문서](https://docs.aws.amazon.com/ko_kr/AmazonRDS/latest/UserGuide/multi-az-db-clusters.html)
- [Amazon RDS 읽기 복제본 공식 문서](https://docs.aws.amazon.com/ko_kr/AmazonRDS/latest/UserGuide/USER_ReadRepl.html)
- [Amazon RDS Multi-AZ DB 인스턴스 공식 문서](https://docs.aws.amazon.com/ko_kr/AmazonRDS/latest/UserGuide/Concepts.MultiAZ.html)

이 자료들을 통해 Multi-AZ DB 클러스터, 읽기 복제본, Multi-AZ DB 인스턴스의 다양한 기능과 설정 방법을 이해하고, 특정 시나리오에서 최적의 솔루션을 선택하는 능력을 키울 수 있습니다.

# 421번
**정답은 C**입니다.

### 설명:

AWS에서 제공하는 **AWS Transfer Family**는 **서버리스 SFTP 서비스**를 제공하며, 이 서비스는 SFTP 프로토콜을 사용하여 데이터를 전송하는 서버를 관리할 필요 없이 AWS S3, EFS, 또는 EBS와 같은 저장소와 통합할 수 있습니다. 요구 사항에 맞는 솔루션을 고려하면 다음과 같습니다:

- **고성능과 보안**:
  - **S3**는 고성능과 높은 **IOPS**를 제공할 수 있으며, **암호화**와 **세밀한 권한 관리**(IAM 역할과 정책을 통해)를 지원합니다. 이로 인해 고성능 스토리지와 보안 요구 사항을 모두 충족할 수 있습니다.
  
- **서버리스 옵션**:
  - **AWS Transfer Family** 서비스는 **서버리스**로 제공되어, EC2 인스턴스를 관리하지 않아도 됩니다. 이 서비스는 필요한 만큼 자동으로 스케일링되며, 높은 가용성과 안정성을 보장합니다.

- **사용자 권한 관리**:
  - **IAM** 역할과 정책을 사용하여 **사용자 권한**을 세밀하게 제어할 수 있습니다. AWS Transfer Family에서는 **S3** 버킷에 대해 접근을 제어하고, 필요한 경우 액세스 로그를 관리할 수 있습니다.

### 각 옵션에 대한 분석:
- **A**: Amazon EBS는 고성능을 제공하지만, **EBS는 EC2 인스턴스와 결합되어 있어 서버리스 솔루션이 아니**므로 요구 사항에 맞지 않습니다. 또한, EBS는 기본적으로 **단일 EC2 인스턴스**에서만 사용할 수 있어 고가용성을 제공하기 어렵습니다.
  
- **B**: Amazon EFS는 높은 IOPS와 성능을 제공하지만, **EFS는 EC2 인스턴스에서 사용할 때 주로 사용되며, AWS Transfer Family에서 EFS를 사용할 경우 추가 구성이 필요**할 수 있습니다. 이 경우에도 **서버리스 요구 사항**을 충족하는 데는 적합하지 않습니다.

- **C**: **S3**는 고성능과 보안을 제공하며, **AWS Transfer Family**와 잘 통합되어, 서버리스로 SFTP 서비스를 제공할 수 있습니다. 또한, **S3 버킷**과 **IAM** 역할을 사용하여 사용자의 액세스를 세밀하게 제어할 수 있습니다.

- **D**: S3 버킷을 VPC 엔드포인트와 연결하는 것은 내부 통신에 적합하지만, **인터넷에 연결된 SFTP 서비스에 대한 요구 사항**에는 맞지 않습니다. 이 솔루션은 **SFTP가 인터넷에 노출되지 않는 경우**에 유용합니다.

### 결론:
**C**는 고성능, 보안, 사용자의 권한 관리와 서버리스 옵션을 모두 제공하는 가장 적합한 솔루션입니다. **AWS Transfer Family**와 **S3**를 결합하면 요구 사항을 완전히 충족할 수 있습니다.
# 422번
### 정답
D. Direct the requests from the API into an Amazon Simple Queue Service (Amazon SQS) queue. Deploy the models as Amazon Elastic Container Service (Amazon ECS) services that read from the queue. Enable AWS Auto Scaling on Amazon ECS for both the cluster and copies of the service based on the queue size.

### 해설
이 문제는 비정기적인 사용 패턴을 가진 머신 러닝 모델을 효율적으로 배포하고 확장하는 방법을 평가합니다. Amazon SQS와 Amazon ECS를 사용하여 비동기 API 요청을 처리하고, Auto Scaling을 통해 클러스터와 서비스 인스턴스를 동적으로 확장하는 것이 가장 적합한 솔루션입니다.

각 옵션을 자세히 살펴보면:

- **A. Direct the requests from the API to a Network Load Balancer (NLB). Deploy the models as AWS Lambda functions that are invoked by the NLB.**
  - Lambda 함수는 짧은 실행 시간에 적합하며, 1GB의 모델 데이터를 메모리에 로드하는 작업에는 적합하지 않습니다. 또한, NLB는 비동기 요청 처리에 적합하지 않습니다.

- **B. Direct the requests from the API to an Application Load Balancer (ALB). Deploy the models as Amazon Elastic Container Service (Amazon ECS) services that read from an Amazon Simple Queue Service (Amazon SQS) queue. Use AWS App Mesh to scale the instances of the ECS cluster based on the SQS queue size.**
  - ALB와 ECS를 사용하는 것은 적절하지만, AWS App Mesh는 서비스 메쉬를 관리하는 데 사용되며, Auto Scaling을 직접적으로 지원하지 않습니다.

- **C. Direct the requests from the API into an Amazon Simple Queue Service (Amazon SQS) queue. Deploy the models as AWS Lambda functions that are invoked by SQS events. Use AWS Auto Scaling to increase the number of vCPUs for the Lambda functions based on the SQS queue size.**
  - Lambda 함수는 짧은 실행 시간에 적합하며, 1GB의 모델 데이터를 메모리에 로드하는 작업에는 적합하지 않습니다. 또한, Lambda 함수는 vCPU를 직접적으로 확장할 수 없습니다.

- **D. Direct the requests from the API into an Amazon Simple Queue Service (Amazon SQS) queue. Deploy the models as Amazon Elastic Container Service (Amazon ECS) services that read from the queue. Enable AWS Auto Scaling on Amazon ECS for both the cluster and copies of the service based on the queue size.**
  - SQS 큐를 사용하여 비동기 요청을 처리하고, ECS 서비스를 사용하여 모델을 배포하는 것은 적절한 접근 방식입니다. Auto Scaling을 통해 클러스터와 서비스 인스턴스를 동적으로 확장할 수 있어 비정기적인 사용 패턴을 효율적으로 처리할 수 있습니다.

따라서, 회사의 요구 사항을 가장 효율적으로 충족하는 솔루션은 옵션 D입니다.

### 필요한 학습 내용

1. **Amazon Simple Queue Service (SQS)**
   - SQS는 메시지를 큐에 저장하고, 이를 소비자에게 전달하는 메시징 서비스입니다.
   - 비동기 요청을 처리하는 데 적합합니다.

2. **Amazon Elastic Container Service (ECS)**
   - ECS는 컨테이너 오케스트레이션 서비스로, 애플리케이션을 컨테이너로 배포하고 관리할 수 있습니다.
   - Auto Scaling을 통해 클러스터와 서비스 인스턴스를 동적으로 확장할 수 있습니다.

3. **AWS Auto Scaling**
   - Auto Scaling은 애플리케이션의 수요에 따라 리소스를 자동으로 확장하거나 축소할 수 있는 서비스입니다.
   - ECS 클러스터와 서비스 인스턴스를 동적으로 확장할 수 있습니다.

4. **AWS Lambda**
   - Lambda는 서버리스 컴퓨팅을 제공하는 서비스로, 특정 이벤트에 따라 코드를 실행할 수 있습니다.
   - 짧은 실행 시간에 적합하며, 1GB의 모델 데이터를 메모리에 로드하는 작업에는 적합하지 않습니다.

5. **Network Load Balancer (NLB) 및 Application Load Balancer (ALB)**
   - NLB는 TCP/UDP 트래픽을 처리하는 로드 밸런서입니다.
   - ALB는 HTTP/HTTPS 트래픽을 처리하는 로드 밸런서로, 비동기 요청 처리에는 적합하지 않습니다.

### 추가 학습 자료
- [Amazon SQS 공식 문서](https://docs.aws.amazon.com/ko_kr/AWSSimpleQueueService/latest/SQSDeveloperGuide/welcome.html)
- [Amazon ECS 공식 문서](https://docs.aws.amazon.com/ko_kr/AmazonECS/latest/developerguide/Welcome.html)
- [AWS Auto Scaling 공식 문서](https://docs.aws.amazon.com/ko_kr/autoscaling/latest/userguide/WhatIsAutoScaling.html)
- [AWS Lambda 공식 문서](https://docs.aws.amazon.com/ko_kr/lambda/latest/dg/welcome.html)
- [Network Load Balancer (NLB) 공식 문서](https://docs.aws.amazon.com/ko_kr/elasticloadbalancing/latest/network/introduction.html)
- [Application Load Balancer (ALB) 공식 문서](https://docs.aws.amazon.com/ko_kr/elasticloadbalancing/latest/application/introduction.html)

이 자료들을 통해 SQS, ECS, Auto Scaling, Lambda, NLB, ALB의 다양한 기능과 설정 방법을 이해하고, 특정 시나리오에서 최적의 솔루션을 선택하는 능력을 키울 수 있습니다.


# 423번
### 정답
A. Role
B. Group

### 해설
IAM 정책은 사용자, 그룹, 역할과 같은 IAM 주체(principal)에 연결할 수 있습니다. 이 정책은 특정 작업(`ssm:ListDocuments` 및 `ssm:GetDocument`)에 대한 권한을 부여합니다. IAM 정책은 리소스 기반 정책이 아니므로, Amazon ECS 리소스나 Amazon EC2 리소스에 직접 연결할 수 없습니다.

각 옵션을 자세히 살펴보면:

- **A. Role**
  - IAM 역할은 특정 작업을 수행할 수 있는 권한을 부여받은 주체입니다. 이 정책을 역할에 연결할 수 있습니다.

- **B. Group**
  - IAM 그룹은 여러 사용자를 포함할 수 있는 주체입니다. 이 정책을 그룹에 연결할 수 있습니다.

- **C. Organization**
  - IAM 정책은 AWS Organizations의 조직 전체에 직접 연결할 수 없습니다. 조직 단위(OU)나 계정 수준에서 SCP(서비스 제어 정책)를 사용할 수 있지만, 이는 다른 유형의 정책입니다.

- **D. Amazon Elastic Container Service (Amazon ECS) resource**
  - IAM 정책은 Amazon ECS 리소스에 직접 연결할 수 없습니다. 대신, ECS 작업 정의에서 IAM 역할을 사용하여 권한을 부여할 수 있습니다.

- **E. Amazon EC2 resource**
  - IAM 정책은 Amazon EC2 인스턴스에 직접 연결할 수 없습니다. 대신, EC2 인스턴스 프로파일을 사용하여 IAM 역할을 연결할 수 있습니다.

따라서, 이 정책을 연결할 수 있는 IAM 주체는 옵션 A와 B입니다.

### 필요한 학습 내용

1. **IAM 정책**
   - IAM 정책은 사용자, 그룹, 역할과 같은 IAM 주체에 연결할 수 있습니다.
   - 특정 작업에 대한 권한을 부여할 수 있습니다.

2. **IAM 역할**
   - IAM 역할은 특정 작업을 수행할 수 있는 권한을 부여받은 주체입니다.
   - 다른 AWS 서비스나 사용자에게 권한을 위임할 수 있습니다.

3. **IAM 그룹**
   - IAM 그룹은 여러 사용자를 포함할 수 있는 주체입니다.
   - 그룹에 연결된 정책은 그룹의 모든 사용자에게 적용됩니다.

4. **AWS Organizations**
   - AWS Organizations는 여러 AWS 계정을 중앙에서 관리할 수 있는 서비스입니다.
   - 서비스 제어 정책(SCP)을 사용하여 조직 단위(OU)나 계정 수준에서 권한을 제어할 수 있습니다.

5. **Amazon ECS 및 Amazon EC2**
   - ECS 작업 정의에서 IAM 역할을 사용하여 권한을 부여할 수 있습니다.
   - EC2 인스턴스 프로파일을 사용하여 IAM 역할을 연결할 수 있습니다.

### 추가 학습 자료
- [IAM 정책 공식 문서](https://docs.aws.amazon.com/ko_kr/IAM/latest/UserGuide/access_policies.html)
- [IAM 역할 공식 문서](https://docs.aws.amazon.com/ko_kr/IAM/latest/UserGuide/id_roles.html)
- [IAM 그룹 공식 문서](https://docs.aws.amazon.com/ko_kr/IAM/latest/UserGuide/id_groups.html)
- [AWS Organizations 공식 문서](https://docs.aws.amazon.com/ko_kr/organizations/latest/userguide/orgs_introduction.html)
- [Amazon ECS 공식 문서](https://docs.aws.amazon.com/ko_kr/AmazonECS/latest/developerguide/Welcome.html)
- [Amazon EC2 공식 문서](https://docs.aws.amazon.com/ko_kr/AWSEC2/latest/UserGuide/concepts.html)

이 자료들을 통해 IAM 정책, 역할, 그룹, AWS Organizations, Amazon ECS, Amazon EC2의 다양한 기능과 설정 방법을 이해하고, 특정 시나리오에서 최적의 솔루션을 선택하는 능력을 키울 수 있습니다.


# 426번
### 정답
A. Use AWS DataSync to move the existing data to Amazon S3. Use AWS CloudTrail to log data events.

### 해설
회사는 의료 애플리케이션의 데이터를 저장해야 하며, 데이터가 자주 변경됩니다. 새로운 규정에 따라 저장된 데이터의 모든 수준에서 감사 액세스가 필요합니다. AWS로 데이터를 안전하게 마이그레이션하고, 감사 요구 사항을 충족해야 합니다.

각 옵션을 자세히 살펴보면:

- **A. Use AWS DataSync to move the existing data to Amazon S3. Use AWS CloudTrail to log data events.**
  - AWS DataSync는 데이터를 AWS로 안전하게 전송하는 데 사용됩니다. Amazon S3는 데이터를 저장하는 데 적합하며, AWS CloudTrail을 사용하여 데이터 이벤트를 로깅하면 감사 요구 사항을 충족할 수 있습니다.

- **B. Use AWS Snowcone to move the existing data to Amazon S3. Use AWS CloudTrail to log management events.**
  - AWS Snowcone은 소규모 데이터 전송에 적합하며, 대규모 데이터 전송에는 적합하지 않습니다. 또한, 관리 이벤트만 로깅하는 것은 감사 요구 사항을 충족하지 못합니다.

- **C. Use Amazon S3 Transfer Acceleration to move the existing data to Amazon S3. Use AWS CloudTrail to log data events.**
  - Amazon S3 Transfer Acceleration은 데이터 전송 속도를 높이는 데 사용되지만, DataSync가 더 적합한 솔루션입니다. CloudTrail을 사용하여 데이터 이벤트를 로깅하는 것은 적절합니다.

- **D. Use AWS Storage Gateway to move the existing data to Amazon S3. Use AWS CloudTrail to log management events.**
  - AWS Storage Gateway는 온프레미스 데이터를 AWS로 이동하는 데 사용될 수 있지만, DataSync가 더 적합한 솔루션입니다. 또한, 관리 이벤트만 로깅하는 것은 감사 요구 사항을 충족하지 못합니다.

따라서, 회사의 요구 사항을 가장 효율적으로 충족하는 솔루션은 옵션 A입니다.

### 필요한 학습 내용

1. **AWS DataSync**
   - DataSync는 데이터를 AWS로 안전하게 전송하는 데 사용됩니다.
   - 대규모 데이터 전송에 적합합니다.

2. **Amazon S3**
   - S3는 객체 스토리지 서비스로, 데이터를 안전하게 저장할 수 있습니다.
   - 데이터 이벤트를 로깅할 수 있습니다.

3. **AWS CloudTrail**
   - CloudTrail은 AWS 계정의 API 호출 및 관련 이벤트를 로깅하는 서비스입니다.
   - 데이터 이벤트와 관리 이벤트를 로깅할 수 있습니다.

4. **AWS Snowcone**
   - Snowcone은 소규모 데이터 전송에 적합한 장치입니다.
   - 대규모 데이터 전송에는 적합하지 않습니다.

5. **Amazon S3 Transfer Acceleration**
   - Transfer Acceleration은 데이터 전송 속도를 높이는 데 사용됩니다.
   - DataSync가 더 적합한 솔루션입니다.

6. **AWS Storage Gateway**
   - Storage Gateway는 온프레미스 데이터를 AWS로 이동하는 데 사용될 수 있습니다.
   - DataSync가 더 적합한 솔루션입니다.

### 추가 학습 자료
- [AWS DataSync 공식 문서](https://docs.aws.amazon.com/ko_kr/datasync/latest/userguide/what-is-datasync.html)
- [Amazon S3 공식 문서](https://docs.aws.amazon.com/ko_kr/AmazonS3/latest/userguide/Welcome.html)
- [AWS CloudTrail 공식 문서](https://docs.aws.amazon.com/ko_kr/awscloudtrail/latest/userguide/cloudtrail-user-guide.html)
- [AWS Snowcone 공식 문서](https://docs.aws.amazon.com/ko_kr/snowcone/latest/developer-guide/what-is-snowcone.html)
- [Amazon S3 Transfer Acceleration 공식 문서](https://docs.aws.amazon.com/ko_kr/AmazonS3/latest/dev/transfer-acceleration.html)
- [AWS Storage Gateway 공식 문서](https://docs.aws.amazon.com/ko_kr/storagegateway/latest/userguide/WhatIsStorageGateway.html)

이 자료들을 통해 DataSync, S3, CloudTrail, Snowcone, Transfer Acceleration, Storage Gateway의 다양한 기능과 설정 방법을 이해하고, 특정 시나리오에서 최적의 솔루션을 선택하는 능력을 키울 수 있습니다.

# 427번
**정답은 B**입니다.

### 이유:

이 요구 사항은 **Java 애플리케이션**을 **Apache Tomcat**에 배포하고, **MySQL 데이터베이스**와 함께 **고가용성**을 보장해야 합니다. 각 옵션을 살펴보겠습니다:

1. **A. Deploy the application in AWS Lambda. Configure an Amazon API Gateway API to connect with the Lambda functions.**
   - AWS Lambda는 **서버리스 컴퓨팅** 서비스를 제공하며, Java 애플리케이션을 실행하는 데는 적합하지 않습니다. 이 서비스는 **연속적인 연결이 필요한 Apache Tomcat** 기반의 애플리케이션에는 적합하지 않습니다.
   - 또한, **MySQL 데이터베이스**와의 연동을 위해서는 Lambda 함수에서 관리하는 연결이 불안정할 수 있으며, **상태가 있는 애플리케이션**을 관리하기에는 부적합합니다.

2. **B. Deploy the application by using AWS Elastic Beanstalk. Configure a load-balanced environment and a rolling deployment policy.**
   - **Elastic Beanstalk**는 **애플리케이션 배포 및 관리**를 단순화하는 **서비스**입니다. Java 애플리케이션을 **Apache Tomcat** 환경에서 쉽게 배포할 수 있습니다.
   - **로드 밸런싱**과 **오토 스케일링**이 기본적으로 제공되어, **고가용성**을 보장할 수 있습니다. 또한, **롤링 배포** 정책을 설정하여 배포 중에도 서비스가 중단되지 않도록 할 수 있습니다.
   - **MySQL**은 **RDS (Relational Database Service)** 또는 다른 관리형 데이터베이스로 별도로 구성하여 고가용성을 제공할 수 있습니다.

3. **C. Migrate the database to Amazon ElastiCache. Configure the ElastiCache security group to allow access from the application.**
   - **ElastiCache**는 **캐시 서비스**로, **MySQL**을 대체할 수 없습니다. ElastiCache는 **읽기 성능 향상**을 위한 캐시 계층으로 사용되지만, **MySQL**은 데이터 저장을 위한 데이터베이스입니다.
   - 따라서 이 옵션은 요구 사항을 충족하지 않습니다.

4. **D. Launch an Amazon EC2 instance. Install a MySQL server on the EC2 instance. Configure the application on the server. Create an AMI. Use the AMI to create a launch template with an Auto Scaling group.**
   - 이 방법은 **EC2 인스턴스를 관리**하고 **MySQL 서버를 수동으로 설정**하는 방식입니다. 그러나 **Elastic Beanstalk**를 사용하면 배포, 관리 및 확장 작업을 훨씬 간단하게 처리할 수 있습니다.
   - **Auto Scaling**과 **AMI**를 사용하여 고가용성을 구현할 수 있지만, **Elastic Beanstalk**를 사용하는 것이 관리 측면에서 훨씬 효율적입니다.

### 결론:
**B**는 **Elastic Beanstalk**를 활용하여 **고가용성** 및 **배포 관리**를 용이하게 하고, **MySQL 데이터베이스**와 함께 **Apache Tomcat** 기반의 **Java 애플리케이션**을 잘 처리할 수 있습니다.

# 428번
### 정답
B. Create an IAM role that includes Lambda as a trusted service. Attach a policy to the role that allows read and write access to the DynamoDB table. Update the configuration of the Lambda function to use the new role as the execution role.

### 해설
AWS Lambda 함수가 DynamoDB 테이블에 접근할 수 있도록 가장 안전한 방법은 IAM 역할을 사용하는 것입니다. IAM 역할을 사용하면 Lambda 함수가 필요한 권한만을 가지도록 제한할 수 있으며, 액세스 키와 시크릿 키를 코드나 환경 변수에 저장할 필요가 없습니다.

각 옵션을 자세히 살펴보면:

- **A. Create an IAM user with programmatic access to the Lambda function. Attach a policy to the user that allows read and write access to the DynamoDB table. Store the access_key_id and secret_access_key parameters as part of the Lambda environment variables. Ensure that other AWS users do not have read and write access to the Lambda function configuration.**
  - IAM 사용자를 생성하고 액세스 키와 시크릿 키를 환경 변수에 저장하는 것은 보안 위험이 있습니다. 키가 노출될 가능성이 있으며, 이는 안전하지 않은 방법입니다.

- **B. Create an IAM role that includes Lambda as a trusted service. Attach a policy to the role that allows read and write access to the DynamoDB table. Update the configuration of the Lambda function to use the new role as the execution role.**
  - IAM 역할을 사용하면 Lambda 함수가 필요한 권한만을 가지도록 제한할 수 있습니다. 이는 가장 안전한 방법입니다. Lambda 함수의 실행 역할로 이 역할을 사용하도록 구성하면 됩니다.

- **C. Create an IAM user with programmatic access to the Lambda function. Attach a policy to the user that allows read and write access to the DynamoDB table. Store the access_key_id and secret_access_key parameters in AWS Systems Manager Parameter Store as secure string parameters. Update the Lambda function code to retrieve the secure string parameters before connecting to the DynamoDB table.**
  - IAM 사용자를 생성하고 키를 Parameter Store에 저장하는 것은 보안이 강화되지만, 여전히 키를 코드에서 사용해야 하므로 보안 위험이 있습니다.

- **D. Create an IAM role that includes DynamoDB as a trusted service. Attach a policy to the role that allows read and write access from the Lambda function. Update the code of the Lambda function to attach to the new role as an execution role.**
  - DynamoDB를 신뢰할 수 있는 서비스로 포함하는 것은 잘못된 설정입니다. Lambda를 신뢰할 수 있는 서비스로 포함해야 합니다.

따라서, 회사의 요구 사항을 가장 효율적으로 충족하는 솔루션은 옵션 B입니다.

### 필요한 학습 내용

1. **IAM 역할**
   - IAM 역할은 특정 작업을 수행할 수 있는 권한을 부여받은 주체입니다.
   - Lambda 함수가 필요한 권한만을 가지도록 제한할 수 있습니다.

2. **AWS Lambda**
   - Lambda는 서버리스 컴퓨팅을 제공하는 서비스로, 특정 이벤트에 따라 코드를 실행할 수 있습니다.
   - IAM 역할을 사용하여 필요한 권한을 부여할 수 있습니다.

3. **Amazon DynamoDB**
   - DynamoDB는 완전 관리형 NoSQL 데이터베이스 서비스입니다.
   - IAM 역할을 사용하여 Lambda 함수가 DynamoDB 테이블에 접근할 수 있도록 권한을 부여할 수 있습니다.

### 추가 학습 자료
- [IAM 역할 공식 문서](https://docs.aws.amazon.com/ko_kr/IAM/latest/UserGuide/id_roles.html)
- [AWS Lambda 공식 문서](https://docs.aws.amazon.com/ko_kr/lambda/latest/dg/welcome.html)
- [Amazon DynamoDB 공식 문서](https://docs.aws.amazon.com/ko_kr/amazondynamodb/latest/developerguide/Introduction.html)

이 자료들을 통해 IAM 역할, Lambda, DynamoDB의 다양한 기능과 설정 방법을 이해하고, 특정 시나리오에서 최적의 솔루션을 선택하는 능력을 키울 수 있습니다.


# 430번
### 정답
B. Design an AWS Lambda function that converts the .csv files into images and stores the images in the S3 bucket. Invoke the Lambda function when a .csv file is uploaded.
C. Create S3 Lifecycle rules for .csv files and image files in the S3 bucket. Transition the .csv files from S3 Standard to S3 Glacier 1 day after they are uploaded. Expire the image files after 30 days.

### 해설
이 문제는 비용 효율적으로 .csv 파일을 이미지로 변환하고, 이미지와 .csv 파일을 적절히 관리하는 방법을 평가합니다. AWS Lambda를 사용하여 .csv 파일을 이미지로 변환하고, S3 Lifecycle 규칙을 사용하여 스토리지 비용을 최적화하는 것이 가장 적합한 솔루션입니다.

각 옵션을 자세히 살펴보면:

- **A. Launch an Amazon EC2 Spot Instance that downloads the .csv files every hour, generates the image files, and uploads the images to the S3 bucket.**
  - EC2 Spot 인스턴스를 사용하는 것은 가능하지만, Lambda를 사용하는 것이 더 비용 효율적이고 관리 오버헤드가 적습니다.

- **B. Design an AWS Lambda function that converts the .csv files into images and stores the images in the S3 bucket. Invoke the Lambda function when a .csv file is uploaded.**
  - Lambda 함수는 서버리스 컴퓨팅을 제공하며, .csv 파일이 업로드될 때 자동으로 이미지를 생성할 수 있습니다. 이는 비용 효율적이고 관리 오버헤드가 적습니다.

- **C. Create S3 Lifecycle rules for .csv files and image files in the S3 bucket. Transition the .csv files from S3 Standard to S3 Glacier 1 day after they are uploaded. Expire the image files after 30 days.**
  - CSV 파일은 6개월마다 ML 모델 교육에 필요하지만, 그 외의 시간 동안은 저장 비용을 최소화할 필요가 있습니다. S3 Glacier는 저장 비용이 매우 저렴하며, CSV 파일이 교육에 필요할 때까지 보관하기에 적합합니다. 또한, 이미지 파일은 30일 후에 만료되도록 설정하여 비용을 최적화할 수 있습니다.

- **D. Create S3 Lifecycle rules for .csv files and image files in the S3 bucket. Transition the .csv files from S3 Standard to S3 One Zone-Infrequent Access (S3 One Zone-IA) 1 day after they are uploaded. Expire the image files after 30 days.**
  - S3 One Zone-IA는 비용이 저렴하지만, 데이터 내구성이 낮습니다. S3 Glacier를 사용하는 것이 더 적합합니다.

- **E. Create S3 Lifecycle rules for .csv files and image files in the S3 bucket. Transition the .csv files from S3 Standard to S3 Standard-Infrequent Access (S3 Standard-IA) 1 day after they are uploaded. Keep the image files in Reduced Redundancy Storage (RRS).**
  - S3 Standard-IA는 비용이 저렴하지만, S3 Glacier를 사용하는 것이 더 비용 효율적입니다. RRS는 더 이상 권장되지 않는 스토리지 클래스입니다.

따라서, 회사의 요구 사항을 가장 효율적으로 충족하는 솔루션은 옵션 B와 C입니다.

### 필요한 학습 내용

1. **AWS Lambda**
   - Lambda는 서버리스 컴퓨팅을 제공하며, 특정 이벤트에 따라 코드를 실행할 수 있습니다.
   - .csv 파일이 업로드될 때 자동으로 이미지를 생성할 수 있습니다.

2. **Amazon S3**
   - S3는 객체 스토리지 서비스로, 데이터를 안전하게 저장할 수 있습니다.
   - S3 Lifecycle 규칙을 사용하여 스토리지 비용을 최적화할 수 있습니다.

3. **S3 Glacier**
   - S3 Glacier는 장기 아카이빙을 위한 저비용 스토리지 서비스입니다.
   - 자주 접근하지 않는 데이터를 저장하는 데 적합합니다.

4. **S3 Lifecycle 규칙**
   - S3 Lifecycle 규칙을 사용하여 객체의 스토리지 클래스를 자동으로 전환하거나 만료시킬 수 있습니다.
   - 스토리지 비용을 최적화하는 데 도움이 됩니다.

### 추가 학습 자료
- [AWS Lambda 공식 문서](https://docs.aws.amazon.com/ko_kr/lambda/latest/dg/welcome.html)
- [Amazon S3 공식 문서](https://docs.aws.amazon.com/ko_kr/AmazonS3/latest/userguide/Welcome.html)
- [S3 Glacier 공식 문서](https://docs.aws.amazon.com/ko_kr/amazonglacier/latest/dev/introduction.html)
- [S3 Lifecycle 규칙 공식 문서](https://docs.aws.amazon.com/ko_kr/AmazonS3/latest/userguide/object-lifecycle-mgmt.html)

이 자료들을 통해 Lambda, S3, S3 Glacier, S3 Lifecycle 규칙의 다양한 기능과 설정 방법을 이해하고, 특정 시나리오에서 최적의 솔루션을 선택하는 능력을 키울 수 있습니다.



# 431번
### 정답
B. Set up an Amazon ElastiCache for Redis cluster to compute and cache the scores for the web application to display.

### 해설
Amazon ElastiCache for Redis는 높은 성능과 낮은 지연 시간을 제공하는 인메모리 데이터 저장소로, 실시간 데이터 처리와 캐싱에 적합합니다. Redis는 데이터 구조를 지원하며, 순위 계산과 같은 작업을 효율적으로 처리할 수 있습니다. 이를 통해 실시간으로 업데이트되는 상위 10개 점수판을 표시할 수 있습니다.

각 옵션을 자세히 살펴보면:

- **A. Set up an Amazon ElastiCache for Memcached cluster to cache the scores for the web application to display.**
  - Memcached는 단순한 키-값 저장소로, 순위 계산과 같은 복잡한 작업을 처리하는 데 적합하지 않습니다.

- **B. Set up an Amazon ElastiCache for Redis cluster to compute and cache the scores for the web application to display.**
  - Redis는 데이터 구조를 지원하며, 순위 계산과 같은 작업을 효율적으로 처리할 수 있습니다. 또한, Redis는 높은 성능과 낮은 지연 시간을 제공하여 실시간 데이터 처리에 적합합니다.

- **C. Place an Amazon CloudFront distribution in front of the web application to cache the scoreboard in a section of the application.**
  - CloudFront는 콘텐츠 배포 네트워크(CDN)로, 정적 콘텐츠를 캐싱하는 데 적합합니다. 실시간으로 업데이트되는 점수판을 캐싱하는 데는 적합하지 않습니다.

- **D. Create a read replica on Amazon RDS for MySQL to run queries to compute the scoreboard and serve the read traffic to the web application.**
  - RDS 읽기 복제본을 사용하여 순위를 계산하는 것은 가능하지만, 데이터베이스에 부하를 줄 수 있으며, 실시간 데이터 처리에 적합하지 않습니다.

따라서, 회사의 요구 사항을 가장 효율적으로 충족하는 솔루션은 옵션 B입니다.

### 필요한 학습 내용

1. **Amazon ElastiCache for Redis**
   - Redis는 높은 성능과 낮은 지연 시간을 제공하는 인메모리 데이터 저장소입니다.
   - 데이터 구조를 지원하며, 순위 계산과 같은 작업을 효율적으로 처리할 수 있습니다.

2. **Amazon ElastiCache for Memcached**
   - Memcached는 단순한 키-값 저장소로, 순위 계산과 같은 복잡한 작업을 처리하는 데 적합하지 않습니다.

3. **Amazon CloudFront**
   - CloudFront는 콘텐츠 배포 네트워크(CDN)로, 정적 콘텐츠를 캐싱하는 데 적합합니다.
   - 실시간으로 업데이트되는 점수판을 캐싱하는 데는 적합하지 않습니다.

4. **Amazon RDS 읽기 복제본**
   - RDS 읽기 복제본을 사용하여 데이터베이스의 읽기 부하를 분산할 수 있습니다.
   - 순위 계산과 같은 작업을 처리하는 데는 적합하지 않습니다.

### 추가 학습 자료
- [Amazon ElastiCache for Redis 공식 문서](https://docs.aws.amazon.com/ko_kr/AmazonElastiCache/latest/red-ug/WhatIs.html)
- [Amazon ElastiCache for Memcached 공식 문서](https://docs.aws.amazon.com/ko_kr/AmazonElastiCache/latest/mem-ug/WhatIs.html)
- [Amazon CloudFront 공식 문서](https://docs.aws.amazon.com/ko_kr/AmazonCloudFront/latest/DeveloperGuide/Introduction.html)
- [Amazon RDS 읽기 복제본 공식 문서](https://docs.aws.amazon.com/ko_kr/AmazonRDS/latest/UserGuide/USER_ReadRepl.html)

이 자료들을 통해 ElastiCache for Redis, ElastiCache for Memcached, CloudFront, RDS 읽기 복제본의 다양한 기능과 설정 방법을 이해하고, 특정 시나리오에서 최적의 솔루션을 선택하는 능력을 키울 수 있습니다.

# 434번
### 정답
A. Create an Auto Scaling group and a load balancer in the disaster recovery Region. Configure the DynamoDB table as a global table. Configure DNS failover to point to the new disaster recovery Region's load balancer.

### 해설
이 문제는 애플리케이션을 다른 AWS 리전에서 최소한의 다운타임으로 사용할 수 있도록 하는 방법을 평가합니다. 가장 적합한 솔루션은 재해 복구 리전에 Auto Scaling 그룹과 로드 밸런서를 미리 설정하고, DynamoDB 테이블을 글로벌 테이블로 구성하여 데이터 복제를 보장하는 것입니다. 또한, DNS 장애 조치를 구성하여 재해 발생 시 새로운 리전의 로드 밸런서로 트래픽을 전환할 수 있습니다.

각 옵션을 자세히 살펴보면:

- **A. Create an Auto Scaling group and a load balancer in the disaster recovery Region. Configure the DynamoDB table as a global table. Configure DNS failover to point to the new disaster recovery Region's load balancer.**
  - 이 옵션은 재해 복구 리전에 미리 Auto Scaling 그룹과 로드 밸런서를 설정하고, DynamoDB 테이블을 글로벌 테이블로 구성하여 데이터 복제를 보장합니다. DNS 장애 조치를 통해 재해 발생 시 새로운 리전의 로드 밸런서로 트래픽을 전환할 수 있습니다. 이는 최소한의 다운타임을 보장하는 솔루션입니다.

- **B. Create an AWS CloudFormation template to create EC2 instances, load balancers, and DynamoDB tables to be launched when needed. Configure DNS failover to point to the new disaster recovery Region's load balancer.**
  - 이 옵션은 재해 발생 시 CloudFormation 템플릿을 사용하여 리소스를 생성하는 방법입니다. 그러나 리소스를 생성하는 데 시간이 걸리므로 다운타임이 발생할 수 있습니다.

- **C. Create an AWS CloudFormation template to create EC2 instances and a load balancer to be launched when needed. Configure the DynamoDB table as a global table. Configure DNS failover to point to the new disaster recovery Region's load balancer.**
  - 이 옵션은 재해 발생 시 CloudFormation 템플릿을 사용하여 EC2 인스턴스와 로드 밸런서를 생성하는 방법입니다. DynamoDB 테이블을 글로벌 테이블로 구성하는 것은 적절하지만, 리소스를 생성하는 데 시간이 걸리므로 다운타임이 발생할 수 있습니다.

- **D. Create an Auto Scaling group and load balancer in the disaster recovery Region. Configure the DynamoDB table as a global table. Create an Amazon CloudWatch alarm to trigger an AWS Lambda function that updates Amazon Route 53 pointing to the disaster recovery load balancer.**
  - 이 옵션은 CloudWatch 알람과 Lambda 함수를 사용하여 Route 53을 업데이트하는 방법입니다. 이는 자동화된 솔루션이지만, DNS 장애 조치를 통해 트래픽을 전환하는 것이 더 간단하고 신뢰할 수 있습니다.

따라서, 회사의 요구 사항을 가장 효율적으로 충족하는 솔루션은 옵션 A입니다.

### 필요한 학습 내용

1. **Auto Scaling 그룹**
   - Auto Scaling 그룹은 EC2 인스턴스를 자동으로 확장하거나 축소할 수 있는 기능을 제공합니다.
   - 재해 복구 리전에 미리 설정하여 최소한의 다운타임을 보장할 수 있습니다.

2. **Elastic Load Balancer (ELB)**
   - ELB는 트래픽을 여러 EC2 인스턴스에 분산시켜 고가용성을 보장합니다.
   - 재해 복구 리전에 미리 설정하여 최소한의 다운타임을 보장할 수 있습니다.

3. **Amazon DynamoDB 글로벌 테이블**
   - 글로벌 테이블은 여러 리전에 걸쳐 데이터를 자동으로 복제하여 고가용성과 내구성을 보장합니다.
   - 재해 복구 시 데이터 손실을 방지할 수 있습니다.

4. **DNS 장애 조치**
   - DNS 장애 조치는 재해 발생 시 트래픽을 다른 리전으로 전환할 수 있는 기능을 제공합니다.
   - Route 53을 사용하여 구성할 수 있습니다.

### 추가 학습 자료
- [Auto Scaling 그룹 공식 문서](https://docs.aws.amazon.com/ko_kr/autoscaling/latest/userguide/what-is-amazon-ec2-auto-scaling.html)
- [Elastic Load Balancer (ELB) 공식 문서](https://docs.aws.amazon.com/ko_kr/elasticloadbalancing/latest/userguide/what-is-load-balancing.html)
- [Amazon DynamoDB 글로벌 테이블 공식 문서](https://docs.aws.amazon.com/ko_kr/amazondynamodb/latest/developerguide/GlobalTables.html)
- [DNS 장애 조치 공식 문서](https://docs.aws.amazon.com/ko_kr/Route53/latest/DeveloperGuide/dns-failover.html)

이 자료들을 통해 Auto Scaling 그룹, ELB, DynamoDB 글로벌 테이블, DNS 장애 조치의 다양한 기능과 설정 방법을 이해하고, 특정 시나리오에서 최적의 솔루션을 선택하는 능력을 키울 수 있습니다.


# 436번 
### 정답
A. Buy reserved DB instances for the total workload. Make the Amazon RDS for PostgreSQL DB instance larger.

### 해설
회사는 증가된 워크로드를 처리하기 위해 인프라를 추가하지 않고 비용 효율적으로 데이터베이스 성능을 향상시키고자 합니다. Amazon RDS에서 예약 인스턴스를 구매하면 장기적으로 비용을 절감할 수 있으며, 인스턴스 크기를 늘려 성능을 향상시킬 수 있습니다.

각 옵션을 자세히 살펴보면:

- **A. Buy reserved DB instances for the total workload. Make the Amazon RDS for PostgreSQL DB instance larger.**
  - 예약 인스턴스를 구매하면 장기적으로 비용을 절감할 수 있습니다. 인스턴스 크기를 늘리면 성능을 향상시킬 수 있습니다. 이는 가장 비용 효율적인 솔루션입니다.

- **B. Make the Amazon RDS for PostgreSQL DB instance a Multi-AZ DB instance.**
  - Multi-AZ 배포는 고가용성과 내구성을 제공하지만, 성능 향상에는 직접적인 영향을 미치지 않습니다. 또한, 비용이 증가할 수 있습니다.

- **C. Buy reserved DB instances for the total workload. Add another Amazon RDS for PostgreSQL DB instance.**
  - 추가 인스턴스를 생성하면 비용이 증가할 수 있습니다. 인프라를 추가하지 않고 성능을 향상시키는 것이 목표이므로 적합하지 않습니다.

- **D. Make the Amazon RDS for PostgreSQL DB instance an on-demand DB instance.**
  - 온디맨드 인스턴스는 유연성을 제공하지만, 장기적으로 예약 인스턴스보다 비용이 더 많이 들 수 있습니다.

따라서, 회사의 요구 사항을 가장 효율적으로 충족하는 솔루션은 옵션 A입니다.

### 필요한 학습 내용

1. **Amazon RDS 예약 인스턴스**
   - 예약 인스턴스를 구매하면 장기적으로 비용을 절감할 수 있습니다.
   - 특정 기간 동안 인스턴스를 예약하여 할인된 가격으로 사용할 수 있습니다.

2. **Amazon RDS 인스턴스 크기 조정**
   - 인스턴스 크기를 늘리면 데이터베이스 성능을 향상시킬 수 있습니다.
   - 증가된 워크로드를 처리할 수 있습니다.

3. **Multi-AZ 배포**
   - Multi-AZ 배포는 고가용성과 내구성을 제공하지만, 성능 향상에는 직접적인 영향을 미치지 않습니다.
   - 비용이 증가할 수 있습니다.

4. **온디맨드 인스턴스**
   - 온디맨드 인스턴스는 유연성을 제공하지만, 장기적으로 예약 인스턴스보다 비용이 더 많이 들 수 있습니다.

### 추가 학습 자료
- [Amazon RDS 예약 인스턴스 공식 문서](https://docs.aws.amazon.com/ko_kr/AmazonRDS/latest/UserGuide/USER_WorkingWithReservedDBInstances.html)
- [Amazon RDS 인스턴스 크기 조정 공식 문서](https://docs.aws.amazon.com/ko_kr/AmazonRDS/latest/UserGuide/Overview.DBInstance.Modifying.html)
- [Multi-AZ 배포 공식 문서](https://docs.aws.amazon.com/ko_kr/AmazonRDS/latest/UserGuide/Concepts.MultiAZ.html)
- [온디맨드 인스턴스 공식 문서](https://docs.aws.amazon.com/ko_kr/AmazonRDS/latest/UserGuide/Concepts.DBInstanceClass.html)

이 자료들을 통해 예약 인스턴스, 인스턴스 크기 조정, Multi-AZ 배포, 온디맨드 인스턴스의 다양한 기능과 설정 방법을 이해하고, 특정 시나리오에서 최적의 솔루션을 선택하는 능력을 키울 수 있습니다.


# 439번
### 정답
A. Add an additional IPv4 CIDR block to increase the number of IP addresses and create additional subnets in the VPC. Create new resources in the new subnets by using the new CIDR.

### 해설
기존 VPC에 추가 IPv4 CIDR 블록을 추가하면 IP 주소 공간을 확장할 수 있습니다. 이는 운영 오버헤드를 최소화하면서 현재 VPC 내에서 IP 주소 부족 문제를 해결하는 가장 간단하고 효율적인 방법입니다.

각 옵션을 자세히 살펴보면:

- **A. Add an additional IPv4 CIDR block to increase the number of IP addresses and create additional subnets in the VPC. Create new resources in the new subnets by using the new CIDR.**
  - 기존 VPC에 추가 CIDR 블록을 추가하면 IP 주소 공간을 확장할 수 있습니다. 이는 운영 오버헤드를 최소화하면서 현재 VPC 내에서 IP 주소 부족 문제를 해결하는 가장 간단하고 효율적인 방법입니다.

- **B. Create a second VPC with additional subnets. Use a peering connection to connect the second VPC with the first VPC. Update the routes and create new resources in the subnets of the second VPC.**
  - 두 번째 VPC를 생성하고 피어링 연결을 설정하는 것은 가능하지만, 이는 운영 오버헤드가 증가할 수 있습니다. 또한, 라우팅 테이블을 업데이트해야 하므로 복잡성이 증가합니다.

- **C. Use AWS Transit Gateway to add a transit gateway and connect a second VPC with the first VPC. Update the routes of the transit gateway and VPCs. Create new resources in the subnets of the second VPC.**
  - Transit Gateway를 사용하여 두 번째 VPC를 연결하는 것은 가능하지만, 이는 운영 오버헤드가 증가할 수 있습니다. 또한, 라우팅 테이블을 업데이트해야 하므로 복잡성이 증가합니다.

- **D. Create a second VPC. Create a Site-to-Site VPN connection between the first VPC and the second VPC by using a VPN-hosted solution on Amazon EC2 and a virtual private gateway. Update the route between VPCs to the traffic through the VPN. Create new resources in the subnets of the second VPC.**
  - Site-to-Site VPN 연결을 설정하는 것은 가능하지만, 이는 운영 오버헤드가 크게 증가할 수 있습니다. 또한, 라우팅 테이블을 업데이트해야 하므로 복잡성이 증가합니다.

따라서, 회사의 요구 사항을 가장 효율적으로 충족하는 솔루션은 옵션 A입니다.

### 필요한 학습 내용

1. **VPC CIDR 블록 추가**
   - 기존 VPC에 추가 CIDR 블록을 추가하여 IP 주소 공간을 확장할 수 있습니다.
   - 이는 운영 오버헤드를 최소화하면서 IP 주소 부족 문제를 해결하는 가장 간단한 방법입니다.

2. **VPC 피어링**
   - 두 VPC 간에 피어링 연결을 설정하여 트래픽을 라우팅할 수 있습니다.
   - 라우팅 테이블을 업데이트해야 하므로 복잡성이 증가할 수 있습니다.

3. **AWS Transit Gateway**
   - Transit Gateway는 여러 VPC와 온프레미스 네트워크를 연결하는 중앙 허브 역할을 합니다.
   - 라우팅 테이블을 업데이트해야 하므로 복잡성이 증가할 수 있습니다.

4. **Site-to-Site VPN**
   - Site-to-Site VPN은 두 네트워크 간에 암호화된 연결을 설정하는 데 사용됩니다.
   - 운영 오버헤드가 크게 증가할 수 있습니다.

### 추가 학습 자료
- [VPC CIDR 블록 추가 공식 문서](https://docs.aws.amazon.com/ko_kr/vpc/latest/userguide/VPC_Subnets.html#vpc-resize)
- [VPC 피어링 공식 문서](https://docs.aws.amazon.com/ko_kr/vpc/latest/peering/what-is-vpc-peering.html)
- [AWS Transit Gateway 공식 문서](https://docs.aws.amazon.com/ko_kr/vpc/latest/tgw/what-is-transit-gateway.html)
- [Site-to-Site VPN 공식 문서](https://docs.aws.amazon.com/ko_kr/vpn/latest/s2svpn/VPC_VPN.html)

이 자료들을 통해 VPC CIDR 블록 추가, VPC 피어링, AWS Transit Gateway, Site-to-Site VPN의 다양한 기능과 설정 방법을 이해하고, 특정 시나리오에서 최적의 솔루션을 선택하는 능력을 키울 수 있습니다.


# 440번
### 정답
A. Import the RDS snapshot directly into Aurora.
C. Upload the database dump to Amazon S3. Then import the database dump into Aurora.

### 해설
Amazon Aurora는 MySQL과 호환되며, RDS 스냅샷을 직접 가져오거나 데이터베이스 덤프를 사용하여 데이터를 가져올 수 있습니다. 이 두 가지 방법은 새로운 DB 인스턴스를 생성하는 데 가장 적합한 솔루션입니다.

각 옵션을 자세히 살펴보면:

- **A. Import the RDS snapshot directly into Aurora.**
  - Amazon Aurora는 MySQL과 호환되므로, RDS 스냅샷을 직접 가져와서 새로운 Aurora DB 인스턴스를 생성할 수 있습니다.

- **B. Upload the RDS snapshot to Amazon S3. Then import the RDS snapshot into Aurora.**
  - RDS 스냅샷을 S3로 업로드한 후 Aurora로 가져오는 것은 필요하지 않습니다. Aurora는 RDS 스냅샷을 직접 가져올 수 있습니다.

- **C. Upload the database dump to Amazon S3. Then import the database dump into Aurora.**
  - 데이터베이스 덤프를 S3에 업로드한 후, Aurora로 가져올 수 있습니다. 이는 데이터베이스 덤프를 사용하는 일반적인 방법입니다.

- **D. Use AWS Database Migration Service (AWS DMS) to import the RDS snapshot into Aurora.**
  - AWS DMS는 데이터베이스 마이그레이션을 위한 서비스이지만, RDS 스냅샷을 직접 가져오는 데는 필요하지 않습니다.

- **E. Upload the database dump to Amazon S3. Then use AWS Database Migration Service (AWS DMS) to import the database dump into Aurora.**
  - 데이터베이스 덤프를 S3에 업로드한 후, AWS DMS를 사용하여 Aurora로 가져오는 것은 가능하지만, DMS를 사용하지 않고 직접 가져오는 것이 더 간단합니다.

따라서, 회사의 요구 사항을 가장 효율적으로 충족하는 솔루션은 옵션 A와 C입니다.

### 필요한 학습 내용

1. **Amazon Aurora**
   - Aurora는 MySQL과 호환되는 고성능 관계형 데이터베이스 서비스입니다.
   - RDS 스냅샷을 직접 가져올 수 있습니다.

2. **RDS 스냅샷**
   - RDS 스냅샷은 데이터베이스의 백업을 생성하는 데 사용됩니다.
   - Aurora로 직접 가져올 수 있습니다.

3. **데이터베이스 덤프**
   - 데이터베이스 덤프는 데이터베이스의 내용을 파일로 내보내는 방법입니다.
   - S3에 업로드한 후 Aurora로 가져올 수 있습니다.

### 추가 학습 자료
- [Amazon Aurora 공식 문서](https://docs.aws.amazon.com/ko_kr/AmazonRDS/latest/AuroraUserGuide/Welcome.html)
- [RDS 스냅샷 공식 문서](https://docs.aws.amazon.com/ko_kr/AmazonRDS/latest/UserGuide/USER_CreateSnapshot.html)
- [데이터베이스 덤프 공식 문서](https://dev.mysql.com/doc/refman/8.0/en/mysqldump.html)

이 자료들을 통해 Aurora, RDS 스냅샷, 데이터베이스 덤프의 다양한 기능과 설정 방법을 이해하고, 특정 시나리오에서 최적의 솔루션을 선택하는 능력을 키울 수 있습니다.

# 442번
### 정답
D. Use Lake Formation tag-based access control to authorize and grant cross-account permissions for the required data to the engineering team accounts.

### 해설
AWS Lake Formation의 태그 기반 접근 제어(TBAC)는 데이터에 태그를 할당하고, 이러한 태그를 기반으로 접근 권한을 관리할 수 있는 기능을 제공합니다. 이를 통해 여러 계정 간에 데이터를 안전하게 공유할 수 있으며, 운영 오버헤드를 최소화할 수 있습니다.

각 옵션을 자세히 살펴보면:

- **A. Copy the required data to a common account. Create an IAM access role in that account. Grant access by specifying a permission policy that includes users from the engineering team accounts as trusted entities.**
  - 데이터를 공통 계정으로 복사하고 IAM 역할을 생성하는 것은 가능하지만, 데이터 복사와 권한 관리를 위한 추가적인 작업이 필요하므로 운영 오버헤드가 증가할 수 있습니다.

- **B. Use the Lake Formation permissions Grant command in each account where the data is stored to allow the required engineering team users to access the data.**
  - 각 계정에서 Lake Formation 권한 부여 명령을 사용하는 것은 가능하지만, 여러 계정에서 개별적으로 권한을 관리해야 하므로 운영 오버헤드가 증가할 수 있습니다.

- **C. Use AWS Data Exchange to privately publish the required data to the required engineering team accounts.**
  - AWS Data Exchange는 데이터 공유를 위한 서비스이지만, 데이터 교환을 위해 추가적인 설정과 관리가 필요할 수 있습니다.

- **D. Use Lake Formation tag-based access control to authorize and grant cross-account permissions for the required data to the engineering team accounts.**
  - Lake Formation의 태그 기반 접근 제어(TBAC)를 사용하면 여러 계정 간에 데이터를 안전하게 공유할 수 있으며, 운영 오버헤드를 최소화할 수 있습니다. 이는 가장 효율적인 솔루션입니다.

따라서, 회사의 요구 사항을 가장 효율적으로 충족하는 솔루션은 옵션 D입니다.

### 필요한 학습 내용

1. **AWS Lake Formation**
   - Lake Formation은 데이터 레이크를 쉽게 설정하고 관리할 수 있는 서비스입니다.
   - 태그 기반 접근 제어(TBAC)를 통해 데이터 접근 권한을 관리할 수 있습니다.

2. **태그 기반 접근 제어 (TBAC)**
   - 데이터에 태그를 할당하고, 이러한 태그를 기반으로 접근 권한을 관리할 수 있는 기능입니다.
   - 여러 계정 간에 데이터를 안전하게 공유할 수 있습니다.

3. **IAM 역할 및 권한**
   - IAM 역할을 생성하고 권한을 부여하여 특정 리소스에 대한 접근을 제어할 수 있습니다.
   - 여러 계정 간에 데이터를 공유할 때 사용할 수 있습니다.

### 추가 학습 자료
- [AWS Lake Formation 공식 문서](https://docs.aws.amazon.com/ko_kr/lake-formation/latest/dg/what-is-lake-formation.html)
- [태그 기반 접근 제어 (TBAC) 공식 문서](https://docs.aws.amazon.com/ko_kr/lake-formation/latest/dg/tag-based-access-control.html)
- [IAM 역할 및 권한 공식 문서](https://docs.aws.amazon.com/ko_kr/IAM/latest/UserGuide/id_roles.html)

이 자료들을 통해 Lake Formation, TBAC, IAM 역할 및 권한의 다양한 기능과 설정 방법을 이해하고, 특정 시나리오에서 최적의 솔루션을 선택하는 능력을 키울 수 있습니다.

# 443번
### 정답
A. Use Amazon S3 with Transfer Acceleration to host the application.

### 해설
Amazon S3 Transfer Acceleration은 전 세계적으로 분산된 엣지 로케이션을 사용하여 S3 버킷으로의 업로드 및 다운로드 속도를 향상시킵니다. 이는 특히 대용량 데이터를 전송할 때 유용하며, 지리적으로 분산된 사용자에게 낮은 지연 시간과 높은 성능을 제공합니다. 또한, S3는 비용 효율적인 스토리지 솔루션입니다.

각 옵션을 자세히 살펴보면:

- **A. Use Amazon S3 with Transfer Acceleration to host the application.**
  - S3 Transfer Acceleration은 전 세계적으로 분산된 엣지 로케이션을 사용하여 업로드 및 다운로드 속도를 향상시킵니다. 이는 대용량 데이터를 전송할 때 유용하며, 지리적으로 분산된 사용자에게 낮은 지연 시간과 높은 성능을 제공합니다.

- **B. Use Amazon S3 with CacheControl headers to host the application.**
  - CacheControl 헤더는 캐싱을 제어하는 데 사용되지만, 업로드 및 다운로드 속도를 직접적으로 향상시키지는 않습니다.

- **C. Use Amazon EC2 with Auto Scaling and Amazon CloudFront to host the application.**
  - EC2와 Auto Scaling, CloudFront를 사용하는 것은 가능하지만, S3 Transfer Acceleration을 사용하는 것이 더 비용 효율적이고 관리 오버헤드가 적습니다.

- **D. Use Amazon EC2 with Auto Scaling and Amazon ElastiCache to host the application.**
  - ElastiCache는 주로 데이터베이스 캐싱에 사용되며, 업로드 및 다운로드 속도를 직접적으로 향상시키지는 않습니다.

따라서, 회사의 요구 사항을 가장 효율적으로 충족하는 솔루션은 옵션 A입니다.

### 필요한 학습 내용

1. **Amazon S3 Transfer Acceleration**
   - S3 Transfer Acceleration은 전 세계적으로 분산된 엣지 로케이션을 사용하여 S3 버킷으로의 업로드 및 다운로드 속도를 향상시킵니다.
   - 대용량 데이터를 전송할 때 유용하며, 지리적으로 분산된 사용자에게 낮은 지연 시간과 높은 성능을 제공합니다.

2. **Amazon S3**
   - S3는 객체 스토리지 서비스로, 정적 웹 콘텐츠를 호스팅하는 데 적합합니다.
   - 비용 효율적이며, Transfer Acceleration을 통해 성능을 향상시킬 수 있습니다.

3. **Amazon CloudFront**
   - CloudFront는 콘텐츠 전송 네트워크(CDN)로, 전 세계에 분산된 엣지 로케이션을 통해 정적 콘텐츠를 캐싱하고 제공할 수 있습니다.
   - S3 Transfer Acceleration과 함께 사용할 수 있습니다.

4. **Amazon ElastiCache**
   - ElastiCache는 주로 데이터베이스 캐싱에 사용됩니다.
   - 업로드 및 다운로드 속도를 직접적으로 향상시키지는 않습니다.

### 추가 학습 자료
- [Amazon S3 Transfer Acceleration 공식 문서](https://docs.aws.amazon.com/ko_kr/AmazonS3/latest/dev/transfer-acceleration.html)
- [Amazon S3 공식 문서](https://docs.aws.amazon.com/ko_kr/AmazonS3/latest/userguide/Welcome.html)
- [Amazon CloudFront 공식 문서](https://docs.aws.amazon.com/ko_kr/AmazonCloudFront/latest/DeveloperGuide/Introduction.html)
- [Amazon ElastiCache 공식 문서](https://docs.aws.amazon.com/ko_kr/AmazonElastiCache/latest/red-ug/WhatIs.html)

이 자료들을 통해 S3 Transfer Acceleration, S3, CloudFront, ElastiCache의 다양한 기능과 설정 방법을 이해하고, 특정 시나리오에서 최적의 솔루션을 선택하는 능력을 키울 수 있습니다.


# 445번
### 정답
A. Create an AWS DataSync agent in the corporate data center. Create a data transfer task Start the transfer to an Amazon S3 bucket.

### 해설
AWS DataSync는 온프레미스 스토리지와 AWS 스토리지 간에 데이터를 효율적으로 전송할 수 있는 서비스입니다. DataSync는 데이터 전송 중에도 데이터에 접근하고 업데이트할 수 있도록 지원하며, 10 Gbps Direct Connect 연결을 통해 대량의 데이터를 빠르게 전송할 수 있습니다. 이는 90일 내에 700TB의 데이터를 클라우드로 이동하는 데 가장 적합한 솔루션입니다.

각 옵션을 자세히 살펴보면:

- **A. Create an AWS DataSync agent in the corporate data center. Create a data transfer task Start the transfer to an Amazon S3 bucket.**
  - DataSync는 대량의 데이터를 효율적으로 전송할 수 있으며, 데이터 전송 중에도 데이터에 접근하고 업데이트할 수 있습니다. 10 Gbps Direct Connect 연결을 통해 빠르게 데이터를 전송할 수 있습니다.

- **B. Back up the data to AWS Snowball Edge Storage Optimized devices. Ship the devices to an AWS data center. Mount a target Amazon S3 bucket on the on-premises file system.**
  - Snowball Edge 장치를 사용하는 것은 가능하지만, 데이터 전송 중에 데이터에 접근하고 업데이트하는 데는 적합하지 않습니다. 또한, 장치를 AWS 데이터 센터로 배송하는 데 시간이 걸릴 수 있습니다.

- **C. Use rsync to copy the data directly from local storage to a designated Amazon S3 bucket over the Direct Connect connection.**
  - rsync를 사용하는 것은 가능하지만, DataSync가 제공하는 최적화된 전송 기능과 데이터 접근 및 업데이트 기능을 제공하지 않습니다.

- **D. Back up the data on tapes. Ship the tapes to an AWS data center. Mount a target Amazon S3 bucket on the on-premises file system.**
  - 테이프 백업을 사용하는 것은 가능하지만, 데이터 전송 중에 데이터에 접근하고 업데이트하는 데는 적합하지 않습니다. 또한, 테이프를 AWS 데이터 센터로 배송하는 데 시간이 걸릴 수 있습니다.

따라서, 회사의 요구 사항을 가장 효율적으로 충족하는 솔루션은 옵션 A입니다.

### 필요한 학습 내용

1. **AWS DataSync**
   - DataSync는 온프레미스 스토리지와 AWS 스토리지 간에 데이터를 효율적으로 전송할 수 있는 서비스입니다.
   - 데이터 전송 중에도 데이터에 접근하고 업데이트할 수 있습니다.

2. **AWS Direct Connect**
   - Direct Connect는 온프레미스 네트워크와 AWS 간에 전용 네트워크 연결을 제공하여 안정적이고 빠른 데이터 전송을 지원합니다.

3. **Amazon S3**
   - S3는 객체 스토리지 서비스로, 대량의 데이터를 저장하고 관리하는 데 적합합니다.

### 추가 학습 자료
- [AWS DataSync 공식 문서](https://docs.aws.amazon.com/ko_kr/datasync/latest/userguide/what-is-datasync.html)
- [AWS Direct Connect 공식 문서](https://docs.aws.amazon.com/ko_kr/directconnect/latest/UserGuide/Welcome.html)
- [Amazon S3 공식 문서](https://docs.aws.amazon.com/ko_kr/AmazonS3/latest/userguide/Welcome.html)

이 자료들을 통해 DataSync, Direct Connect, S3의 다양한 기능과 설정 방법을 이해하고, 특정 시나리오에서 최적의 솔루션을 선택하는 능력을 키울 수 있습니다.


# 447번
### 정답
A. Create Amazon Route 53 health checks for each Region. Use an active-active failover configuration.

### 해설
Amazon Route 53은 DNS 기반의 트래픽 라우팅 서비스로, 여러 리전에 걸쳐 트래픽을 분산시키고 장애 발생 시 자동으로 장애 조치를 수행할 수 있습니다. Route 53의 활성-활성(Active-Active) 장애 조치 구성과 헬스 체크를 사용하면, 여러 리전에 걸쳐 트래픽을 분산시키고, 특정 리전에 장애가 발생할 경우 다른 리전으로 트래픽을 자동으로 라우팅할 수 있습니다.

각 옵션을 자세히 살펴보면:

- **A. Create Amazon Route 53 health checks for each Region. Use an active-active failover configuration.**
  - Route 53 헬스 체크와 활성-활성 장애 조치 구성을 사용하면, 여러 리전에 걸쳐 트래픽을 분산시키고 장애 발생 시 자동으로 장애 조치를 수행할 수 있습니다. 이는 다중 리전 배포와 장애 조치 요구 사항을 충족하는 가장 적합한 솔루션입니다.

- **B. Create an Amazon CloudFront distribution with an origin for each Region. Use CloudFront health checks to route traffic.**
  - CloudFront는 주로 콘텐츠 전송 네트워크(CDN)로 사용되며, 다중 리전 트래픽 라우팅을 위한 최적의 솔루션은 아닙니다.

- **C. Create a transit gateway. Attach the transit gateway to the API Gateway endpoint in each Region. Configure the transit gateway to route requests.**
  - Transit Gateway는 주로 VPC 간의 네트워크 연결을 관리하는 데 사용되며, 다중 리전 트래픽 라우팅을 위한 최적의 솔루션은 아닙니다.

- **D. Create an Application Load Balancer in the primary Region. Set the target group to point to the API Gateway endpoint hostnames in each Region.**
  - Application Load Balancer는 주로 단일 리전 내에서 트래픽을 분산시키는 데 사용되며, 다중 리전 트래픽 라우팅을 위한 최적의 솔루션은 아닙니다.

따라서, 회사의 요구 사항을 가장 효율적으로 충족하는 솔루션은 옵션 A입니다.

### 필요한 학습 내용

1. **Amazon Route 53**
   - Route 53은 DNS 기반의 트래픽 라우팅 서비스로, 여러 리전에 걸쳐 트래픽을 분산시키고 장애 발생 시 자동으로 장애 조치를 수행할 수 있습니다.
   - 활성-활성(Active-Active) 장애 조치 구성을 사용하여 다중 리전 배포와 장애 조치 요구 사항을 충족할 수 있습니다.

2. **헬스 체크**
   - 헬스 체크는 리소스의 상태를 모니터링하고, 장애 발생 시 자동으로 장애 조치를 수행할 수 있는 기능입니다.
   - Route 53 헬스 체크를 사용하여 여러 리전에 걸쳐 트래픽을 분산시키고 장애 발생 시 자동으로 장애 조치를 수행할 수 있습니다.

### 추가 학습 자료
- [Amazon Route 53 공식 문서](https://docs.aws.amazon.com/ko_kr/Route53/latest/DeveloperGuide/Welcome.html)
- [Route 53 헬스 체크 공식 문서](https://docs.aws.amazon.com/ko_kr/Route53/latest/DeveloperGuide/dns-failover.html)

이 자료들을 통해 Route 53과 헬스 체크의 다양한 기능과 설정 방법을 이해하고, 특정 시나리오에서 최적의 솔루션을 선택하는 능력을 키울 수 있습니다.


# 448번
### 정답
C. Add a second set of VPNs to the Management VPC from a second customer gateway device.

### 해설
현재 아키텍처에서 Management VPC는 단일 고객 게이트웨이 장치를 통해 VPN을 사용하여 데이터 센터에 연결됩니다. 이는 단일 장애 지점(SPOF)을 형성합니다. 이 문제를 해결하려면 두 번째 고객 게이트웨이 장치를 추가하고, Management VPC에 두 번째 VPN 세트를 설정하여 고가용성을 보장해야 합니다.

각 옵션을 자세히 살펴보면:

- **A. Add a set of VPNs between the Management and Production VPCs.**
  - Management VPC와 Production VPC 간의 VPN을 추가하는 것은 두 VPC 간의 통신을 보장할 수 있지만, 데이터 센터와의 연결에 대한 단일 장애 지점을 해결하지는 못합니다.

- **B. Add a second virtual private gateway and attach it to the Management VPC.**
  - 두 번째 가상 프라이빗 게이트웨이를 추가하는 것은 가능하지만, 고객 게이트웨이 장치의 단일 장애 지점을 해결하지는 못합니다.

- **C. Add a second set of VPNs to the Management VPC from a second customer gateway device.**
  - 두 번째 고객 게이트웨이 장치를 추가하고, Management VPC에 두 번째 VPN 세트를 설정하면, 데이터 센터와의 연결에 대한 단일 장애 지점을 해결할 수 있습니다. 이는 고가용성을 보장하는 가장 적합한 솔루션입니다.

- **D. Add a second VPC peering connection between the Management VPC and the Production VPC.**
  - 두 번째 VPC 피어링 연결을 추가하는 것은 두 VPC 간의 통신을 보장할 수 있지만, 데이터 센터와의 연결에 대한 단일 장애 지점을 해결하지는 못합니다.

따라서, 회사의 요구 사항을 가장 효율적으로 충족하는 솔루션은 옵션 C입니다.

### 필요한 학습 내용

1. **VPN 연결**
   - VPN 연결은 온프레미스 네트워크와 AWS VPC 간에 암호화된 연결을 설정하는 데 사용됩니다.
   - 두 번째 고객 게이트웨이 장치를 추가하고, 두 번째 VPN 세트를 설정하여 고가용성을 보장할 수 있습니다.

2. **고객 게이트웨이**
   - 고객 게이트웨이는 온프레미스 네트워크와 AWS 간의 VPN 연결을 설정하는 데 사용되는 장치입니다.
   - 두 번째 고객 게이트웨이 장치를 추가하여 단일 장애 지점을 해결할 수 있습니다.

3. **VPC 피어링**
   - VPC 피어링은 두 VPC 간에 트래픽을 라우팅할 수 있는 기능을 제공합니다.
   - 두 VPC 간의 통신을 보장할 수 있지만, 데이터 센터와의 연결에 대한 단일 장애 지점을 해결하지는 못합니다.

### 추가 학습 자료
- [AWS VPN 연결 공식 문서](https://docs.aws.amazon.com/ko_kr/vpn/latest/s2svpn/VPC_VPN.html)
- [고객 게이트웨이 공식 문서](https://docs.aws.amazon.com/ko_kr/vpn/latest/s2svpn/SetUpVPNConnections.html)
- [VPC 피어링 공식 문서](https://docs.aws.amazon.com/ko_kr/vpc/latest/peering/what-is-vpc-peering.html)

이 자료들을 통해 VPN 연결, 고객 게이트웨이, VPC 피어링의 다양한 기능과 설정 방법을 이해하고, 특정 시나리오에서 최적의 솔루션을 선택하는 능력을 키울 수 있습니다.

# 454번
### 정답
C. Use Workload Discovery on AWS to generate architecture diagrams of the workloads.

### 해설
Workload Discovery on AWS는 AWS 리소스의 아키텍처 다이어그램을 자동으로 생성하고, 리소스 간의 관계를 시각화하는 도구입니다. 이는 여러 AWS 계정과 리전에 걸쳐 있는 리소스의 관계를 효율적으로 매핑하고 시각화하는 데 가장 적합한 솔루션입니다.

각 옵션을 자세히 살펴보면:

- **A. Use AWS Systems Manager Inventory to generate a map view from the detailed view report.**
  - AWS Systems Manager Inventory는 인벤토리 데이터를 수집하고 관리하는 데 유용하지만, 리소스 간의 관계를 시각화하는 데는 적합하지 않습니다.

- **B. Use AWS Step Functions to collect workload details. Build architecture diagrams of the workloads manually.**
  - AWS Step Functions를 사용하여 워크로드 세부 정보를 수집할 수 있지만, 아키텍처 다이어그램을 수동으로 작성해야 하므로 운영 효율성이 떨어집니다.

- **C. Use Workload Discovery on AWS to generate architecture diagrams of the workloads.**
  - Workload Discovery on AWS는 AWS 리소스의 아키텍처 다이어그램을 자동으로 생성하고, 리소스 간의 관계를 시각화하는 데 가장 적합한 솔루션입니다.

- **D. Use AWS X-Ray to view the workload details. Build architecture diagrams with relationships.**
  - AWS X-Ray는 애플리케이션의 성능을 모니터링하고 분석하는 데 유용하지만, 리소스 간의 관계를 시각화하는 데는 적합하지 않습니다.

따라서, 회사의 요구 사항을 가장 효율적으로 충족하는 솔루션은 옵션 C입니다.

### 필요한 학습 내용

1. **Workload Discovery on AWS**
   - Workload Discovery on AWS는 AWS 리소스의 아키텍처 다이어그램을 자동으로 생성하고, 리소스 간의 관계를 시각화하는 도구입니다.
   - 여러 AWS 계정과 리전에 걸쳐 있는 리소스의 관계를 효율적으로 매핑하고 시각화할 수 있습니다.

2. **AWS Systems Manager Inventory**
   - Systems Manager Inventory는 인벤토리 데이터를 수집하고 관리하는 데 유용합니다.
   - 리소스 간의 관계를 시각화하는 데는 적합하지 않습니다.

3. **AWS Step Functions**
   - Step Functions는 서버리스 워크플로를 조정하는 데 사용됩니다.
   - 워크로드 세부 정보를 수집할 수 있지만, 아키텍처 다이어그램을 수동으로 작성해야 하므로 운영 효율성이 떨어집니다.

4. **AWS X-Ray**
   - X-Ray는 애플리케이션의 성능을 모니터링하고 분석하는 데 유용합니다.
   - 리소스 간의 관계를 시각화하는 데는 적합하지 않습니다.

### 추가 학습 자료
- [Workload Discovery on AWS 공식 문서](https://aws.amazon.com/solutions/implementations/workload-discovery/)
- [AWS Systems Manager Inventory 공식 문서](https://docs.aws.amazon.com/ko_kr/systems-manager/latest/userguide/systems-manager-inventory.html)
- [AWS Step Functions 공식 문서](https://docs.aws.amazon.com/ko_kr/step-functions/latest/dg/welcome.html)
- [AWS X-Ray 공식 문서](https://docs.aws.amazon.com/ko_kr/xray/latest/devguide/aws-xray.html)

이 자료들을 통해 Workload Discovery on AWS, Systems Manager Inventory, Step Functions, X-Ray의 다양한 기능과 설정 방법을 이해하고, 특정 시나리오에서 최적의 솔루션을 선택하는 능력을 키울 수 있습니다.


# 455번
**정답은 B, D, F**입니다.

### 요구 사항 분석:
- **AWS 계정마다 다른 예산을 설정하고, 예산이 초과되었을 때 알림을 받고 리소스 생성 차단**을 자동으로 하려는 요구 사항입니다.
- **AWS Budgets**는 예산을 설정하고, 예산에 도달했을 때 알림을 보내거나 자동으로 예산 초과를 처리하는 작업을 설정할 수 있습니다.
- **예산 경고** 및 **자동 차단**을 위한 작업은 IAM 역할과 서비스 제어 정책(SCP)을 활용하여 관리할 수 있습니다.

각 옵션을 살펴보겠습니다:

1. **A. Use AWS Budgets to create a budget. Set the budget amount under the Cost and Usage Reports section of the required AWS accounts.**
   - **잘못된 옵션**: **Cost and Usage Reports**는 비용과 사용량에 대한 보고서를 제공하는 도구로, 예산을 설정하는 데 필요한 기능이 아닙니다. 예산을 설정하는 곳은 **Billing Dashboard**입니다.

2. **B. Use AWS Budgets to create a budget. Set the budget amount under the Billing dashboards of the required AWS accounts.**
   - **정답**: AWS Budgets는 **Billing Dashboard**에서 예산을 설정할 수 있습니다. 각 계정에서 예산을 설정하고 경고 알림을 받을 수 있습니다.

3. **C. Create an IAM user for AWS Budgets to run budget actions with the required permissions.**
   - **잘못된 옵션**: AWS Budgets는 **IAM 사용자**가 아니라 **IAM 역할**을 통해 예산 작업을 실행해야 합니다. 예산을 실행할 권한을 가진 **IAM 역할**을 설정해야 합니다.

4. **D. Create an IAM role for AWS Budgets to run budget actions with the required permissions.**
   - **정답**: AWS Budgets가 예산 작업을 실행하려면 **IAM 역할**이 필요합니다. 이 역할은 예산에 대한 자동화된 작업을 실행하는 데 필요한 권한을 가져야 합니다.

5. **E. Add an alert to notify the company when each account meets its budget threshold. Add a budget action that selects the IAM identity created with the appropriate config rule to prevent provisioning of additional resources.**
   - **잘못된 옵션**: 예산을 초과했을 때 리소스를 차단하려면 **IAM Identity**와 **Config Rule**을 사용하는 것보다는 **SCP**를 사용하는 것이 더 적합합니다. IAM Identity와 Config Rule은 리소스 생성 차단에 대한 올바른 방법이 아닙니다.

6. **F. Add an alert to notify the company when each account meets its budget threshold. Add a budget action that selects the IAM identity created with the appropriate service control policy (SCP) to prevent provisioning of additional resources.**
   - **정답**: 예산 경고가 발생했을 때 **SCP**를 활용하여 리소스 프로비저닝을 차단할 수 있습니다. 서비스 제어 정책(SCP)은 조직 내의 계정에서 리소스 프로비저닝을 제어하는 데 매우 유용합니다.

### 결론:
- **B.**와 **D.**는 예산을 설정하고 예산 작업을 실행하는 데 필요한 설정을 설명하며,
- **F.**는 예산이 초과되었을 때 **SCP**를 사용하여 리소스를 차단하는 방법을 설명합니다.

따라서 **B, D, F**가 요구 사항을 충족하는 올바른 조합입니다.

# 456번
**정답은 B. Create point-in-time Amazon Elastic Block Store (Amazon EBS) snapshots of the EC2 instances. Copy the snapshots to the second Region periodically.**

### 이유:
이 요구 사항을 **가장 비용 효율적인 방식**으로 해결하려면 **EBS 스냅샷을 사용하여 EC2 인스턴스 데이터를 백업하고, 이를 주기적으로 두 번째 리전으로 복사하는 방법**이 가장 적합합니다.

각 옵션을 살펴보겠습니다:

1. **A. Create a disaster recovery (DR) plan that has a similar number of EC2 instances in the second Region. Configure data replication.**
   - 이 방법은 **비용 효율적이지 않습니다**. 두 번째 리전에 **유사한 EC2 인스턴스를 배포**하여 데이터 복제를 설정하면, EC2 리소스를 **상시 실행**해야 하므로 비용이 많이 듭니다. 요구 사항에서는 **백업**만 필요한 것이므로, 이 방법은 불필요한 비용을 발생시킬 수 있습니다.

2. **B. Create point-in-time Amazon Elastic Block Store (Amazon EBS) snapshots of the EC2 instances. Copy the snapshots to the second Region periodically.**
   - **정답**: **EBS 스냅샷**을 생성하여 EC2 인스턴스의 상태를 백업하고, 이를 **주기적으로 두 번째 리전으로 복사**하면, **비용 효율적으로** 백업을 관리할 수 있습니다. EBS 스냅샷은 **포인트 인 타임** 백업을 제공하고, 다른 리전으로 복사할 수 있어 **저렴하고 효율적인** 백업 솔루션입니다.

3. **C. Create a backup plan by using AWS Backup. Configure cross-Region backup to the second Region for the EC2 instances.**
   - AWS Backup을 사용하면 **교차 리전 백업**을 설정할 수 있지만, AWS Backup은 **관리 서비스**이므로 **EBS 스냅샷 복사**보다는 더 복잡하고 비용이 높을 수 있습니다. 요구 사항이 **백업만 필요**하고, **비용을 최적화**하는 것이 목표라면 EBS 스냅샷을 사용하는 것이 더 나은 선택입니다.

4. **D. Deploy a similar number of EC2 instances in the second Region. Use AWS DataSync to transfer the data from the source Region to the second Region.**
   - 이 방법은 **불필요한 EC2 인스턴스**를 두 번째 리전에 배포해야 하므로 **비용 효율적이지 않습니다**. **AWS DataSync**는 **대량 데이터 전송**에 적합한 도구이지만, EC2 인스턴스 데이터를 **백업**하는 목적에는 **과도한 해결책**입니다.

### 결론:
**B. EBS 스냅샷을 사용하여 EC2 인스턴스의 데이터를 백업하고, 이를 주기적으로 두 번째 리전으로 복사하는 방법**이 **비용 효율적이고 간단하며 요구 사항을 충족**하는 최적의 솔루션입니다.

# 457번
### 정답
C. Use AWS Transfer Family to transfer the data. Create an AWS Lambda function for IdP authentication.

### 해설
AWS Transfer Family는 SFTP, FTPS, FTP 및 AS2와 같은 프로토콜을 지원하여 데이터를 전송할 수 있는 관리형 서비스입니다. 또한, AWS Lambda를 사용하여 사용자 인증을 위한 커스텀 로직을 구현할 수 있습니다. 이 솔루션은 AS2 프로토콜을 지원하며, IdP를 통한 사용자 인증 요구 사항을 충족할 수 있습니다.

각 옵션을 자세히 살펴보면:

- **A. Use AWS DataSync to transfer the data. Create an AWS Lambda function for IdP authentication.**
  - AWS DataSync는 데이터 전송을 자동화하는 데 유용하지만, AS2 프로토콜을 지원하지 않습니다.

- **B. Use Amazon AppFlow flows to transfer the data. Create an Amazon Elastic Container Service (Amazon ECS) task for IdP authentication.**
  - Amazon AppFlow는 SaaS 애플리케이션 간의 데이터 전송을 자동화하는 데 유용하지만, AS2 프로토콜을 지원하지 않습니다.

- **C. Use AWS Transfer Family to transfer the data. Create an AWS Lambda function for IdP authentication.**
  - AWS Transfer Family는 AS2 프로토콜을 지원하며, AWS Lambda를 사용하여 사용자 인증을 위한 커스텀 로직을 구현할 수 있습니다. 이는 요구 사항을 가장 효율적으로 충족하는 솔루션입니다.

- **D. Use AWS Storage Gateway to transfer the data. Create an Amazon Cognito identity pool for IdP authentication.**
  - AWS Storage Gateway는 온프레미스 스토리지와 AWS 클라우드 간의 데이터 전송을 지원하지만, AS2 프로토콜을 지원하지 않습니다.

따라서, 회사의 요구 사항을 가장 효율적으로 충족하는 솔루션은 옵션 C입니다.

### 필요한 학습 내용

1. **AWS Transfer Family**
   - AWS Transfer Family는 SFTP, FTPS, FTP 및 AS2와 같은 프로토콜을 지원하여 데이터를 전송할 수 있는 관리형 서비스입니다.
   - AS2 프로토콜을 지원하며, 사용자 인증을 위한 커스텀 로직을 구현할 수 있습니다.

2. **AWS Lambda**
   - AWS Lambda는 서버리스 컴퓨팅 서비스로, 사용자 인증을 위한 커스텀 로직을 구현할 수 있습니다.
   - Transfer Family와 통합하여 사용자 인증을 처리할 수 있습니다.

3. **IdP 인증**
   - IdP를 사용하여 사용자 인증을 처리할 수 있습니다.
   - Lambda를 사용하여 IdP 인증 로직을 구현할 수 있습니다.

### 추가 학습 자료
- [AWS Transfer Family 공식 문서](https://docs.aws.amazon.com/ko_kr/transfer/latest/userguide/what-is-aws-transfer.html)
- [AWS Lambda 공식 문서](https://docs.aws.amazon.com/ko_kr/lambda/latest/dg/welcome.html)
- [IdP 인증 공식 문서](https://docs.aws.amazon.com/ko_kr/IAM/latest/UserGuide/id_roles_providers.html)

이 자료들을 통해 AWS Transfer Family, AWS Lambda, IdP 인증의 다양한 기능과 설정 방법을 이해하고, 특정 시나리오에서 최적의 솔루션을 선택하는 능력을 키울 수 있습니다.


# 463번
### 정답
C. Use AWS Lambda with a Python script

### 해설
AWS Lambda는 서버리스 컴퓨팅 서비스로, **짧은 시간 동안 실행되는 작업에 대해 비용 효율적인 솔루션을 제공**합니다. Lambda 함수는 사용한 만큼만 비용을 지불하며, 인프라 관리가 필요 없습니다. 주어진 시나리오에서 데이터 처리에 필요한 메모리와 실행 시간이 Lambda의 제한 내에 있으므로, Lambda를 사용하는 것이 가장 비용 효율적입니다.

각 옵션을 자세히 살펴보면:

- **A. Use AWS Glue with a Scala job**
  - AWS Glue는 데이터 처리 및 변환을 자동화하는 데 유용하지만, Lambda를 사용하는 것이 더 비용 효율적입니다.

- **B. Use Amazon EMR with an Apache Spark script**
  - Amazon EMR은 대규모 데이터 처리에 적합하지만, 작은 데이터 처리 작업에는 비용이 많이 들 수 있습니다.

- **C. Use AWS Lambda with a Python script**
  - Lambda는 서버리스 컴퓨팅 서비스로, 짧은 시간 동안 실행되는 작업에 대해 비용 효율적인 솔루션을 제공합니다. 주어진 시나리오에서 Lambda를 사용하는 것이 가장 비용 효율적입니다.

- **D. Use AWS Glue with a PySpark job**
  - AWS Glue는 데이터 처리 및 변환을 자동화하는 데 유용하지만, Lambda를 사용하는 것이 더 비용 효율적입니다.

따라서, 회사의 요구 사항을 가장 효율적으로 충족하는 솔루션은 옵션 C입니다.

### 필요한 학습 내용

1. **AWS Lambda**
   - Lambda는 서버리스 컴퓨팅 서비스로, 인프라 관리 없이 코드를 실행할 수 있습니다.
   - 사용한 만큼만 비용을 지불하며, 짧은 시간 동안 실행되는 작업에 대해 비용 효율적인 솔루션을 제공합니다.

2. **AWS Glue**
   - Glue는 데이터 처리 및 변환을 자동화하는 데 유용한 관리형 ETL 서비스입니다.
   - 대규모 데이터 처리에 적합하지만, 작은 데이터 처리 작업에는 비용이 많이 들 수 있습니다.

3. **Amazon EMR**
   - EMR은 대규모 데이터 처리에 적합한 관리형 클러스터 플랫폼입니다.
   - 작은 데이터 처리 작업에는 비용이 많이 들 수 있습니다.

### 추가 학습 자료
- [AWS Lambda 공식 문서](https://docs.aws.amazon.com/ko_kr/lambda/latest/dg/welcome.html)
- [AWS Glue 공식 문서](https://docs.aws.amazon.com/ko_kr/glue/latest/dg/what-is-glue.html)
- [Amazon EMR 공식 문서](https://docs.aws.amazon.com/ko_kr/emr/latest/ManagementGuide/emr-what-is-emr.html)

이 자료들을 통해 Lambda, Glue, EMR의 다양한 기능과 설정 방법을 이해하고, 특정 시나리오에서 최적의 솔루션을 선택하는 능력을 키울 수 있습니다.

# 464번
**정답은 A. Convert the existing database instance to a Multi-AZ deployment by modifying the database instance and specifying the Multi-AZ option.**

### 이유:
이 문제는 **RDS PostgreSQL Single-AZ** 인스턴스에서 **단일 장애 지점(Single Point of Failure)을 제거하고, 애플리케이션 코드 변경 없이 데이터베이스의 다운타임을 최소화**하려는 요구사항을 다루고 있습니다.

각 선택지를 살펴보겠습니다:

1. **A. Convert the existing database instance to a Multi-AZ deployment by modifying the database instance and specifying the Multi-AZ option.**
   - **정답**: 기존 **Single-AZ** 인스턴스를 **Multi-AZ** 배포로 변환하는 방법입니다. 이 방법은 **애플리케이션 코드 변경 없이** **가용성을 높이고**, **단일 장애 지점**을 제거하는 가장 효율적이고 간단한 방법입니다. **Multi-AZ 배포**는 AWS가 자동으로 **두 개의 AZ**에서 인스턴스를 복제하여 장애 발생 시 자동으로 **대체 인스턴스**로 전환됩니다. 이 옵션은 최소한의 작업으로 **내결함성**을 제공하며, **애플리케이션 다운타임을 최소화**할 수 있습니다.

2. **B. Create a new RDS Multi-AZ deployment. Take a snapshot of the current RDS instance and restore the new Multi-AZ deployment with the snapshot.**
   - **비효율적**: 새로운 **Multi-AZ 배포**를 만들고, **스냅샷**을 사용해 복구하는 방법입니다. 이 방법은 **다운타임**이 필요하며, **애플리케이션 코드 변경 없이** 기존 인스턴스를 Multi-AZ로 변환하는 것보다 더 복잡하고 시간이 소요됩니다. 또한, **데이터 손실 가능성**도 존재할 수 있습니다.

3. **C. Create a read-only replica of the PostgreSQL database in another Availability Zone. Use Amazon Route 53 weighted record sets to distribute requests across the databases.**
   - **비효율적**: 읽기 전용 복제본을 만들어 **Route 53**을 사용해 트래픽을 분배하는 방식은 **읽기 작업**에 대해서만 유효합니다. **쓰기 작업**에 대한 가용성 문제는 해결되지 않으며, **단일 장애 지점**을 제거하는 데 완전한 해결책이 되지 않습니다. 또한 **애플리케이션 코드 변경**이 필요할 수 있습니다.

4. **D. Place the RDS for PostgreSQL database in an Amazon EC2 Auto Scaling group with a minimum group size of two. Use Amazon Route 53 weighted record sets to distribute requests across instances.**
   - **비효율적**: RDS 인스턴스를 **EC2 Auto Scaling 그룹에 배치**하는 방법은 **RDS** 서비스의 사용 방식에 맞지 않으며, EC2 인스턴스에서 **데이터베이스 관리**를 해야 하는 복잡성을 초래합니다. 또한, **Route 53**을 사용해 트래픽을 분배하는 방식은 **RDS**가 제공하는 **Multi-AZ 기능**과 비교해 **가용성**을 제공하는 데 있어 더 복잡하고 관리적인 오버헤드가 커집니다.

### 결론:
**A**는 **AWS RDS의 기본 기능**인 **Multi-AZ 배포**를 통해 가용성과 내결함성을 **간단하고 효율적으로** 제공하며, **애플리케이션 코드 변경 없이** 단일 장애 지점을 제거할 수 있는 가장 적합한 방법입니다.

# 465번
### 정답
C. Use Provisioned IOPS SSD (io2) EBS volumes with Amazon Elastic Block Store (Amazon EBS) Multi-Attach

### 해설
Amazon EBS Multi-Attach 기능은 **여러 EC2 인스턴스에서 동시에 하나의 EBS 볼륨에 액세스할 수 있게** 해줍니다. 이 기능은 현재 Provisioned IOPS SSD (io2) 볼륨에서만 지원됩니다. io2 볼륨은 높은 성능과 안정성을 제공하므로, 여러 인스턴스에서 동시에 블록 스토리지에 쓰기 작업을 수행해야 하는 애플리케이션에 적합합니다.

각 옵션을 자세히 살펴보면:

- **A. Use General Purpose SSD (gp3) EBS volumes with Amazon Elastic Block Store (Amazon EBS) Multi-Attach**
  - gp3 볼륨은 Multi-Attach 기능을 지원하지 않습니다.

- **B. Use Throughput Optimized HDD (st1) EBS volumes with Amazon Elastic Block Store (Amazon EBS) Multi-Attach**
  - st1 볼륨은 Multi-Attach 기능을 지원하지 않습니다.

- **C. Use Provisioned IOPS SSD (io2) EBS volumes with Amazon Elastic Block Store (Amazon EBS) Multi-Attach**
  - io2 볼륨은 Multi-Attach 기능을 지원하며, 높은 성능과 안정성을 제공합니다. 이는 여러 인스턴스에서 동시에 블록 스토리지에 쓰기 작업을 수행해야 하는 애플리케이션에 적합합니다.

- **D. Use General Purpose SSD (gp2) EBS volumes with Amazon Elastic Block Store (Amazon EBS) Multi-Attach**
  - gp2 볼륨은 Multi-Attach 기능을 지원하지 않습니다.

따라서, 회사의 요구 사항을 가장 효율적으로 충족하는 솔루션은 옵션 C입니다.

### 필요한 학습 내용

1. **Amazon EBS Multi-Attach**
   - Multi-Attach 기능은 여러 EC2 인스턴스에서 동시에 하나의 EBS 볼륨에 액세스할 수 있게 해줍니다.
   - 현재 Provisioned IOPS SSD (io2) 볼륨에서만 지원됩니다.

2. **Provisioned IOPS SSD (io2)**
   - io2 볼륨은 높은 성능과 안정성을 제공하며, Multi-Attach 기능을 지원합니다.
   - 여러 인스턴스에서 동시에 블록 스토리지에 쓰기 작업을 수행해야 하는 애플리케이션에 적합합니다.

3. **General Purpose SSD (gp3)**
   - gp3 볼륨은 비용 효율적인 SSD 스토리지 옵션이지만, Multi-Attach 기능을 지원하지 않습니다.

4. **Throughput Optimized HDD (st1)**
   - st1 볼륨은 비용 효율적인 HDD 스토리지 옵션이지만, Multi-Attach 기능을 지원하지 않습니다.

### 추가 학습 자료
- [Amazon EBS Multi-Attach 공식 문서](https://docs.aws.amazon.com/ko_kr/AWSEC2/latest/UserGuide/ebs-volumes-multi.html)
- [Provisioned IOPS SSD (io2) 공식 문서](https://docs.aws.amazon.com/ko_kr/AWSEC2/latest/UserGuide/ebs-volume-types.html#io2-ebs-volumes)
- [General Purpose SSD (gp3) 공식 문서](https://docs.aws.amazon.com/ko_kr/AWSEC2/latest/UserGuide/ebs-volume-types.html#gp3-ebs-volumes)
- [Throughput Optimized HDD (st1) 공식 문서](https://docs.aws.amazon.com/ko_kr/AWSEC2/latest/UserGuide/ebs-volume-types.html#st1-ebs-volumes)

이 자료들을 통해 EBS Multi-Attach, io2, gp3, st1의 다양한 기능과 설정 방법을 이해하고, 특정 시나리오에서 최적의 솔루션을 선택하는 능력을 키울 수 있습니다.

# 467번
### 정답
B. Turn on discount sharing from the Billing Preferences section of the account console in the company's Organizations management account.

### 해설
AWS Organizations에서 할인 공유(discount sharing)를 활성화하면, 조직 내의 모든 계정이 Compute Savings Plan의 혜택을 공유할 수 있습니다. 이를 통해 Compute Savings Plan의 사용률을 최적화하고, 전체 조직의 비용을 절감할 수 있습니다. **할인 공유는 조직의 관리 계정에서 활성화해야 합니다.**

각 옵션을 자세히 살펴보면:

- **A. Turn on discount sharing from the Billing Preferences section of the account console in the member account that purchased the Compute Savings Plan.**
  - 할인 공유는 조직의 관리 계정에서 활성화해야 하므로, 멤버 계정에서 활성화하는 것은 적절하지 않습니다.

- **B. Turn on discount sharing from the Billing Preferences section of the account console in the company's Organizations management account.**
  - 조직의 관리 계정에서 할인 공유를 활성화하면, 조직 내의 모든 계정이 Compute Savings Plan의 혜택을 공유할 수 있습니다. 이는 Compute Savings Plan의 사용률을 최적화하는 데 가장 적절한 솔루션입니다.

- **C. Migrate additional compute workloads from another AWS account to the account that has the Compute Savings Plan.**
  - 추가적인 컴퓨팅 워크로드를 마이그레이션하는 것은 가능하지만, 할인 공유를 활성화하는 것이 더 효율적입니다.

- **D. Sell the excess Savings Plan commitment in the Reserved Instance Marketplace.**
  - Savings Plan은 Reserved Instance Marketplace에서 판매할 수 없습니다. 이는 Reserved Instances에만 해당됩니다.

따라서, 회사의 요구 사항을 가장 효율적으로 충족하는 솔루션은 옵션 B입니다.

### 필요한 학습 내용

1. **AWS Organizations**
   - AWS Organizations는 여러 AWS 계정을 중앙에서 관리할 수 있는 서비스입니다.
   - 할인 공유를 통해 조직 내의 모든 계정이 Compute Savings Plan의 혜택을 공유할 수 있습니다.

2. **Compute Savings Plan**
   - Compute Savings Plan은 특정 컴퓨팅 리소스에 대한 비용 절감을 제공하는 예약 요금제입니다.
   - 할인 공유를 통해 조직 내의 모든 계정이 Compute Savings Plan의 혜택을 공유할 수 있습니다.

3. **할인 공유 (Discount Sharing)**
   - 할인 공유를 활성화하면, 조직 내의 모든 계정이 Compute Savings Plan의 혜택을 공유할 수 있습니다.
   - 이는 조직의 관리 계정에서 활성화해야 합니다.

### 추가 학습 자료
- [AWS Organizations 공식 문서](https://docs.aws.amazon.com/ko_kr/organizations/latest/userguide/orgs_introduction.html)
- [Compute Savings Plan 공식 문서](https://docs.aws.amazon.com/ko_kr/savingsplans/latest/userguide/compute-savings-plans.html)
- [할인 공유 공식 문서](https://docs.aws.amazon.com/ko_kr/awsaccountbilling/latest/aboutv2/consolidated-billing.html#turnondiscountsharing)

이 자료들을 통해 AWS Organizations, Compute Savings Plan, 할인 공유의 다양한 기능과 설정 방법을 이해하고, 특정 시나리오에서 최적의 솔루션을 선택하는 능력을 키울 수 있습니다.

# 468번
### 정답
B. Design a REST API by using Amazon API Gateway. Host the application in Amazon Elastic Container Service (Amazon ECS) in a private subnet. Create a private VPC link for API Gateway to access Amazon ECS.

### 해설
Amazon API Gateway는 REST API를 설계하고, Amazon ECS에서 호스팅되는 백엔드 서비스에 액세스할 수 있는 기능을 제공합니다. **API Gateway와 Amazon ECS 간의 통신을 위해 VPC 링크를 생성**하면, **API Gateway가 프라이빗 VPC 서브넷에 있는 ECS 서비스에 안전하게 액세스**할 수 있습니다. 이는 **REST API를 통해 프론트엔드를 사용자에게 제공하고, 백엔드 서비스에 안전하게 액세스할 수 있는 가장 적절한 솔루션**입니다.

각 옵션을 자세히 살펴보면:

- **A. Design a WebSocket API by using Amazon API Gateway. Host the application in Amazon Elastic Container Service (Amazon ECS) in a private subnet. Create a private VPC link for API Gateway to access Amazon ECS.**
  - WebSocket API는 실시간 양방향 통신에 적합하지만, 이 시나리오에서는 REST API가 요구됩니다.

- **B. Design a REST API by using Amazon API Gateway. Host the application in Amazon Elastic Container Service (Amazon ECS) in a private subnet. Create a private VPC link for API Gateway to access Amazon ECS.**
  - REST API를 사용하여 프론트엔드를 제공하고, VPC 링크를 통해 API Gateway가 프라이빗 VPC 서브넷에 있는 ECS 서비스에 안전하게 액세스할 수 있습니다. 이는 요구 사항을 가장 효율적으로 충족하는 솔루션입니다.

- **C. Design a WebSocket API by using Amazon API Gateway. Host the application in Amazon Elastic Container Service (Amazon ECS) in a private subnet. Create a security group for API Gateway to access Amazon ECS.**
  - WebSocket API는 실시간 양방향 통신에 적합하지만, 이 시나리오에서는 REST API가 요구됩니다. 또한, 보안 그룹만으로는 API Gateway와 ECS 간의 안전한 통신을 보장하기 어렵습니다.

- **D. Design a REST API by using Amazon API Gateway. Host the application in Amazon Elastic Container Service (Amazon ECS) in a private subnet. Create a security group for API Gateway to access Amazon ECS.**
  - REST API를 사용하는 것은 적절하지만, 보안 그룹만으로는 API Gateway와 ECS 간의 안전한 통신을 보장하기 어렵습니다. VPC 링크를 사용하는 것이 더 적절합니다.

따라서, 회사의 요구 사항을 가장 효율적으로 충족하는 솔루션은 옵션 B입니다.

### 필요한 학습 내용

1. **Amazon API Gateway**
   - API Gateway는 REST API를 설계하고, 백엔드 서비스에 액세스할 수 있는 기능을 제공합니다.
   - VPC 링크를 통해 프라이빗 VPC 서브넷에 있는 서비스에 안전하게 액세스할 수 있습니다.

2. **Amazon Elastic Container Service (ECS)**
   - ECS는 컨테이너화된 애플리케이션을 관리하고 배포할 수 있는 서비스입니다.
   - 프라이빗 VPC 서브넷에 ECS 서비스를 호스팅할 수 있습니다.

3. **VPC 링크**
   - VPC 링크는 API Gateway와 프라이빗 VPC 서브넷에 있는 서비스 간의 안전한 통신을 보장합니다.
   - API Gateway가 프라이빗 VPC 서브넷에 있는 ECS 서비스에 액세스할 수 있도록 합니다.

### 추가 학습 자료
- [Amazon API Gateway 공식 문서](https://docs.aws.amazon.com/ko_kr/apigateway/latest/developerguide/welcome.html)
- [Amazon Elastic Container Service (ECS) 공식 문서](https://docs.aws.amazon.com/ko_kr/AmazonECS/latest/developerguide/Welcome.html)
- [VPC 링크 공식 문서](https://docs.aws.amazon.com/ko_kr/apigateway/latest/developerguide/getting-started-with-private-integration.html)

이 자료들을 통해 API Gateway, ECS, VPC 링크의 다양한 기능과 설정 방법을 이해하고, 특정 시나리오에서 최적의 솔루션을 선택하는 능력을 키울 수 있습니다.

# 470번
### 정답
D. Create an egress-only internet gateway and make it the destination of the subnet's route table

### 해설
Egress-Only Internet Gateway는 IPv6 트래픽에 대해 아웃바운드 인터넷 액세스를 제공하면서, 외부에서의 인바운드 트래픽을 차단하는 데 사용됩니다. 이는 회사의 보안 정책을 준수하면서 EC2 인스턴스가 외부 애플리케이션과 통신할 수 있도록 합니다.

각 옵션을 자세히 살펴보면:

- **A. Create a NAT gateway and make it the destination of the subnet's route table**
  - NAT 게이트웨이는 IPv4 트래픽에 대해 아웃바운드 인터넷 액세스를 제공하지만, IPv6 트래픽에는 적합하지 않습니다.

- **B. Create an internet gateway and make it the destination of the subnet's route table**
  - 인터넷 게이트웨이는 인바운드 및 아웃바운드 트래픽을 모두 허용하므로, 회사의 보안 정책을 준수하지 않습니다.

- **C. Create a virtual private gateway and make it the destination of the subnet's route table**
  - 가상 프라이빗 게이트웨이는 VPC와 온프레미스 네트워크 간의 연결을 제공하는 데 사용되며, 인터넷 액세스에는 적합하지 않습니다.

- **D. Create an egress-only internet gateway and make it the destination of the subnet's route table**
  - Egress-Only Internet Gateway는 IPv6 트래픽에 대해 아웃바운드 인터넷 액세스를 제공하면서, 외부에서의 인바운드 트래픽을 차단합니다. 이는 회사의 보안 정책을 준수하면서 EC2 인스턴스가 외부 애플리케이션과 통신할 수 있도록 합니다.

따라서, 회사의 요구 사항을 가장 효율적으로 충족하는 솔루션은 옵션 D입니다.

### 필요한 학습 내용

1. **Egress-Only Internet Gateway**
   - Egress-Only Internet Gateway는 IPv6 트래픽에 대해 아웃바운드 인터넷 액세스를 제공하면서, 외부에서의 인바운드 트래픽을 차단합니다.
   - 이는 외부 애플리케이션과의 통신을 허용하면서 보안 정책을 준수하는 데 적합합니다.

2. **NAT Gateway**
   - NAT 게이트웨이는 IPv4 트래픽에 대해 아웃바운드 인터넷 액세스를 제공하지만, IPv6 트래픽에는 적합하지 않습니다.

3. **Internet Gateway**
   - 인터넷 게이트웨이는 인바운드 및 아웃바운드 트래픽을 모두 허용하므로, 외부에서의 인바운드 트래픽을 차단하는 데 적합하지 않습니다.

4. **Virtual Private Gateway**
   - 가상 프라이빗 게이트웨이는 VPC와 온프레미스 네트워크 간의 연결을 제공하는 데 사용되며, 인터넷 액세스에는 적합하지 않습니다.

### 추가 학습 자료
- [Egress-Only Internet Gateway 공식 문서](https://docs.aws.amazon.com/ko_kr/vpc/latest/userguide/egress-only-internet-gateway.html)
- [NAT Gateway 공식 문서](https://docs.aws.amazon.com/ko_kr/vpc/latest/userguide/vpc-nat-gateway.html)
- [Internet Gateway 공식 문서](https://docs.aws.amazon.com/ko_kr/vpc/latest/userguide/VPC_Internet_Gateway.html)
- [Virtual Private Gateway 공식 문서](https://docs.aws.amazon.com/ko_kr/vpn/latest/s2svpn/VPC_VPN.html)

이 자료들을 통해 Egress-Only Internet Gateway, NAT Gateway, Internet Gateway, Virtual Private Gateway의 다양한 기능과 설정 방법을 이해하고, 특정 시나리오에서 최적의 솔루션을 선택하는 능력을 키울 수 있습니다.


# 475번
### 정답
C. Amazon Elastic File System (Amazon EFS) with the Standard storage class

### 해설
Amazon Elastic File System (Amazon EFS)는 고가용성과 내구성을 제공하는 완전 관리형 파일 시스템입니다. EFS는 각 가용 영역에 마운트 타겟을 제공하며, AWS Backup을 사용하여 다른 리전으로 데이터를 복제할 수 있습니다. EFS는 여러 가용 영역에 걸쳐 데이터를 자동으로 복제하여 높은 내구성을 보장하며, AWS Backup을 통해 8시간의 RPO를 충족할 수 있습니다.

각 옵션을 자세히 살펴보면:

- **A. Amazon FSx for Windows File Server with a Multi-AZ deployment**
  - FSx for Windows File Server는 Windows 기반 애플리케이션에 적합하지만, EFS가 더 높은 내구성과 가용성을 제공합니다.

- **B. Amazon FSx for NetApp ONTAP with a Multi-AZ deployment**
  - FSx for NetApp ONTAP는 고성능 파일 시스템을 제공하지만, EFS가 더 높은 내구성과 가용성을 제공합니다.

- **C. Amazon Elastic File System (Amazon EFS) with the Standard storage class**
  - EFS는 고가용성과 내구성을 제공하며, 각 가용 영역에 마운트 타겟을 제공합니다. AWS Backup을 사용하여 다른 리전으로 데이터를 복제할 수 있으며, 8시간의 RPO를 충족할 수 있습니다.

- **D. Amazon FSx for OpenZFS**
  - FSx for OpenZFS는 고성능 파일 시스템을 제공하지만, EFS가 더 높은 내구성과 가용성을 제공합니다.

따라서, 회사의 요구 사항을 가장 효율적으로 충족하는 솔루션은 옵션 C입니다.

### 필요한 학습 내용

1. **Amazon Elastic File System (EFS)**
   - EFS는 고가용성과 내구성을 제공하는 완전 관리형 파일 시스템입니다.
   - 각 가용 영역에 마운트 타겟을 제공하며, AWS Backup을 사용하여 다른 리전으로 데이터를 복제할 수 있습니다.

2. **AWS Backup**
   - AWS Backup은 여러 AWS 서비스의 데이터를 백업하고 복구할 수 있는 관리형 서비스입니다.
   - EFS 데이터를 다른 리전으로 복제하여 8시간의 RPO를 충족할 수 있습니다.

3. **Amazon FSx**
   - FSx는 고성능 파일 시스템을 제공하는 서비스입니다.
   - FSx for Windows File Server, FSx for NetApp ONTAP, FSx for OpenZFS는 각각 특정 사용 사례에 적합합니다.

### 추가 학습 자료
- [Amazon Elastic File System (EFS) 공식 문서](https://docs.aws.amazon.com/ko_kr/efs/latest/ug/whatisefs.html)
- [AWS Backup 공식 문서](https://docs.aws.amazon.com/ko_kr/aws-backup/latest/devguide/whatisbackup.html)
- [Amazon FSx 공식 문서](https://docs.aws.amazon.com/ko_kr/fsx/latest/WindowsGuide/what-is.html)

이 자료들을 통해 EFS, AWS Backup, FSx의 다양한 기능과 설정 방법을 이해하고, 특정 시나리오에서 최적의 솔루션을 선택하는 능력을 키울 수 있습니다.

# 476번
### 정답
C. Create an IAM policy that grants least privilege permission. Attach the policy to the IAM groups

### 해설
IAM 그룹에 최소 권한 정책을 적용하여 사용자에게 필요한 최소한의 권한만 부여하는 것이 가장 안전한 방법입니다. 이를 통해 각 부서의 사용자에게 필요한 권한만 부여할 수 있으며, 권한 남용을 방지할 수 있습니다.

각 옵션을 자세히 살펴보면:

- **A. Apply service control policies (SCPs) to manage access permissions**
  - SCP는 AWS Organizations에서 계정 수준의 권한을 관리하는 데 사용되며, 개별 사용자나 그룹에 대한 세부 권한 관리를 위해서는 적합하지 않습니다.

- **B. Create IAM roles that have least privilege permission. Attach the roles to the IAM groups**
  - IAM 역할은 주로 AWS 리소스에 대한 임시 권한을 부여하는 데 사용됩니다. IAM 그룹에 직접 정책을 적용하는 것이 더 적절합니다.

- **C. Create an IAM policy that grants least privilege permission. Attach the policy to the IAM groups**
  - IAM 정책을 사용하여 최소 권한을 부여하고, 이를 IAM 그룹에 적용하면 각 부서의 사용자에게 필요한 최소한의 권한만 부여할 수 있습니다. 이는 가장 안전한 방법입니다.

- **D. Create IAM roles. Associate the roles with a permissions boundary that defines the maximum permissions**
  - 권한 경계를 사용하여 최대 권한을 정의할 수 있지만, IAM 그룹에 직접 정책을 적용하는 것이 더 간단하고 효과적입니다.

따라서, 회사의 요구 사항을 가장 효율적으로 충족하는 솔루션은 옵션 C입니다.

### 필요한 학습 내용

1. **IAM 그룹**
   - IAM 그룹은 여러 사용자에게 동일한 권한을 부여할 수 있는 방법입니다.
   - 그룹에 정책을 적용하여 사용자에게 필요한 권한을 부여할 수 있습니다.

2. **IAM 정책**
   - IAM 정책은 AWS 리소스에 대한 권한을 정의하는 JSON 문서입니다.
   - 최소 권한 원칙을 적용하여 사용자에게 필요한 최소한의 권한만 부여할 수 있습니다.

3. **서비스 제어 정책 (SCP)**
   - SCP는 AWS Organizations에서 계정 수준의 권한을 관리하는 데 사용됩니다.
   - 개별 사용자나 그룹에 대한 세부 권한 관리를 위해서는 적합하지 않습니다.

4. **IAM 역할**
   - IAM 역할은 AWS 리소스에 대한 임시 권한을 부여하는 데 사용됩니다.
   - 주로 다른 AWS 서비스나 계정 간의 액세스를 위해 사용됩니다.

### 추가 학습 자료
- [IAM 그룹 공식 문서](https://docs.aws.amazon.com/ko_kr/IAM/latest/UserGuide/id_groups.html)
- [IAM 정책 공식 문서](https://docs.aws.amazon.com/ko_kr/IAM/latest/UserGuide/access_policies.html)
- [서비스 제어 정책 (SCP) 공식 문서](https://docs.aws.amazon.com/ko_kr/organizations/latest/userguide/orgs_manage_policies_scp.html)
- [IAM 역할 공식 문서](https://docs.aws.amazon.com/ko_kr/IAM/latest/UserGuide/id_roles.html)

이 자료들을 통해 IAM 그룹, IAM 정책, SCP, IAM 역할의 다양한 기능과 설정 방법을 이해하고, 특정 시나리오에서 최적의 솔루션을 선택하는 능력을 키울 수 있습니다.


# 484번
### 정답
A. Create a new organization in AWS Organizations with all features turned on. Create the new AWS accounts in the organization.
E. Set up AWS IAM Identity Center (AWS Single Sign-On) in the organization. Configure IAM Identity Center, and integrate it with the company's corporate directory service.

### 해설
AWS Organizations를 사용하여 여러 AWS 계정을 중앙에서 관리하고, AWS IAM Identity Center (AWS Single Sign-On)를 사용하여 중앙 집중식 인증을 설정하는 것이 가장 적절한 솔루션입니다. AWS Organizations를 사용하면 여러 계정을 중앙에서 관리할 수 있으며, IAM Identity Center를 사용하면 회사의 중앙 디렉터리 서비스와 통합하여 인증을 관리할 수 있습니다.

각 옵션을 자세히 살펴보면:

- **A. Create a new organization in AWS Organizations with all features turned on. Create the new AWS accounts in the organization.**
  - AWS Organizations를 사용하여 여러 계정을 중앙에서 관리할 수 있습니다. 모든 기능을 활성화하면 서비스 제어 정책(SCP) 등 다양한 기능을 사용할 수 있습니다.

- **B. Set up an Amazon Cognito identity pool. Configure AWS IAM Identity Center (AWS Single Sign-On) to accept Amazon Cognito authentication.**
  - Amazon Cognito는 주로 애플리케이션 사용자 인증에 사용되며, 중앙 디렉터리 서비스와의 통합에는 적합하지 않습니다.

- **C. Configure a service control policy (SCP) to manage the AWS accounts. Add AWS IAM Identity Center (AWS Single Sign-On) to AWS Directory Service.**
  - SCP는 계정의 권한을 관리하는 데 사용되지만, 인증을 관리하는 데는 적합하지 않습니다. 또한, IAM Identity Center를 AWS Directory Service에 추가하는 것은 적절하지 않습니다.

- **D. Create a new organization in AWS Organizations. Configure the organization's authentication mechanism to use AWS Directory Service directly.**
  - AWS Organizations는 직접 인증 메커니즘을 제공하지 않습니다. IAM Identity Center를 사용하여 중앙 디렉터리 서비스와 통합하는 것이 더 적절합니다.

- **E. Set up AWS IAM Identity Center (AWS Single Sign-On) in the organization. Configure IAM Identity Center, and integrate it with the company's corporate directory service.**
  - IAM Identity Center를 사용하여 중앙 디렉터리 서비스와 통합하면, 여러 AWS 계정에 대한 중앙 집중식 인증을 설정할 수 있습니다.

따라서, 회사의 요구 사항을 가장 효율적으로 충족하는 솔루션은 옵션 A와 E입니다.

### 필요한 학습 내용

1. **AWS Organizations**
   - 여러 AWS 계정을 중앙에서 관리할 수 있는 서비스입니다.
   - 모든 기능을 활성화하면 서비스 제어 정책(SCP) 등 다양한 기능을 사용할 수 있습니다.

2. **AWS IAM Identity Center (AWS Single Sign-On)**
   - 여러 AWS 계정에 대한 중앙 집중식 인증을 설정할 수 있는 서비스입니다.
   - 회사의 중앙 디렉터리 서비스와 통합하여 인증을 관리할 수 있습니다.

3. **Amazon Cognito**
   - 주로 애플리케이션 사용자 인증에 사용됩니다.
   - 중앙 디렉터리 서비스와의 통합에는 적합하지 않습니다.

4. **서비스 제어 정책 (SCP)**
   - 계정의 권한을 관리하는 데 사용됩니다.
   - 인증을 관리하는 데는 적합하지 않습니다.

### 추가 학습 자료
- [AWS Organizations 공식 문서](https://docs.aws.amazon.com/ko_kr/organizations/latest/userguide/orgs_introduction.html)
- [AWS IAM Identity Center (AWS Single Sign-On) 공식 문서](https://docs.aws.amazon.com/ko_kr/singlesignon/latest/userguide/what-is.html)
- [Amazon Cognito 공식 문서](https://docs.aws.amazon.com/ko_kr/cognito/latest/developerguide/what-is-amazon-cognito.html)
- [서비스 제어 정책 (SCP) 공식 문서](https://docs.aws.amazon.com/ko_kr/organizations/latest/userguide/orgs_manage_policies_scp.html)

이 자료들을 통해 AWS Organizations, IAM Identity Center, Amazon Cognito, SCP의 다양한 기능과 설정 방법을 이해하고, 특정 시나리오에서 최적의 솔루션을 선택하는 능력을 키울 수 있습니다.


# 485번
### 정답
A. Store the video archives in Amazon S3 Glacier and use Expedited retrievals.

### 해설
Amazon S3 Glacier는 장기 보관 및 아카이빙을 위한 저비용 스토리지 서비스입니다. S3 Glacier는 데이터를 거의 사용하지 않는 경우에 매우 비용 효율적이며, 필요할 때 데이터를 빠르게 복원할 수 있는 옵션을 제공합니다. Expedited retrievals를 사용하면 데이터를 최대 5분 내에 복원할 수 있습니다. 이는 비용을 최소화하면서도 필요한 경우 데이터를 빠르게 복원할 수 있는 가장 적합한 솔루션입니다.

각 옵션을 자세히 살펴보면:

- **A. Store the video archives in Amazon S3 Glacier and use Expedited retrievals.**
  - S3 Glacier는 저비용 스토리지 서비스로, Expedited retrievals를 사용하면 데이터를 최대 5분 내에 복원할 수 있습니다. 이는 비용을 최소화하면서도 필요한 경우 데이터를 빠르게 복원할 수 있는 가장 적합한 솔루션입니다.

- **B. Store the video archives in Amazon S3 Glacier and use Standard retrievals.**
  - Standard retrievals는 데이터 복원 시간이 몇 시간까지 걸릴 수 있으므로, 5분 내에 데이터를 복원해야 하는 요구 사항을 충족하지 못합니다.

- **C. Store the video archives in Amazon S3 Standard-Infrequent Access (S3 Standard-IA).**
  - S3 Standard-IA는 자주 액세스되지 않는 데이터를 위한 스토리지 클래스이지만, S3 Glacier보다 비용이 더 높습니다.

- **D. Store the video archives in Amazon S3 One Zone-Infrequent Access (S3 One Zone-IA).**
  - S3 One Zone-IA는 단일 가용 영역에 데이터를 저장하며, S3 Glacier보다 비용이 더 높습니다. 또한, 단일 가용 영역에 데이터를 저장하는 것은 내구성 측면에서 위험할 수 있습니다.

따라서, 회사의 요구 사항을 가장 효율적으로 충족하는 솔루션은 옵션 A입니다.

### 필요한 학습 내용

1. **Amazon S3 Glacier**
   - S3 Glacier는 장기 보관 및 아카이빙을 위한 저비용 스토리지 서비스입니다.
   - Expedited retrievals를 사용하면 데이터를 최대 5분 내에 복원할 수 있습니다.

2. **Standard retrievals**
   - Standard retrievals는 데이터 복원 시간이 몇 시간까지 걸릴 수 있습니다.
   - 5분 내에 데이터를 복원해야 하는 요구 사항을 충족하지 못합니다.

3. **S3 Standard-Infrequent Access (S3 Standard-IA)**
   - S3 Standard-IA는 자주 액세스되지 않는 데이터를 위한 스토리지 클래스입니다.
   - S3 Glacier보다 비용이 더 높습니다.

4. **S3 One Zone-Infrequent Access (S3 One Zone-IA)**
   - S3 One Zone-IA는 단일 가용 영역에 데이터를 저장하며, S3 Glacier보다 비용이 더 높습니다.
   - 단일 가용 영역에 데이터를 저장하는 것은 내구성 측면에서 위험할 수 있습니다.

### 추가 학습 자료
- [Amazon S3 Glacier 공식 문서](https://docs.aws.amazon.com/ko_kr/amazonglacier/latest/dev/introduction.html)
- [S3 Standard-Infrequent Access (S3 Standard-IA) 공식 문서](https://docs.aws.amazon.com/ko_kr/AmazonS3/latest/dev/storage-class-intro.html#sc-infrequent-access)
- [S3 One Zone-Infrequent Access (S3 One Zone-IA) 공식 문서](https://docs.aws.amazon.com/ko_kr/AmazonS3/latest/dev/storage-class-intro.html#sc-one-zone-ia)

이 자료들을 통해 S3 Glacier, S3 Standard-IA, S3 One Zone-IA의 다양한 기능과 설정 방법을 이해하고, 특정 시나리오에서 최적의 솔루션을 선택하는 능력을 키울 수 있습니다.


# 486번
### 정답
A. Use Amazon S3 to host static content. Use Amazon Elastic Container Service (Amazon ECS) with AWS Fargate for compute power. Use a managed Amazon RDS cluster for the database.

### 해설
이 솔루션은 세 가지 요구 사항을 모두 충족합니다: 배포를 간소화하고 운영 비용을 줄이는 것입니다.

1. **Amazon S3**는 정적 웹사이트 콘텐츠를 호스팅하는 데 매우 비용 효율적이고 간단한 방법입니다.
2. **Amazon ECS with AWS Fargate**는 서버리스 컨테이너 관리 서비스로, 인프라를 관리할 필요 없이 컨테이너를 실행할 수 있습니다. 이는 운영 비용을 줄이고 배포를 간소화합니다.
3. **Amazon RDS**는 관리형 관계형 데이터베이스 서비스로, 데이터베이스 관리 작업을 자동화하여 운영 비용을 줄입니다.

각 옵션을 자세히 살펴보면:

- **A. Use Amazon S3 to host static content. Use Amazon Elastic Container Service (Amazon ECS) with AWS Fargate for compute power. Use a managed Amazon RDS cluster for the database.**
  - 이 옵션은 정적 콘텐츠 호스팅, 컨테이너화된 애플리케이션 실행, 관리형 데이터베이스 사용을 모두 포함하여 배포를 간소화하고 운영 비용을 줄이는 데 가장 적합합니다.

- **B. Use Amazon CloudFront to host static content. Use Amazon Elastic Container Service (Amazon ECS) with Amazon EC2 for compute power. Use a managed Amazon RDS cluster for the database.**
  - CloudFront는 정적 콘텐츠를 캐시하는 데 유용하지만, S3와 함께 사용하는 것이 더 일반적입니다. 또한, EC2를 사용하면 인프라 관리가 필요하므로 운영 비용이 증가할 수 있습니다.

- **C. Use Amazon S3 to host static content. Use Amazon Elastic Kubernetes Service (Amazon EKS) with AWS Fargate for compute power. Use a managed Amazon RDS cluster for the database.**
  - EKS는 Kubernetes 클러스터를 관리하는 데 유용하지만, ECS가 더 간단하고 비용 효율적일 수 있습니다.

- **D. Use Amazon EC2 Reserved Instances to host static content. Use Amazon Elastic Kubernetes Service (Amazon EKS) with Amazon EC2 for compute power. Use a managed Amazon RDS cluster for the database.**
  - EC2 Reserved Instances를 사용하면 인프라 관리가 필요하므로 운영 비용이 증가할 수 있습니다. 또한, EKS와 EC2를 사용하는 것은 복잡성을 증가시킬 수 있습니다.

따라서, 회사의 요구 사항을 가장 효율적으로 충족하는 솔루션은 옵션 A입니다.

### 필요한 학습 내용

1. **Amazon S3**
   - 정적 웹사이트 콘텐츠를 호스팅하는 데 매우 비용 효율적이고 간단한 방법입니다.

2. **Amazon Elastic Container Service (ECS) with AWS Fargate**
   - 서버리스 컨테이너 관리 서비스로, 인프라를 관리할 필요 없이 컨테이너를 실행할 수 있습니다.
   - 운영 비용을 줄이고 배포를 간소화합니다.

3. **Amazon RDS**
   - 관리형 관계형 데이터베이스 서비스로, 데이터베이스 관리 작업을 자동화하여 운영 비용을 줄입니다.

4. **Amazon CloudFront**
   - 정적 콘텐츠를 캐시하는 데 유용하지만, S3와 함께 사용하는 것이 더 일반적입니다.

5. **Amazon Elastic Kubernetes Service (EKS)**
   - Kubernetes 클러스터를 관리하는 데 유용하지만, ECS가 더 간단하고 비용 효율적일 수 있습니다.

6. **Amazon EC2 Reserved Instances**
   - 인프라 관리가 필요하므로 운영 비용이 증가할 수 있습니다.

### 추가 학습 자료
- [Amazon S3 공식 문서](https://docs.aws.amazon.com/ko_kr/AmazonS3/latest/dev/WebsiteHosting.html)
- [Amazon ECS with AWS Fargate 공식 문서](https://docs.aws.amazon.com/ko_kr/AmazonECS/latest/developerguide/what-is-fargate.html)
- [Amazon RDS 공식 문서](https://docs.aws.amazon.com/ko_kr/AmazonRDS/latest/UserGuide/Welcome.html)
- [Amazon CloudFront 공식 문서](https://docs.aws.amazon.com/ko_kr/AmazonCloudFront/latest/DeveloperGuide/Introduction.html)
- [Amazon EKS 공식 문서](https://docs.aws.amazon.com/ko_kr/eks/latest/userguide/what-is-eks.html)
- [Amazon EC2 Reserved Instances 공식 문서](https://docs.aws.amazon.com/ko_kr/AWSEC2/latest/UserGuide/ec2-reserved-instances.html)

이 자료들을 통해 S3, ECS with Fargate, RDS, CloudFront, EKS, EC2 Reserved Instances의 다양한 기능과 설정 방법을 이해하고, 특정 시나리오에서 최적의 솔루션을 선택하는 능력을 키울 수 있습니다.


# 487번
### 정답
C. Amazon Elastic File System (Amazon EFS) with multiple mount targets

### 해설
Amazon Elastic File System (Amazon EFS)는 완전 관리형 파일 시스템으로, 여러 Linux 인스턴스에서 동시에 액세스할 수 있으며, 온프레미스 환경에서도 네이티브 프로토콜을 통해 마운트할 수 있습니다. EFS는 고가용성과 확장성을 제공하며, 최소 크기 요구 사항이 없습니다. 여러 마운트 타겟을 사용하면 여러 가용 영역에 걸쳐 고가용성을 보장할 수 있습니다.

각 옵션을 자세히 살펴보면:

- **A. Amazon FSx Multi-AZ deployments**
  - Amazon FSx는 고성능 파일 시스템을 제공하지만, EFS가 더 적합한 요구 사항을 충족합니다.

- **B. Amazon Elastic Block Store (Amazon EBS) Multi-Attach volumes**
  - EBS Multi-Attach 볼륨은 여러 인스턴스에서 동시에 액세스할 수 있지만, 파일 시스템으로서의 기능을 제공하지 않으며, 온프레미스 환경에서 네이티브 프로토콜을 통해 마운트할 수 없습니다.

- **C. Amazon Elastic File System (Amazon EFS) with multiple mount targets**
  - EFS는 여러 Linux 인스턴스에서 동시에 액세스할 수 있으며, 온프레미스 환경에서도 네이티브 프로토콜을 통해 마운트할 수 있습니다. 여러 마운트 타겟을 사용하면 고가용성을 보장할 수 있습니다.

- **D. Amazon Elastic File System (Amazon EFS) with a single mount target and multiple access points**
  - 단일 마운트 타겟을 사용하는 경우 고가용성을 보장하기 어렵습니다. 여러 마운트 타겟을 사용하는 것이 더 적절합니다.

따라서, 회사의 요구 사항을 가장 효율적으로 충족하는 솔루션은 옵션 C입니다.

### 필요한 학습 내용

1. **Amazon Elastic File System (EFS)**
   - 완전 관리형 파일 시스템으로, 여러 Linux 인스턴스에서 동시에 액세스할 수 있습니다.
   - 온프레미스 환경에서도 네이티브 프로토콜을 통해 마운트할 수 있습니다.
   - 고가용성과 확장성을 제공하며, 최소 크기 요구 사항이 없습니다.

2. **Amazon FSx**
   - 고성능 파일 시스템을 제공하지만, EFS가 더 적합한 요구 사항을 충족합니다.

3. **Amazon Elastic Block Store (EBS) Multi-Attach**
   - 여러 인스턴스에서 동시에 액세스할 수 있지만, 파일 시스템으로서의 기능을 제공하지 않습니다.
   - 온프레미스 환경에서 네이티브 프로토콜을 통해 마운트할 수 없습니다.

4. **EFS 마운트 타겟**
   - 여러 마운트 타겟을 사용하면 여러 가용 영역에 걸쳐 고가용성을 보장할 수 있습니다.

### 추가 학습 자료
- [Amazon Elastic File System (EFS) 공식 문서](https://docs.aws.amazon.com/ko_kr/efs/latest/ug/whatisefs.html)
- [Amazon FSx 공식 문서](https://docs.aws.amazon.com/ko_kr/fsx/latest/WindowsGuide/what-is.html)
- [Amazon Elastic Block Store (EBS) Multi-Attach 공식 문서](https://docs.aws.amazon.com/ko_kr/AWSEC2/latest/UserGuide/ebs-volumes-multi.html)

이 자료들을 통해 EFS, FSx, EBS Multi-Attach의 다양한 기능과 설정 방법을 이해하고, 특정 시나리오에서 최적의 솔루션을 선택하는 능력을 키울 수 있습니다.


# 489번
### 정답
C. Configure an Amazon SNS dead letter queue that has an Amazon Simple Queue Service (Amazon SQS) target with a retention period of 14 days.

### 해설
Amazon SNS는 메시지를 전송할 때 실패한 메시지를 처리하기 위해 Dead Letter Queue(DLQ)를 지원합니다. Amazon SQS는 메시지를 최대 14일 동안 보관할 수 있는 큐를 제공하므로, SNS DLQ의 타겟으로 SQS를 설정하면 실패한 메시지를 14일 동안 보관하고 분석할 수 있습니다. 이는 최소한의 개발 노력으로 요구 사항을 충족하는 가장 적합한 솔루션입니다.

각 옵션을 자세히 살펴보면:

- **A. Configure an Amazon SNS dead letter queue that has an Amazon Kinesis Data Stream target with a retention period of 14 days.**
  - Kinesis Data Stream은 실시간 데이터 스트리밍을 위한 서비스로, 메시지 보관 및 분석을 위해서는 추가 개발이 필요합니다.

- **B. Add an Amazon Simple Queue Service (Amazon SQS) queue with a retention period of 14 days between the application and Amazon SNS.**
  - SQS 큐를 SNS와 애플리케이션 사이에 추가하는 것은 불필요한 복잡성을 초래할 수 있습니다. SNS DLQ를 사용하는 것이 더 적절합니다.

- **C. Configure an Amazon SNS dead letter queue that has an Amazon Simple Queue Service (Amazon SQS) target with a retention period of 14 days.**
  - SNS DLQ의 타겟으로 SQS를 설정하면 실패한 메시지를 14일 동안 보관하고 분석할 수 있습니다. 이는 최소한의 개발 노력으로 요구 사항을 충족하는 가장 적합한 솔루션입니다.

- **D. Configure an Amazon SNS dead letter queue that has an Amazon DynamoDB target with a TTL attribute set for a retention period of 14 days.**
  - DynamoDB를 사용하여 메시지를 보관할 수 있지만, SQS를 사용하는 것이 더 간단하고 적절합니다.

따라서, 회사의 요구 사항을 가장 효율적으로 충족하는 솔루션은 옵션 C입니다.

### 필요한 학습 내용

1. **Amazon SNS Dead Letter Queue (DLQ)**
   - SNS는 메시지를 전송할 때 실패한 메시지를 처리하기 위해 DLQ를 지원합니다.
   - DLQ의 타겟으로 SQS를 설정하면 실패한 메시지를 보관하고 분석할 수 있습니다.

2. **Amazon Simple Queue Service (SQS)**
   - SQS는 메시지를 최대 14일 동안 보관할 수 있는 큐를 제공합니다.
   - SNS DLQ의 타겟으로 설정하여 실패한 메시지를 보관하고 분석할 수 있습니다.

3. **Amazon Kinesis Data Stream**
   - 실시간 데이터 스트리밍을 위한 서비스로, 메시지 보관 및 분석을 위해서는 추가 개발이 필요합니다.

4. **Amazon DynamoDB**
   - 메시지를 보관할 수 있지만, SQS를 사용하는 것이 더 간단하고 적절합니다.

### 추가 학습 자료
- [Amazon SNS Dead Letter Queue 공식 문서](https://docs.aws.amazon.com/ko_kr/sns/latest/dg/sns-dead-letter-queues.html)
- [Amazon Simple Queue Service (SQS) 공식 문서](https://docs.aws.amazon.com/ko_kr/AWSSimpleQueueService/latest/SQSDeveloperGuide/welcome.html)
- [Amazon Kinesis Data Stream 공식 문서](https://docs.aws.amazon.com/ko_kr/streams/latest/dev/introduction.html)
- [Amazon DynamoDB 공식 문서](https://docs.aws.amazon.com/ko_kr/amazondynamodb/latest/developerguide/Introduction.html)

이 자료들을 통해 SNS DLQ, SQS, Kinesis Data Stream, DynamoDB의 다양한 기능과 설정 방법을 이해하고, 특정 시나리오에서 최적의 솔루션을 선택하는 능력을 키울 수 있습니다.


# 490번
### 정답
B. Export the data directly from DynamoDB to Amazon S3 with continuous backups. Turn on point-in-time recovery for the table.

### 해설
Amazon DynamoDB는 데이터를 Amazon S3로 직접 내보내는 기능을 제공하며, 이를 통해 연속 백업을 설정할 수 있습니다. 이 방법은 최소한의 코딩으로 구현할 수 있으며, 애플리케이션의 가용성이나 테이블의 읽기 용량 단위(RCU)에 영향을 주지 않습니다. 또한, 포인트 인 타임 복구(PITR)를 활성화하면 특정 시점으로 데이터를 복구할 수 있습니다.

각 옵션을 자세히 살펴보면:

- **A. Use an Amazon EMR cluster. Create an Apache Hive job to back up the data to Amazon S3.**
  - Amazon EMR과 Apache Hive를 사용하는 것은 복잡하고, 백업을 설정하는 데 많은 코딩이 필요합니다.

- **B. Export the data directly from DynamoDB to Amazon S3 with continuous backups. Turn on point-in-time recovery for the table.**
  - DynamoDB에서 데이터를 S3로 직접 내보내는 기능을 사용하면 최소한의 코딩으로 연속 백업을 설정할 수 있습니다. 이는 애플리케이션의 가용성이나 RCU에 영향을 주지 않습니다.

- **C. Configure Amazon DynamoDB Streams. Create an AWS Lambda function to consume the stream and export the data to an Amazon S3 bucket.**
  - DynamoDB Streams와 Lambda를 사용하는 것은 추가적인 설정과 코딩이 필요합니다. 또한, 스트림을 소비하는 동안 RCU에 영향을 미칠 수 있습니다.

- **D. Create an AWS Lambda function to export the data from the database tables to Amazon S3 on a regular basis. Turn on point-in-time recovery for the table.**
  - Lambda 함수를 사용하여 데이터를 정기적으로 내보내는 것은 추가적인 설정과 코딩이 필요합니다. 또한, 정기적인 내보내기 동안 RCU에 영향을 미칠 수 있습니다.

따라서, 회사의 요구 사항을 가장 효율적으로 충족하는 솔루션은 옵션 B입니다.

### 필요한 학습 내용

1. **Amazon DynamoDB 연속 백업**
   - DynamoDB는 데이터를 Amazon S3로 직접 내보내는 기능을 제공하며, 이를 통해 연속 백업을 설정할 수 있습니다.
   - 최소한의 코딩으로 구현할 수 있으며, 애플리케이션의 가용성이나 RCU에 영향을 주지 않습니다.

2. **포인트 인 타임 복구 (PITR)**
   - PITR을 활성화하면 특정 시점으로 데이터를 복구할 수 있습니다.

3. **Amazon EMR과 Apache Hive**
   - EMR과 Hive를 사용하는 것은 복잡하고, 백업을 설정하는 데 많은 코딩이 필요합니다.

4. **Amazon DynamoDB Streams와 AWS Lambda**
   - Streams와 Lambda를 사용하는 것은 추가적인 설정과 코딩이 필요합니다.
   - 스트림을 소비하는 동안 RCU에 영향을 미칠 수 있습니다.

### 추가 학습 자료
- [Amazon DynamoDB 연속 백업 공식 문서](https://docs.aws.amazon.com/ko_kr/amazondynamodb/latest/developerguide/BackupRestore.html)
- [포인트 인 타임 복구 (PITR) 공식 문서](https://docs.aws.amazon.com/ko_kr/amazondynamodb/latest/developerguide/PointInTimeRecovery.html)
- [Amazon EMR 공식 문서](https://docs.aws.amazon.com/ko_kr/emr/latest/ManagementGuide/emr-what-is-emr.html)
- [Amazon DynamoDB Streams 공식 문서](https://docs.aws.amazon.com/ko_kr/amazondynamodb/latest/developerguide/Streams.html)
- [AWS Lambda 공식 문서](https://docs.aws.amazon.com/ko_kr/lambda/latest/dg/welcome.html)

이 자료들을 통해 DynamoDB 연속 백업, PITR, EMR과 Hive, DynamoDB Streams와 Lambda의 다양한 기능과 설정 방법을 이해하고, 특정 시나리오에서 최적의 솔루션을 선택하는 능력을 키울 수 있습니다.


# 491번
### 정답
A. Use AWS Lambda event source mapping. Set Amazon Simple Queue Service (Amazon SQS) standard queues as the event source. Use AWS Key Management Service (SSE-KMS) for encryption. Add the kms:Decrypt permission for the Lambda execution role.

### 해설
이 솔루션은 비용 효율적이며, 각 요청을 최소한 한 번 처리할 수 있도록 보장합니다. Amazon SQS 표준 큐는 높은 처리량과 적어도 한 번의 메시지 전달을 보장합니다. AWS Lambda 이벤트 소스 매핑을 사용하여 SQS 표준 큐를 이벤트 소스로 설정하면, Lambda 함수가 큐에서 메시지를 읽고 처리할 수 있습니다. 또한, AWS Key Management Service (SSE-KMS)를 사용하여 데이터를 암호화하고, Lambda 실행 역할에 kms:Decrypt 권한을 추가하여 암호화된 데이터를 처리할 수 있습니다.

각 옵션을 자세히 살펴보면:

- **A. Use AWS Lambda event source mapping. Set Amazon Simple Queue Service (Amazon SQS) standard queues as the event source. Use AWS Key Management Service (SSE-KMS) for encryption. Add the kms:Decrypt permission for the Lambda execution role.**
  - SQS 표준 큐는 높은 처리량과 적어도 한 번의 메시지 전달을 보장합니다. SSE-KMS를 사용하여 데이터를 암호화하고, Lambda 실행 역할에 kms:Decrypt 권한을 추가하여 암호화된 데이터를 처리할 수 있습니다. 이는 비용 효율적이며 요구 사항을 충족합니다.

- **B. Use AWS Lambda event source mapping. Use Amazon Simple Queue Service (Amazon SQS) FIFO queues as the event source. Use SQS managed encryption keys (SSE-SQS) for encryption. Add the encryption key invocation permission for the Lambda function.**
  - SQS FIFO 큐는 메시지 순서를 보장하지만, 비용이 더 높을 수 있습니다. 또한, SSE-SQS를 사용하면 추가적인 설정이 필요합니다.

- **C. Use the AWS Lambda event source mapping. Set Amazon Simple Queue Service (Amazon SQS) FIFO queues as the event source. Use AWS KMS keys (SSE-KMS). Add the kms:Decrypt permission for the Lambda execution role.**
  - SQS FIFO 큐는 메시지 순서를 보장하지만, 비용이 더 높을 수 있습니다. SSE-KMS를 사용하여 데이터를 암호화하고, Lambda 실행 역할에 kms:Decrypt 권한을 추가할 수 있습니다.

- **D. Use the AWS Lambda event source mapping. Set Amazon Simple Queue Service (Amazon SQS) standard queues as the event source. Use AWS KMS keys (SSE-KMS) for encryption. Add the encryption key invocation permission for the Lambda function.**
  - 이 옵션도 적절하지만, kms:Decrypt 권한을 추가하는 것이 더 명확합니다.

따라서, 회사의 요구 사항을 가장 효율적으로 충족하는 솔루션은 옵션 A입니다.

### 필요한 학습 내용

1. **Amazon SQS 표준 큐**
   - 높은 처리량과 적어도 한 번의 메시지 전달을 보장합니다.

2. **AWS Lambda 이벤트 소스 매핑**
   - Lambda 함수가 SQS 큐에서 메시지를 읽고 처리할 수 있도록 설정합니다.

3. **AWS Key Management Service (SSE-KMS)**
   - 데이터를 암호화하고, Lambda 실행 역할에 kms:Decrypt 권한을 추가하여 암호화된 데이터를 처리할 수 있습니다.

4. **Amazon SQS FIFO 큐**
   - 메시지 순서를 보장하지만, 비용이 더 높을 수 있습니다.

### 추가 학습 자료
- [Amazon SQS 표준 큐 공식 문서](https://docs.aws.amazon.com/ko_kr/AWSSimpleQueueService/latest/SQSDeveloperGuide/standard-queues.html)
- [AWS Lambda 이벤트 소스 매핑 공식 문서](https://docs.aws.amazon.com/ko_kr/lambda/latest/dg/invocation-eventsourcemapping.html)
- [AWS Key Management Service (SSE-KMS) 공식 문서](https://docs.aws.amazon.com/ko_kr/kms/latest/developerguide/overview.html)
- [Amazon SQS FIFO 큐 공식 문서](https://docs.aws.amazon.com/ko_kr/AWSSimpleQueueService/latest/SQSDeveloperGuide/FIFO-queues.html)

이 자료들을 통해 SQS 표준 큐, Lambda 이벤트 소스 매핑, SSE-KMS, SQS FIFO 큐의 다양한 기능과 설정 방법을 이해하고, 특정 시나리오에서 최적의 솔루션을 선택하는 능력을 키울 수 있습니다.


# 492번
### 정답
B. Use AWS Organizations to organize the accounts into organizational units (OUs). Define and attach a service control policy (SCP) to control the usage of EC2 instance types.

### 해설
AWS Organizations를 사용하여 계정을 조직 단위(OU)로 구성하고, 서비스 제어 정책(SCP)을 정의하여 특정 EC2 인스턴스 유형의 사용을 제한하는 것이 가장 적합한 솔루션입니다. SCP는 중앙에서 관리할 수 있으며, 모든 계정에 일관되게 적용할 수 있습니다. 이는 최소한의 개발 노력으로 요구 사항을 충족할 수 있는 방법입니다.

각 옵션을 자세히 살펴보면:

- **A. Develop AWS Systems Manager templates that use an approved EC2 creation process. Use the approved Systems Manager templates to provision EC2 instances.**
  - Systems Manager 템플릿을 사용하는 것은 추가적인 개발 노력이 필요하며, 모든 사용자가 이를 따르도록 강제하기 어렵습니다.

- **B. Use AWS Organizations to organize the accounts into organizational units (OUs). Define and attach a service control policy (SCP) to control the usage of EC2 instance types.**
  - AWS Organizations와 SCP를 사용하면 중앙에서 계정의 리소스 사용을 제어할 수 있습니다. 이는 최소한의 개발 노력으로 요구 사항을 충족할 수 있는 방법입니다.

- **C. Configure an Amazon EventBridge rule that invokes an AWS Lambda function when an EC2 instance is created. Stop disallowed EC2 instance types.**
  - EventBridge와 Lambda를 사용하는 것은 추가적인 개발 노력이 필요하며, 실시간으로 인스턴스를 중지하는 것은 복잡할 수 있습니다.

- **D. Set up AWS Service Catalog products for the staff to create the allowed EC2 instance types. Ensure that staff can deploy EC2 instances only by using the Service Catalog products.**
  - Service Catalog를 사용하는 것은 추가적인 설정과 관리가 필요하며, 모든 사용자가 이를 따르도록 강제하기 어렵습니다.

따라서, 회사의 요구 사항을 가장 효율적으로 충족하는 솔루션은 옵션 B입니다.

### 필요한 학습 내용

1. **AWS Organizations**
   - 여러 AWS 계정을 중앙에서 관리할 수 있는 서비스입니다.
   - 조직 단위(OU)로 계정을 구성하고, 서비스 제어 정책(SCP)을 정의하여 리소스 사용을 제어할 수 있습니다.

2. **서비스 제어 정책 (SCP)**
   - SCP는 AWS Organizations에서 계정 수준의 권한을 관리하는 데 사용됩니다.
   - 특정 리소스 유형의 사용을 제한할 수 있습니다.

3. **AWS Systems Manager**
   - Systems Manager 템플릿을 사용하여 EC2 인스턴스를 프로비저닝할 수 있습니다.
   - 추가적인 개발 노력이 필요합니다.

4. **Amazon EventBridge와 AWS Lambda**
   - EventBridge와 Lambda를 사용하여 특정 이벤트에 대한 작업을 자동화할 수 있습니다.
   - 추가적인 개발 노력이 필요합니다.

5. **AWS Service Catalog**
   - Service Catalog를 사용하여 승인된 리소스 템플릿을 제공할 수 있습니다.
   - 추가적인 설정과 관리가 필요합니다.

### 추가 학습 자료
- [AWS Organizations 공식 문서](https://docs.aws.amazon.com/ko_kr/organizations/latest/userguide/orgs_introduction.html)
- [서비스 제어 정책 (SCP) 공식 문서](https://docs.aws.amazon.com/ko_kr/organizations/latest/userguide/orgs_manage_policies_scp.html)
- [AWS Systems Manager 공식 문서](https://docs.aws.amazon.com/ko_kr/systems-manager/latest/userguide/what-is-systems-manager.html)
- [Amazon EventBridge 공식 문서](https://docs.aws.amazon.com/ko_kr/eventbridge/latest/userguide/what-is-amazon-eventbridge.html)
- [AWS Service Catalog 공식 문서](https://docs.aws.amazon.com/ko_kr/servicecatalog/latest/adminguide/introduction.html)

이 자료들을 통해 AWS Organizations, SCP, Systems Manager, EventBridge, Service Catalog의 다양한 기능과 설정 방법을 이해하고, 특정 시나리오에서 최적의 솔루션을 선택하는 능력을 키울 수 있습니다.


# 493번
정답은 **D, E, F**입니다.

### 설명:

1. **D. Use Amazon Transcribe to convert the audio recordings in any language into text.**
   - Amazon Transcribe는 오디오 파일을 텍스트로 변환하는 서비스입니다. 고객 서비스 콜 녹음은 다양한 언어로 되어 있을 수 있기 때문에, 이 서비스는 **오디오를 텍스트로 변환**하는 데 필수적입니다.

2. **E. Use Amazon Translate to translate text in any language to English.**
   - **Amazon Translate**는 텍스트를 자동으로 번역할 수 있는 서비스입니다. 다양한 언어로 된 텍스트를 **영어로 번역**하는 데 사용됩니다. 이 단계는 고객 서비스 콜을 영어로 번역해야 하는 요구 사항을 충족시킵니다.

3. **F. Use Amazon Comprehend to create the sentiment analysis reports.**
   - **Amazon Comprehend**는 감정 분석을 포함한 텍스트 분석을 제공하는 서비스입니다. 텍스트를 **영어로 번역**한 후, Amazon Comprehend를 사용하여 **감정 분석 보고서를 생성**할 수 있습니다.

### 나머지 옵션에 대한 설명:
- **A. Use Amazon Comprehend to translate the audio recordings into English.**
  - Amazon Comprehend는 **텍스트 분석**을 위한 서비스로, 오디오를 텍스트로 번역하는 기능은 없습니다. 이 목적을 위해서는 **Amazon Transcribe**와 **Amazon Translate**를 사용하는 것이 적합합니다.

- **B. Use Amazon Lex to create the written sentiment analysis reports.**
  - Amazon Lex는 **챗봇**을 만들 때 사용하는 서비스입니다. 고객 서비스 콜의 감정 분석을 위해서는 **Amazon Comprehend**를 사용하는 것이 맞습니다.

- **C. Use Amazon Polly to convert the audio recordings into text.**
  - Amazon Polly는 **텍스트를 음성으로 변환**하는 서비스입니다. 오디오 파일을 텍스트로 변환하려면 **Amazon Transcribe**를 사용해야 합니다.

### 결론:
고객 서비스 콜의 **오디오를 텍스트로 변환**하고, **다양한 언어에서 영어로 번역**한 후, **감정 분석**을 통해 보고서를 생성하는 프로세스는 **Amazon Transcribe**, **Amazon Translate**, **Amazon Comprehend**를 사용하는 조합으로 구현할 수 있습니다.

# 499번
### 정답
D. Contact an AWS Direct Connect Partner to order a 200 Mbps hosted connection for an existing AWS account.

### 해설
회사의 평균 연결 사용률이 10% 미만이므로, 1 Gbps Direct Connect 연결은 과도할 수 있습니다. 200 Mbps 호스티드 연결은 비용을 절감하면서도 필요한 대역폭을 제공할 수 있습니다. AWS Direct Connect 파트너를 통해 200 Mbps 호스티드 연결을 주문하면, 보안과 성능을 유지하면서 비용을 줄일 수 있습니다.

각 옵션을 자세히 살펴보면:

- **A. Set up a new 1 Gbps Direct Connect connection. Share the connection with another AWS account.**
  - 1 Gbps 연결을 공유하는 것은 비용을 줄일 수 있지만, 여전히 과도한 대역폭을 제공하며, 다른 계정과의 공유는 보안 문제를 야기할 수 있습니다.

- **B. Set up a new 200 Mbps Direct Connect connection in the AWS Management Console.**
  - AWS Management Console에서는 200 Mbps Direct Connect 연결을 직접 설정할 수 없습니다. AWS Direct Connect 파트너를 통해 호스티드 연결을 주문해야 합니다.

- **C. Contact an AWS Direct Connect Partner to order a 1 Gbps connection. Share the connection with another AWS account.**
  - 1 Gbps 연결을 공유하는 것은 비용을 줄일 수 있지만, 여전히 과도한 대역폭을 제공하며, 다른 계정과의 공유는 보안 문제를 야기할 수 있습니다.

- **D. Contact an AWS Direct Connect Partner to order a 200 Mbps hosted connection for an existing AWS account.**
  - AWS Direct Connect 파트너를 통해 200 Mbps 호스티드 연결을 주문하면, 보안과 성능을 유지하면서 비용을 줄일 수 있습니다. 이는 회사의 요구 사항을 가장 효율적으로 충족하는 솔루션입니다.

따라서, 회사의 요구 사항을 가장 효율적으로 충족하는 솔루션은 옵션 D입니다.

### 필요한 학습 내용

1. **AWS Direct Connect**
   - AWS Direct Connect는 온프레미스 데이터 센터와 AWS 간의 전용 네트워크 연결을 제공합니다.
   - 다양한 대역폭 옵션을 제공하며, AWS Direct Connect 파트너를 통해 호스티드 연결을 주문할 수 있습니다.

2. **호스티드 연결**
   - AWS Direct Connect 파트너를 통해 제공되는 호스티드 연결은 다양한 대역폭 옵션을 제공하며, 비용을 절감할 수 있습니다.

3. **AWS Management Console**
   - AWS Management Console에서는 Direct Connect 연결을 직접 설정할 수 없습니다. AWS Direct Connect 파트너를 통해 호스티드 연결을 주문해야 합니다.

### 추가 학습 자료
- [AWS Direct Connect 공식 문서](https://docs.aws.amazon.com/ko_kr/directconnect/latest/UserGuide/Welcome.html)
- [AWS Direct Connect 파트너 공식 문서](https://aws.amazon.com/directconnect/partners/)
- [호스티드 연결 공식 문서](https://docs.aws.amazon.com/ko_kr/directconnect/latest/UserGuide/hosted-connections.html)

이 자료들을 통해 AWS Direct Connect, 호스티드 연결, AWS Management Console의 다양한 기능과 설정 방법을 이해하고, 특정 시나리오에서 최적의 솔루션을 선택하는 능력을 키울 수 있습니다.


# 500번
### 정답
A. Deploy AWS DataSync agents on premises. Schedule DataSync tasks to transfer the data to the FSx for Windows File Server file system.
E. Order an AWS Snowball Edge Storage Optimized device. Connect the device to the on-premises network. Copy data to the device by using the AWS CLI. Ship the device back to AWS for import into Amazon S3. Schedule AWS DataSync tasks to transfer the data to the FSx for Windows File Server file system.

### 해설
AWS DataSync와 AWS Snowball Edge Storage Optimized 장치를 사용하면 파일 권한을 유지하면서 데이터를 Amazon FSx for Windows File Server로 마이그레이션하고 통합할 수 있습니다. DataSync는 파일 권한을 포함한 메타데이터를 유지하면서 데이터를 전송할 수 있으며, Snowball Edge는 대량의 데이터를 물리적으로 전송하는 데 적합합니다.

각 옵션을 자세히 살펴보면:

- **A. Deploy AWS DataSync agents on premises. Schedule DataSync tasks to transfer the data to the FSx for Windows File Server file system.**
  - DataSync 에이전트를 온프레미스에 배포하고, DataSync 작업을 예약하여 데이터를 FSx for Windows File Server로 전송하면 파일 권한을 유지할 수 있습니다.

- **B. Copy the shares on each file server into Amazon S3 buckets by using the AWS CLI. Schedule AWS DataSync tasks to transfer the data to the FSx for Windows File Server file system.**
  - S3로 데이터를 복사하는 것은 파일 권한을 유지하는 데 적합하지 않습니다.

- **C. Remove the drives from each file server. Ship the drives to AWS for import into Amazon S3. Schedule AWS DataSync tasks to transfer the data to the FSx for Windows File Server file system.**
  - 드라이브를 제거하고 AWS로 배송하는 것은 복잡하고 시간이 많이 걸릴 수 있습니다.

- **D. Order an AWS Snowcone device. Connect the device to the on-premises network. Launch AWS DataSync agents on the device. Schedule DataSync tasks to transfer the data to the FSx for Windows File Server file system.**
  - Snowcone 장치는 소규모 데이터 전송에 적합하며, 대량의 데이터를 전송하는 데는 적합하지 않습니다.

- **E. Order an AWS Snowball Edge Storage Optimized device. Connect the device to the on-premises network. Copy data to the device by using the AWS CLI. Ship the device back to AWS for import into Amazon S3. Schedule AWS DataSync tasks to transfer the data to the FSx for Windows File Server file system.**
  - Snowball Edge Storage Optimized 장치는 대량의 데이터를 물리적으로 전송하는 데 적합하며, DataSync 작업을 예약하여 데이터를 FSx for Windows File Server로 전송할 수 있습니다.

따라서, 회사의 요구 사항을 가장 효율적으로 충족하는 솔루션은 옵션 A와 E입니다.

### 필요한 학습 내용

1. **AWS DataSync**
   - 파일 권한을 포함한 메타데이터를 유지하면서 데이터를 전송할 수 있습니다.
   - 온프레미스에 DataSync 에이전트를 배포하고, DataSync 작업을 예약하여 데이터를 전송할 수 있습니다.

2. **AWS Snowball Edge Storage Optimized**
   - 대량의 데이터를 물리적으로 전송하는 데 적합합니다.
   - 데이터를 AWS로 전송한 후, DataSync 작업을 예약하여 데이터를 FSx for Windows File Server로 전송할 수 있습니다.

3. **Amazon FSx for Windows File Server**
   - Windows 파일 서버와 호환되는 완전 관리형 파일 시스템입니다.
   - 파일 권한을 유지하면서 데이터를 마이그레이션할 수 있습니다.

### 추가 학습 자료
- [AWS DataSync 공식 문서](https://docs.aws.amazon.com/ko_kr/datasync/latest/userguide/what-is-datasync.html)
- [AWS Snowball Edge 공식 문서](https://docs.aws.amazon.com/ko_kr/snowball/latest/developer-guide/what-is-snowball.html)
- [Amazon FSx for Windows File Server 공식 문서](https://docs.aws.amazon.com/ko_kr/fsx/latest/WindowsGuide/what-is.html)

이 자료들을 통해 AWS DataSync, AWS Snowball Edge, Amazon FSx for Windows File Server의 다양한 기능과 설정 방법을 이해하고, 특정 시나리오에서 최적의 솔루션을 선택하는 능력을 키울 수 있습니다.



# 502번
### 문제 502
회사는 Amazon EC2에서 콘텐츠 관리 시스템(CMS)을 사용하는 웹사이트를 운영하고 있습니다. CMS는 단일 EC2 인스턴스에서 실행되며 데이터 계층으로 Amazon Aurora MySQL Multi-AZ DB 인스턴스를 사용합니다. 웹사이트 이미지는 EC2 인스턴스 내부에 마운트된 Amazon Elastic Block Store (Amazon EBS) 볼륨에 저장됩니다.

웹사이트의 성능과 복원력을 향상시키기 위해 솔루션 아키텍트가 취해야 할 조치는 무엇입니까? (두 가지를 선택하십시오.)

A. 웹사이트 이미지를 모든 EC2 인스턴스에 마운트된 Amazon S3 버킷으로 이동합니다.
B. 기본 EC2 인스턴스에서 NFS 공유를 사용하여 웹사이트 이미지를 공유합니다. 이 공유를 다른 EC2 인스턴스에 마운트합니다.
C. 웹사이트 이미지를 모든 EC2 인스턴스에 마운트된 Amazon Elastic File System (Amazon EFS) 파일 시스템으로 이동합니다.
D. 기존 EC2 인스턴스에서 Amazon Machine Image (AMI)를 생성합니다. 이 AMI를 사용하여 Auto Scaling 그룹의 일부로 Application Load Balancer 뒤에 새로운 인스턴스를 프로비저닝합니다. Auto Scaling 그룹이 최소 두 개의 인스턴스를 유지하도록 구성합니다. 웹사이트를 위해 AWS Global Accelerator에서 가속기를 구성합니다.
E. 기존 EC2 인스턴스에서 Amazon Machine Image (AMI)를 생성합니다. 이 AMI를 사용하여 Auto Scaling 그룹의 일부로 Application Load Balancer 뒤에 새로운 인스턴스를 프로비저닝합니다. Auto Scaling 그룹이 최소 두 개의 인스턴스를 유지하도록 구성합니다. 웹사이트를 위해 Amazon CloudFront 배포를 구성합니다.

### 정답
**C. Move the website images onto an Amazon Elastic File System (Amazon EFS) file system that is mounted on every EC2 instance.**  
**E. Create an Amazon Machine Image (AMI) from the existing EC2 instance. Use the AMI to provision new instances behind an Application Load Balancer as part of an Auto Scaling group. Configure the Auto Scaling group to maintain a minimum of two instances. Configure an Amazon CloudFront distribution for the website.**

### 해설
- **C. Move the website images onto an Amazon Elastic File System (Amazon EFS) file system that is mounted on every EC2 instance.**
  - **적합성**: Amazon EFS는 여러 EC2 인스턴스에서 동시에 액세스할 수 있는 공유 파일 시스템을 제공합니다. 이는 웹사이트 이미지의 가용성과 복원력을 향상시킵니다.

- **E. Create an Amazon Machine Image (AMI) from the existing EC2 instance. Use the AMI to provision new instances behind an Application Load Balancer as part of an Auto Scaling group. Configure the Auto Scaling group to maintain a minimum of two instances. Configure an Amazon CloudFront distribution for the website.**
  - **적합성**: AMI를 사용하여 새로운 인스턴스를 프로비저닝하고 Auto Scaling 그룹과 Application Load Balancer를 구성하면, 웹사이트의 가용성과 복원력을 크게 향상시킬 수 있습니다. 또한, Amazon CloudFront를 사용하여 콘텐츠를 캐시하고 전 세계적으로 배포하면 성능을 최적화할 수 있습니다.

### 다른 옵션들에 대한 설명
- **A. Move the website images into an Amazon S3 bucket that is mounted on every EC2 instance.**
  - Amazon S3는 객체 스토리지로, 파일 시스템처럼 마운트할 수 없습니다. 대신 S3를 직접 액세스해야 합니다.

- **B. Share the website images by using an NFS share from the primary EC2 instance. Mount this share on the other EC2 instances.**
  - NFS 공유는 단일 장애 지점이 될 수 있으며, 고가용성을 보장하지 않습니다.

- **D. Create an Amazon Machine Image (AMI) from the existing EC2 instance. Use the AMI to provision new instances behind an Application Load Balancer as part of an Auto Scaling group. Configure the Auto Scaling group to maintain a minimum of two instances. Configure an accelerator in AWS Global Accelerator for the website.**
  - AWS Global Accelerator는 주로 네트워크 성능을 최적화하는 데 사용되며, 웹사이트 콘텐츠 배포에는 CloudFront가 더 적합합니다.

따라서, C와 E 옵션이 가장 적합한 솔루션입니다.

# 503번
### 문제 503
회사는 인프라 모니터링 서비스를 운영하고 있습니다. 회사는 고객 AWS 계정의 데이터를 모니터링할 수 있는 새로운 기능을 구축하고 있습니다. 이 새로운 기능은 고객 계정에서 AWS API를 호출하여 Amazon EC2 인스턴스를 설명하고 Amazon CloudWatch 메트릭을 읽을 것입니다.

회사가 가장 안전한 방법으로 고객 계정에 접근하려면 어떻게 해야 합니까?

A. 고객이 EC2 및 CloudWatch 읽기 전용 권한과 회사 계정에 대한 신뢰 정책을 가진 IAM 역할을 계정에 생성하도록 합니다.
B. 읽기 전용 EC2 및 CloudWatch 권한이 있는 역할에 대한 임시 AWS 자격 증명을 제공하는 토큰 자판기를 구현하는 서버리스 API를 생성합니다.
C. 고객이 EC2 및 CloudWatch 읽기 전용 권한이 있는 IAM 사용자를 계정에 생성하도록 합니다. 고객 액세스 및 비밀 키를 암호화하여 비밀 관리 시스템에 저장합니다.
D. 고객이 EC2 및 CloudWatch 읽기 전용 권한이 있는 IAM 역할을 사용하도록 Amazon Cognito 사용자를 계정에 생성하도록 합니다. Amazon Cognito 사용자와 비밀번호를 암호화하여 비밀 관리 시스템에 저장합니다.

### 정답
**A. Ensure that the customers create an IAM role in their account with read-only EC2 and CloudWatch permissions and a trust policy to the company’s account.**

### 해설
- **A. Ensure that the customers create an IAM role in their account with read-only EC2 and CloudWatch permissions and a trust policy to the company’s account.**
  - **적합성 및 보안**: 고객이 읽기 전용 EC2 및 CloudWatch 권한을 가진 IAM 역할을 생성하고, 회사 계정에 대한 신뢰 정책을 설정하면, 회사는 고객 계정에 안전하게 접근할 수 있습니다. 이 방법은 고객의 자격 증명을 직접 저장하지 않으므로 보안이 강화됩니다.

### 다른 옵션들에 대한 설명
- **B. Create a serverless API that implements a token vending machine to provide temporary AWS credentials for a role with read-only EC2 and CloudWatch permissions.**
  - 토큰 자판기를 구현하는 것은 복잡성이 증가하며, 고객 계정에 대한 직접적인 신뢰 관계를 설정하는 것보다 덜 안전할 수 있습니다.

- **C. Ensure that the customers create an IAM user in their account with read-only EC2 and CloudWatch permissions. Encrypt and store customer access and secret keys in a secrets management system.**
  - IAM 사용자를 생성하고 자격 증명을 저장하는 것은 보안 위험이 높습니다. 자격 증명이 유출될 경우 큰 문제가 발생할 수 있습니다.

- **D. Ensure that the customers create an Amazon Cognito user in their account to use an IAM role with read-only EC2 and CloudWatch permissions. Encrypt and store the Amazon Cognito user and password in a secrets management system.**
  - Amazon Cognito 사용자를 사용하는 것은 이 시나리오에 적합하지 않으며, 자격 증명을 저장하는 것은 보안 위험이 높습니다.

따라서, 고객이 읽기 전용 EC2 및 CloudWatch 권한과 회사 계정에 대한 신뢰 정책을 가진 IAM 역할을 생성하도록 하는 A 옵션이 가장 적합한 솔루션입니다.

# 512번
### 문제 512
회사는 AWS Organizations를 사용하여 계정별로 태그가 지정된 리소스를 관리하고 있습니다. 회사는 AWS Backup을 사용하여 AWS 인프라 리소스를 백업합니다. 회사는 모든 AWS 리소스를 백업해야 합니다.

가장 적은 운영 오버헤드로 이러한 요구 사항을 충족하는 솔루션은 무엇입니까?

---

A. AWS Config를 사용하여 태그가 지정되지 않은 모든 리소스를 식별합니다. 식별된 리소스에 대해 프로그래밍 방식으로 태그를 지정합니다. 백업 계획에서 태그를 사용합니다.

B. AWS Config를 사용하여 실행되지 않는 모든 리소스를 식별합니다. 해당 리소스를 백업 볼트에 추가합니다.

C. 모든 AWS 계정 소유자가 백업해야 할 리소스를 식별하기 위해 자신의 리소스를 검토하도록 요구합니다.

D. Amazon Inspector를 사용하여 모든 비준수 리소스를 식별합니다.

### 정답
**A. Use AWS Config to identify all untagged resources. Tag the identified resources programmatically. Use tags in the backup plan.**

### 해설
- **A. Use AWS Config to identify all untagged resources. Tag the identified resources programmatically. Use tags in the backup plan.**
  - **적합성 및 운영 오버헤드 최소화**: AWS Config를 사용하여 태그가 지정되지 않은 리소스를 식별하고, 프로그래밍 방식으로 태그를 지정하면 모든 리소스를 체계적으로 관리할 수 있습니다. 태그를 사용하여 백업 계획을 구성하면, 백업해야 할 리소스를 자동으로 선택할 수 있어 운영 오버헤드를 최소화할 수 있습니다.

### 다른 옵션들에 대한 설명
- **B. Use AWS Config to identify all resources that are not running. Add those resources to the backup vault.**
  - 실행되지 않는 리소스를 백업하는 것은 비효율적이며, 모든 리소스를 백업하는 요구 사항을 충족하지 않습니다.

- **C. Require all AWS account owners to review their resources to identify the resources that need to be backed up.**
  - 모든 계정 소유자가 리소스를 검토하도록 요구하는 것은 운영 오버헤드가 크며, 일관성을 보장하기 어렵습니다.

- **D. Use Amazon Inspector to identify all noncompliant resources.**
  - Amazon Inspector는 보안 및 규정 준수 검사를 수행하는 도구로, 백업해야 할 리소스를 식별하는 데 적합하지 않습니다.

따라서, AWS Config를 사용하여 태그가 지정되지 않은 리소스를 식별하고 프로그래밍 방식으로 태그를 지정한 후, 태그를 사용하여 백업 계획을 구성하는 A 옵션이 가장 적합한 솔루션입니다.

# 514번
### 문제 514
회사는 Amazon EC2 인스턴스에서 마이크로서비스 애플리케이션을 실행하고 있습니다. 회사는 애플리케이션을 확장성을 위해 Amazon Elastic Kubernetes Service (Amazon EKS) 클러스터로 마이그레이션하려고 합니다. 회사는 보안 준수를 유지하기 위해 Amazon EKS 제어 플레인을 프라이빗 액세스가 true로 설정되고 퍼블릭 액세스가 false로 설정되도록 구성해야 합니다. 또한, 데이터 플레인을 프라이빗 서브넷에 배치해야 합니다. 그러나 노드가 클러스터에 가입할 수 없다는 오류 알림을 받았습니다.

노드가 클러스터에 가입할 수 있도록 하는 솔루션은 무엇입니까?

A. AmazonEKSNodeRole IAM 역할에 필요한 권한을 부여합니다.
B. 노드가 제어 플레인에 액세스할 수 있도록 인터페이스 VPC 엔드포인트를 생성합니다.
C. 노드를 퍼블릭 서브넷에서 다시 생성합니다. EC2 노드에 대한 보안 그룹을 제한합니다.
D. 노드의 보안 그룹에서 아웃바운드 트래픽을 허용합니다.

### 정답
**B. Create interface VPC endpoints to allow nodes to access the control plane.**

### 해설
- **B. Create interface VPC endpoints to allow nodes to access the control plane.**
  - **적합성**: Amazon EKS 제어 플레인이 프라이빗 액세스만 허용하도록 구성된 경우, 노드가 제어 플레인에 액세스하려면 인터페이스 VPC 엔드포인트를 생성해야 합니다. 이를 통해 프라이빗 서브넷에 있는 노드가 제어 플레인에 안전하게 액세스할 수 있습니다.

### 다른 옵션들에 대한 설명
- **A. Grant the required permission in AWS Identity and Access Management (IAM) to the AmazonEKSNodeRole IAM role.**
  - IAM 권한은 중요하지만, 현재 문제는 네트워크 연결 문제로 인해 발생한 것입니다.

- **C. Recreate nodes in the public subnet. Restrict security groups for EC2 nodes.**
  - 퍼블릭 서브넷에 노드를 배치하는 것은 보안 준수 요구 사항을 위반할 수 있습니다.

- **D. Allow outbound traffic in the security group of the nodes.**
  - 아웃바운드 트래픽을 허용하는 것은 필요할 수 있지만, 인터페이스 VPC 엔드포인트를 생성하는 것이 더 적합한 솔루션입니다.

따라서, 노드가 제어 플레인에 액세스할 수 있도록 인터페이스 VPC 엔드포인트를 생성하는 B 옵션이 가장 적합한 솔루션입니다.

# 515번
Amazon Redshift는 데이터 웨어하우징 솔루션으로, 주로 대규모 데이터 분석을 위해 설계되었습니다. 주어진 질문에서 AWS로 애플리케이션을 마이그레이션하는 회사의 상황에 적합한 사용 사례를 선택해야 합니다. 다음은 각 옵션에 대한 평가입니다.

### 정답
**C. Building analytics workloads during specified hours and when the application is not active**  
**E. Scaling globally to support petabytes of data and tens of millions of requests per minute**  
**A. Supporting data APIs to access data with traditional, containerized, and event-driven applications**  

### 해설

- **A. Supporting data APIs to access data with traditional, containerized, and event-driven applications**
  - **해설**: Amazon Redshift는 SQL 쿼리를 통해 데이터를 접근할 수 있으며, 다양한 애플리케이션에서 데이터에 접근하는 API를 지원할 수 있습니다. 특히, 전통적인 애플리케이션, 컨테이너화된 애플리케이션, 이벤트 기반 애플리케이션과 통합할 수 있습니다.

- **B. Supporting client-side and server-side encryption**
  - **해설**: Amazon Redshift는 데이터 암호화 기능을 제공하지만, 이 항목은 Redshift의 사용 사례에 적합한 사용이 아닙니다. 암호화는 보안 관련 기능이며, 직접적인 사용 사례라기보다는 보안 요구 사항에 해당합니다.

- **C. Building analytics workloads during specified hours and when the application is not active**
  - **해설**: Amazon Redshift는 대규모 데이터 분석을 위해 설계된 데이터 웨어하우스입니다. 특정 시간 동안 작업 부하를 처리하는 데 적합하며, 비활성 상태의 애플리케이션과 함께 사용될 수 있습니다. 이는 리소스를 효율적으로 사용할 수 있는 방법입니다.

- **D. Caching data to reduce the pressure on the backend database**
  - **해설**: Amazon Redshift는 데이터 웨어하우스이며, 주로 분석 작업에 사용됩니다. 데이터 캐싱은 Redshift의 주된 기능이 아니므로 이 경우에는 적합하지 않습니다.

- **E. Scaling globally to support petabytes of data and tens of millions of requests per minute**
  - **해설**: Amazon Redshift는 대규모 데이터 세트를 처리하고, 높은 성능의 분석 요청을 지원할 수 있는 기능을 가지고 있습니다. 글로벌 스케일링과 대량의 데이터 처리에 적합한 솔루션입니다.

- **F. Creating a secondary replica of the cluster by using the AWS Management Console**
  - **해설**: Amazon Redshift는 복제 기능을 제공하지만, 클러스터의 '세컨더리 복제본'을 생성하는 것은 데이터 웨어하우스의 주요 사용 사례가 아닙니다. 또한, AWS Management Console을 통해 단순히 복제본을 생성하는 것에 대한 사용 사례라기보다는 관리 기능에 해당합니다.

따라서, 적합한 사용 사례로는 **C, E, A**가 선택됩니다.

# 520번
### 정답: B. Configure DynamoDB in on-demand mode by using the DynamoDB Standard table class.

#### 이유:
- **비용 효율성:** DynamoDB의 온디맨드 모드는 예측할 수 없는 트래픽 패턴에 가장 적합합니다. 사용한 만큼만 비용을 지불하므로, 트래픽이 급증하거나 감소할 때 비용 효율적으로 대응할 수 있습니다.
- **자동 스케일링:** 온디맨드 모드는 자동으로 스케일링되므로, 애플리케이션 트래픽에 따라 자동으로 읽기 및 쓰기 처리량을 조정할 수 있습니다.

#### 다른 보기가 정답이 될 수 없는 이유:

**A. Configure DynamoDB with provisioned read and write by using the DynamoDB Standard table class. Set DynamoDB auto scaling to a maximum defined capacity.**
- **비용 효율성 부족:** 프로비저닝된 용량 모드는 트래픽이 예측 가능할 때 유리하지만, 예측할 수 없는 트래픽 패턴에서는 비효율적일 수 있습니다. 최대 용량을 설정해도 트래픽 급증 시에는 비용이 많이 들 수 있습니다.

**C. Configure DynamoDB with provisioned read and write by using the DynamoDB Standard Infrequent Access (DynamoDB Standard-IA) table class. Set DynamoDB auto scaling to a maximum defined capacity.**
- **적합하지 않음:** DynamoDB Standard-IA는 자주 액세스되지 않는 데이터를 위해 설계되었습니다. 트래픽이 중간에서 높은 수준으로 예측되는 경우에는 적합하지 않습니다.

**D. Configure DynamoDB in on-demand mode by using the DynamoDB Standard Infrequent Access (DynamoDB Standard-IA) table class.**
- **적합하지 않음:** DynamoDB Standard-IA는 자주 액세스되지 않는 데이터를 위해 설계되었습니다. 트래픽이 중간에서 높은 수준으로 예측되는 경우에는 적합하지 않습니다.

### 요약:
DynamoDB의 온디맨드 모드는 예측할 수 없는 트래픽 패턴에 가장 적합하며, 자동으로 스케일링되어 비용 효율적으로 애플리케이션 트래픽에 대응할 수 있습니다. 따라서 DynamoDB Standard 테이블 클래스를 사용하는 온디맨드 모드가 가장 적합한 선택입니다.

## Provisioned Read and Write
클라우드 서비스에서 **프로비저닝된 읽기 및 쓰기 용량**은 주로 **Amazon DynamoDB**와 같은 데이터베이스 또는 스토리지 시스템과 관련이 있습니다. 이는 예상되는 트래픽에 맞춰 데이터베이스 테이블이나 기타 리소스에 할당하는 읽기 및 쓰기 처리량을 의미합니다.

다음은 주요 개념에 대한 설명입니다:

### 1. **프로비저닝된 용량 모드 (DynamoDB)**
   - 사용자가 **읽기 용량 단위(RCU)** 및 **쓰기 용량 단위(WCU)**를 지정합니다.
   - DynamoDB는 지정된 초당 읽기 및 쓰기 요청을 처리할 수 있도록 용량을 할당하며, 예측 가능한 성능을 보장합니다.
   - 주로 **예측 가능한 워크로드**가 있는 애플리케이션에 적합하며, 트래픽 수요를 사전에 예측할 수 있을 때 유리합니다.

   **읽기 용량 단위(RCU):**
   - 1 RCU는 초당 1개의 강력한 일관성 읽기 또는 2개의 최종적 일관성 읽기(항목 크기 4 KB 이하)를 처리할 수 있습니다.
   
   **쓰기 용량 단위(WCU):**
   - 1 WCU는 초당 1개의 쓰기 요청(항목 크기 1 KB 이하)을 처리할 수 있습니다.
   
   만약 애플리케이션이 프로비저닝된 용량을 초과하는 요청을 하면, DynamoDB는 추가 요청을 제한하거나 응답 시간이 느려지거나 요청이 거부될 수 있습니다.

### 2. **온디맨드 모드와의 비교**
   - **온디맨드 모드**에서는 용량을 사전에 할당하지 않습니다. DynamoDB가 요청 수에 따라 자동으로 확장하며, **예측 불가능한 워크로드**를 처리하는 데 적합합니다. 하지만 트래픽이 빈번하게 급증할 경우 비용이 더 높을 수 있습니다.

스마트 팩토리 환경에서 이러한 설정을 최적화하는 방법이나, 프로비저닝된 용량과 온디맨드 모드의 장단점에 대해 더 알고 싶으신가요?


# 521번
### 정답: C. In every business account, create an IAM role named BU_ROLE with a policy that gives the role access to the DynamoDB table and a trust policy to trust a specific role in the inventory application account. In the inventory account, create a role named APP_ROLE that allows access to the STS AssumeRole API operation. Configure the application to use APP_ROLE and assume the crossaccount role BU_ROLE to read the DynamoDB table.

#### 이유:
- **보안:** IAM 역할을 사용하여 교차 계정 액세스를 설정하면, 각 비즈니스 계정에서 중앙 애플리케이션 계정으로의 액세스를 세밀하게 제어할 수 있습니다. 신뢰 정책을 통해 특정 역할만 액세스할 수 있도록 제한할 수 있습니다.
- **유연성:** STS AssumeRole API를 사용하여 필요한 경우에만 임시 자격 증명을 얻을 수 있어 보안이 강화됩니다.
- **자동화:** IAM 역할을 사용하면 자격 증명 회전이 자동으로 관리되므로 수동 회전의 필요성이 없습니다.

#### 다른 보기가 정답이 될 수 없는 이유:

**A. Integrate DynamoDB with AWS Secrets Manager in the inventory application account. Configure the application to use the correct secret from Secrets Manager to authenticate and read the DynamoDB table. Schedule secret rotation for every 30 days.**
- **보안:** Secrets Manager를 사용하여 자격 증명을 저장하고 회전할 수 있지만, 각 비즈니스 계정에 대한 개별 자격 증명을 관리해야 하므로 복잡성이 증가합니다.
- **유연성 부족:** IAM 역할을 사용하는 것만큼 세밀한 액세스 제어를 제공하지 않습니다.

**B. In every business account, create an IAM user that has programmatic access. Configure the application to use the correct IAM user access key ID and secret access key to authenticate and read the DynamoDB table. Manually rotate IAM access keys every 30 days.**
- **보안:** IAM 사용자의 액세스 키를 수동으로 회전해야 하므로 보안 위험이 증가합니다.
- **운영 오버헤드:** 수동 회전은 운영 오버헤드가 크고, 실수로 인해 보안 취약점이 발생할 수 있습니다.

**D. Integrate DynamoDB with AWS Certificate Manager (ACM). Generate identity certificates to authenticate DynamoDB. Configure the application to use the correct certificate to authenticate and read the DynamoDB table.**
- **적합하지 않음:** ACM은 주로 SSL/TLS 인증서를 관리하는 데 사용됩니다. DynamoDB 인증에 적합하지 않습니다.
- **복잡성:** 인증서를 사용한 인증은 이 시나리오에 적합하지 않으며, 관리가 복잡해질 수 있습니다.

### 요약:
IAM 역할을 사용하여 교차 계정 액세스를 설정하는 것은 보안, 유연성 및 자동화 측면에서 가장 적합한 솔루션입니다. 따라서 C 옵션이 가장 적합한 선택입니다.


# 523번
### 정답: A. AWS AppSync pipeline resolvers

#### 이유:
- **운영 효율성:** AWS AppSync는 GraphQL API를 사용하여 여러 데이터 소스에서 데이터를 효율적으로 가져올 수 있습니다. 파이프라인 리졸버는 여러 DynamoDB 테이블에서 데이터를 가져오는 데 최적화되어 있습니다.
- **성능:** AppSync는 서버리스 아키텍처로, 자동으로 확장되며, 애플리케이션의 기본 성능에 영향을 주지 않습니다.
- **통합:** AppSync는 여러 데이터 소스를 통합하여 단일 API로 제공할 수 있어, 데이터 접근이 간편해집니다.

#### 다른 보기가 정답이 될 수 없는 이유:

**B. Amazon CloudFront with Lambda@Edge functions**
- **적합하지 않음:** CloudFront와 Lambda@Edge는 주로 콘텐츠 전송 네트워크(CDN)와 엣지 컴퓨팅을 위한 솔루션입니다. 여러 DynamoDB 테이블에서 데이터를 가져오는 데 최적화되어 있지 않습니다.

**C. Edge-optimized Amazon API Gateway with AWS Lambda functions**
- **적합하지 않음:** API Gateway와 Lambda는 강력한 조합이지만, 여러 데이터 소스를 통합하는 데 있어 AppSync만큼 효율적이지 않습니다. 또한, API Gateway는 주로 RESTful API를 제공하는 데 사용됩니다.

**D. Amazon Athena Federated Query with a DynamoDB connector**
- **적합하지 않음:** Athena Federated Query는 여러 데이터 소스에서 쿼리를 실행할 수 있지만, 실시간 데이터 접근보다는 분석 쿼리에 더 적합합니다. 또한, 운영 효율성 측면에서 AppSync만큼 간편하지 않습니다.

### 요약:
AWS AppSync 파이프라인 리졸버는 여러 DynamoDB 테이블에서 데이터를 효율적으로 가져올 수 있으며, 서버리스 아키텍처로 애플리케이션의 기본 성능에 영향을 주지 않습니다. 따라서 A 옵션이 가장 적합한 선택입니다.


# 526번
### 문제 526
솔루션 아키텍트는 애플리케이션의 복원력을 검토하고 있습니다. 솔루션 아키텍트는 데이터베이스 관리자가 최근 확장 연습의 일환으로 애플리케이션의 Amazon Aurora PostgreSQL 데이터베이스 작성자 인스턴스를 장애 조치했음을 알게 되었습니다. 장애 조치로 인해 애플리케이션에 3분의 다운타임이 발생했습니다.

확장 연습 중 다운타임을 줄이기 위해 가장 적은 운영 오버헤드로 해결할 수 있는 솔루션은 무엇입니까?

A. 장애 조치 중 부하를 처리하기 위해 클러스터에 더 많은 Aurora PostgreSQL 읽기 복제본을 생성합니다.
B. 동일한 AWS 리전에서 보조 Aurora PostgreSQL 클러스터를 설정합니다. 장애 조치 중 애플리케이션이 보조 클러스터의 작성자 엔드포인트를 사용하도록 업데이트합니다.
C. 장애 조치 중 부하를 처리하기 위해 Amazon ElastiCache for Memcached 클러스터를 생성합니다.
D. 데이터베이스에 대해 Amazon RDS 프록시를 설정합니다. 애플리케이션이 프록시 엔드포인트를 사용하도록 업데이트합니다.

### 정답
**D. Set up an Amazon RDS proxy for the database. Update the application to use the proxy endpoint.**

### 해설
- **D. Set up an Amazon RDS proxy for the database. Update the application to use the proxy endpoint.**
  - **적합성 및 운영 오버헤드 최소화**: Amazon RDS Proxy는 데이터베이스 연결을 관리하고, 장애 조치 시 연결을 유지하여 다운타임을 최소화할 수 있습니다. 이는 운영 오버헤드가 적고, 애플리케이션의 변경이 최소화됩니다.

### 다른 옵션들에 대한 설명
- **A. Create more Aurora PostgreSQL read replicas in the cluster to handle the load during failover.**
  - 읽기 복제본은 읽기 성능을 향상시킬 수 있지만, 쓰기 성능과 장애 조치 시의 다운타임을 줄이는 데는 도움이 되지 않습니다.

- **B. Set up a secondary Aurora PostgreSQL cluster in the same AWS Region. During failover, update the application to use the secondary cluster's writer endpoint.**
  - 보조 클러스터를 설정하는 것은 복잡성이 증가하며, 애플리케이션의 변경이 많이 필요합니다.

- **C. Create an Amazon ElastiCache for Memcached cluster to handle the load during failover.**
  - ElastiCache는 캐싱 솔루션으로, 데이터베이스 장애 조치와는 직접적인 관련이 없습니다.

따라서, Amazon RDS Proxy를 설정하고 애플리케이션이 프록시 엔드포인트를 사용하도록 업데이트하는 D 옵션이 가장 적합한 솔루션입니다.

### 해설:
- **A. Access usage cost-related data by using the AWS Cost Explorer API with pagination.**
  - **운영 오버헤드 최소화**: AWS Cost Explorer API를 사용하면 프로그래밍 방식으로 비용 데이터를 쉽게 액세스할 수 있습니다. API를 통해 현재 연도의 비용 데이터와 향후 12개월 동안의 비용 예측 데이터를 가져올 수 있습니다. 또한, API는 자동화된 스크립트나 애플리케이션에서 직접 호출할 수 있어 운영 오버헤드가 최소화됩니다.

### 다른 옵션들에 대한 설명:
- **B. Access usage cost-related data by using downloadable AWS Cost Explorer report .csv files.**
  - CSV 파일을 다운로드하여 사용하는 방법은 수동 작업이 필요하며, 자동화된 접근 방식에 비해 운영 오버헤드가 높습니다.

- **C. Configure AWS Budgets actions to send usage cost data to the company through FTP.**
  - FTP를 통해 데이터를 전송하는 것은 추가적인 설정과 관리가 필요하며, 운영 오버헤드가 증가할 수 있습니다.

- **D. Create AWS Budgets reports for usage cost data. Send the data to the company through SMTP.**
  - SMTP를 통해 데이터를 전송하는 것은 추가적인 설정과 관리가 필요하며, 운영 오버헤드가 증가할 수 있습니다.

따라서, AWS Cost Explorer API를 사용하는 것이 가장 운영 오버헤드가 적고 효율적인 솔루션입니다.


# 527번
### 문제 527
회사는 단일 AWS 리전에서 실행되는 지역 기반 구독 스트리밍 서비스를 운영하고 있습니다. 아키텍처는 Amazon EC2 인스턴스에서 실행되는 웹 서버와 애플리케이션 서버로 구성됩니다. EC2 인스턴스는 Elastic Load Balancers 뒤에 있는 Auto Scaling 그룹에 있습니다. 아키텍처에는 여러 가용 영역에 걸쳐 확장된 Amazon Aurora 글로벌 데이터베이스 클러스터가 포함됩니다.

회사는 글로벌 확장을 원하며 애플리케이션의 다운타임을 최소화하고자 합니다.

어떤 솔루션이 가장 높은 내결함성을 제공합니까?

---

A. 웹 계층과 애플리케이션 계층의 Auto Scaling 그룹을 확장하여 두 번째 리전의 가용 영역에 인스턴스를 배포합니다. 기본 리전과 두 번째 리전에 데이터베이스를 배포하기 위해 Aurora 글로벌 데이터베이스를 사용합니다. Amazon Route 53 상태 확인을 사용하여 두 번째 리전에 장애 조치 라우팅 정책을 설정합니다.

B. 웹 계층과 애플리케이션 계층을 두 번째 리전에 배포합니다. 두 번째 리전에 Aurora PostgreSQL 교차 리전 Aurora 복제본을 추가합니다. Amazon Route 53 상태 확인을 사용하여 두 번째 리전에 장애 조치 라우팅 정책을 설정합니다. 필요에 따라 보조를 기본으로 승격합니다.

C. 웹 계층과 애플리케이션 계층을 두 번째 리전에 배포합니다. 두 번째 리전에 Aurora PostgreSQL 데이터베이스를 생성합니다. AWS Database Migration Service (AWS DMS)를 사용하여 기본 데이터베이스를 두 번째 리전으로 복제합니다. Amazon Route 53 상태 확인을 사용하여 두 번째 리전에 장애 조치 라우팅 정책을 설정합니다.

D. 웹 계층과 애플리케이션 계층을 두 번째 리전에 배포합니다. 기본 리전과 두 번째 리전에 데이터베이스를 배포하기 위해 Amazon Aurora 글로벌 데이터베이스를 사용합니다. Amazon Route 53 상태 확인을 사용하여 두 번째 리전에 장애 조치 라우팅 정책을 설정합니다. 필요에 따라 보조를 기본으로 승격합니다.

### 정답
**A. Extend the Auto Scaling groups for the web tier and the application tier to deploy instances in Availability Zones in a second Region. Use an Aurora global database to deploy the database in the primary Region and the second Region. Use Amazon Route 53 health checks with a failover routing policy to the second Region.**

### 해설
- **A. Extend the Auto Scaling groups for the web tier and the application tier to deploy instances in Availability Zones in a second Region. Use an Aurora global database to deploy the database in the primary Region and the second Region. Use Amazon Route 53 health checks with a failover routing policy to the second Region.**
  - **적합성 및 내결함성**: 이 솔루션은 웹 계층과 애플리케이션 계층을 두 번째 리전으로 확장하여 가용성을 높이고, Aurora 글로벌 데이터베이스를 사용하여 여러 리전에 걸쳐 데이터베이스를 배포합니다. Route 53 상태 확인과 장애 조치 라우팅 정책을 사용하여 한 리전에서 문제가 발생할 경우 자동으로 두 번째 리전으로 트래픽을 라우팅할 수 있습니다. 이는 가장 높은 내결함성을 제공합니다.

### 다른 옵션들에 대한 설명
- **B. Deploy the web tier and the application tier to a second Region. Add an Aurora PostgreSQL cross-Region Aurora Replica in the second Region. Use Amazon Route 53 health checks with a failover routing policy to the second Region. Promote the secondary to primary as needed.**
  - Aurora 글로벌 데이터베이스를 사용하는 것보다 교차 리전 복제본을 사용하는 것은 더 많은 지연 시간을 초래할 수 있습니다.

- **C. Deploy the web tier and the application tier to a second Region. Create an Aurora PostgreSQL database in the second Region. Use AWS Database Migration Service (AWS DMS) to replicate the primary database to the second Region. Use Amazon Route 53 health checks with a failover routing policy to the second Region.**
  - AWS DMS를 사용한 데이터베이스 복제는 실시간 동기화가 아니므로, 데이터 일관성 문제가 발생할 수 있습니다.

- **D. Deploy the web tier and the application tier to a second Region. Use an Amazon Aurora global database to deploy the database in the primary Region and the second Region. Use Amazon Route 53 health checks with a failover routing policy to the second Region. Promote the secondary to primary as needed.**
  - 이 옵션은 A와 유사하지만, A 옵션이 더 구체적이고 명확한 단계로 설명되어 있습니다.

따라서, A 옵션이 가장 높은 내결함성을 제공하는 솔루션입니다.

### 해설:
- **A. Extend the Auto Scaling groups for the web tier and the application tier to deploy instances in Availability Zones in a second Region. Use an Aurora global database to deploy the database in the primary Region and the second Region. Use Amazon Route 53 health checks with a failover routing policy to the second Region.**
  - **최고의 내결함성**: 이 솔루션은 웹 계층과 애플리케이션 계층을 두 번째 리전으로 확장하고, Aurora 글로벌 데이터베이스를 사용하여 두 리전 간에 데이터베이스를 배포합니다. Route 53의 헬스 체크와 장애 조치 라우팅 정책을 사용하여 한 리전에서 문제가 발생할 경우 자동으로 두 번째 리전으로 트래픽을 전환할 수 있습니다. 이는 글로벌 확장성과 최소한의 다운타임을 보장합니다.

### 다른 옵션들에 대한 설명:
- **B. Deploy the web tier and the application tier to a second Region. Add an Aurora PostgreSQL cross-Region Aurora Replica in the second Region. Use Amazon Route 53 health checks with a failover routing policy to the second Region. Promote the secondary to primary as needed.**
  - 이 솔루션은 Aurora 글로벌 데이터베이스 대신 크로스 리전 리플리카를 사용합니다. 이는 데이터 동기화와 장애 조치 속도에서 글로벌 데이터베이스에 비해 다소 불리할 수 있습니다.

- **C. Deploy the web tier and the application tier to a second Region. Create an Aurora PostgreSQL database in the second Region. Use AWS Database Migration Service (AWS DMS) to replicate the primary database to the second Region. Use Amazon Route 53 health checks with a failover routing policy to the second Region.**
  - AWS DMS를 사용한 데이터베이스 복제는 실시간 동기화가 아닌 배치 기반이므로, 실시간 데이터 동기화와 장애 조치 속도에서 글로벌 데이터베이스에 비해 불리할 수 있습니다.

- **D. Deploy the web tier and the application tier to a second Region. Use an Amazon Aurora global database to deploy the database in the primary Region and the second Region. Use Amazon Route 53 health checks with a failover routing policy to the second Region. Promote the secondary to primary as needed.**
  - 이 옵션은 A와 유사하지만, A 옵션이 더 명확하게 Auto Scaling 그룹을 확장하여 두 번째 리전에 배포하는 것을 언급하고 있습니다.

따라서, A 옵션이 가장 높은 내결함성을 제공하는 솔루션입니다.


# 531번
정답은 **A**입니다.

### 해설:
- **A. Create a function URL for the Lambda function. Provide the Lambda function URL to the third party for the webhook.**
  - **운영 효율성**: Lambda 함수 URL을 생성하면, Lambda 함수를 HTTP(S) 엔드포인트로 직접 호출할 수 있습니다. 이는 설정이 간단하고, 추가적인 인프라를 필요로 하지 않으며, 운영 오버헤드가 최소화됩니다. 제3자에게 Lambda 함수 URL을 제공하면, 웹훅을 통해 데이터를 쉽게 수신할 수 있습니다.

### 다른 옵션들에 대한 설명:
- **B. Deploy an Application Load Balancer (ALB) in front of the Lambda function. Provide the ALB URL to the third party for the webhook.**
  - ALB를 사용하면 추가적인 설정과 비용이 발생하며, 운영 오버헤드가 증가합니다. Lambda 함수 URL을 사용하는 것이 더 간단하고 효율적입니다.

- **C. Create an Amazon Simple Notification Service (Amazon SNS) topic. Attach the topic to the Lambda function. Provide the public hostname of the SNS topic to the third party for the webhook.**
  - SNS 주제를 사용하는 것은 웹훅을 처리하는 데 적합하지 않습니다. SNS는 주로 메시지 브로커 역할을 하며, 직접적인 HTTP(S) 호출을 처리하는 데는 적합하지 않습니다.

- **D. Create an Amazon Simple Queue Service (Amazon SQS) queue. Attach the queue to the Lambda function. Provide the public hostname of the SQS queue to the third party for the webhook.**
  - SQS 큐를 사용하는 것은 웹훅을 처리하는 데 적합하지 않습니다. SQS는 메시지 큐잉 서비스로, 직접적인 HTTP(S) 호출을 처리하는 데는 적합하지 않습니다.

따라서, Lambda 함수 URL을 생성하여 제3자에게 제공하는 것이 가장 운영 효율적인 솔루션입니다.


# 533번
정답은 **A**입니다.

### 해설:
- **A. Use Amazon Macie. Create an Amazon EventBridge rule to filter the SensitiveData event type from Macie findings and to send an Amazon Simple Notification Service (Amazon SNS) notification to the security team.**
  - **적합성**: Amazon Macie는 S3 버킷에서 PII를 자동으로 감지할 수 있는 서비스입니다. Macie의 SensitiveData 이벤트 유형을 필터링하는 Amazon EventBridge 규칙을 생성하고, 이를 통해 Amazon SNS 알림을 보안 팀에 전송하면, PII가 포함된 객체를 자동으로 감지하고 알림을 보낼 수 있습니다. 이는 규제 요구 사항을 충족하는 데 적합한 솔루션입니다.

### 다른 옵션들에 대한 설명:
- **B. Use Amazon GuardDuty. Create an Amazon EventBridge rule to filter the CRITICAL event type from GuardDuty findings and to send an Amazon Simple Notification Service (Amazon SNS) notification to the security team.**
  - GuardDuty는 주로 보안 위협을 감지하는 데 사용되며, PII 감지에는 적합하지 않습니다.

- **C. Use Amazon Macie. Create an Amazon EventBridge rule to filter the SensitiveData:S3Object/Personal event type from Macie findings and to send an Amazon Simple Queue Service (Amazon SQS) notification to the security team.**
  - SQS를 사용하는 것은 가능하지만, SNS를 사용하는 것이 더 적합합니다. SNS는 알림을 즉시 전송할 수 있으며, 보안 팀이 실시간으로 대응할 수 있도록 합니다.

- **D. Use Amazon GuardDuty. Create an Amazon EventBridge rule to filter the CRITICAL event type from GuardDuty findings and to send an Amazon Simple Queue Service (Amazon SQS) notification to the security team.**
  - GuardDuty는 주로 보안 위협을 감지하는 데 사용되며, PII 감지에는 적합하지 않습니다.

따라서, Amazon Macie와 Amazon SNS를 사용하는 A 옵션이 가장 적합한 솔루션입니다.

## SQS의 장점
Amazon Simple Queue Service (SQS)를 사용하면 다음과 같은 장점이 있습니다:

1. **비동기 처리**: SQS는 메시지를 큐에 저장하고, 소비자가 이를 비동기적으로 처리할 수 있게 합니다. 이를 통해 시스템의 구성 요소 간의 결합도를 낮추고, 각 구성 요소가 독립적으로 확장될 수 있습니다.

2. **내구성**: SQS는 메시지를 안전하게 저장하며, 메시지가 손실되지 않도록 보장합니다. 메시지는 여러 가용 영역에 걸쳐 복제되어 높은 내구성을 제공합니다.

3. **확장성**: SQS는 자동으로 확장되어 대량의 메시지를 처리할 수 있습니다. 이를 통해 트래픽이 급증하는 상황에서도 안정적으로 메시지를 처리할 수 있습니다.

4. **유연한 메시지 처리**: SQS는 메시지의 순서 보장(표준 큐) 및 중복 제거(FIFO 큐) 기능을 제공합니다. 이를 통해 다양한 애플리케이션 요구사항에 맞게 큐를 구성할 수 있습니다.

5. **비용 효율성**: SQS는 사용한 만큼만 비용을 지불하는 방식으로 운영되며, 초기 비용 없이 시작할 수 있습니다.

6. **통합**: SQS는 AWS Lambda, Amazon SNS, Amazon S3 등 다양한 AWS 서비스와 쉽게 통합할 수 있어, 복잡한 워크플로우를 간단하게 구성할 수 있습니다.

이러한 장점들로 인해 SQS는 분산 시스템에서 메시지 전달 및 처리의 신뢰성을 높이고, 시스템의 확장성과 유연성을 향상시키는 데 유용합니다.


# 534번

- 답이 C가 아닌가..


이 문제는 AWS S3 스토리지 클래스를 활용하여 로그 데이터를 비용 효율적으로 관리하는 방법에 대한 것입니다. 각 선택지를 검토한 후, 요구사항을 충족하면서도 비용 효율적인 솔루션을 찾아보겠습니다.

### 요구 사항 분석
1. **고가용성 유지**: 로그는 30일 동안 빈번한 분석을 위해 고가용성이 있어야 합니다.
2. **추가 백업 보관**: 로그는 추가적으로 60일 동안 보관되어야 하므로, 총 90일이 필요합니다.
3. **삭제**: 생성된 지 90일 후에 로그는 삭제되어야 합니다.

### 선택지 분석

- **A.** 
  - 30일 후 S3 Standard로 전환하고, 90일 후 삭제하는 만료 작업을 설정합니다.
  - **비용**: S3 Standard는 고가용성을 제공하지만, 요구사항에 비해 저장 비용이 높을 수 있습니다. 

- **B.**
  - 30일 후 S3 Standard-IA로 전환하고, 90일 후 S3 Glacier로 이동합니다. 그리고 90일 후 삭제 작업을 설정합니다.
  - **비용**: S3 Standard-IA는 자주 접근하지 않는 데이터를 위한 비용 절감형 스토리지입니다. 그러나, 90일 후 Glacier로 이동하는 것은 비효율적입니다. 

- **C.**
  - 30일 후 S3 Glacier로 전환하고, 90일 후 삭제 작업을 설정합니다.
  - **비용**: Glacier는 장기 저장을 위한 스토리지이지만, 이 경우에는 빈번한 접근이 필요한 로그 데이터에 적합하지 않습니다.

- **D.**
  - 30일 후 S3 One Zone-IA로 전환하고, 90일 후 Glacier로 이동한 후 삭제 작업을 설정합니다.
  - **비용**: S3 One Zone-IA는 비용 절감형 스토리지로, 특정 가용 영역 내에서만 데이터를 저장하므로 비용이 저렴합니다. 그러나 빈번한 접근에는 적합하지 않을 수 있습니다.

### 최종 결론
가장 비용 효율적이며 요구사항을 충족하는 솔루션은 **A**입니다. 이 선택지는 고가용성을 제공하며, S3 Standard는 빈번한 분석에 적합하고, 만료 작업을 통해 90일 후에 자동으로 삭제할 수 있습니다. 

### 정답
**A. Transition objects to the S3 Standard storage class 30 days after creation. Write an expiration action that directs Amazon S3 to delete objects after 90 days.**


# 539번
정답은 **C**입니다.

### 해설:
- **C. Use AWS Elastic Disaster Recovery configured to replicate disk changes to AWS as a pilot light.**
  - **비용 효율성 및 요구사항 충족**: AWS Elastic Disaster Recovery (DRS)는 디스크 변경 사항을 AWS로 실시간으로 복제하여 RPO를 30초 이하로 유지할 수 있습니다. 또한, 복구 시간 목표(RTO) 60분 이내에 시스템을 복구할 수 있도록 지원합니다. 이 솔루션은 비용을 최소화하면서도 요구되는 RPO와 RTO를 충족할 수 있습니다.

### 다른 옵션들에 대한 설명:
- **A. Configure a multi-site active/active setup between the on-premises server and AWS by using Microsoft SQL Server Enterprise with Always On availability groups.**
  - Always On 가용성 그룹을 사용한 다중 사이트 활성/활성 설정은 높은 가용성을 제공하지만, 비용이 많이 들 수 있습니다. 이는 비용을 최소화하려는 요구사항에 부합하지 않습니다.

- **B. Configure a warm standby Amazon RDS for SQL Server database on AWS. Configure AWS Database Migration Service (AWS DMS) to use change data capture (CDC).**
  - Warm standby 설정은 비용을 절감할 수 있지만, RPO 30초 이하를 보장하기 어려울 수 있습니다. 또한, RDS는 SQL Server Standard를 지원하지 않으므로, 이 옵션은 적합하지 않습니다.

- **D. Use third-party backup software to capture backups every night. Store a secondary set of backups in Amazon S3.**
  - 매일 밤 백업을 캡처하고 S3에 저장하는 것은 RPO 30초 이하와 RTO 60분을 충족하지 못합니다. 이는 주기적인 백업이므로 실시간 복제와는 거리가 멉니다.

따라서, AWS Elastic Disaster Recovery를 사용하여 디스크 변경 사항을 AWS로 복제하는 C 옵션이 가장 적합한 솔루션입니다.


# 540번
정답은 **C**입니다.

### 해설:
- **C. Use Amazon RDS deployed in a Multi-AZ cluster deployment to create an Oracle database. Direct the reporting functions to use the reader instance in the cluster deployment.**
  - **운영 효율성 및 고가용성**: Amazon RDS의 Multi-AZ 클러스터 배포는 고가용성을 제공하며, 읽기 전용 인스턴스를 통해 보고 기능을 오프로드할 수 있습니다. 이는 주 데이터베이스 시스템의 성능을 향상시키고, 보고 기능을 별도의 리더 인스턴스로 분리하여 운영 효율성을 높입니다.

### 다른 옵션들에 대한 설명:
- **A. Use AWS Database Migration Service (AWS DMS) to create an Amazon RDS DB instance in multiple AWS Regions. Point the reporting functions toward a separate DB instance from the primary DB instance.**
  - 여러 AWS 리전에 RDS 인스턴스를 생성하는 것은 고가용성을 제공할 수 있지만, 복잡성과 비용이 증가할 수 있습니다. 또한, 리전 간 데이터 동기화가 필요합니다.

- **B. Use Amazon RDS in a Single-AZ deployment to create an Oracle database. Create a read replica in the same zone as the primary DB instance. Direct the reporting functions to the read replica.**
  - Single-AZ 배포는 고가용성을 제공하지 않으며, 가용성 요구 사항을 충족하지 못합니다.

- **D. Use Amazon RDS deployed in a Multi-AZ instance deployment to create an Amazon Aurora database. Direct the reporting functions to the reader instances.**
  - Amazon Aurora는 높은 성능과 가용성을 제공하지만, Oracle 데이터베이스와의 호환성 문제로 인해 적합하지 않을 수 있습니다. 또한, Aurora는 Oracle과 다른 데이터베이스 엔진입니다.

따라서, Multi-AZ 클러스터 배포를 사용하여 Oracle 데이터베이스를 생성하고, 리더 인스턴스를 통해 보고 기능을 오프로드하는 C 옵션이 가장 운영 효율적인 솔루션입니다.


# 541번
정답은 **A, C, E**입니다.

### 해설:
- **A. Create an AWS Lambda function to retrieve user information from Amazon DynamoDB. Create an Amazon API Gateway endpoint to accept RESTful APIs. Send the API calls to the Lambda function.**
  - **비용 효율성**: Lambda 함수는 사용한 만큼만 비용이 발생하므로, 예측할 수 없는 요청 패턴에 적합합니다. DynamoDB는 서버리스 데이터베이스로, 비용 효율적이고 확장성이 뛰어납니다. API Gateway를 사용하여 RESTful API를 제공하면, Lambda 함수와 통합하여 유연하게 데이터를 처리할 수 있습니다.

- **C. Create an Amazon Cognito user pool to authenticate users.**
  - **사용자 인증**: Amazon Cognito는 사용자 인증을 위한 관리형 서비스로, 사용자 풀을 생성하여 유료 구독자만 웹 애플리케이션에 로그인하고 사용할 수 있도록 할 수 있습니다. 이는 사용자 인증을 간편하게 관리할 수 있는 비용 효율적인 방법입니다.

- **E. Use AWS Amplify to serve the frontend web content with HTML, CSS, and JS. Use an integrated Amazon CloudFront configuration.**
  - **프론트엔드 호스팅**: AWS Amplify는 프론트엔드 웹 콘텐츠를 호스팅하는 데 적합하며, HTML, CSS, JS 파일을 쉽게 배포할 수 있습니다. 또한, CloudFront와 통합하여 전 세계적으로 콘텐츠를 빠르게 제공할 수 있습니다. 이는 비용 효율적이고 관리가 용이한 솔루션입니다.

### 다른 옵션들에 대한 설명:
- **B. Create an Amazon Elastic Container Service (Amazon ECS) service behind an Application Load Balancer to retrieve user information from Amazon RDS. Create an Amazon API Gateway endpoint to accept RESTful APIs. Send the API calls to the Lambda function.**
  - ECS와 RDS를 사용하는 것은 비용이 더 많이 들 수 있으며, Lambda와 DynamoDB를 사용하는 것보다 복잡합니다.

- **D. Create an Amazon Cognito identity pool to authenticate users.**
  - Identity Pool은 주로 AWS 리소스에 대한 임시 자격 증명을 제공하는 데 사용되며, 사용자 인증에는 User Pool이 더 적합합니다.

- **F. Use Amazon S3 static web hosting with PHP, CSS, and JS. Use Amazon CloudFront to serve the frontend web content.**
  - S3 정적 웹 호스팅은 PHP를 지원하지 않으며, 서버리스 아키텍처를 사용하는 것이 더 비용 효율적입니다.

따라서, A, C, E 옵션이 가장 비용 효율적이고 요구 사항을 충족하는 솔루션입니다.


# 542번
정답은 **B**입니다.

### 해설:
- **B. Generate and provide CloudFront signed URLs to premium customers.**
  - **적합성**: CloudFront 서명된 URL을 사용하면 특정 사용자에게만 콘텐츠에 접근할 수 있는 권한을 부여할 수 있습니다. 이는 프리미엄 고객에게만 미디어 스트림과 파일 콘텐츠에 접근할 수 있도록 하는 요구사항을 충족합니다. 서명된 URL은 만료 시간을 설정할 수 있어, 영화 대여나 음악 다운로드와 같은 특정 목적을 위한 콘텐츠 제공에도 적합합니다.

### 다른 옵션들에 대한 설명:
- **A. Generate and provide S3 signed cookies to premium customers.**
  - S3 서명된 쿠키는 S3 객체에 대한 접근을 제어할 수 있지만, CloudFront를 통해 콘텐츠를 제공하는 경우에는 CloudFront 서명된 URL이 더 적합합니다.

- **C. Use origin access control (OAC) to limit the access of non-premium customers.**
  - OAC는 원본 서버에 대한 접근을 제어하는 데 사용되며, 프리미엄 고객에게만 콘텐츠를 제공하는 요구사항을 직접적으로 충족하지 않습니다.

- **D. Generate and activate field-level encryption to block non-premium customers.**
  - 필드 수준 암호화는 데이터의 특정 필드를 암호화하는 데 사용되며, 접근 제어와는 관련이 없습니다.

따라서, CloudFront 서명된 URL을 생성하여 프리미엄 고객에게 제공하는 B 옵션이 가장 적합한 솔루션입니다.


# 543번
정답은 **A**와 **E**입니다.

### 해설:
- **A. From the AWS Account Management Console of the management account, turn on discount sharing from the billing preferences section.**
  - **할인 공유 활성화**: 관리 계정의 AWS Account Management Console에서 청구 환경 설정 섹션에서 할인 공유를 활성화하면, Savings Plan 할인 혜택을 조직 내 다른 계정과 공유할 수 있습니다.

- **E. Create an organization in AWS Organizations in the existing AWS account with the existing EC2 instances and Savings Plan. Invite the other AWS accounts to join the organization from the management account.**
  - **조직 생성 및 계정 초대**: 기존 EC2 인스턴스와 Savings Plan이 있는 AWS 계정에서 AWS Organizations를 사용하여 조직을 생성하고, 다른 AWS 계정을 초대하여 조직에 가입시킵니다. 이를 통해 Savings Plan 할인 혜택을 조직 내 모든 계정에서 사용할 수 있습니다.

### 다른 옵션들에 대한 설명:
- **B. From the AWS Account Management Console of the account that purchased the existing Savings Plan, turn on discount sharing from the billing preferences section. Include all accounts.**
  - 할인 공유는 관리 계정에서 설정해야 하므로, Savings Plan을 구매한 계정에서 설정하는 것은 적절하지 않습니다.

- **C. From the AWS Organizations management account, use AWS Resource Access Manager (AWS RAM) to share the Savings Plan with other accounts.**
  - AWS RAM은 리소스 공유를 위한 서비스이지만, Savings Plan 할인 공유에는 사용되지 않습니다.

- **D. Create an organization in AWS Organizations in a new payer account. Invite the other AWS accounts to join the organization from the management account.**
  - 새로운 결제 계정에서 조직을 생성하는 것은 불필요한 추가 작업입니다. 기존 계정에서 조직을 생성하는 것이 더 효율적입니다.

따라서, A와 E 옵션이 가장 적합한 솔루션입니다.


# 544번
정답은 **A**입니다.

### 해설:
- **A. Create a canary release deployment stage for API Gateway. Deploy the latest API version. Point an appropriate percentage of traffic to the canary stage. After API verification, promote the canary stage to the production stage.**
  - **최소한의 영향 및 데이터 손실**: 카나리 릴리스 배포는 새로운 API 버전을 점진적으로 릴리스하여, 일부 트래픽만 새로운 버전으로 라우팅합니다. 이를 통해 새로운 버전의 API를 검증하고, 문제가 없으면 프로덕션 단계로 승격시킬 수 있습니다. 이 방법은 고객에게 최소한의 영향을 주며, 데이터 손실을 방지할 수 있습니다.

### 다른 옵션들에 대한 설명:
- **B. Create a new API Gateway endpoint with a new version of the API in OpenAPI YAML file format. Use the import-to-update operation in merge mode into the API in API Gateway. Deploy the new version of the API to the production stage.**
  - 새로운 API 버전을 병합 모드로 업데이트하는 것은 가능하지만, 카나리 릴리스와 같은 점진적인 릴리스 전략을 제공하지 않습니다.

- **C. Create a new API Gateway endpoint with a new version of the API in OpenAPI JSON file format. Use the import-to-update operation in overwrite mode into the API in API Gateway. Deploy the new version of the API to the production stage.**
  - 덮어쓰기 모드로 업데이트하는 것은 기존 API를 즉시 대체하므로, 고객에게 영향을 미칠 수 있으며 데이터 손실의 위험이 있습니다.

- **D. Create a new API Gateway endpoint with new versions of the API definitions. Create a custom domain name for the new API Gateway API. Point the Route 53 alias record to the new API Gateway API custom domain name.**
  - 새로운 API 게이트웨이 엔드포인트와 커스텀 도메인을 생성하는 것은 가능하지만, 기존 고객에게 영향을 미칠 수 있으며, 데이터 손실의 위험이 있습니다.

따라서, 카나리 릴리스 배포를 사용하여 새로운 API 버전을 점진적으로 릴리스하는 A 옵션이 가장 적합한 솔루션입니다.


# 550번
AWS Key Management Service (KMS) 키로 암호화된 Lambda 환경 변수를 해독하고 사용하기 위해 솔루션 아키텍트가 수행해야 하는 단계는 다음과 같습니다:

1. **Lambda 실행 역할에 AWS KMS 권한 추가** (옵션 B): Lambda 함수가 `kms:Decrypt` API 호출을 할 수 있는 권한을 가져야 환경 변수를 실행 중에 해독할 수 있습니다.

2. **Lambda 실행 역할을 KMS 키 정책에 허용** (옵션 D): KMS 키 정책에 Lambda 실행 역할이 해당 키를 사용하여 암호를 해독할 수 있도록 명시적으로 허용해야 합니다. 이 권한이 없으면 Lambda 역할에 해독 권한이 있어도 키 정책에서 액세스를 차단하게 됩니다【9†source】【10†source】.

이 두 가지 단계는 Lambda 함수가 KMS로 암호화된 환경 변수를 정상적으로 사용하도록 보장합니다.


## 551번
정답은 **A**입니다.

### 해설:
- **A. Use S3 Standard. Use an S3 Lifecycle rule to transition the reports to S3 Glacier after 7 days.**
  - **비용 효율성 및 요구사항 충족**: S3 Standard는 처음 7일 동안 빈번하게 접근되는 보고서를 저장하는 데 적합합니다. 이후 S3 Glacier로 전환하면 비용을 절감할 수 있으며, **S3 Glacier**는 데이터 복구 시간이 **최대 6시간 이내**로 요구사항을 충족합니다.

### 다른 옵션들에 대한 설명:
- **B. Use S3 Standard. Use an S3 Lifecycle rule to transition the reports to S3 Standard-Infrequent Access (S3 Standard-IA) after 7 days.**
  - S3 Standard-IA는 자주 접근되지 않는 데이터를 저장하는 데 적합하지만, 장기 보관 및 비용 절감 측면에서 S3 Glacier가 더 유리합니다.

- **C. Use S3 Intelligent-Tiering. Configure S3 Intelligent-Tiering to transition the reports to S3 Standard-Infrequent Access (S3 Standard-IA) and S3 Glacier.**
  - S3 Intelligent-Tiering은 자동으로 데이터를 적절한 스토리지 클래스로 전환하지만, 비용 절감 측면에서 S3 Standard와 S3 Glacier를 사용하는 것이 더 효율적입니다.

- **D. Use S3 Standard. Use an S3 Lifecycle rule to transition the reports to S3 Glacier Deep Archive after 7 days.**
  - **S3 Glacier Deep Archive**는 비용이 매우 저렴하지만, 데이터 복구 시간이 **최대 12시간 이상** 걸릴 수 있어 요구사항을 충족하지 못합니다.

따라서, S3 Standard를 사용하여 처음 7일 동안 보고서를 저장하고, 이후 S3 Glacier로 전환하는 A 옵션이 가장 비용 효율적이고 요구사항을 충족하는 솔루션입니다.


## 552번
정답은 **B**입니다.

### 해설:
**B. No Upfront Compute Savings Plan for a 1-year term**입니다.

### 이유:
- **Compute Savings Plan**은 특정 인스턴스 유형에 묶이지 않고 다양한 인스턴스 유형, 리전, 운영 체제에서 유연하게 사용할 수 있습니다. 따라서 회사가 2~3개월마다 인스턴스 유형과 패밀리를 변경해야 한다면, Compute Savings Plan이 적합합니다.
- **No Upfront**은 초기 비용 없이 매달 사용하는 만큼 지불하므로 유동적인 자원 사용에 유리합니다.
- **1년 약정**은 비용 절감 효과를 유지하면서도 비교적 유연한 기간입니다.

다른 옵션들은 특정 인스턴스 유형에 고정되거나 긴 약정 기간(예: 3년)이 있어 인스턴스 변경에 불리할 수 있습니다.

### 다른 옵션들에 대한 설명:
- **A. Purchase Partial Upfront Reserved Instances for a 3-year term.**
  - Reserved Instances는 특정 인스턴스 유형과 가족에 고정되므로, 2-3개월마다 인스턴스 유형과 가족을 변경해야 하는 요구사항을 충족하지 못합니다. 또한, 3년 기간은 너무 길어 유연성이 부족합니다.

- **C. Purchase All Upfront Reserved Instances for a 1-year term.**
  - Reserved Instances는 특정 인스턴스 유형과 가족에 고정되므로, 2-3개월마다 인스턴스 유형과 가족을 변경해야 하는 요구사항을 충족하지 못합니다.

- **D. Purchase an All Upfront EC2 Instance Savings Plan for a 1-year term.**
  - EC2 Instance Savings Plan은 특정 인스턴스 유형과 가족에 고정되므로, Compute Savings Plan에 비해 유연성이 부족합니다.

따라서, No Upfront Compute Savings Plan을 1년 기간으로 구매하는 B 옵션이 가장 적합한 솔루션입니다.


# 554번
이 문제에서 회사는 메모리 사용량이 높은 SAP 애플리케이션과 SQL Server 데이터베이스를 온프레미스 환경에서 AWS로 마이그레이션하려고 합니다. 이때, 가장 적합한 솔루션은 **옵션 C: 애플리케이션과 데이터베이스 모두에 메모리 최적화 인스턴스 패밀리를 사용하는 것**입니다.

### 설명:
- **메모리 최적화 인스턴스**는 고메모리 요구 사항이 있는 애플리케이션과 데이터베이스에 적합합니다. 예를 들어, *R5*나 *X1* 인스턴스는 대규모 데이터를 처리하거나 인메모리 작업을 수행하는 SAP 애플리케이션과 SQL Server 데이터베이스에서 최적의 성능을 제공합니다【21†source】【22†source】.
- 컴퓨팅 최적화나 스토리지 최적화 인스턴스는 이 시나리오에서 부적합합니다. 이 문제에서의 주요 병목 현상은 스토리지 용량이나 컴퓨팅 성능이 아닌 메모리이기 때문입니다.
- 고성능 컴퓨팅(HPC) 인스턴스는 매우 강력하지만, 일반적인 SAP 애플리케이션 및 데이터베이스 워크로드에는 과도한 선택일 수 있으며, 메모리가 더 중요한 역할을 합니다【22†source】.

이 설정은 SAP 애플리케이션과 SQL Server 데이터베이스 모두의 높은 메모리 요구 사항을 충족시켜 최적의 성능을 보장합니다.


# 556번
정답은 **B**입니다.

### 해설:
- **B. Create an IAM role that has the required permissions to read and write from the DynamoDB tables. Add the role to the EC2 instance profile, and associate the instance profile with the application instances.**
  - **적합성**: IAM 역할을 사용하여 EC2 인스턴스에 필요한 권한을 부여하면, API 자격 증명을 템플릿에 노출하지 않고도 DynamoDB 테이블에 접근할 수 있습니다. EC2 인스턴스 프로파일을 통해 IAM 역할을 EC2 인스턴스에 연결하면, 애플리케이션이 안전하게 DynamoDB 테이블에 접근할 수 있습니다.

### 다른 옵션들에 대한 설명:
- **A. Create an IAM role to read the DynamoDB tables. Associate the role with the application instances by referencing an instance profile.**
  - 이 옵션은 읽기 권한만 부여하므로, DynamoDB 테이블에 쓰기 권한이 필요한 경우에는 적합하지 않습니다.

- **C. Use the parameter section in the AWS CloudFormation template to have the user input access and secret keys from an already-created IAM user that has the required permissions to read and write from the DynamoDB tables.**
  - 사용자로부터 액세스 및 비밀 키를 입력받는 것은 보안상 위험이 있으며, 자격 증명을 템플릿에 노출하는 것은 바람직하지 않습니다.

- **D. Create an IAM user in the AWS CloudFormation template that has the required permissions to read and write from the DynamoDB tables. Use the GetAtt function to retrieve the access and secret keys, and pass them to the application instances through the user data.**
  - IAM 사용자를 생성하고 자격 증명을 전달하는 것은 보안상 위험이 있으며, 자격 증명을 템플릿에 노출하는 것은 바람직하지 않습니다.

따라서, IAM 역할을 생성하고 EC2 인스턴스 프로파일을 통해 애플리케이션 인스턴스에 연결하는 B 옵션이 가장 적합한 솔루션입니다.


# 557번
정답은 **B**입니다.

### 해설:
- **B. Use Amazon EMR to process the S3 data. Use Amazon EMR with the Amazon Redshift data to enrich the S3 data.**
  - **병렬 데이터 처리 및 데이터 풍부화**: Amazon EMR은 대규모 데이터 세트를 병렬로 처리하는 데 적합한 관리형 클러스터 플랫폼입니다. EMR을 사용하여 S3에 저장된 반구조화 데이터를 빠르게 처리할 수 있습니다. 또한, EMR은 Amazon Redshift와 통합되어 Redshift에 저장된 데이터를 사용하여 S3 데이터를 풍부화할 수 있습니다. 이는 요구사항을 충족하는 가장 적합한 솔루션입니다.

### 다른 옵션들에 대한 설명:
- **A. Use Amazon Athena to process the S3 data. Use AWS Glue with the Amazon Redshift data to enrich the S3 data.**
  - Amazon Athena는 대화형 쿼리 서비스로, 대규모 병렬 데이터 처리에는 적합하지 않을 수 있습니다. 또한, AWS Glue는 ETL 작업에 주로 사용되며, 병렬 데이터 처리 성능이 EMR에 비해 떨어질 수 있습니다.

- **C. Use Amazon EMR to process the S3 data. Use Amazon Kinesis Data Streams to move the S3 data into Amazon Redshift so that the data can be enriched.**
  - Kinesis Data Streams는 실시간 데이터 스트리밍 서비스로, S3 데이터를 Redshift로 이동하는 데 적합하지 않습니다. EMR을 사용하여 직접 데이터를 처리하고 풍부화하는 것이 더 효율적입니다.

- **D. Use AWS Glue to process the S3 data. Use AWS Lake Formation with the Amazon Redshift data to enrich the S3 data.**
  - AWS Glue는 ETL 작업에 주로 사용되며, 병렬 데이터 처리 성능이 EMR에 비해 떨어질 수 있습니다. 또한, AWS Lake Formation은 데이터 레이크 관리 서비스로, 데이터 풍부화 작업에 직접적으로 사용되지는 않습니다.

따라서, Amazon EMR을 사용하여 S3 데이터를 병렬로 처리하고, Redshift 데이터를 사용하여 데이터를 풍부화하는 B 옵션이 가장 적합한 솔루션입니다.


# 559번
정답은 **B**와 **E**입니다.

### 해설:
- **B. Select a specific user-defined tag in the AWS Billing console.**
  - **사용자 정의 태그 선택**: AWS Billing 콘솔에서 사용자 정의 태그를 선택하면, 비용 보고서에서 해당 태그를 기준으로 비용을 분류할 수 있습니다. 이는 각 제품 라인별로 비용을 세분화하는 데 필요합니다.

- **E. Activate the selected tag from the Organizations management account.**
  - **태그 활성화**: AWS Organizations 관리 계정에서 선택한 태그를 활성화하면, 조직 내 모든 계정에서 해당 태그를 사용할 수 있습니다. 이는 태그를 기반으로 비용을 추적하고 보고하는 데 필수적입니다.

### 다른 옵션들에 대한 설명:
- **A. Select a specific AWS generated tag in the AWS Billing console.**
  - AWS에서 생성한 태그는 사용자 정의 태그와 달리 특정 비용 분류를 위해 사용되지 않습니다.

- **C. Select a specific user-defined tag in the AWS Resource Groups console.**
  - AWS Resource Groups 콘솔에서 태그를 선택하는 것은 리소스 그룹화를 위한 것이며, 비용 보고와는 직접적인 관련이 없습니다.

- **D. Activate the selected tag from each AWS account.**
  - 각 AWS 계정에서 태그를 활성화하는 것은 가능하지만, Organizations 관리 계정에서 태그를 활성화하는 것이 더 효율적입니다.

따라서, AWS Billing 콘솔에서 사용자 정의 태그를 선택하고, Organizations 관리 계정에서 해당 태그를 활성화하는 B와 E 옵션이 가장 적합한 솔루션입니다.


# 560번
정답은 **B**입니다.

### 해설:
- **B. Provision the AWS accounts by using AWS Control Tower. Use AWS Config aggregated rules to identify the changes to the OU hierarchy.**
  - **운영 오버헤드 최소화**: AWS Control Tower는 멀티 계정 환경을 쉽게 설정하고 관리할 수 있는 서비스입니다. AWS Config를 사용하여 OU 계층 구조의 변경 사항을 모니터링하고, 집계된 규칙을 통해 변경 사항을 식별할 수 있습니다. 이를 통해 운영 팀에 알림을 보낼 수 있습니다. 이 솔루션은 자동화된 모니터링과 알림을 제공하여 운영 오버헤드를 최소화합니다.

### 다른 옵션들에 대한 설명:
- **A. Provision the AWS accounts by using AWS Control Tower. Use account drift notifications to identify the changes to the OU hierarchy.**
  - 계정 드리프트 알림은 계정 수준의 변경 사항을 모니터링하는 데 사용되며, OU 계층 구조의 변경 사항을 식별하는 데는 적합하지 않습니다.

** 계정 드리프트 알림(Account Drift Notification)은 AWS Control Tower에서 관리하는 계정이 처음 설정된 상태와 달라졌을 때, 이를 감지하고 알림을 보내는 기능입니다. "드리프트"란 계정이 Control Tower의 거버넌스 기준과 불일치하게 변경되었을 때를 의미합니다.

예를 들어, AWS Control Tower에서 관리 중인 계정에 대해 특정 규칙이나 정책이 적용되었는데, 시간이 지나면서 수동 변경 또는 자동화된 작업에 의해 설정이 바뀌면 "드리프트"가 발생합니다. 이런 드리프트가 발생하면 AWS Control Tower는 이를 감지하고 알림을 제공하여 수정할 수 있도록 도와줍니다.

이 기능을 통해 조직은 관리되는 계정이 항상 설정된 정책과 일치하는지 확인하고, 불필요한 리스크를 줄일 수 있습니다.



- **C. Use AWS Service Catalog to create accounts in Organizations. Use an AWS CloudTrail organization trail to identify the changes to the OU hierarchy.**
  - AWS Service Catalog는 주로 제품 및 서비스 카탈로그를 관리하는 데 사용되며, 계정 생성 및 OU 계층 구조 변경 모니터링에는 적합하지 않습니다. CloudTrail은 변경 사항을 기록할 수 있지만, 직접적인 알림 기능을 제공하지 않습니다.

- **D. Use AWS CloudFormation templates to create accounts in Organizations. Use the drift detection operation on a stack to identify the changes to the OU hierarchy.**
  - CloudFormation 드리프트 감지는 스택 리소스의 변경 사항을 감지하는 데 사용되며, OU 계층 구조의 변경 사항을 식별하는 데는 적합하지 않습니다.

따라서, AWS Control Tower와 AWS Config 집계 규칙을 사용하여 OU 계층 구조의 변경 사항을 모니터링하고 알림을 설정하는 B 옵션이 가장 적합한 솔루션입니다.


# 562번
### 문제 분석
솔루션 아키텍트는 VPC 내의 Amazon EC2 인스턴스에서 Amazon DynamoDB로의 API 호출이 인터넷을 거치지 않도록 해야 합니다. 즉, **인터넷 경로를 우회**하고 **프라이빗 네트워크**를 통해 DynamoDB와 통신하도록 구성해야 합니다.

### 정답: **A. Create a route table entry for the endpoint.**  
**B. Create a gateway endpoint for DynamoDB.**

### 해설:

#### 각 선택지 분석:

**A. Create a route table entry for the endpoint.**
- Gateway 엔드포인트를 생성하면 VPC 내부에서 해당 서비스로의 트래픽이 인터넷을 통과하지 않도록 합니다. 이 엔드포인트는 VPC의 라우팅 테이블에 추가되어, 해당 경로로 트래픽을 라우팅하도록 설정해야 합니다.
- **필수 단계**로, 엔드포인트가 올바르게 동작하려면 VPC 라우팅 테이블에 엔드포인트에 대한 항목을 추가해야 합니다.

**B. Create a gateway endpoint for DynamoDB.**
- **Amazon DynamoDB**는 **Gateway 엔드포인트**를 지원합니다. Gateway 엔드포인트는 인터넷을 경유하지 않고 VPC 내부에서 해당 서비스로 트래픽을 전달하는 역할을 합니다. 
- Gateway 엔드포인트는 VPC의 라우팅 테이블과 통합되어 설정되므로, EC2 인스턴스는 인터넷을 거치지 않고 직접 DynamoDB에 액세스할 수 있습니다.

**C. Create an interface endpoint for Amazon EC2.**
- **인터페이스 엔드포인트**는 VPC에서 PrivateLink를 사용하여 특정 서비스에 연결하는 방식입니다. 하지만, DynamoDB는 **Gateway 엔드포인트**로 구성되므로, 인터페이스 엔드포인트는 이 문제에서 적절하지 않습니다.

**D. Create an elastic network interface for the endpoint in each of the subnets of the VPC.**
- Elastic Network Interface (ENI)는 인터페이스 엔드포인트에 사용됩니다. 하지만, DynamoDB는 Gateway 엔드포인트를 사용하기 때문에 ENI가 필요하지 않습니다. 이 단계는 DynamoDB와 관련이 없습니다.

**E. Create a security group entry in the endpoint's security group to provide access.**
- **보안 그룹(Security Group)**은 인터페이스 엔드포인트에서 사용되는 네트워크 보안 제어 기능입니다. 하지만, Gateway 엔드포인트는 보안 그룹을 사용하지 않습니다. 보안 그룹 설정은 이 경우 필요하지 않습니다.

### 정리:
**Amazon DynamoDB**는 **Gateway 엔드포인트**를 사용해야 하므로, **A. 경로 테이블 항목 생성**과 **B. Gateway 엔드포인트 생성**이 정답입니다. Gateway 엔드포인트는 라우팅 테이블과 연동되어 트래픽을 인터넷을 통하지 않고 VPC 내에서 전달하게 해줍니다.


# 563번
### 문제 분석
회사는 **Amazon EKS** 클러스터와 **온프레미스 Kubernetes** 클러스터에서 애플리케이션을 실행하며, **중앙 위치에서 모든 클러스터와 워크로드를 볼 수 있는 방법**을 찾고 있습니다. 이 요구를 충족시키면서 **운영 오버헤드를 최소화**하는 해결책을 찾아야 합니다.

### 정답: **B. Use Amazon EKS Connector to register and connect all Kubernetes clusters.**

### 해설:

#### 각 선택지 분석:

**A. Use Amazon CloudWatch Container Insights to collect and group the cluster information.**
- **Amazon CloudWatch Container Insights**는 컨테이너 기반 애플리케이션의 메트릭 및 로그 데이터를 수집하는 데 사용됩니다. EKS 클러스터의 성능 모니터링을 도와주지만, **클러스터 전체를 중앙 위치에서 관리하는 기능**은 제공하지 않습니다. 또한, **온프레미스 Kubernetes 클러스터**와 직접적인 연결이 어렵습니다.
- **운영 오버헤드**: 온프레미스 클러스터 통합을 위해 추가적인 설정과 구성이 필요할 수 있어, 오버헤드가 발생할 수 있습니다.
  
**B. Use Amazon EKS Connector to register and connect all Kubernetes clusters.**
- **Amazon EKS Connector**는 **EKS 클러스터와 온프레미스 Kubernetes 클러스터**를 **중앙 위치에서 모니터링하고 관리할 수 있도록 연결하는 도구**입니다. EKS Connector를 사용하면 모든 클러스터를 **Amazon EKS 콘솔**에서 중앙 집중화된 관리 인터페이스로 볼 수 있으며, 클러스터 정보 및 워크로드를 한 곳에서 관리할 수 있습니다.
- **운영 오버헤드**: 최소화된 오버헤드로, 클러스터들을 중앙에서 관리할 수 있는 이상적인 솔루션입니다.

**C. Use AWS Systems Manager to collect and view the cluster information.**
- **AWS Systems Manager**는 인스턴스 관리에 뛰어난 도구로, 클러스터 정보를 직접적으로 모니터링하거나 연결하는 데 적합하지 않습니다. 클러스터 상태 및 워크로드 모니터링을 위한 직접적인 지원이 부족합니다.
- **운영 오버헤드**: 별도의 구성 작업이 많이 필요하며, 클러스터 관리 기능이 부족합니다.

**D. Use Amazon EKS Anywhere as the primary cluster to view the other clusters with native Kubernetes commands.**
- **Amazon EKS Anywhere**는 온프레미스에서 Kubernetes 클러스터를 실행할 수 있는 솔루션이지만, **다른 클러스터를 중앙에서 관리**하는 기능이 기본적으로 제공되지 않습니다. 또한, EKS Anywhere는 **Kubernetes 명령어로 클러스터를 관리**하는 방식을 지원하지만, EKS 콘솔이나 GUI를 통한 중앙 집중 관리와는 다릅니다.
- **운영 오버헤드**: Kubernetes 명령어를 통해 클러스터를 관리하는 데 추가 작업이 필요할 수 있습니다.

### 정리:
**Amazon EKS Connector**를 사용하면 **EKS 콘솔**에서 모든 **EKS 및 온프레미스 Kubernetes 클러스터**를 중앙에서 관리할 수 있으며, 이 방법이 가장 **운영 오버헤드가 적은 솔루션**입니다. EKS Connector는 간편하게 모든 클러스터를 하나의 콘솔에서 모니터링하고 관리할 수 있도록 해줍니다.


# 569번
정답은 **A**입니다.

### 해설:
- **A. Check for metrics in Amazon CloudWatch in the namespace for AWS/Events.**
  - **적합성**: Amazon CloudWatch에서 AWS/Events 네임스페이스의 메트릭을 확인하면, EventBridge 규칙이 조건을 충족하고 있는지, 그리고 규칙의 타겟이 호출되고 있는지 여부를 모니터링할 수 있습니다. CloudWatch 메트릭은 이벤트가 발생했는지, 타겟이 호출되었는지에 대한 정보를 제공합니다.

### 다른 옵션들에 대한 설명:
- **B. Review events in the Amazon Simple Queue Service (Amazon SQS) dead-letter queue.**
  - SQS 데드레터 큐는 실패한 메시지를 저장하는 데 사용되며, EventBridge 규칙의 조건 충족 여부나 타겟 호출 여부를 직접적으로 확인하는 데는 적합하지 않습니다.

- **C. Check for the events in Amazon CloudWatch Logs.**
  - CloudWatch Logs는 로그 데이터를 저장하고 분석하는 데 사용되지만, EventBridge 규칙의 조건 충족 여부나 타겟 호출 여부를 모니터링하는 데는 적합하지 않습니다.

- **D. Check the trails in AWS CloudTrail for the EventBridge events.**
  - CloudTrail은 AWS 계정의 API 호출을 기록하는 데 사용되며, EventBridge 이벤트의 조건 충족 여부나 타겟 호출 여부를 직접적으로 확인하는 데는 적합하지 않습니다.

따라서, Amazon CloudWatch에서 AWS/Events 네임스페이스의 메트릭을 확인하는 A 옵션이 가장 적합한 솔루션입니다.


# 571번
정답은 **A**입니다.

### 해설:
- **A. Use a local machine to create a certificate that is signed by the third-party CA. Import the certificate into AWS Certificate Manager (ACM). Create an HTTP API in Amazon API Gateway with a custom domain. Configure the custom domain to use the certificate.**
  - **적합성**: 이 옵션은 로컬 머신에서 특정 공인 제3자 인증 기관(CA)으로 서명된 인증서를 생성하고, 이를 AWS Certificate Manager (ACM)에 가져오는 과정을 포함합니다. 그런 다음, Amazon API Gateway에서 HTTP API를 생성하고, 사용자 지정 도메인을 구성하여 가져온 인증서를 사용합니다. 이는 TLSv1.3을 지원하고, 특정 CA로 서명된 인증서를 사용하는 요구사항을 충족합니다.

### 다른 옵션들에 대한 설명:
- **B. Create a certificate in AWS Certificate Manager (ACM) that is signed by the third-party CA. Create an HTTP API in Amazon API Gateway with a custom domain. Configure the custom domain to use the certificate.**
  - AWS Certificate Manager (ACM)에서 직접 제3자 CA로 서명된 인증서를 생성하는 것은 불가능합니다. 인증서를 로컬에서 생성한 후 ACM에 가져와야 합니다.

- **C. Use AWS Certificate Manager (ACM) to create a certificate that is signed by the third-party CA. Import the certificate into AWS Certificate Manager (ACM). Create an AWS Lambda function with a Lambda function URL. Configure the Lambda function URL to use the certificate.**
  - Lambda 함수 URL은 사용자 지정 도메인 및 인증서 구성을 지원하지 않습니다. 또한, Lambda 함수 URL은 API Gateway와 같은 기능을 제공하지 않습니다.

- **D. Create a certificate in AWS Certificate Manager (ACM) that is signed by the third-party CA. Create an AWS Lambda function with a Lambda function URL. Configure the Lambda function URL to use the certificate.**
  - Lambda 함수 URL은 사용자 지정 도메인 및 인증서 구성을 지원하지 않습니다. 또한, Lambda 함수 URL은 API Gateway와 같은 기능을 제공하지 않습니다.

따라서, 로컬 머신에서 인증서를 생성하고 이를 ACM에 가져와서 API Gateway의 사용자 지정 도메인에 사용하는 A 옵션이 가장 적합한 솔루션입니다.


# 573번
정답은 **D**입니다.

### 해설:
- **D. Configure Lambda SnapStart.**
  - **비용 효율성 및 요구사항 충족**: Lambda SnapStart는 Java 기반 Lambda 함수의 콜드 스타트 시간을 줄이기 위해 설계된 기능입니다. SnapStart는 함수의 초기화 상태를 저장하고, 이후 호출 시 이를 재사용하여 콜드 스타트 시간을 줄입니다. 이는 비용 효율적으로 콜드 스타트와 이상 지연 시간을 줄이는 데 도움이 됩니다.

### 다른 옵션들에 대한 설명:
- **A. Configure Lambda provisioned concurrency.**
  - 프로비저닝된 동시성은 콜드 스타트를 줄이는 데 효과적이지만, 항상 일정한 수의 인스턴스를 유지해야 하므로 비용이 더 많이 들 수 있습니다.

- **B. Increase the timeout of the Lambda functions.**
  - 타임아웃을 증가시키는 것은 함수 실행 시간을 늘리는 것이며, 콜드 스타트 시간을 줄이는 데는 도움이 되지 않습니다.

- **C. Increase the memory of the Lambda functions.**
  - 메모리를 증가시키면 함수의 성능이 향상될 수 있지만, 콜드 스타트 시간을 줄이는 데는 직접적인 도움이 되지 않습니다. 또한, 메모리 증가로 인해 비용이 증가할 수 있습니다.

따라서, Lambda SnapStart를 구성하여 Java 기반 Lambda 함수의 콜드 스타트 시간을 줄이는 D 옵션이 가장 비용 효율적인 솔루션입니다.


# 574번
정답은 **A**입니다.

### 해설:
- **A. Migrate the existing RDS for MySQL database to an Aurora Serverless v2 MySQL database cluster.**
  - **비용 효율성**: Aurora Serverless v2는 사용량에 따라 자동으로 확장 및 축소되는 서버리스 데이터베이스입니다. 이 데이터베이스는 사용하지 않을 때 비용이 발생하지 않으며, 필요한 경우에만 비용이 발생합니다. 따라서, 주당 2시간만 운영해야 하는 애플리케이션에 가장 비용 효율적인 솔루션입니다.

### 다른 옵션들에 대한 설명:
- **B. Migrate the existing RDS for MySQL database to an Aurora MySQL database cluster.**
  - Aurora MySQL 클러스터는 항상 실행 중이어야 하므로, 주당 2시간만 운영하는 경우에도 비용이 발생합니다. 이는 비용 효율적이지 않습니다.

- **C. Migrate the existing RDS for MySQL database to an Amazon EC2 instance that runs MySQL. Purchase an instance reservation for the EC2 instance.**
  - EC2 인스턴스를 예약 구매하면 비용이 절감될 수 있지만, 인스턴스가 항상 실행 중이어야 하므로 주당 2시간만 운영하는 경우에는 비용 효율적이지 않습니다.

- **D. Migrate the existing RDS for MySQL database to an Amazon Elastic Container Service (Amazon ECS) cluster that uses MySQL container images to run tasks.**
  - ECS 클러스터를 사용하면 컨테이너를 관리해야 하며, 이는 추가적인 운영 오버헤드를 발생시킬 수 있습니다. 또한, 주당 2시간만 운영하는 경우에도 비용 효율적이지 않을 수 있습니다.

따라서, Aurora Serverless v2를 사용하여 필요할 때만 비용이 발생하도록 하는 A 옵션이 가장 비용 효율적인 솔루션입니다.


# 575번
정답은 **C**입니다.

### 해설:
- **C. Create an Amazon RDS database with Multi-AZ DB cluster deployment.**
  - **운영 효율성 및 요구사항 충족**: Amazon RDS의 Multi-AZ DB 클러스터 배포는 고가용성을 제공하며, 읽기 작업을 위한 추가 용량을 제공합니다. Multi-AZ DB 클러스터는 여러 가용 영역에 걸쳐 자동으로 데이터베이스를 복제하여 장애 발생 시에도 데이터베이스의 가용성을 유지합니다. 또한, 읽기 전용 인스턴스를 추가하여 읽기 작업의 성능을 향상시킬 수 있습니다.

### 다른 옵션들에 대한 설명:
- **A. Create an Amazon DynamoDB database table configured with global tables.**
  - DynamoDB는 NoSQL 데이터베이스로, PostgreSQL과 같은 관계형 데이터베이스를 대체하기에는 적합하지 않습니다.

- **B. Create an Amazon RDS database with Multi-AZ deployments.**
  - Multi-AZ 배포는 고가용성을 제공하지만, 읽기 작업을 위한 추가 용량을 제공하지 않습니다. 읽기 성능을 향상시키기 위해서는 읽기 전용 인스턴스가 필요합니다.

- **D. Create an Amazon RDS database configured with cross-Region read replicas.**
  - 교차 리전 읽기 복제본은 읽기 성능을 향상시킬 수 있지만, 고가용성을 제공하는 데는 적합하지 않습니다. 또한, 운영 오버헤드가 증가할 수 있습니다.

따라서, Amazon RDS의 Multi-AZ DB 클러스터 배포를 사용하는 C 옵션이 가장 적합한 솔루션입니다.


# 577번
정답은 **C**입니다.

### 해설:
- **C. Use AWS Certificate Manager (ACM) to create a certificate. Use DNS validation for the domain.**
  - **운영 효율성**: AWS Certificate Manager (ACM)를 사용하여 TLS 인증서를 생성하고, DNS 검증을 사용하면 인증서의 생성 및 갱신이 자동화됩니다. DNS 검증은 한 번 설정하면 자동으로 갱신되므로, 이메일 검증보다 운영 효율성이 높습니다. CloudFront와 ACM을 통합하여 TLS 인증서를 자동으로 관리할 수 있습니다.

### 다른 옵션들에 대한 설명:
- **A. Use a CloudFront security policy to create a certificate.**
  - CloudFront 보안 정책은 TLS 인증서를 생성하는 기능을 제공하지 않습니다. TLS 인증서는 ACM과 같은 서비스에서 생성해야 합니다.

- **B. Use a CloudFront origin access control (OAC) to create a certificate.**
  - CloudFront 원본 접근 제어(OAC)는 원본 서버에 대한 접근을 제어하는 기능으로, TLS 인증서를 생성하는 기능을 제공하지 않습니다.

- **D. Use AWS Certificate Manager (ACM) to create a certificate. Use email validation for the domain.**
  - 이메일 검증은 인증서 갱신 시마다 수동으로 이메일을 확인해야 하므로, DNS 검증에 비해 운영 효율성이 낮습니다.

따라서, AWS Certificate Manager (ACM)를 사용하여 TLS 인증서를 생성하고, DNS 검증을 사용하는 C 옵션이 가장 운영 효율적인 솔루션입니다.


# 579번
정답은 **A**입니다.

### 해설:
- **A. Use the Instance Scheduler on AWS to configure start and stop schedules.**
  - **비용 최적화 및 운영 오버헤드 감소**: Instance Scheduler on AWS를 사용하면 RDS 인스턴스를 특정 시간에 자동으로 시작하고 중지할 수 있습니다. 이 솔루션은 주중 업무 시간 동안에만 트래픽을 받는 애플리케이션에 적합하며, 비업무 시간 동안 인스턴스를 중지하여 비용을 절감할 수 있습니다. 또한, 자동화된 스케줄링을 통해 운영 오버헤드를 줄일 수 있습니다.

### 다른 옵션들에 대한 설명:
- **B. Turn off automatic backups. Create weekly manual snapshots of the database.**
  - 자동 백업을 끄고 수동 스냅샷을 생성하는 것은 비용 절감에 큰 영향을 미치지 않으며, 데이터 보호 측면에서 위험할 수 있습니다.

- **C. Create a custom AWS Lambda function to start and stop the database based on minimum CPU utilization.**
  - Lambda 함수를 사용하여 데이터베이스를 시작하고 중지하는 것은 가능하지만, Instance Scheduler를 사용하는 것보다 설정과 관리가 더 복잡할 수 있습니다.

- **D. Purchase All Upfront reserved DB instances.**
  - All Upfront 예약 인스턴스를 구매하면 비용을 절감할 수 있지만, 주중 업무 시간 동안에만 트래픽을 받는 애플리케이션에는 적합하지 않습니다. 예약 인스턴스는 항상 실행 중이어야 하므로, 비업무 시간 동안에도 비용이 발생합니다.

따라서, Instance Scheduler on AWS를 사용하여 시작 및 중지 일정을 구성하는 A 옵션이 가장 적합한 솔루션입니다.


# 580번
정답은 **D**입니다.

### 해설:
- **D. Host the application on an Amazon EC2 instance. Use an Amazon Elastic Block Store (Amazon EBS) GP3 volume to run the application.**
  - **비용 효율성 및 성능**: Amazon EBS GP3 볼륨은 GP2 볼륨에 비해 더 낮은 비용으로 더 높은 성능을 제공합니다. GP3 볼륨은 IOPS와 처리량을 독립적으로 조정할 수 있어, 지연 시간에 민감한 애플리케이션에 적합합니다. EC2 인스턴스와 EBS GP3 볼륨을 사용하면 애플리케이션 아키텍처를 변경하지 않고도 AWS 클라우드로의 리프트 앤 시프트를 수행할 수 있습니다.

### 다른 옵션들에 대한 설명:
- **A. Configure an Auto Scaling group with an Amazon EC2 instance. Use an Amazon FSx for Lustre file system to run the application.**
  - Amazon FSx for Lustre는 고성능 파일 시스템으로, 주로 고성능 컴퓨팅(HPC) 워크로드에 사용됩니다. 지연 시간에 민감한 애플리케이션에는 적합하지 않을 수 있으며, 비용이 더 많이 들 수 있습니다.

- **B. Host the application on an Amazon EC2 instance. Use an Amazon Elastic Block Store (Amazon EBS) GP2 volume to run the application.**
  - GP2 볼륨은 GP3 볼륨에 비해 비용이 더 높고 성능이 낮습니다. GP3 볼륨을 사용하는 것이 더 비용 효율적입니다.

- **C. Configure an Auto Scaling group with an Amazon EC2 instance. Use an Amazon FSx for OpenZFS file system to run the application.**
  - Amazon FSx for OpenZFS는 파일 시스템으로, 블록 스토리지가 필요한 지연 시간에 민감한 애플리케이션에는 적합하지 않을 수 있습니다. 또한, 비용이 더 많이 들 수 있습니다.

따라서, Amazon EC2 인스턴스와 Amazon EBS GP3 볼륨을 사용하는 D 옵션이 가장 비용 효율적이고 성능이 뛰어난 솔루션입니다.

# 581번
정답은 **A**입니다.

### 해설:
- **A. Set the Auto Scaling group's minimum capacity to two. Deploy one On-Demand Instance in one Availability Zone and one On-Demand Instance in a second Availability Zone.**
  - **고가용성 및 내결함성**: 최소 용량을 2로 설정하고, 두 개의 가용 영역(AZ)에 각각 하나의 온디맨드 인스턴스를 배포하면, 하나의 AZ에 장애가 발생하더라도 다른 AZ에서 애플리케이션이 계속 실행될 수 있습니다. 이는 고가용성과 내결함성을 보장합니다.

### 다른 옵션들에 대한 설명:
- **B. Set the Auto Scaling group's minimum capacity to four. Deploy two On-Demand Instances in one Availability Zone and two On-Demand Instances in a second Availability Zone.**
  - 최소 용량을 4로 설정하는 것은 필요 이상으로 많은 인스턴스를 실행하게 되어 비용이 증가할 수 있습니다. 최소 2개의 인스턴스만 항상 실행되면 되므로, 이 옵션은 과도합니다.

- **C. Set the Auto Scaling group's minimum capacity to two. Deploy four Spot Instances in one Availability Zone.**
  - Spot 인스턴스는 언제든지 회수될 수 있으므로, 항상 실행되어야 하는 상태 저장 애플리케이션에는 적합하지 않습니다. 또한, 하나의 AZ에만 배포하는 것은 고가용성을 보장하지 않습니다.

- **D. Set the Auto Scaling group's minimum capacity to four. Deploy two On-Demand Instances in one Availability Zone and two Spot Instances in a second Availability Zone.**
  - 최소 용량을 4로 설정하는 것은 필요 이상으로 많은 인스턴스를 실행하게 되어 비용이 증가할 수 있습니다. 또한, Spot 인스턴스는 언제든지 회수될 수 있으므로, 항상 실행되어야 하는 상태 저장 애플리케이션에는 적합하지 않습니다.

따라서, 최소 용량을 2로 설정하고, 두 개의 가용 영역에 각각 하나의 온디맨드 인스턴스를 배포하는 A 옵션이 가장 적합한 솔루션입니다.


# 583번
정답은 **C. Order multiple AWS Snowball devices that have Tape Gateway. Copy the physical tapes to virtual tapes in Snowball. Ship the Snowball devices to AWS. Create a lifecycle policy to move the tapes to Amazon S3 Glacier Deep Archive.** 입니다.

### 해설:

1. **옵션 A**:
   - **AWS DataSync**를 사용하여 데이터를 Amazon S3 Glacier Flexible Retrieval로 마이그레이션하는 방법입니다.
   - 1 Gbps의 인터넷 연결 속도로 5 PB의 데이터를 전송하는 데는 매우 오랜 시간이 걸립니다. 이는 비용 효율적이지 않습니다.

2. **옵션 B**:
   - 온프레미스 백업 애플리케이션을 사용하여 데이터를 Amazon S3 Glacier Deep Archive로 직접 쓰는 방법입니다.
   - 이 방법도 인터넷 연결 속도로 인해 시간이 많이 소요되며, 비용 효율적이지 않습니다.

3. **옵션 C**:
   - **AWS Snowball** 장치를 주문하여 Tape Gateway를 사용해 물리적 테이프를 가상 테이프로 복사하고, 이를 AWS로 배송하는 방법입니다.
   - Snowball 장치는 대용량 데이터를 물리적으로 전송할 수 있어 인터넷 연결 속도의 제약을 받지 않습니다.
   - 이후 Amazon S3 Glacier Deep Archive로 데이터를 이동하는 라이프사이클 정책을 설정할 수 있습니다.
   - 이 방법이 가장 비용 효율적이며, 대용량 데이터 전송에 적합합니다.

4. **옵션 D**:
   - 온프레미스 Tape Gateway를 구성하고, 가상 테이프를 AWS 클라우드에 생성하여 백업 소프트웨어를 사용해 물리적 테이프를 가상 테이프로 복사하는 방법입니다.
   - 이 방법도 인터넷 연결 속도로 인해 시간이 많이 소요되며, 비용 효율적이지 않습니다.

따라서, **옵션 C**가 가장 비용 효율적이고, 대용량 데이터를 AWS로 마이그레이션하는 데 적합한 솔루션입니다.


# 584번
정답은 **A**입니다.

### 해설:
- **A. Run the EC2 instances in a spread placement group.**
  - **적합성**: Spread placement group은 각 EC2 인스턴스를 서로 다른 물리적 하드웨어에 배치하여, 단일 하드웨어 장애가 여러 인스턴스에 영향을 미치지 않도록 합니다. 이는 대량의 데이터를 병렬로 처리하는 애플리케이션에 적합하며, 네트워크 아키텍처를 구성하여 노드 그룹이 동일한 하드웨어를 공유하지 않도록 할 수 있습니다.

### 다른 옵션들에 대한 설명:
- **B. Group the EC2 instances in separate accounts.**
  - EC2 인스턴스를 별도의 계정에 그룹화하는 것은 물리적 하드웨어 분리를 보장하지 않습니다.

- **C. Configure the EC2 instances with dedicated tenancy.**
  - 전용 테넌시는 인스턴스가 다른 고객의 인스턴스와 물리적 하드웨어를 공유하지 않도록 보장하지만, 동일한 고객의 인스턴스 간의 물리적 하드웨어 분리를 보장하지 않습니다.

- **D. Configure the EC2 instances with shared tenancy.**
  - 공유 테넌시는 인스턴스가 다른 고객의 인스턴스와 물리적 하드웨어를 공유할 수 있도록 허용하므로, 물리적 하드웨어 분리를 보장하지 않습니다.

따라서, EC2 인스턴스를 스프레드 배치 그룹에 배치하여 물리적 하드웨어 분리를 보장하는 A 옵션이 가장 적합한 솔루션입니다.


# 585번
### 문제 585
솔루션 아키텍트는 장애 조치(failover) AWS 리전에서 Amazon EC2 용량을 제공하기 위한 재해 복구(DR) 전략을 설계하고 있습니다. 비즈니스 요구 사항에 따르면 DR 전략은 장애 조치 리전에서 용량을 충족해야 합니다.

어떤 솔루션이 이러한 요구 사항을 충족합니까?

A. 장애 조치 리전에서 온디맨드 인스턴스를 구매합니다.
B. 장애 조치 리전에서 EC2 절약 계획을 구매합니다.
C. 장애 조치 리전에서 리전 예약 인스턴스를 구매합니다.
D. 장애 조치 리전에서 용량 예약을 구매합니다.

### 정답
**D. Purchase a Capacity Reservation in the failover Region.**

### 해설
- **D. Purchase a Capacity Reservation in the failover Region.**
  - **적합성**: 용량 예약(Capacity Reservation)은 특정 리전에서 EC2 인스턴스 용량을 예약하여, 장애 조치 시 필요한 용량을 보장합니다. 이는 재해 복구 전략에서 요구하는 용량을 충족하는 데 가장 적합한 솔루션입니다.

### 다른 옵션들에 대한 설명
- **A. Purchase On-Demand Instances in the failover Region.**
  - 온디맨드 인스턴스는 필요할 때 즉시 사용할 수 있지만, 장애 조치 시 필요한 용량을 보장하지 않습니다.

- **B. Purchase an EC2 Savings Plan in the failover Region.**
  - 절약 계획(Savings Plan)은 비용 절감에 도움이 되지만, 용량을 예약하거나 보장하지 않습니다.

- **C. Purchase regional Reserved Instances in the failover Region.**
  - 예약 인스턴스는 특정 인스턴스 유형과 기간에 대해 비용을 절감할 수 있지만, 용량을 보장하지 않습니다.

따라서, 장애 조치 리전에서 용량을 보장하기 위해 용량 예약을 구매하는 D 옵션이 가장 적합한 솔루션입니다.


# 586번
### 문제 586
회사는 AWS Organizations의 조직에 다섯 개의 조직 단위(OU)를 가지고 있습니다. 각 OU는 회사가 소유한 다섯 개의 비즈니스에 해당합니다. 회사의 연구 및 개발(R&D) 부서는 회사에서 분리되어 자체 조직이 필요합니다. 솔루션 아키텍트는 이를 위해 별도의 새로운 관리 계정을 생성했습니다.

새로운 관리 계정에서 솔루션 아키텍트가 다음으로 해야 할 일은 무엇입니까?

A. 전환 기간 동안 R&D AWS 계정이 두 조직의 일부가 되도록 합니다.
B. R&D AWS 계정이 이전 조직을 떠난 후 새로운 조직의 일부가 되도록 초대합니다.
C. 새로운 조직에 새로운 R&D AWS 계정을 생성합니다. 이전 R&D AWS 계정에서 새로운 R&D AWS 계정으로 리소스를 마이그레이션합니다.
D. R&D AWS 계정이 새로운 조직에 가입하도록 합니다. 새로운 관리 계정을 이전 조직의 구성원으로 만듭니다.

### 정답
**B. Invite the R&D AWS account to be part of the new organization after the R&D AWS account has left the prior organization.**

### 해설
- **B. Invite the R&D AWS account to be part of the new organization after the R&D AWS account has left the prior organization.**
  - **적합성**: AWS Organizations에서는 하나의 계정이 동시에 두 개의 조직에 속할 수 없습니다. 따라서, R&D AWS 계정이 이전 조직을 떠난 후 새로운 조직에 초대하는 것이 올바른 절차입니다.

### 다른 옵션들에 대한 설명
- **A. Have the R&D AWS account be part of both organizations during the transition.**
  - AWS 계정은 동시에 두 개의 조직에 속할 수 없습니다.

- **C. Create a new R&D AWS account in the new organization. Migrate resources from the prior R&D AWS account to the new R&D AWS account.**
  - 새로운 계정을 생성하고 리소스를 마이그레이션하는 것은 불필요한 작업이며, 기존 계정을 새로운 조직으로 이동하는 것이 더 간단하고 효율적입니다.

- **D. Have the R&D AWS account join the new organization. Make the new management account a member of the prior organization.**
  - 새로운 관리 계정을 이전 조직의 구성원으로 만드는 것은 요구사항을 충족하지 않습니다.

따라서, R&D AWS 계정이 이전 조직을 떠난 후 새로운 조직의 일부가 되도록 초대하는 B 옵션이 가장 적합한 솔루션입니다.


# 587번
### 문제 587
회사는 다양한 웹 애플리케이션에서 고객 활동을 캡처하여 분석하고 예측을 수행하는 솔루션을 설계하고 있습니다. 웹 애플리케이션의 고객 활동은 예측할 수 없으며 갑자기 증가할 수 있습니다. 회사는 다른 웹 애플리케이션과 통합되는 솔루션이 필요합니다. 솔루션에는 보안 목적으로 인증 단계가 포함되어야 합니다.

어떤 솔루션이 이러한 요구 사항을 충족합니까?

A. Amazon Elastic Container Service (Amazon ECS) 컨테이너 인스턴스 앞에 Gateway Load Balancer (GWLB)를 구성하고, 회사가 수신한 정보를 Amazon Elastic File System (Amazon EFS) 파일 시스템에 저장합니다. 인증은 GWLB에서 해결됩니다.

B. Amazon Kinesis 데이터 스트림 앞에 Amazon API Gateway 엔드포인트를 구성하고, 회사가 수신한 정보를 Amazon S3 버킷에 저장합니다. AWS Lambda 함수를 사용하여 인증을 해결합니다.

C. Amazon Kinesis Data Firehose 앞에 Amazon API Gateway 엔드포인트를 구성하고, 회사가 수신한 정보를 Amazon S3 버킷에 저장합니다. API Gateway Lambda authorizer를 사용하여 인증을 해결합니다.

D. Amazon Elastic Container Service (Amazon ECS) 컨테이너 인스턴스 앞에 Gateway Load Balancer (GWLB)를 구성하고, 회사가 수신한 정보를 Amazon Elastic File System (Amazon EFS) 파일 시스템에 저장합니다. AWS Lambda 함수를 사용하여 인증을 해결합니다.

### 정답
**C. Configure an Amazon API Gateway endpoint in front of an Amazon Kinesis Data Firehose that stores the information that the company receives in an Amazon S3 bucket. Use an API Gateway Lambda authorizer to resolve authorization.**

### 해설
- **C. Configure an Amazon API Gateway endpoint in front of an Amazon Kinesis Data Firehose that stores the information that the company receives in an Amazon S3 bucket. Use an API Gateway Lambda authorizer to resolve authorization.**
  - **적합성**: Amazon API Gateway는 다양한 웹 애플리케이션과 쉽게 통합될 수 있으며, API Gateway Lambda authorizer를 사용하여 인증을 처리할 수 있습니다. Amazon Kinesis Data Firehose는 데이터를 실시간으로 수집하고 Amazon S3 버킷에 저장할 수 있어, 갑작스러운 트래픽 증가를 처리하는 데 적합합니다.

### 다른 옵션들에 대한 설명
- **A. Configure a Gateway Load Balancer (GWLB) in front of an Amazon Elastic Container Service (Amazon ECS) container instance that stores the information that the company receives in an Amazon Elastic File System (Amazon EFS) file system. Authorization is resolved at the GWLB.**
  - GWLB는 주로 네트워크 트래픽을 로드 밸런싱하는 데 사용되며, 인증을 처리하는 데 적합하지 않습니다.

- **B. Configure an Amazon API Gateway endpoint in front of an Amazon Kinesis data stream that stores the information that the company receives in an Amazon S3 bucket. Use an AWS Lambda function to resolve authorization.**
  - Kinesis Data Stream은 실시간 데이터 스트리밍을 처리할 수 있지만, Kinesis Data Firehose가 더 적합한 선택입니다. 또한, Lambda 함수를 사용하여 인증을 처리하는 것보다 API Gateway Lambda authorizer를 사용하는 것이 더 효율적입니다.

- **D. Configure a Gateway Load Balancer (GWLB) in front of an Amazon Elastic Container Service (Amazon ECS) container instance that stores the information that the company receives on an Amazon Elastic File System (Amazon EFS) file system. Use an AWS Lambda function to resolve authorization.**
  - GWLB는 주로 네트워크 트래픽을 로드 밸런싱하는 데 사용되며, 인증을 처리하는 데 적합하지 않습니다.

따라서, Amazon API Gateway 엔드포인트를 Amazon Kinesis Data Firehose 앞에 구성하고, API Gateway Lambda authorizer를 사용하여 인증을 처리하는 C 옵션이 가장 적합한 솔루션입니다.


# 588번
### 문제 588
한 전자상거래 회사는 Microsoft SQL Server Enterprise Edition을 실행하는 Amazon RDS DB 인스턴스에 대한 재해 복구 솔루션을 원합니다. 회사의 현재 복구 시점 목표(RPO)와 복구 시간 목표(RTO)는 24시간입니다.

어떤 솔루션이 이러한 요구 사항을 가장 비용 효율적으로 충족합니까?

A. 교차 리전 읽기 복제본을 생성하고, 읽기 복제본을 기본 인스턴스로 승격합니다.
B. AWS Database Migration Service (AWS DMS)를 사용하여 RDS 교차 리전 복제를 생성합니다.
C. 교차 리전 복제를 사용하여 매 24시간마다 네이티브 백업을 Amazon S3 버킷에 복사합니다.
D. 자동 스냅샷을 매 24시간마다 다른 리전으로 복사합니다.

### 정답
**D. Copy automatic snapshots to another Region every 24 hours.**

### 해설
- **D. Copy automatic snapshots to another Region every 24 hours.**
  - **비용 효율성**: 자동 스냅샷을 매 24시간마다 다른 리전으로 복사하는 것은 비용 효율적인 재해 복구 솔루션입니다. 이 방법은 RPO와 RTO가 24시간인 요구 사항을 충족하며, 추가적인 인프라 비용 없이 데이터를 안전하게 보호할 수 있습니다.

### 다른 옵션들에 대한 설명
- **A. Create a cross-Region read replica and promote the read replica to the primary instance.**
  - 교차 리전 읽기 복제본을 생성하고 승격하는 것은 고가용성을 제공하지만, 비용이 더 많이 들 수 있습니다.

- **B. Use AWS Database Migration Service (AWS DMS) to create RDS cross-Region replication.**
  - AWS DMS를 사용한 교차 리전 복제는 실시간 복제를 제공하지만, 비용이 더 많이 들 수 있습니다.

- **C. Use cross-Region replication every 24 hours to copy native backups to an Amazon S3 bucket.**
  - 네이티브 백업을 S3 버킷에 복사하는 것은 가능하지만, 자동 스냅샷을 사용하는 것이 더 간단하고 비용 효율적입니다.

따라서, 자동 스냅샷을 매 24시간마다 다른 리전으로 복사하는 D 옵션이 가장 비용 효율적인 솔루션입니다.


# 593번
### 문제 593
솔루션 아키텍트는 고가용성 Amazon ElastiCache for Redis 기반 솔루션을 설계하고 있습니다. 솔루션 아키텍트는 장애가 발생해도 성능 저하나 데이터 손실이 발생하지 않도록 해야 합니다. 솔루션은 노드 수준과 리전 수준에서 고가용성을 제공해야 합니다.

어떤 솔루션이 이러한 요구 사항을 충족합니까?

A. 여러 노드를 포함하는 샤드가 있는 Multi-AZ Redis 복제 그룹을 사용합니다.
B. Redis append only files (AOF)가 켜진 여러 노드를 포함하는 Redis 샤드를 사용합니다.
C. 복제 그룹에 하나 이상의 읽기 복제본이 있는 Multi-AZ Redis 클러스터를 사용합니다.
D. Auto Scaling이 켜진 여러 노드를 포함하는 Redis 샤드를 사용합니다.

### 정답
**A. Use Multi-AZ Redis replication groups with shards that contain multiple nodes.**

### 해설
- **A. Use Multi-AZ Redis replication groups with shards that contain multiple nodes.**
  - **적합성**: Multi-AZ Redis 복제 그룹을 사용하면 노드 수준과 리전 수준에서 고가용성을 제공할 수 있습니다. 여러 노드를 포함하는 샤드를 사용하면 데이터 복제와 장애 조치가 가능하여 성능 저하나 데이터 손실을 방지할 수 있습니다.

### 다른 옵션들에 대한 설명
- **B. Use Redis shards that contain multiple nodes with Redis append only files (AOF) turned on.**
  - AOF는 데이터 내구성을 제공하지만, 고가용성을 보장하지 않습니다. 또한, 리전 수준의 고가용성을 제공하지 않습니다.

- **C. Use a Multi-AZ Redis cluster with more than one read replica in the replication group.**
  - 읽기 복제본을 사용하는 것은 읽기 성능을 향상시킬 수 있지만, 쓰기 성능과 데이터 내구성 측면에서 충분하지 않을 수 있습니다. 또한, 리전 수준의 고가용성을 제공하지 않습니다.

- **D. Use Redis shards that contain multiple nodes with Auto Scaling turned on.**
  - Auto Scaling은 인스턴스 수를 자동으로 조정할 수 있지만, 고가용성과 데이터 내구성을 보장하지 않습니다.

따라서, 여러 노드를 포함하는 샤드가 있는 Multi-AZ Redis 복제 그룹을 사용하는 A 옵션이 가장 적합한 솔루션입니다.


# 597번
### 문제 597
회사는 Amazon API Gateway와 AWS Lambda를 사용하여 내부 서버리스 애플리케이션을 AWS에 호스팅하고 있습니다. 회사의 직원들은 매일 애플리케이션을 사용하기 시작할 때 높은 지연 시간 문제를 보고합니다. 회사는 지연 시간을 줄이기를 원합니다.

어떤 솔루션이 이러한 요구 사항을 충족합니까?

A. API Gateway의 스로틀링 한도를 증가시킵니다.
B. 매일 직원들이 애플리케이션을 사용하기 시작하기 전에 Lambda 프로비저닝된 동시성을 증가시키기 위해 예약된 스케일링을 설정합니다.
C. 매일 아침 Amazon CloudWatch 알람을 생성하여 Lambda 함수를 알람의 대상으로 시작합니다.
D. Lambda 함수 메모리를 증가시킵니다.

### 정답
**B. Set up a scheduled scaling to increase Lambda provisioned concurrency before employees begin to use the application each day.**

### 해설
- **B. Set up a scheduled scaling to increase Lambda provisioned concurrency before employees begin to use the application each day.**
  - **적합성**: Lambda 프로비저닝된 동시성을 사용하면 함수가 콜드 스타트 없이 즉시 실행될 수 있도록 미리 인스턴스를 준비할 수 있습니다. 예약된 스케일링을 설정하여 매일 직원들이 애플리케이션을 사용하기 시작하기 전에 프로비저닝된 동시성을 증가시키면, 초기 지연 시간을 줄일 수 있습니다.

### 다른 옵션들에 대한 설명
- **A. Increase the API Gateway throttling limit.**
  - API Gateway의 스로틀링 한도를 증가시키는 것은 지연 시간 문제를 해결하지 못합니다. 이는 요청 수를 제한하는 설정일 뿐입니다.

- **C. Create an Amazon CloudWatch alarm to initiate a Lambda function as a target for the alarm at the beginning of each day.**
  - CloudWatch 알람을 사용하여 Lambda 함수를 시작하는 것은 지연 시간을 줄이는 데 직접적인 도움이 되지 않습니다.

- **D. Increase the Lambda function memory.**
  - Lambda 함수 메모리를 증가시키는 것은 함수의 실행 속도를 향상시킬 수 있지만, 콜드 스타트 문제를 해결하지는 못합니다.

따라서, 매일 직원들이 애플리케이션을 사용하기 시작하기 전에 Lambda 프로비저닝된 동시성을 증가시키기 위해 예약된 스케일링을 설정하는 B 옵션이 가장 적합한 솔루션입니다.


# 598번
### 문제 598
한 연구 회사는 온프레미스 장치를 사용하여 분석을 위한 데이터를 생성합니다. 회사는 AWS 클라우드를 사용하여 데이터를 분석하고자 합니다. 장치는 .csv 파일을 생성하고 SMB 파일 공유에 데이터를 쓸 수 있습니다. 회사 분석가는 SQL 명령을 사용하여 데이터를 쿼리할 수 있어야 합니다. 분석가는 하루 종일 주기적으로 쿼리를 실행할 것입니다.

어떤 단계 조합이 이러한 요구 사항을 가장 비용 효율적으로 충족합니까? (세 가지를 선택하십시오.)

A. 온프레미스에 AWS Storage Gateway를 Amazon S3 File Gateway 모드로 배포합니다.
B. 온프레미스에 AWS Storage Gateway를 Amazon FSx File Gateway 모드로 배포합니다.
C. Amazon S3에 있는 데이터를 기반으로 테이블을 생성하기 위해 AWS Glue 크롤러를 설정합니다.
D. Amazon S3에 있는 데이터를 쿼리하기 위해 EMR File System (EMRFS)을 사용하는 Amazon EMR 클러스터를 설정합니다. 분석가에게 접근 권한을 제공합니다.
E. Amazon S3에 있는 데이터를 쿼리하기 위해 Amazon Redshift 클러스터를 설정합니다. 분석가에게 접근 권한을 제공합니다.
F. Amazon S3에 있는 데이터를 쿼리하기 위해 Amazon Athena를 설정합니다. 분석가에게 접근 권한을 제공합니다.

### 정답
**A. Deploy an AWS Storage Gateway on premises in Amazon S3 File Gateway mode.**  
**C. Set up an AWS Glue crawler to create a table based on the data that is in Amazon S3.**  
**F. Setup Amazon Athena to query the data that is in Amazon S3. Provide access to analysts.**

### 해설
- **A. Deploy an AWS Storage Gateway on premises in Amazon S3 File Gateway mode.**
  - **적합성**: AWS Storage Gateway를 Amazon S3 File Gateway 모드로 배포하면 온프레미스 장치에서 생성된 .csv 파일을 Amazon S3로 쉽게 전송할 수 있습니다. 이는 SMB 파일 공유를 지원하며, 데이터를 클라우드로 안전하게 전송할 수 있습니다.

- **C. Set up an AWS Glue crawler to create a table based on the data that is in Amazon S3.**
  - **적합성**: AWS Glue 크롤러를 사용하여 Amazon S3에 저장된 데이터를 기반으로 테이블을 생성하면, 데이터 카탈로그를 자동으로 생성할 수 있습니다. 이는 데이터를 쉽게 쿼리할 수 있도록 준비하는 데 도움이 됩니다.

- **F. Setup Amazon Athena to query the data that is in Amazon S3. Provide access to analysts.**
  - **적합성 및 비용 효율성**: Amazon Athena는 서버리스 쿼리 서비스로, S3에 저장된 데이터를 SQL을 사용하여 직접 쿼리할 수 있습니다. 이는 추가적인 인프라 비용 없이도 데이터를 분석할 수 있는 비용 효율적인 솔루션입니다.

### 다른 옵션들에 대한 설명
- **B. Deploy an AWS Storage Gateway on premises in Amazon FSx File Gateway mode.**
  - Amazon FSx File Gateway는 SMB 파일 공유를 지원하지만, Amazon S3와의 통합이 필요합니다.

- **D. Set up an Amazon EMR cluster with EMR File System (EMRFS) to query the data that is in Amazon S3. Provide access to analysts.**
  - Amazon EMR은 대규모 데이터 처리에 적합하지만, 비용이 더 많이 들 수 있습니다.

- **E. Set up an Amazon Redshift cluster to query the data that is in Amazon S3. Provide access to analysts.**
  - Amazon Redshift는 데이터 웨어하우스 솔루션으로, 비용이 더 많이 들 수 있습니다.

따라서, A, C, F 옵션이 가장 비용 효율적으로 요구 사항을 충족하는 솔루션입니다.

# 599번
### 문제 599
회사는 Amazon Elastic Container Service (Amazon ECS) 클러스터와 Amazon RDS DB 인스턴스를 사용하여 결제 처리 애플리케이션을 구축하고 실행하려고 합니다. 회사는 규정 준수를 위해 애플리케이션을 온프레미스 데이터 센터에서 실행할 것입니다.

솔루션 아키텍트는 솔루션의 일부로 AWS Outposts를 사용하려고 합니다. 솔루션 아키텍트는 회사의 운영 팀과 협력하여 애플리케이션을 구축하고 있습니다.

회사의 운영 팀이 책임져야 할 활동은 무엇입니까? (세 가지를 선택하십시오.)

A. Outposts 랙에 대한 안정적인 전원 및 네트워크 연결 제공
B. Outposts에서 실행되는 가상화 하이퍼바이저, 스토리지 시스템 및 AWS 서비스 관리
C. 데이터 센터 환경의 물리적 보안 및 접근 제어
D. Outposts 랙 내의 전원 공급 장치, 서버 및 네트워킹 장비를 포함한 Outposts 인프라의 가용성
E. Outposts 구성 요소의 물리적 유지 관리
F. 서버 장애 및 유지 관리 이벤트를 완화하기 위해 Amazon ECS 클러스터에 추가 용량 제공

### 정답
**A. Providing resilient power and network connectivity to the Outposts racks**  
**C. Physical security and access controls of the data center environment**  
**E. Physical maintenance of Outposts components**

### 해설
- **A. Providing resilient power and network connectivity to the Outposts racks**
  - **적합성**: 회사의 운영 팀은 Outposts 랙에 안정적인 전원 및 네트워크 연결을 제공해야 합니다. 이는 온프레미스 환경에서 Outposts를 운영하는 데 필수적입니다.

- **C. Physical security and access controls of the data center environment**
  - **적합성**: 회사의 운영 팀은 데이터 센터 환경의 물리적 보안 및 접근 제어를 책임져야 합니다. 이는 온프레미스 데이터 센터의 보안 유지에 필수적입니다.

- **E. Physical maintenance of Outposts components**
  - **적합성**: 회사의 운영 팀은 Outposts 구성 요소의 물리적 유지 관리를 책임져야 합니다. 이는 하드웨어의 정상적인 작동을 보장하는 데 필요합니다.

### 다른 옵션들에 대한 설명
- **B. Managing the virtualization hypervisor, storage systems, and the AWS services that run on Outposts**
  - AWS는 Outposts에서 실행되는 가상화 하이퍼바이저, 스토리지 시스템 및 AWS 서비스를 관리합니다.

- **D. Availability of the Outposts infrastructure including the power supplies, servers, and networking equipment within the Outposts racks**
  - Outposts 인프라의 가용성은 AWS의 책임입니다.

- **F. Providing extra capacity for Amazon ECS clusters to mitigate server failures and maintenance events**
  - ECS 클러스터의 추가 용량 제공은 AWS의 책임입니다.

따라서, A, C, E 옵션이 회사의 운영 팀이 책임져야 할 활동입니다.


# 601
### 문제 601
회사는 Amazon RDS for PostgreSQL DB 인스턴스에서 중요한 데이터베이스를 운영하고 있습니다. 회사는 최소한의 다운타임과 데이터 손실로 Amazon Aurora PostgreSQL로 마이그레이션하려고 합니다.

가장 적은 운영 오버헤드로 이러한 요구 사항을 충족하는 솔루션은 무엇입니까?

---

A. RDS for PostgreSQL DB 인스턴스의 DB 스냅샷을 생성하여 새로운 Aurora PostgreSQL DB 클러스터를 채웁니다.

B. RDS for PostgreSQL DB 인스턴스의 Aurora 읽기 복제본을 생성합니다. Aurora 읽기 복제본을 새로운 Aurora PostgreSQL DB 클러스터로 승격합니다.

C. Amazon S3에서 데이터 가져오기를 사용하여 데이터베이스를 Aurora PostgreSQL DB 클러스터로 마이그레이션합니다.

D. pg_dump 유틸리티를 사용하여 RDS for PostgreSQL 데이터베이스를 백업합니다. 백업을 새로운 Aurora PostgreSQL DB 클러스터에 복원합니다.

### 정답
**B. Create an Aurora read replica of the RDS for PostgreSQL DB instance. Promote the Aurora read replicate to a new Aurora PostgreSQL DB cluster.**

### 해설
- **B. Create an Aurora read replica of the RDS for PostgreSQL DB instance. Promote the Aurora read replicate to a new Aurora PostgreSQL DB cluster.**
  - **적합성 및 운영 오버헤드 최소화**: Aurora 읽기 복제본을 생성하면 RDS for PostgreSQL DB 인스턴스와 실시간으로 동기화됩니다. 그런 다음 읽기 복제본을 Aurora PostgreSQL DB 클러스터로 승격하면 최소한의 다운타임과 데이터 손실로 마이그레이션할 수 있습니다. 이는 자동화된 프로세스이므로 운영 오버헤드가 적습니다.

### 다른 옵션들에 대한 설명
- **A. Create a DB snapshot of the RDS for PostgreSQL DB instance to populate a new Aurora PostgreSQL DB cluster.**
  - DB 스냅샷을 사용하는 것은 데이터베이스를 복원하는 동안 다운타임이 발생할 수 있습니다.

- **C. Use data import from Amazon S3 to migrate the database to an Aurora PostgreSQL DB cluster.**
  - S3에서 데이터 가져오기를 사용하는 것은 복잡성이 증가하며, 실시간 동기화가 불가능합니다.

- **D. Use the pg_dump utility to back up the RDS for PostgreSQL database. Restore the backup to a new Aurora PostgreSQL DB cluster.**
  - pg_dump를 사용하는 것은 수동 프로세스이며, 백업 및 복원 동안 다운타임이 발생할 수 있습니다.

따라서, RDS for PostgreSQL DB 인스턴스의 Aurora 읽기 복제본을 생성하고 이를 새로운 Aurora PostgreSQL DB 클러스터로 승격하는 B 옵션이 가장 적합한 솔루션입니다.


# 603
### 문제 603
회사는 최근 AWS 클라우드로 마이그레이션했습니다. 회사는 반구조화된 데이터 세트의 대규모 병렬 주문형 처리를 위한 서버리스 솔루션을 원합니다. 데이터는 Amazon S3에 저장된 로그, 미디어 파일, 판매 거래 및 IoT 센서 데이터로 구성됩니다. 회사는 솔루션이 데이터 세트의 수천 개 항목을 병렬로 처리하기를 원합니다.

가장 높은 운영 효율성으로 이러한 요구 사항을 충족하는 솔루션은 무엇입니까?

---

A. AWS Step Functions Map 상태를 Inline 모드에서 사용하여 데이터를 병렬로 처리합니다.

B. AWS Step Functions Map 상태를 Distributed 모드에서 사용하여 데이터를 병렬로 처리합니다.

C. AWS Glue를 사용하여 데이터를 병렬로 처리합니다.

D. 여러 AWS Lambda 함수를 사용하여 데이터를 병렬로 처리합니다.

### 정답
**B. Use the AWS Step Functions Map state in Distributed mode to process the data in parallel.**

### 해설
- **B. Use the AWS Step Functions Map state in Distributed mode to process the data in parallel.**
  - **적합성 및 운영 효율성**: AWS Step Functions의 Map 상태를 Distributed 모드에서 사용하면 대규모 병렬 처리를 효율적으로 수행할 수 있습니다. Distributed 모드는 수천 개의 항목을 병렬로 처리하는 데 최적화되어 있으며, 서버리스 환경에서 높은 확장성과 운영 효율성을 제공합니다.

### 다른 옵션들에 대한 설명
- **A. Use the AWS Step Functions Map state in Inline mode to process the data in parallel.**
  - Inline 모드는 병렬 처리를 지원하지만, Distributed 모드만큼 확장성이 뛰어나지 않습니다.

- **C. Use AWS Glue to process the data in parallel.**
  - AWS Glue는 데이터 처리에 적합하지만, Step Functions의 Distributed 모드만큼 병렬 처리에 최적화되어 있지 않습니다.

- **D. Use several AWS Lambda functions to process the data in parallel.**
  - 여러 Lambda 함수를 사용하는 것은 병렬 처리를 수행할 수 있지만, Step Functions의 Distributed 모드를 사용하는 것보다 관리 오버헤드가 큽니다.

따라서, AWS Step Functions Map 상태를 Distributed 모드에서 사용하여 데이터를 병렬로 처리하는 B 옵션이 가장 적합한 솔루션입니다.


# 604
### 문제 604
회사는 6주 동안 10PB의 데이터를 Amazon S3로 마이그레이션할 예정입니다. 현재 데이터 센터에는 인터넷으로 연결된 500Mbps 업링크가 있습니다. 다른 온프레미스 애플리케이션도 이 업링크를 공유합니다. 회사는 이 일회성 마이그레이션 작업을 위해 인터넷 대역폭의 80%를 사용할 수 있습니다.

이 요구 사항을 충족하는 솔루션은 무엇입니까?

---

A. AWS DataSync를 구성하여 데이터를 Amazon S3로 마이그레이션하고 데이터를 자동으로 검증합니다.
B. rsync를 사용하여 데이터를 직접 Amazon S3로 전송합니다.
C. AWS CLI와 여러 복사 프로세스를 사용하여 데이터를 직접 Amazon S3로 전송합니다.
D. 여러 AWS Snowball 장치를 주문합니다. 데이터를 장치에 복사합니다. 장치를 AWS로 보내 데이터를 Amazon S3로 복사합니다.

### 정답
**D. Order multiple AWS Snowball devices. Copy the data to the devices. Send the devices to AWS to copy the data to Amazon S3.**

### 해설
- **D. Order multiple AWS Snowball devices. Copy the data to the devices. Send the devices to AWS to copy the data to Amazon S3.**
  - **적합성 및 효율성**: AWS Snowball은 대규모 데이터 마이그레이션을 위한 오프라인 데이터 전송 서비스입니다. 10PB의 데이터를 6주 동안 500Mbps 업링크를 통해 전송하는 것은 현실적이지 않습니다. Snowball 장치를 사용하면 데이터를 빠르고 안전하게 전송할 수 있으며, 인터넷 대역폭을 사용하지 않으므로 다른 온프레미스 애플리케이션에 영향을 주지 않습니다.

### 다른 옵션들에 대한 설명
- **A. Configure AWS DataSync to migrate the data to Amazon S3 and to automatically verify the data.**
  - DataSync는 온라인 데이터 전송을 위한 서비스로, 500Mbps 업링크를 통해 10PB의 데이터를 6주 동안 전송하는 것은 비현실적입니다.

- **B. Use rsync to transfer the data directly to Amazon S3.**
  - rsync는 효율적인 파일 전송 도구이지만, 500Mbps 업링크를 통해 10PB의 데이터를 6주 동안 전송하는 것은 비현실적입니다.

- **C. Use the AWS CLI and multiple copy processes to send the data directly to Amazon S3.**
  - AWS CLI와 여러 복사 프로세스를 사용하는 것은 500Mbps 업링크를 통해 10PB의 데이터를 6주 동안 전송하는 데 충분하지 않습니다.

따라서, 여러 AWS Snowball 장치를 주문하여 데이터를 장치에 복사하고, 장치를 AWS로 보내 데이터를 Amazon S3로 복사하는 D 옵션이 가장 적합한 솔루션입니다.


# 605
### 문제 605
회사는 여러 온프레미스 Internet Small Computer Systems Interface (iSCSI) 네트워크 스토리지 서버를 보유하고 있습니다. 회사는 이러한 서버의 수를 줄이기 위해 AWS 클라우드로 이동하려고 합니다. 솔루션 아키텍트는 자주 사용되는 데이터에 대한 저지연 액세스를 제공하고 최소한의 인프라 변경으로 온프레미스 서버에 대한 의존성을 줄여야 합니다.

어떤 솔루션이 이러한 요구 사항을 충족합니까?

---

A. Amazon S3 파일 게이트웨이를 배포합니다.

B. Amazon Elastic Block Store (Amazon EBS) 스토리지를 배포하고 Amazon S3로 백업합니다.

C. 저장된 볼륨으로 구성된 AWS Storage Gateway 볼륨 게이트웨이를 배포합니다.

D. 캐시된 볼륨으로 구성된 AWS Storage Gateway 볼륨 게이트웨이를 배포합니다.

### 정답
**D. Deploy an AWS Storage Gateway volume gateway that is configured with cached volumes.**

### 해설
- **D. Deploy an AWS Storage Gateway volume gateway that is configured with cached volumes.**
  - **적합성**: AWS Storage Gateway의 캐시된 볼륨 모드는 자주 액세스하는 데이터를 로컬에 캐시하여 저지연 액세스를 제공하면서, 기본 데이터는 AWS 클라우드에 저장됩니다. 이는 온프레미스 서버에 대한 의존성을 줄이고, 최소한의 인프라 변경으로 클라우드로의 전환을 가능하게 합니다.

### 다른 옵션들에 대한 설명
- **A. Deploy an Amazon S3 File Gateway.**
  - S3 파일 게이트웨이는 파일 기반 스토리지 솔루션으로, iSCSI 네트워크 스토리지 서버를 대체하는 데 적합하지 않습니다.

- **B. Deploy Amazon Elastic Block Store (Amazon EBS) storage with backups to Amazon S3.**
  - EBS는 블록 스토리지 솔루션으로, 온프레미스 iSCSI 서버를 직접 대체하는 데 적합하지 않으며, 백업을 위해 S3를 사용하는 것은 저지연 액세스를 제공하지 않습니다.

- **C. Deploy an AWS Storage Gateway volume gateway that is configured with stored volumes.**
  - 저장된 볼륨 모드는 모든 데이터를 로컬에 저장하고 주기적으로 AWS로 백업합니다. 이는 온프레미스 서버에 대한 의존성을 줄이는 데 적합하지 않습니다.

따라서, 캐시된 볼륨으로 구성된 AWS Storage Gateway 볼륨 게이트웨이를 배포하는 D 옵션이 가장 적합한 솔루션입니다.

# 607
### 문제 607
회사는 온프레미스 데이터 센터에서 AWS 클라우드로 이중 계층 애플리케이션을 마이그레이션했습니다. 데이터 계층은 12TB의 일반 목적 SSD Amazon Elastic Block Store (Amazon EBS) 스토리지를 사용하는 Amazon RDS for Oracle의 Multi-AZ 배포입니다. 애플리케이션은 문서를 바이너리 대형 객체(blob)로 데이터베이스에 저장하도록 설계되었으며, 평균 문서 크기는 6MB입니다.

데이터베이스 크기가 시간이 지남에 따라 증가하여 성능이 저하되고 스토리지 비용이 증가했습니다. 회사는 데이터베이스 성능을 향상시키고 고가용성과 복원력을 갖춘 솔루션이 필요합니다.

가장 비용 효율적으로 이러한 요구 사항을 충족하는 솔루션은 무엇입니까?

---

A. RDS DB 인스턴스 크기를 줄입니다. 스토리지 용량을 24TiB로 늘립니다. 스토리지 유형을 Magnetic으로 변경합니다.

B. RDS DB 인스턴스 크기를 늘립니다. 스토리지 용량을 24TiB로 늘립니다. 스토리지 유형을 Provisioned IOPS로 변경합니다.

C. Amazon S3 버킷을 생성합니다. 애플리케이션을 업데이트하여 문서를 S3 버킷에 저장합니다. 객체 메타데이터를 기존 데이터베이스에 저장합니다.

D. Amazon DynamoDB 테이블을 생성합니다. 애플리케이션을 업데이트하여 DynamoDB를 사용합니다. AWS Database Migration Service (AWS DMS)를 사용하여 데이터를 Oracle 데이터베이스에서 DynamoDB로 마이그레이션합니다.

### 정답
**C. Create an Amazon S3 bucket. Update the application to store documents in the S3 bucket. Store the object metadata in the existing database.**

### 해설
- **C. Create an Amazon S3 bucket. Update the application to store documents in the S3 bucket. Store the object metadata in the existing database.**
  - **적합성 및 비용 효율성**: Amazon S3는 대규모 데이터 저장을 위한 저렴하고 확장 가능한 스토리지 솔루션입니다. 문서를 S3 버킷에 저장하고 객체 메타데이터를 기존 데이터베이스에 저장하면, 데이터베이스의 크기를 줄이고 성능을 향상시킬 수 있습니다. 또한, S3는 높은 내구성과 가용성을 제공하므로 복원력도 보장됩니다.

### 다른 옵션들에 대한 설명
- **A. Reduce the RDS DB instance size. Increase the storage capacity to 24 TiB. Change the storage type to Magnetic.**
  - Magnetic 스토리지는 성능이 낮고, 데이터베이스 성능을 향상시키는 데 적합하지 않습니다.

- **B. Increase the RDS DB instance size. Increase the storage capacity to 24 TiB. Change the storage type to Provisioned IOPS.**
  - Provisioned IOPS는 성능을 향상시킬 수 있지만, 비용이 많이 들며, 데이터베이스 크기를 줄이는 데 도움이 되지 않습니다.

- **D. Create an Amazon DynamoDB table. Update the application to use DynamoDB. Use AWS Database Migration Service (AWS DMS) to migrate data from the Oracle database to DynamoDB.**
  - DynamoDB는 NoSQL 데이터베이스로, 기존의 RDBMS와는 다른 데이터 모델을 사용합니다. 애플리케이션을 DynamoDB로 마이그레이션하는 것은 복잡하고 비용이 많이 들 수 있습니다.

따라서, Amazon S3 버킷을 생성하고 애플리케이션을 업데이트하여 문서를 S3 버킷에 저장하고 객체 메타데이터를 기존 데이터베이스에 저장하는 C 옵션이 가장 적합한 솔루션입니다.

# 608
### 문제 608
회사는 전 세계 20,000개 이상의 소매점 위치에 배포된 클라이언트를 제공하는 애플리케이션을 보유하고 있습니다. 애플리케이션은 포트 443에서 HTTPS를 통해 노출되는 백엔드 웹 서비스로 구성됩니다. 애플리케이션은 Application Load Balancer (ALB) 뒤에 있는 Amazon EC2 인스턴스에서 호스팅됩니다. 소매점 위치는 공용 인터넷을 통해 웹 애플리케이션과 통신합니다. 회사는 각 소매점 위치가 로컬 ISP에 의해 할당된 IP 주소를 등록할 수 있도록 허용합니다.

회사의 보안 팀은 소매점 위치에서 등록된 IP 주소만 액세스할 수 있도록 애플리케이션 엔드포인트의 보안을 강화할 것을 권장합니다.

솔루션 아키텍트는 이러한 요구 사항을 충족하기 위해 무엇을 해야 합니까?

A. ALB에 AWS WAF 웹 ACL을 연결합니다. ALB에서 IP 규칙 세트를 사용하여 트래픽을 필터링합니다. 규칙의 IP 주소를 등록된 IP 주소로 업데이트합니다.
B. ALB를 관리하기 위해 AWS Firewall Manager를 배포합니다. ALB에 대한 트래픽을 제한하도록 방화벽 규칙을 구성합니다. 방화벽 규칙을 수정하여 등록된 IP 주소를 포함합니다.
C. IP 주소를 Amazon DynamoDB 테이블에 저장합니다. ALB에서 AWS Lambda 인증 함수를 구성하여 들어오는 요청이 등록된 IP 주소에서 오는지 확인합니다.
D. ALB의 공용 인터페이스가 포함된 서브넷에서 네트워크 ACL을 구성합니다. 네트워크 ACL의 인그레스 규칙을 등록된 IP 주소 항목으로 업데이트합니다.

### 정답
**A. Associate an AWS WAF web ACL with the ALB. Use IP rule sets on the ALB to filter traffic. Update the IP addresses in the rule to include the registered IP addresses.**

### 해설
- **A. Associate an AWS WAF web ACL with the ALB. Use IP rule sets on the ALB to filter traffic. Update the IP addresses in the rule to include the registered IP addresses.**
  - **적합성 및 효율성**: AWS WAF는 웹 애플리케이션 방화벽으로, ALB와 통합하여 IP 주소 기반 필터링을 포함한 다양한 보안 규칙을 적용할 수 있습니다. IP 규칙 세트를 사용하여 등록된 IP 주소만 허용하도록 설정하면, 보안 팀의 요구 사항을 충족할 수 있습니다. 또한, AWS WAF는 관리가 용이하고 확장성이 뛰어납니다.

### 다른 옵션들에 대한 설명
- **B. Deploy AWS Firewall Manager to manage the ALConfigure firewall rules to restrict traffic to the ALModify the firewall rules to include the registered IP addresses.**
  - AWS Firewall Manager는 여러 계정과 리소스에 대한 중앙 집중식 방화벽 규칙 관리를 제공하지만, 이 시나리오에서는 AWS WAF를 사용하는 것이 더 적합합니다.

- **C. Store the IP addresses in an Amazon DynamoDB table. Configure an AWS Lambda authorization function on the ALB to validate that incoming requests are from the registered IP addresses.**
  - Lambda 함수를 사용한 인증은 가능하지만, AWS WAF를 사용하는 것보다 복잡성이 높고 관리 오버헤드가 큽니다.

- **D. Configure the network ACL on the subnet that contains the public interface of the ALB. Update the ingress rules on the network ACL with entries for each of the registered IP addresses.**
  - 네트워크 ACL은 서브넷 수준에서 작동하며, 수천 개의 IP 주소를 관리하는 데 적합하지 않습니다. 또한, 네트워크 ACL은 상태 비저장 방화벽이므로, AWS WAF를 사용하는 것이 더 적합합니다.

따라서, ALB에 AWS WAF 웹 ACL을 연결하고 IP 규칙 세트를 사용하여 트래픽을 필터링하는 A 옵션이 가장 적합한 솔루션입니다.


# 617
정답: B. Create an Amazon Elastic File System (Amazon EFS) file system.  
E. Install an AWS DataSync agent in the on-premises data center. Use a DataSync task between the on-premises location and AWS.

### 해설:
이 문제는 온프레미스 데이터 센터의 NFS 기반 파일 시스템을 AWS로 중단 없이 마이그레이션하고, AWS의 여러 리소스가 NFS 프로토콜을 사용하여 데이터에 접근할 수 있도록 하는 가장 비용 효율적인 방법을 찾는 것입니다. 각 옵션을 분석해 보겠습니다.

#### A. Create an Amazon FSx for Lustre file system.
- **Amazon FSx for Lustre**는 고성능 컴퓨팅 워크로드에 최적화된 파일 시스템입니다. 하지만 일반적인 NFS 기반 파일 시스템을 대체하기에는 비용 효율적이지 않습니다.

#### B. Create an Amazon Elastic File System (Amazon EFS) file system.
- **Amazon EFS**는 완전 관리형 NFS 파일 시스템으로, AWS의 여러 리소스가 NFS 프로토콜을 사용하여 데이터에 접근할 수 있습니다.
- EFS는 온프레미스 데이터 센터의 NFS 기반 파일 시스템을 대체하는 데 적합하며, 비용 효율적입니다.

#### C. Create an Amazon S3 bucket to receive the data.
- **Amazon S3**는 객체 스토리지 서비스로, NFS 프로토콜을 지원하지 않습니다. 따라서 NFS 기반 파일 시스템을 대체하는 데 적합하지 않습니다.

#### D. Manually use an operating system copy command to push the data into the AWS destination.
- 수동으로 운영 체제의 복사 명령을 사용하여 데이터를 AWS로 전송하는 것은 가능하지만, 이는 중단 없는 마이그레이션을 보장하지 않으며, 운영 오버헤드가 큽니다.

#### E. Install an AWS DataSync agent in the on-premises data center. Use a DataSync task between the on-premises location and AWS.
- **AWS DataSync**는 온프레미스 데이터 센터와 AWS 간의 데이터 전송을 자동화하고 가속화하는 서비스입니다.
- DataSync를 사용하면 중단 없이 데이터를 마이그레이션할 수 있으며, 운영 오버헤드가 적습니다.

따라서, 가장 적합한 솔루션은 **Amazon Elastic File System (Amazon EFS) 파일 시스템을 생성하고, AWS DataSync 에이전트를 온프레미스 데이터 센터에 설치하여 DataSync 작업을 사용하는 것**입니다. 이 방법은 비용 효율적이며, 중단 없는 마이그레이션을 보장합니다.


# 622
이 문제에서는 구독자를 위한 웹 애플리케이션을 만들고 있으며, 애플리케이션은 정적 단일 페이지와 지속적인 데이터베이스 계층으로 구성됩니다. 애플리케이션은 아침에 4시간 동안 수백만 명의 사용자와 나머지 시간 동안 수천 명의 사용자만 있을 것입니다. 데이터 아키텍트는 스키마를 신속하게 발전시킬 수 있는 기능을 요청했습니다. 이러한 요구 사항을 충족하고 가장 높은 확장성을 제공하는 솔루션을 찾아야 합니다. 각 옵션을 분석해 보겠습니다.

### 옵션 분석

#### **A. Deploy Amazon DynamoDB as the database solution. Provision on-demand capacity.**
- **장점**: DynamoDB는 완전 관리형 NoSQL 데이터베이스로, 자동으로 확장할 수 있으며, 온디맨드 용량 프로비저닝을 통해 트래픽 급증에 적절하게 대응할 수 있습니다. 스키마를 쉽게 발전시킬 수 있는 유연성을 제공합니다.
- **단점**: 특정 쿼리에 대한 제약이 있을 수 있지만, 고성능의 확장성을 제공하는 것은 확실합니다.

#### **B. Deploy Amazon Aurora as the database solution. Choose the serverless DB engine mode.**
- **장점**: Aurora의 서버리스 모드는 필요에 따라 자동으로 용량을 조정할 수 있으며, 스키마의 발전도 쉽게 처리할 수 있습니다. 또한, 트래픽 패턴이 변동적인 경우에 적합합니다.
- **단점**: 서버리스 옵션은 AWS 리전과 환경 설정에 따라 복잡할 수 있습니다. 그러나 전반적으로 높은 확장성과 유연성을 제공합니다.

#### **C. Deploy Amazon DynamoDB as the database solution. Ensure that DynamoDB auto scaling is enabled.**
- **장점**: DynamoDB의 자동 확장 기능은 수요에 따라 테이블의 용량을 자동으로 조정하여 높은 성능과 확장성을 제공합니다. 또한 스키마 발전의 유연성도 제공합니다.
- **단점**: 관리가 필요한 부분이 있지만, 전반적으로 높은 성능을 유지할 수 있습니다.

#### **D. Deploy the static content into an Amazon S3 bucket. Provision an Amazon CloudFront distribution with the S3 bucket as the origin.**
- **장점**: 정적 콘텐츠를 S3에 저장하고 CloudFront를 통해 배포하면 전 세계적으로 빠른 응답 속도를 제공할 수 있습니다. 높은 트래픽을 효율적으로 처리할 수 있습니다.
- **단점**: 이 솔루션은 데이터베이스에 대한 요구 사항을 직접 충족하지 않지만, 정적 콘텐츠를 배포하는 데 매우 효과적입니다.

#### **E. Deploy the web servers for static content across a fleet of Amazon EC2 instances in Auto Scaling groups. Configure the instances to periodically refresh the content from an Amazon Elastic File System (Amazon EFS) volume.**
- **장점**: EC2 인스턴스와 Auto Scaling 그룹을 사용하면 트래픽에 따라 인스턴스를 자동으로 조정할 수 있습니다.
- **단점**: EC2 인스턴스 관리 및 운영 비용이 발생할 수 있으며, 정적 콘텐츠 배포에 비효율적일 수 있습니다.

### **결론**
**정답은 A와 D입니다.**
- **A. Deploy Amazon DynamoDB as the database solution. Provision on-demand capacity.**
- **D. Deploy the static content into an Amazon S3 bucket. Provision an Amazon CloudFront distribution with the S3 bucket as the origin.**

이 조합은 데이터베이스와 정적 콘텐츠 배포 모두에서 높은 확장성과 운영 효율성을 제공합니다. DynamoDB는 빠르게 변화하는 트래픽을 처리하고, S3와 CloudFront는 정적 콘텐츠를 전 세계 사용자에게 효율적으로 제공할 수 있습니다.


# 624
이 문제에서는 회사가 1,500명의 사용자에게 AWS 리소스에 대한 접근을 제공하고자 하며, 사용자가 또 다른 신원 관리를 원하지 않는 상황입니다. 회사는 Active Directory 사용자 그룹을 사용하여 온프레미스 리소스에 대한 접근을 관리하고 있습니다. 이에 대한 해결책을 찾아야 합니다. 각 옵션을 분석해 보겠습니다.

### 옵션 분석

#### **A. Create an IAM user for each user in the company. Attach the appropriate policies to each user.**
- **장점**: 각 사용자에게 IAM 사용자를 생성하여 접근 권한을 관리할 수 있습니다.
- **단점**: 사용자가 1,500명이나 되기 때문에 사용자 계정 관리가 비효율적이며, 추가적인 신원 관리가 필요합니다. 요구 사항에 부합하지 않습니다.

#### **B. Use Amazon Cognito with an Active Directory user pool. Create roles with the appropriate policies attached.**
- **장점**: Amazon Cognito를 사용하면 사용자 인증 및 권한 부여를 관리할 수 있습니다.
- **단점**: Active Directory와의 직접 통합보다는 제한적이며, 추가적인 관리가 필요할 수 있습니다. 또한, 요구 사항에서 원하는 신원 유지와 관련하여 완전한 해결책은 아닙니다.

#### **C. Define cross-account roles with the appropriate policies attached. Map the roles to the Active Directory groups.**
- **장점**: Active Directory 그룹을 AWS 리소스에 대한 권한 부여에 활용할 수 있습니다.
- **단점**: 이는 크로스 계정 역할을 정의하는 방식이며, 요구 사항에서 Active Directory 사용자에 대한 직접적인 관리와 연계되지는 않습니다. 관리가 복잡할 수 있습니다.

#### **D. Configure Security Assertion Markup Language (SAML) 2.0-based federation. Create roles with the appropriate policies attached. Map the roles to the Active Directory groups.**
- **장점**: SAML 2.0 기반의 연합을 구성하면 Active Directory 사용자 그룹과 AWS 리소스 간에 통합된 인증을 할 수 있습니다. 사용자는 기존 Active Directory 자격 증명을 사용하여 AWS에 액세스할 수 있으며, 별도의 계정 관리를 필요로 하지 않습니다.
- **단점**: 초기 설정이 약간 복잡할 수 있지만, 사용자 관리와 보안 측면에서 가장 효율적입니다.

### **결론**
**정답은 D. Configure Security Assertion Markup Language (SAML) 2.0-based federation. Create roles with the appropriate policies attached. Map the roles to the Active Directory groups.**입니다.

이 솔루션은 사용자가 기존의 Active Directory 자격 증명을 통해 AWS 리소스에 액세스할 수 있게 하여, 추가적인 신원 관리 없이 요구 사항을 충족할 수 있는 가장 효율적인 방법입니다. SAML 2.0 기반 연합을 통해 보안과 관리 측면에서 유리한 접근을 제공합니다.


# 626
이 문제에서는 회사가 온프레미스에 저장된 데이터를 Amazon S3 버킷으로 마이그레이션하고, 전송 후 데이터의 무결성을 자동으로 검증해야 하는 상황입니다. 각 옵션을 분석해 보겠습니다.

### 옵션 분석

#### **A. Order an AWS Snowball Edge device. Configure the Snowball Edge device to perform the online data transfer to an S3 bucket.**
- **장점**: AWS Snowball Edge는 대량의 데이터를 오프라인으로 전송할 수 있는 장치입니다. 그러나 이 옵션은 "온라인" 데이터 전송을 지원하지 않습니다. Snowball Edge는 데이터 전송 후 무결성을 검증하지만, 요구 사항에 맞지 않습니다.

#### **B. Deploy an AWS DataSync agent on premises. Configure the DataSync agent to perform the online data transfer to an S3 bucket.**
- **장점**: AWS DataSync는 온프레미스 데이터의 온라인 전송을 지원하며, 데이터 전송 후 무결성을 자동으로 검증하는 기능이 있습니다. DataSync는 데이터를 S3로 전송하면서 검증을 수행하여 전송 후 데이터의 무결성을 보장합니다.
- **단점**: 별도의 DataSync 에이전트를 배포해야 하므로 초기 설정이 필요합니다.

#### **C. Create an Amazon S3 File Gateway on premises. Configure the S3 File Gateway to perform the online data transfer to an S3 bucket.**
- **장점**: S3 File Gateway를 사용하면 온프레미스 파일 데이터를 S3 버킷으로 마이그레이션할 수 있습니다. 파일 게이트웨이는 데이터를 쉽게 S3에 저장할 수 있도록 하지만, 무결성 검증 기능이 기본적으로 제공되지 않습니다.
- **단점**: 전송 후 무결성을 자동으로 검증할 수 있는 기능이 없습니다.

#### **D. Configure an accelerator in Amazon S3 Transfer Acceleration on premises. Configure the accelerator to perform the online data transfer to an S3 bucket.**
- **장점**: S3 Transfer Acceleration은 전 세계에서 S3로의 데이터 전송 속도를 높이는 기능입니다. 하지만 무결성을 검증하는 기능은 내장되어 있지 않습니다.
- **단점**: 데이터 전송 후 무결성을 자동으로 검증할 수 있는 기능이 없습니다.

### **결론**
**정답은 B. Deploy an AWS DataSync agent on premises. Configure the DataSync agent to perform the online data transfer to an S3 bucket.**입니다.

AWS DataSync를 사용하면 온프레미스에서 S3 버킷으로 온라인 데이터 전송을 지원하며, 전송 후 데이터의 무결성을 자동으로 검증하는 기능이 있어 회사의 요구 사항을 충족합니다.

# 627
이 문제에서는 DNS 서버를 AWS로 마이그레이션하고, 고가용성을 극대화하면서 운영 관리 오버헤드를 최소화하는 솔루션을 찾아야 합니다. 각 옵션을 분석해 보겠습니다.

### 옵션 분석

#### **A. Create 200 new hosted zones in the Amazon Route 53 console. Import zone files.**
- **장점**: Amazon Route 53은 DNS 서비스로, 고가용성과 낮은 운영 오버헤드를 제공합니다. 새로운 호스팅 영역을 만들고 존 파일을 가져오면 기존 DNS 구성을 쉽게 이전할 수 있습니다.
- **단점**: 다수의 호스팅 영역을 수동으로 생성해야 하므로 초기 작업이 번거롭고 관리 측면에서 다소 복잡할 수 있습니다.

#### **B. Launch a single large Amazon EC2 instance. Import zone files. Configure Amazon CloudWatch alarms and notifications to alert the company about any downtime.**
- **장점**: EC2 인스턴스를 사용하여 DNS 서버를 호스팅하면 기존의 인프라와 비슷한 방식으로 운영할 수 있습니다.
- **단점**: 단일 인스턴스에 의존하기 때문에 가용성이 낮아집니다. EC2 인스턴스가 다운되면 DNS 서비스가 중단됩니다.

#### **C. Migrate the servers to AWS by using AWS Server Migration Service (AWS SMS). Configure Amazon CloudWatch alarms and notifications to alert the company about any downtime.**
- **장점**: AWS SMS를 사용하면 온프레미스 서버를 AWS로 쉽게 마이그레이션할 수 있습니다. CloudWatch를 통한 모니터링 및 알림 기능도 제공됩니다.
- **단점**: DNS 서버의 고가용성을 보장하지 않으며, 여전히 관리 오버헤드가 발생할 수 있습니다. 마이그레이션된 서버가 가용성을 높이는 방법이 아닙니다.

#### **D. Launch an Amazon EC2 instance in an Auto Scaling group across two Availability Zones. Import zone files. Set the desired capacity to 1 and the maximum capacity to 3 for the Auto Scaling group. Configure scaling alarms to scale based on CPU utilization.**
- **장점**: Auto Scaling 그룹을 사용하면 두 개의 가용 영역에 걸쳐 EC2 인스턴스를 배포하여 고가용성을 보장할 수 있습니다. 수요에 따라 자동으로 인스턴스를 확장할 수 있습니다.
- **단점**: 설정과 관리가 다른 옵션에 비해 복잡할 수 있으며, 비용이 증가할 수 있습니다.

### **결론**
**정답은 A. Create 200 new hosted zones in the Amazon Route 53 console. Import zone files.**입니다.

Amazon Route 53을 사용하면 DNS 서비스를 운영하는 데 있어 고가용성과 낮은 운영 오버헤드를 제공할 수 있습니다. 기존의 DNS 존을 쉽게 가져오고, Route 53의 기능을 통해 DNS 관리를 자동화하고 간소화할 수 있어 이 요구 사항을 가장 잘 충족합니다.


# 628
이 문제에서는 여러 AWS 계정에서 실행되는 애플리케이션이 여러 Amazon S3 버킷에 데이터 업로드를 수행할 때, 미완료된 멀티파트 업로드를 보고하여 비용 준수 목적을 달성하는 솔루션을 찾아야 합니다. 각 옵션을 분석해 보겠습니다.

### 옵션 분석

#### **A. Configure AWS Config with a rule to report the incomplete multipart upload object count.**
- **장점**: AWS Config는 리소스의 구성을 지속적으로 평가하고 변경 사항을 기록할 수 있습니다. 그러나 S3의 멀티파트 업로드에 대한 특정 규칙이 제공되지 않습니다. 따라서 이 옵션은 미완료된 업로드를 직접 보고하기에는 적합하지 않습니다.
- **단점**: 미완료된 멀티파트 업로드를 모니터링하는 데 AWS Config의 규칙을 설정해야 하므로 추가적인 작업이 필요합니다.

#### **B. Create a service control policy (SCP) to report the incomplete multipart upload object count.**
- **장점**: SCP는 AWS Organizations의 계정에 대한 권한을 관리하는 데 사용됩니다.
- **단점**: SCP는 미완료된 멀티파트 업로드에 대한 보고 기능을 제공하지 않으며, 따라서 이 요구사항을 충족하지 못합니다.

#### **C. Configure S3 Storage Lens to report the incomplete multipart upload object count.**
- **장점**: S3 Storage Lens는 S3 버킷에 대한 통계 및 메트릭을 수집하여 다양한 리포트를 생성할 수 있는 기능입니다. 미완료된 멀티파트 업로드에 대한 정보도 포함될 수 있어, 비용 관리에 유용한 인사이트를 제공할 수 있습니다.
- **단점**: 설정이 필요한 경우가 있지만, 비교적 적은 관리 오버헤드를 요구합니다.

#### **D. Create an S3 Multi-Region Access Point to report the incomplete multipart upload object count.**
- **장점**: S3 Multi-Region Access Point는 여러 AWS Region에 있는 S3 버킷에 대한 통합 액세스를 제공합니다.
- **단점**: 이 기능은 미완료된 멀티파트 업로드를 보고하는 기능과는 직접적으로 관련이 없습니다.

### **결론**
**정답은 C. Configure S3 Storage Lens to report the incomplete multipart upload object count.**입니다.

S3 Storage Lens는 S3 버킷에 대한 메트릭을 제공하고, 미완료된 멀티파트 업로드에 대한 통계를 수집할 수 있어, 이 요구사항을 가장 효율적으로 충족합니다. 운영 오버헤드도 최소화할 수 있는 장점이 있습니다.

# 629
- 커뮤니티에는 답 D가 많음

이 문제에서는 Amazon RDS for MySQL의 데이터베이스 버전을 보안 준수 이유로 업그레이드해야 하며, 데이터 손실 없이 신속하게 업그레이드하고 기능을 테스트할 수 있는 솔루션을 찾아야 합니다. 각 옵션을 분석해 보겠습니다.

### 옵션 분석

#### **A. Create an RDS manual snapshot. Upgrade to the new version of Amazon RDS for MySQL.**
- **장점**: RDS 수동 스냅샷을 생성하면 현재 데이터베이스 상태를 저장할 수 있어 데이터 손실 없이 업그레이드를 진행할 수 있습니다. 업그레이드 후 기능을 테스트할 수 있습니다.
- **단점**: 스냅샷 생성 후 업그레이드가 진행되므로, 테스트 중에 데이터베이스를 복원하는 추가 작업이 필요할 수 있습니다. 그러나, 스냅샷을 통해 데이터 손실을 방지할 수 있는 장점이 있습니다.

#### **B. Use native backup and restore. Restore the data to the upgraded new version of Amazon RDS for MySQL.**
- **장점**: 내장된 백업 및 복원 기능을 사용하면 데이터베이스를 다른 인스턴스에 복원할 수 있습니다.
- **단점**: 이 방법은 복잡하고, 시간 소모적일 수 있으며, 데이터베이스 버전 업그레이드 후 다시 복원하는 과정에서 데이터 손실 위험이 있습니다.

#### **C. Use AWS Database Migration Service (AWS DMS) to replicate the data to the upgraded new version of Amazon RDS for MySQL.**
- **장점**: AWS DMS를 사용하면 데이터베이스 간에 데이터를 지속적으로 복제할 수 있어 다운타임을 최소화할 수 있습니다.
- **단점**: 설정과 관리에 더 많은 오버헤드가 발생하며, 단순한 업그레이드 작업에 비해 복잡합니다.

#### **D. Use Amazon RDS Blue/Green Deployments to deploy and test production changes.**
- **장점**: Blue/Green 배포는 새로운 데이터베이스 환경을 쉽게 테스트할 수 있는 방법입니다.
- **단점**: 이 방법은 주로 새로운 기능을 도입하거나 큰 변화가 필요할 때 유용하며, 일반적인 데이터베이스 버전 업그레이드에는 과도한 해결책일 수 있습니다. 또한 추가적인 관리가 필요합니다.

### **결론**
**정답은 A. Create an RDS manual snapshot. Upgrade to the new version of Amazon RDS for MySQL.**입니다.

이 방법은 운영 오버헤드가 가장 적고, 데이터 손실 없이 신속하게 업그레이드할 수 있는 솔루션입니다. 수동 스냅샷을 통해 업그레이드 전의 상태를 안전하게 저장하고, 업그레이드 후 기능을 테스트할 수 있습니다.



# 631
정답은 **B. Use Amazon Neptune to store the information. Use Neptune Streams to process changes in the database.**입니다.

### 해설

1. **요구 사항 분석**  
   - **데이터베이스**: 사용자 프로필, 관계, 상호작용 데이터를 저장하려면 데이터 간 관계를 쉽게 표현할 수 있는 그래프 데이터베이스가 필요합니다.
   - **관계 분석**: 관계 기반 데이터의 효율적 분석 및 사용자 추천 기능을 위해 그래프 데이터베이스가 적합합니다.
   - **데이터 변경 모니터링**: 데이터베이스에서의 변경 사항을 실시간으로 감지하고 처리할 수 있는 스트리밍 기능이 필요합니다.
   - **운영 오버헤드 최소화**: 최소한의 운영 오버헤드를 요구하므로 완전 관리형 서비스와 기본적으로 통합된 기능이 필요합니다.

2. **옵션 분석**  
   - **Amazon Neptune**은 그래프 데이터베이스로, 복잡한 관계를 저장하고 처리할 수 있으며, **Neptune Streams** 기능을 통해 데이터 변경 사항을 실시간으로 처리할 수 있습니다. 이는 모든 요구 사항을 충족하는 가장 적합한 솔루션입니다.
   - **Amazon QLDB**는 원장형 데이터베이스로 변경 불가능한 트랜잭션 기록을 제공하지만, 그래프 데이터베이스가 아니므로 관계 분석에는 적합하지 않습니다.

3. **정답 선택**
   - **B (Amazon Neptune + Neptune Streams)**은 그래프 데이터베이스를 사용해 데이터 관계를 효율적으로 저장하고, **Neptune Streams**로 데이터 변경 사항을 실시간 모니터링할 수 있어 **최소한의 운영 오버헤드**로 모든 요구 사항을 충족합니다.

따라서 정답은 **B**입니다.

# 632
정답은 **C. Store the data in an Amazon Elastic File System (Amazon EFS) file system. Mount the file system on the application instances.**입니다.

### 해설

1. **요구 사항 분석**
   - **데이터 저장**: 데이터가 계속 증가하고, 대용량 저장이 필요합니다.
   - **멀티 AZ**: 여러 가용 영역에 걸쳐 배포된 EC2 인스턴스들이 데이터를 공유할 수 있어야 합니다.
   - **실시간 변경**: 데이터가 EC2 인스턴스에 의해 자주 수정될 예정이며, 이는 공유 파일 시스템이 필요함을 의미합니다.
   - **확장성**: 데이터의 양이 6개월 동안 지속적으로 증가할 것이므로 확장 가능한 스토리지 솔루션이 적합합니다.

2. **옵션 분석**
   - **A (Amazon S3 Glacier)**: S3 Glacier는 저비용 장기 보관용 스토리지로, 빈번한 접근과 실시간 데이터 수정에는 적합하지 않습니다.
   - **B (Amazon EBS)**: EBS 볼륨은 단일 EC2 인스턴스에만 직접 연결할 수 있기 때문에 여러 인스턴스에서의 접근이 불가능하며, 여러 AZ 간 공유도 어렵습니다.
   - **C (Amazon EFS)**: EFS는 멀티 AZ 환경에서의 파일 시스템 공유가 가능하며, 필요한 용량만큼 자동으로 확장할 수 있어 대규모 데이터 저장과 빈번한 접근 및 수정 작업에 이상적입니다.
   - **D (EBS Provisioned IOPS)**: 이 역시 EBS의 한 형태로, 단일 인스턴스 전용으로 설계되어 다중 인스턴스에서의 공유가 불가능합니다.

3. **정답 선택**
   - **C (Amazon EFS)**는 여러 인스턴스에 걸쳐 공유할 수 있는 완전 관리형 파일 시스템으로, 멀티 AZ 환경에서 확장성과 가용성을 제공하며 빈번한 접근과 데이터 변경이 필요한 경우에도 유리합니다.

따라서 정답은 **C**입니다.

# 633
정답은 **C. Create a read replica from the source DB instance. Serve read traffic from the read replica.**입니다.

### 해설

1. **요구 사항 분석**
   - **성능 문제**: 데이터베이스 쿼리가 성능 저하의 원인으로, 읽기 트래픽 분산이 필요합니다.
   - **Multi-AZ 배포**: 현재 설정은 Multi-AZ이므로 고가용성을 위해 스탠바이 복제본이 있으며, 이는 주로 장애 복구 용도입니다. 성능 향상에는 읽기 트래픽을 처리할 수 있는 다른 방법이 필요합니다.

2. **옵션 분석**
   - **A (Multi-AZ 스탠바이 복제본 사용)**: Multi-AZ 스탠바이 복제본은 고가용성을 위한 것이며, 일반적인 읽기 요청을 처리하지 않습니다.
   - **B (Transfer Acceleration 사용)**: Transfer Acceleration은 Amazon S3 전송 가속화 기능으로, RDS와는 관련이 없어 성능 개선에 도움이 되지 않습니다.
   - **C (읽기 복제본 생성)**: 읽기 복제본을 생성하여 읽기 트래픽을 분산하면 데이터베이스의 읽기 성능이 향상됩니다. RDS의 읽기 복제본은 읽기 전용 트래픽을 처리하도록 설계되어 성능 문제 해결에 적합합니다.
   - **D (Kinesis Data Firehose 사용)**: Kinesis Data Firehose는 실시간 데이터 스트리밍 서비스로, RDS 쿼리 성능 향상과는 관계가 없습니다.

3. **정답 선택**
   - **C (읽기 복제본 생성)**은 읽기 트래픽을 분산하여 성능을 향상시키는 데 효과적입니다.

따라서 정답은 **C**입니다.



# 634
정답은 **C. Configure cross-account access for the S3 bucket to the accounts that the agencies own.**입니다.

### 해설

1. **요구 사항 분석**
   - **데이터 접근**: 각 분석 기관이 S3 버킷에 저장된 데이터를 읽기 전용으로 접근할 수 있어야 합니다.
   - **보안과 운영 효율성**: 데이터 공유 시 보안이 강화되어야 하며, 운영 효율성을 극대화하는 방식이 필요합니다.

2. **옵션 분석**
   - **A (S3 글로벌 테이블)**: S3에는 글로벌 테이블 기능이 없으며, 이는 Amazon DynamoDB의 기능입니다. S3 데이터를 여러 계정으로 공유하려면 다른 방법이 필요합니다.
   - **B (S3 버킷을 일시적으로 공개)**: 버킷을 공용으로 만들면 누구나 접근할 수 있어 보안에 취약하며, 요구 사항을 충족하지 못합니다.
   - **C (크로스 계정 액세스 구성)**: S3 버킷에 대한 크로스 계정 액세스를 설정하여 각 기관이 자신의 AWS 계정을 통해 데이터에 접근할 수 있게 하면 보안이 강화됩니다. 또한 관리자가 각 계정에 대한 권한을 일괄적으로 설정할 수 있어 운영 효율성도 높습니다.
   - **D (소스 계정에 IAM 사용자 생성)**: 각 분석가에게 소스 계정에 대한 IAM 사용자를 생성하면 관리 부담이 커지고, 특히 많은 분석가가 있을 경우 운영 효율성이 떨어집니다.

3. **정답 선택**
   - **C (크로스 계정 액세스 구성)**은 각 기관이 보유한 계정으로 데이터에 접근할 수 있게 하므로 보안과 운영 효율성을 극대화할 수 있는 최적의 솔루션입니다.

따라서 정답은 **C**입니다.


# 635
정답은 **C. Create an FSx for ONTAP instance in the secondary Region. Use NetApp SnapMirror to replicate data from the primary Region to the secondary Region.**입니다.

### 해설

1. **요구 사항 분석**
   - **프로토콜 요구사항**: CIFS와 NFS 프로토콜을 지원해야 합니다.
   - **재해 복구(Disaster Recovery)**: 다른 리전에 데이터를 복제하여 장애 시 데이터를 사용할 수 있어야 합니다.
   - **운영 오버헤드 최소화**: 간단하고 효율적인 DR 솔루션이 필요합니다.

2. **옵션 분석**
   - **A (AWS Lambda를 사용하여 S3로 데이터 복사 및 복제)**: S3는 CIFS와 NFS 프로토콜을 지원하지 않으므로 DR 시에도 프로토콜 일관성을 제공하지 못합니다.
   - **B (AWS Backup으로 백업 후 복사 및 복구)**: 백업을 통해 재해 복구를 할 수 있지만, DR 환경에서 실시간 복제 및 CIFS/NFS 접근이 필요할 때 즉시 사용할 수 없습니다. 복원 시간이 추가적으로 소요되며 운영 오버헤드가 더 큽니다.
   - **C (NetApp SnapMirror를 사용하여 FSx for ONTAP 복제)**: NetApp SnapMirror는 FSx for ONTAP 간의 데이터 복제를 지원하며, 동일한 CIFS/NFS 프로토콜을 사용하는 데이터를 실시간으로 복제할 수 있어 재해 복구 요건에 가장 적합한 솔루션입니다. SnapMirror는 운영 오버헤드가 적고 FSx for ONTAP의 기본 기능으로 구성과 유지보수가 간편합니다.
   - **D (Amazon EFS 볼륨 생성 및 복제)**: EFS는 CIFS 프로토콜을 지원하지 않으며, NetApp ONTAP과의 호환성도 부족하여 DR 요건에 맞지 않습니다.

3. **정답 선택**
   - **C (FSx for ONTAP 인스턴스와 NetApp SnapMirror 사용)**은 필요한 프로토콜(CIFS와 NFS) 지원과 손쉬운 데이터 복제를 제공하므로 가장 적합한 DR 솔루션입니다.

따라서 정답은 **C**입니다.


# 638
정답은 **A. Use an AWS Lambda function to create an S3 presigned URL. Instruct employees to use the URL.**입니다.

### 해설

1. **요구 사항 분석**
   - **보안**: 데이터를 안전하게 접근해야 합니다.
   - **운영 오버헤드 최소화**: 운영과 관리 부담이 적어야 합니다.
   - **데이터 공유**: 전 세계 직원들에게 데이터를 공유할 수 있어야 합니다.

2. **옵션 분석**
   - **A (S3 프리사인드 URL 생성)**: S3 프리사인드 URL을 사용하면 지정된 시간 동안 S3 객체에 대한 접근을 제공할 수 있으며, 직원들에게 안전하게 데이터를 공유할 수 있습니다. 또한 프리사인드 URL은 운영 오버헤드가 매우 적고, AWS Lambda를 통해 URL을 동적으로 생성할 수 있어 효율적입니다.
   - **B (IAM 사용자 및 정책 생성)**: 각 직원에게 IAM 사용자를 만들고 S3에 접근 권한을 부여하는 것은 관리 오버헤드가 높습니다. 특히 다수의 직원이 있는 경우 사용자를 개별 관리하는 것이 비효율적입니다.
   - **C (S3 파일 게이트웨이)**: 파일 게이트웨이는 온프레미스와의 통합에 적합하며, 글로벌 직원들에게 데이터를 공유하는 용도로는 과도한 설정과 오버헤드가 발생합니다.
   - **D (AWS Transfer Family SFTP 엔드포인트)**: Transfer Family는 주로 SFTP가 필요한 특정 파일 전송을 위해 설계된 서비스로, S3에 직접 접근하는 것보다 복잡하고 추가적인 설정과 비용이 발생할 수 있습니다.

3. **정답 선택**
   - **A (S3 프리사인드 URL)**은 데이터를 안전하게 공유할 수 있으며, 운영 오버헤드를 최소화하면서도 전 세계 직원에게 손쉽게 접근을 제공할 수 있는 최적의 솔루션입니다.

따라서 정답은 **A**입니다.


# 639
정답은 **A. Disable session affinity (sticky sessions) on the ALB**입니다.

### 해설

1. **문제 분석**
   - ALB 뒤에 배치된 여러 EC2 인스턴스 중 하나로 트래픽이 집중되고 있습니다.
   - 이는 특정 인스턴스에 세션이 고정되는 **세션 어피니티(Sticky Sessions)** 기능으로 인해 발생할 수 있습니다. 이 기능이 활성화되면 클라이언트가 동일한 인스턴스로 계속 연결되어 부하 분산이 불균형하게 됩니다.

2. **옵션 분석**
   - **A (세션 어피니티 비활성화)**: 세션 어피니티를 비활성화하면 ALB가 트래픽을 인스턴스에 고르게 분배할 수 있어 특정 인스턴스에 트래픽이 몰리는 현상을 방지할 수 있습니다.
   - **B (Network Load Balancer로 교체)**: NLB는 주로 TCP 및 고성능 네트워크 부하 분산에 사용되며, HTTP/HTTPS 트래픽을 처리하는 ALB의 기능과 다릅니다. 따라서 문제 해결과 관련이 없습니다.
   - **C (AZ당 EC2 인스턴스 수 증가)**: 인스턴스 수를 늘리는 것은 성능을 높일 수 있지만, 트래픽 분배 문제가 해결되지 않으면 여전히 특정 인스턴스로 트래픽이 집중될 수 있습니다.
   - **D (ALB의 헬스 체크 빈도 조정)**: 헬스 체크 빈도를 조정해도 트래픽 분배 문제를 해결하지는 못합니다. 이 옵션은 주로 인스턴스의 가용성 모니터링과 관련이 있습니다.

3. **정답 선택**
   - **A (세션 어피니티 비활성화)**는 트래픽을 모든 인스턴스에 균등하게 분배하는 데 효과적이므로 최적의 해결책입니다.

따라서 정답은 **A**입니다.

# 640
정답은 **B. Grant the decrypt permission for the Lambda IAM role in the KMS key's policy**와 **D. Create a new IAM policy with the kms:decrypt permission and attach the policy to the Lambda function.**입니다.

### 해설

1. **요구 사항 분석**
   - Lambda 함수가 AWS KMS를 사용하여 암호화된 파일을 다운로드하고 복호화해야 합니다.
   - Lambda 함수가 KMS 키를 사용하여 데이터를 복호화하려면 적절한 권한이 필요합니다.

2. **옵션 분석**
   - **A (Lambda 함수의 리소스 정책에 kms:decrypt 권한 부여)**: AWS KMS는 IAM 역할을 사용하여 권한을 관리하므로 Lambda 함수의 리소스 정책이 KMS 권한을 부여하는 것은 올바르지 않습니다.
   - **B (KMS 키의 정책에 Lambda IAM 역할에 대한 decrypt 권한 부여)**: Lambda 함수가 사용하는 IAM 역할에 대해 KMS 키 정책에 kms:decrypt 권한을 부여하면 Lambda가 KMS 키를 사용하여 파일을 복호화할 수 있습니다.
   - **C (KMS 키의 정책에 Lambda 리소스 정책에 대한 decrypt 권한 부여)**: KMS 키 정책에 Lambda 리소스 정책을 추가하는 것은 지원되지 않으며 올바른 방법이 아닙니다.
   - **D (kms:decrypt 권한이 있는 IAM 정책 생성 후 Lambda 함수에 연결)**: Lambda 함수에 적절한 IAM 정책을 추가하면 Lambda가 KMS 키를 사용하여 데이터를 복호화하는 데 필요한 권한을 얻을 수 있습니다.
   - **E (kms:decrypt 권한이 있는 새로운 IAM 역할 생성 후 Lambda 함수에 연결)**: 새로운 IAM 역할을 생성하여 Lambda 함수에 연결할 수 있지만, Lambda 함수의 기존 IAM 역할에 권한을 추가하는 것이 더 효율적입니다.

3. **정답 선택**
   - **B**와 **D**의 조합은 Lambda 함수가 AWS KMS를 통해 파일을 복호화하는 데 필요한 권한을 설정하는 가장 적합한 방법입니다.

따라서 정답은 **B**와 **D**입니다.


# 644
정답은 **A. Use the AWS Certificate Manager (ACM) console to request a public certificate for the apex top domain example.com and a wildcard certificate for *.example.com.**와 **E. Validate domain ownership for the domain by adding the required DNS records to the DNS provider.**입니다.

### 해설

1. **요구 사항 분석**
   - 웹사이트 데이터를 암호화하기 위해 SSL/TLS 인증서가 필요합니다.
   - 각 서브도메인(country1.example.com, country2.example.com)을 지원하기 위해 와일드카드 인증서가 필요합니다.

2. **옵션 분석**
   - **A (ACM 콘솔에서 apex 도메인과 와일드카드 인증서 요청)**: example.com과 *.example.com의 공개 인증서를 요청하면, 루트 도메인과 모든 서브도메인에 대한 HTTPS 트래픽을 안전하게 암호화할 수 있습니다.
   - **B (ACM 콘솔에서 개인 인증서 요청)**: 개인 인증서는 AWS 내부에서만 사용되며, 공용 웹사이트 암호화에는 적합하지 않습니다.
   - **C (ACM 콘솔에서 공용 및 개인 인증서 요청)**: 개인 인증서는 필요하지 않으므로 이 조합은 부적절합니다.
   - **D (도메인 소유권을 이메일로 검증)**: 이메일 검증 방법은 사용 가능하지만 DNS 검증이 더 일반적이고 AWS 환경에서 선호됩니다.
   - **E (DNS 레코드 추가로 도메인 소유권 검증)**: DNS 레코드를 추가하여 도메인 소유권을 검증하는 방법은 안전하고 AWS Certificate Manager와 잘 통합됩니다.

3. **정답 선택**
   - **A**와 **E**의 조합은 웹사이트 데이터를 암호화하고 필요한 모든 도메인 및 서브도메인을 지원하는 방법으로 적합합니다.

따라서 정답은 **A**와 **E**입니다.


# 645
정답은 **B. Use an AWS Key Management Service (AWS KMS) external key store backed by an external key manager.**입니다.

### 해설

1. **요구 사항 분석**
   - **규제 및 컴플라이언스**: 키 관리자가 AWS 클라우드 외부에 있어야 합니다.
   - **암호화 및 복호화 관리**: 암호화 및 복호화는 외부 키 관리자에서 관리해야 합니다.
   - **다양한 외부 키 관리자 지원**: 여러 벤더의 외부 키 관리자와 호환되어야 합니다.

2. **옵션 분석**
   - **A (AWS CloudHSM 키 저장소 사용)**: CloudHSM은 AWS 내에서 암호화 키를 저장하는 서비스로, 외부 키 관리자의 요구를 충족하지 않습니다.
   - **B (AWS KMS 외부 키 저장소 사용)**: AWS KMS 외부 키 저장소를 사용하면 AWS KMS에서 암호화 작업을 수행하면서 외부 키 관리자가 제공하는 키를 사용할 수 있습니다. 이 솔루션은 규제 요구 사항을 충족하면서도 다양한 외부 키 관리자를 지원하므로 운영 오버헤드가 최소화됩니다.
   - **C (기본 AWS KMS 관리형 키 저장소 사용)**: 기본 KMS 관리형 키는 AWS 내에서 관리되므로 외부 키 관리자의 요구 사항을 충족하지 않습니다.
   - **D (AWS CloudHSM 클러스터에 의해 지원되는 사용자 정의 키 저장소 사용)**: CloudHSM은 AWS 내에서 키를 관리하므로 외부 키 관리자의 요구를 충족하지 않습니다. 

3. **정답 선택**
   - **B (AWS KMS 외부 키 저장소 사용)**는 외부 키 관리자의 요구를 충족하며 AWS와의 통합을 통해 최소한의 운영 오버헤드로 암호화 및 복호화를 관리할 수 있는 최적의 솔루션입니다.

따라서 정답은 **B**입니다.

# 647
정답은 **A. Use AWS Global Accelerator with health checks.**입니다.

### 해설

1. **요구 사항 분석**
   - **전 세계 사용자에게 서비스 제공**: 전 세계 사용자를 대상으로 하는 VoIP 애플리케이션입니다.
   - **고가용성 및 자동 장애 조치**: 여러 AWS 리전 간에 자동으로 장애 조치가 이루어져야 합니다.
   - **사용자 지연 최소화**: 사용자 디바이스의 IP 주소 캐싱에 의존하지 않고 지연을 최소화해야 합니다.

2. **옵션 분석**
   - **A (AWS Global Accelerator 사용)**: Global Accelerator는 지리적으로 분산된 사용자에게 최적의 엔드포인트를 제공하고, 엔드포인트의 가용성을 모니터링하여 자동으로 장애 조치를 수행합니다. 이는 VoIP와 같은 실시간 애플리케이션에 적합하며 지연을 최소화합니다.
   - **B (Amazon Route 53의 지리적 라우팅 정책 사용)**: Route 53의 지리적 라우팅은 요청을 특정 리전으로 라우팅할 수 있지만, 실시간으로 상태를 모니터링하고 자동으로 장애 조치를 수행하는 기능은 없습니다. 
   - **C (Amazon CloudFront 배포 생성)**: CloudFront는 콘텐츠 배포 네트워크(CDN)로, VoIP 트래픽에는 적합하지 않으며, 자동 장애 조치 기능도 없습니다.
   - **D (Application Load Balancer를 사용한 경로 기반 라우팅)**: ALB는 HTTP(S) 트래픽에 대한 라우팅을 제공하지만, 여러 리전 간의 고가용성을 제공하고 자동으로 장애 조치를 수행하는 데 필요한 기능은 없습니다.

3. **정답 선택**
   - **A (AWS Global Accelerator 사용)**는 글로벌 사용자에게 최적의 성능을 제공하고 자동 장애 조치 기능을 갖추고 있어 요구 사항을 충족하는 가장 적합한 솔루션입니다.

따라서 정답은 **A**입니다.


# 648
정답은 **B. Use Amazon FSx for Lustre persistent file systems.**입니다.

### 해설

1. **요구 사항 분석**
   - **데이터 처리**: 수백 기가바이트의 데이터를 처리해야 하며, 서브 밀리초(latency) 성능이 요구됩니다.
   - **고성능 컴퓨팅 환경**: HPC 환경에서 대량의 데이터를 효율적으로 처리할 수 있는 스토리지가 필요합니다.
   - **동시 액세스**: 수천 개의 컴퓨트 인스턴스가 동시에 데이터에 접근해야 합니다.

2. **옵션 분석**
   - **A (Amazon FSx for Lustre 임시 파일 시스템 사용)**: 임시 파일 시스템은 주로 데이터 처리의 중간 결과를 저장하는 데 사용되며, 지속적인 데이터 저장에는 적합하지 않습니다. 데이터가 저장된 후에도 지속적으로 접근할 수 있어야 하므로 적합하지 않습니다.
   - **B (Amazon FSx for Lustre 지속 파일 시스템 사용)**: FSx for Lustre의 지속 파일 시스템은 고성능 스토리지 솔루션으로, HPC 환경에서 대량의 데이터를 낮은 지연 시간으로 처리할 수 있습니다. 여러 인스턴스에서 동시에 데이터를 읽고 쓸 수 있도록 설계되었습니다.
   - **C (Amazon EFS의 Bursting Throughput 모드 사용)**: EFS는 관리형 파일 시스템이지만, HPC 환경의 높은 처리량 요구를 충족하기에는 성능이 부족할 수 있습니다.
   - **D (Amazon EFS의 Provisioned Throughput 모드 사용)**: Provisioned Throughput은 EFS의 성능을 향상시킬 수 있지만, FSx for Lustre가 제공하는 높은 성능과 서브 밀리초 지연 요구를 만족시키기에는 한계가 있습니다.

3. **정답 선택**
   - **B (Amazon FSx for Lustre 지속 파일 시스템 사용)**는 요구 사항을 충족하는 가장 적합한 솔루션입니다. 고성능 컴퓨팅 환경에 최적화되어 있고, 대량의 데이터에 대한 낮은 지연 시간 및 높은 처리량을 제공하여 여러 인스턴스에서 동시에 접근할 수 있습니다.

따라서 정답은 **B**입니다.


# 649
정답은 **C. Configure the General Purpose SSD (gp3) EBS volume storage type and provision 15,000 IOPS.**입니다.

### 해설

1. **요구 사항 분석**
   - **PostgreSQL 데이터베이스**를 Amazon RDS로 마이그레이션하고, **독립적인 IOPS 성능**을 프로비저닝해야 합니다.
   - **최대 15,000 IOPS**를 필요로 하며, 비용 효율성이 중요합니다.

2. **옵션 분석**
   - **A (General Purpose SSD (gp2) EBS 볼륨 사용)**: gp2는 기본적으로 IOPS가 스토리지 용량에 의존하므로 15,000 IOPS를 프로비저닝하기 위해서는 상당한 용량의 스토리지(최소 3TB)가 필요합니다. 이는 비용 효율적이지 않습니다.
   - **B (Provisioned IOPS SSD (io1) EBS 볼륨 사용)**: io1은 높은 IOPS를 제공할 수 있지만, 비용이 상대적으로 비쌉니다. 이 요구사항을 충족할 수 있지만, 더 비용 효율적인 대안이 있습니다.
   - **C (General Purpose SSD (gp3) EBS 볼륨 사용)**: gp3는 독립적으로 IOPS를 프로비저닝할 수 있으며, 최소 3,000 IOPS에서 최대 16,000 IOPS까지 설정할 수 있습니다. 또한, gp3의 가격이 gp2보다 더 낮고, 성능이 우수합니다. 따라서 비용 효율적인 솔루션입니다.
   - **D (EBS 자기 저장 볼륨 사용)**: 자기 저장 볼륨은 성능이 낮고, 최대 IOPS 요구를 충족하기에 적합하지 않습니다. 또한, 안정적인 성능을 제공하지 못합니다.

3. **정답 선택**
   - **C (General Purpose SSD (gp3) EBS 볼륨 사용)**는 독립적으로 IOPS를 프로비저닝할 수 있고, 비용 효율적인 방법으로 요구 사항을 충족하는 최상의 선택입니다.

따라서 정답은 **C**입니다.

# 652
정답은 **B**입니다.

### 해설

**Amazon EMR 클러스터**는 **온디맨드(안정성 보장)** 및 **스팟 인스턴스(비용 절감)**를 혼합하여 사용할 수 있으며, 클러스터의 종류(상시 실행 클러스터와 일시적 클러스터)에 따라 비용과 안정성에 차이가 있습니다. 이 문제는 데이터 손실을 방지하면서 비용을 최적화하는 방법을 묻고 있습니다.

#### 각 옵션 분석

1. **A. 상시 실행 클러스터 + 온디맨드 인스턴스(주요/코어) + 스팟 인스턴스(태스크)**:
   - 상시 실행 클러스터는 데이터 파이프라인이 반복적이거나 24시간 가동이 필요한 경우에 적합합니다.
   - 그러나, 이 문제의 경우 일일 6시간만 클러스터가 필요하므로 비효율적입니다.
   - 결과적으로 비용 최적화 측면에서 적합하지 않습니다.

2. **B. 일시적 클러스터 + 온디맨드 인스턴스(주요/코어) + 스팟 인스턴스(태스크)**:
   - 일시적 클러스터는 필요한 작업이 완료되면 클러스터가 자동으로 종료되므로, 비용 효율성이 높습니다.
   - 주요 및 코어 노드에 온디맨드 인스턴스를 사용하여 데이터 손실 위험을 줄이며, 태스크 노드에 스팟 인스턴스를 사용해 비용을 절감할 수 있습니다.
   - 이 구성이 데이터 손실을 방지하면서도 비용 효율적입니다.

3. **C. 일시적 클러스터 + 온디맨드 인스턴스(주요) + 스팟 인스턴스(코어/태스크)**:
   - 코어 노드에 스팟 인스턴스를 사용할 경우, 인스턴스가 중단되면 **데이터 손실 위험**이 있습니다.
   - 따라서, 데이터 손실을 방지하기 위해 코어 노드는 온디맨드로 설정하는 것이 적합합니다.

4. **D. 상시 실행 클러스터 + 온디맨드 인스턴스(주요) + 스팟 인스턴스(코어/태스크)**:
   - 상시 실행 클러스터와 스팟 인스턴스를 함께 사용하면 비용은 절감되지만, 데이터 손실 위험이 크며 일시적 요구에 적합하지 않습니다.

### 결론
**옵션 B**는 일시적 클러스터를 통해 6시간 후 자동 종료되고, 주요/코어 노드에 온디맨드 인스턴스를 사용하여 데이터 손실을 방지하면서 태스크 노드에 스팟 인스턴스를 사용해 비용을 최소화합니다.

# 653
정답은 **B**입니다.

### 해설

이 문제에서는 **AWS 계정에서 생성되는 모든 리소스에 대해, 리소스를 생성한 사용자의 비용 센터 ID로 태그를 자동으로 추가**하는 방법을 묻고 있습니다. 이 요구 사항을 충족하려면, 각 리소스 생성 이벤트에 반응해 비용 센터를 조회하고 태그를 추가할 수 있어야 합니다.

#### 각 옵션 분석

1. **A. 서비스 제어 정책(SCP) 사용**:
   - SCP는 계정이나 조직의 권한을 제한할 수 있지만, 리소스 생성 시 태그를 자동으로 추가할 수 있는 기능은 없습니다.
   - SCP는 리소스가 특정 태그 없이 생성되지 않도록 제한할 수 있지만, 이 문제에서는 태그가 자동으로 추가되는 기능이 필요합니다.
   - 따라서, 이 방법은 적합하지 않습니다.

2. **B. Lambda 함수 + EventBridge 규칙 (정답)**:
   - EventBridge 규칙을 사용해 **CloudTrail의 리소스 생성 이벤트**에 반응하여 Lambda 함수를 실행할 수 있습니다.
   - Lambda 함수가 RDS 데이터베이스에서 비용 센터 정보를 조회하여 리소스를 적절한 태그로 업데이트합니다.
   - 이 방법은 요구 사항을 효율적으로 충족하며, 리소스가 생성될 때마다 비용 센터 정보를 기반으로 자동 태그를 추가하는 자동화된 솔루션을 제공합니다.

3. **C. Lambda 함수를 CloudFormation 스택으로 배포 + EventBridge 정기적 호출**:
   - 이 방법은 Lambda 함수 호출을 정기적으로 스케줄링하므로, 리소스 생성 직후 태그가 추가되지 않을 수 있습니다.
   - 실시간 반응이 필요할 경우 적합하지 않으며, EventBridge 규칙으로 CloudTrail 이벤트를 즉시 처리할 수 있는 **B 옵션**보다 효율성이 떨어집니다.

4. **D. Lambda 함수 + EventBridge 규칙 (기본값 태그 적용)**:
   - 이 옵션은 기본값 태그를 사용하므로, 사용자별로 정확한 비용 센터 태그를 적용할 수 없습니다.
   - 각 사용자의 비용 센터 ID로 태그를 지정해야 한다는 요구 사항을 충족하지 못합니다.

### 결론
**옵션 B**는 EventBridge와 Lambda 함수를 통해 실시간으로 리소스 생성 이벤트에 반응하고, RDS 데이터베이스에서 비용 센터 ID를 조회하여 태그를 정확히 추가하므로, **가장 효율적이고 요구 사항을 충족하는 솔루션**입니다.


# 655
정답은 **C**와 **E**입니다.

### 해설

이 문제는 **웹 애플리케이션을 위한 세션 지속성(Sticky Sessions), 공용 액세스, WAF 보안 설정**을 요구하고 있습니다. 각 요구 사항을 만족시키기 위해 AWS의 적합한 서비스를 선택해야 합니다.

#### 요구 사항 분석

1. **세션 지속성(Sticky Sessions)**:
   - 세션 지속성은 **Application Load Balancer (ALB)**에서 설정할 수 있습니다. ALB는 세션을 고정하는 기능을 제공하므로, 사용자가 같은 인스턴스에 연결될 수 있습니다.

2. **공용 인터넷 액세스**:
   - ALB는 인터넷을 통해 접근할 수 있는 공용 엔드포인트를 제공하며, Auto Scaling 그룹과 EC2 인스턴스를 대상으로 지정할 수 있습니다.

3. **WAF 보안 적용**:
   - **AWS WAF**는 ALB와 통합되어 **웹 ACL**을 통해 웹 애플리케이션에 추가적인 보안 계층을 제공합니다.

#### 각 옵션 분석

1. **A. Network Load Balancer 사용**:
   - NLB는 세션 지속성을 지원하지 않으며, 주로 전송 계층(TCP/UDP) 트래픽을 처리하므로, 이 요구 사항에 적합하지 않습니다.

2. **B. Gateway Load Balancer 사용**:
   - Gateway Load Balancer는 네트워크 보안 및 가시성에 적합하며 세션 지속성을 지원하지 않습니다. 웹 애플리케이션 로드 밸런싱을 위해 적절한 선택이 아닙니다.

3. **C. Application Load Balancer 사용 (정답)**:
   - ALB는 세션 지속성(Sticky Sessions)을 지원하고, 공용 액세스를 제공하며, AWS WAF와도 통합할 수 있습니다.
   - 따라서, ALB는 요구 사항을 충족하는 최적의 로드 밸런서 옵션입니다.

4. **D. 두 번째 타겟 그룹 생성 후 Elastic IP 추가**:
   - Elastic IP 주소를 EC2 인스턴스에 추가하는 것은 세션 지속성을 해결하지 않으며, 고정된 IP를 사용하게 되어 고가용성을 저하시킬 수 있습니다.

5. **E. WAF 웹 ACL 생성 및 엔드포인트에 연결 (정답)**:
   - WAF 웹 ACL을 생성하고 ALB 엔드포인트에 연결하면 **웹 애플리케이션 방화벽**이 설정되어 보안 요구 사항을 충족할 수 있습니다.

### 결론
**옵션 C와 E**는 세션 지속성, 공용 엔드포인트 액세스, WAF 보안 요구 사항을 충족하는 가장 적합한 솔루션입니다.

# 657
정답은 **B**입니다.

### 해설

이 문제는 **여러 계정에서 관리되는 보안 그룹 규칙을 중앙에서 관리하여 CIDR 범위 업데이트의 관리 오버헤드를 최소화**하는 방법을 묻고 있습니다. 각 옵션은 다중 계정 및 글로벌 설정을 지원하는 방법을 제안하며, 효율적인 중앙 관리 방안을 선택하는 것이 중요합니다.

#### 각 옵션 분석

1. **A. 관리 계정에서 보안 그룹 생성 및 업데이트**:
   - 관리 계정에서만 보안 그룹을 관리하면 여러 계정에서 사용하는 보안 그룹을 중앙에서 관리할 수 없습니다.
   - 계정 간 공유 없이 관리 계정에만 보안 그룹을 생성하는 것은 요구 사항을 충족하지 않습니다.

2. **B. VPC 고객 관리 프리픽스 목록 생성 + AWS RAM을 통한 프리픽스 목록 공유 (정답)**:
   - **고객 관리 프리픽스 목록**을 사용하면 CIDR 범위를 쉽게 관리할 수 있으며, 목록을 보안 그룹 규칙에 사용할 수 있습니다.
   - **AWS RAM(Resource Access Manager)**을 통해 프리픽스 목록을 조직 내 여러 계정에 공유할 수 있어, 다중 계정에서 CIDR 범위를 간단히 업데이트하고 적용할 수 있습니다.
   - 이 방법은 관리 오버헤드를 줄이고, 여러 계정에 걸쳐 업데이트를 간소화하는 비용 효율적인 솔루션입니다.

3. **C. AWS 관리형 프리픽스 목록 사용 + Security Hub 정책 및 Lambda 사용**:
   - 관리형 프리픽스 목록은 특정 공용 IP 블록에만 적용되며, 조직의 내부 CIDR 범위는 사용자 지정이 필요합니다.
   - 또한 Lambda 함수를 통한 프리픽스 목록 자동 업데이트 설정은 복잡도를 높일 수 있습니다.
   - 따라서 고객 관리 프리픽스 목록을 통한 간소화된 옵션보다 비용과 관리 효율성이 떨어집니다.

4. **D. 중앙 관리 계정에서 보안 그룹 생성 + AWS Firewall Manager 정책**:
   - AWS Firewall Manager는 보안 그룹을 중앙에서 관리할 수 있지만, 보안 그룹에 CIDR 범위를 쉽게 추가하거나 제거하는 데는 적합하지 않습니다.
   - Firewall Manager 정책은 중앙 관리에는 좋으나, 여러 계정에서 CIDR 범위를 효율적으로 업데이트할 수 있는 **프리픽스 목록**을 사용하는 옵션이 더 적합합니다.

### 결론
**옵션 B**는 고객 관리 프리픽스 목록을 통해 CIDR 범위를 관리하고, 이를 AWS RAM을 통해 조직 내에 공유하여 **중앙에서 CIDR 업데이트를 간소화**할 수 있는 가장 비용 효율적인 솔루션입니다.

# 658
정답은 **A**와 **E**입니다.

### 해설

이 문제는 **지연 시간이 낮고 고성능의 파일 공유 시스템**을 AWS 클라우드에서 구현하는 방법을 묻고 있으며, **NFS 및 SMB 멀티 프로토콜 접근성**을 요구하고 있습니다. 각 옵션은 고성능 컴퓨팅(HPC) 워크로드에 적합한 파일 시스템과 배치 그룹을 제안하며, 요구 사항에 따라 최적의 선택을 해야 합니다.

#### 각 옵션 분석

1. **A. 컴퓨트 최적화 EC2 인스턴스 + 클러스터 배치 그룹 (정답)**:
   - 클러스터 배치 그룹은 EC2 인스턴스를 **단일 가용 영역** 내에 배치하여 **지연 시간을 최소화하고 네트워크 성능을 최대화**하는 데 적합합니다.
   - HPC 워크로드와 같이 높은 네트워크 성능이 필요한 경우에 가장 유리한 옵션입니다.

2. **B. 컴퓨트 최적화 EC2 인스턴스 + 파티션 배치 그룹**:
   - 파티션 배치 그룹은 가용성을 위해 서로 다른 파티션에 인스턴스를 배치하는 방식으로, 고성능 네트워크 연결이 필요한 경우 클러스터 배치 그룹에 비해 적합하지 않습니다.
   - 지연 시간이 중요한 HPC 워크로드에는 적합하지 않습니다.

3. **C. Amazon FSx for Lustre 파일 시스템**:
   - FSx for Lustre는 고성능 파일 시스템으로 HPC 워크로드에 적합하지만, **NFS 및 SMB 멀티 프로토콜 접근을 지원하지 않습니다**.
   - NFS 및 SMB 프로토콜 접근성을 요구하는 이 문제에는 적합하지 않습니다.

4. **D. Amazon FSx for OpenZFS 파일 시스템**:
   - FSx for OpenZFS는 NFS 프로토콜을 지원하지만, **SMB 프로토콜을 지원하지 않습니다**.
   - 이 문제에서는 멀티 프로토콜 접근성을 요구하므로 적합하지 않습니다.

5. **E. Amazon FSx for NetApp ONTAP 파일 시스템 (정답)**:
   - FSx for NetApp ONTAP는 **NFS 및 SMB 멀티 프로토콜 접근성을 모두 지원**하며, 고성능이 필요한 HPC 워크로드에 적합합니다.
   - ONTAP 파일 시스템은 성능과 지연 시간 면에서 유리하므로 요구 사항을 충족합니다.

### 결론
**옵션 A와 E**는 클러스터 배치 그룹과 FSx for NetApp ONTAP 파일 시스템을 사용하여 **지연 시간을 최소화하고 NFS 및 SMB 멀티 프로토콜 지원**을 제공하는 가장 적합한 솔루션입니다.


# 659
이 경우, 요구 사항은 **50TB의 데이터를 2주 이내에 안전하게 AWS로 전송**하는 것입니다. 또한, 기존 데이터 센터에서 **Site-to-Site VPN 연결**이 이미 설정되어 있지만, 이 연결은 **90%가 사용 중**이므로, VPN을 통한 전송에는 한계가 있을 수 있습니다.

따라서 가장 적합한 솔루션은 **C. AWS Snowball Edge Storage Optimized**입니다.

### 이유:

1. **AWS Snowball Edge Storage Optimized**:
   - **대용량 데이터 이동에 최적화**된 물리적 장치입니다. 이 장치는 **50TB**까지의 데이터를 저장할 수 있으며, **2주 이내에 데이터 이동**을 완료할 수 있습니다.
   - **오프라인 방식으로 데이터 이동**하므로, 인터넷 연결이나 VPN 대역폭에 영향을 받지 않습니다. **빠르고 안전하게 대용량 데이터를 AWS로 전송**할 수 있습니다.
   - 데이터를 Snowball 장치에 복사한 후, AWS로 배송하여 자동으로 데이터를 S3와 같은 서비스로 업로드합니다. 이렇게 하면 **네트워크 대역폭의 제약 없이 대용량 데이터를 신속하게 이동**할 수 있습니다.

2. **다른 옵션들 분석**:
   - **A. AWS DataSync with a VPC endpoint**:
     - **AWS DataSync**는 데이터를 빠르고 효율적으로 전송할 수 있는 서비스입니다. 하지만 **90% 사용 중인 VPN 연결**은 대역폭의 제약을 받을 수 있기 때문에 이 솔루션을 선택하기에는 적합하지 않습니다. **VPN 연결의 대역폭 한계**를 고려할 때, Snowball Edge가 더 효과적입니다.
   
   - **B. AWS Direct Connect**:
     - **Direct Connect**는 고속 전용 네트워크 연결을 제공합니다. 그러나 이미 **VPN 연결을 사용하고 있고, 데이터 센터를 이동하는 중**이므로, 추가적으로 **Direct Connect를 설정**하는 것은 시간이 많이 걸리고 비효율적일 수 있습니다. 또한, 이 옵션은 이미 제공된 2주 내에 작업을 완료하는 데 적합하지 않습니다.
   
   - **D. AWS Storage Gateway**:
     - **Storage Gateway**는 온프레미스와 AWS 클라우드 간에 파일 시스템을 연결하는 서비스로, 데이터를 실시간으로 동기화하는 데 사용됩니다. 그러나 대용량의 데이터를 2주 내에 **한 번에 전송하는 용도로는 적합하지 않습니다**.

### 결론:
**C. AWS Snowball Edge Storage Optimized**는 **50TB의 대용량 데이터를 빠르고 안전하게 전송**할 수 있는 최적의 솔루션입니다. 인터넷 대역폭에 영향을 받지 않으며, 주어진 시간 내에 작업을 완료할 수 있습니다.

# 663
정답은 **C. Create an S3 bucket policy that restricts bucket access to the ECS task execution role. Create a VPC endpoint for Amazon RDS for MySQL. Update the RDS for MySQL security group to allow access from only the subnets that the ECS cluster will generate tasks in.**입니다.

### 해설:

이 문제는 다음과 같은 요구사항을 충족해야 합니다:
1. **ECS 클러스터가 RDS 데이터베이스와 S3 버킷에 접근할 수 있도록 설정**
2. **데이터베이스와 S3 버킷의 접근 권한을 ECS 클러스터로 제한**

**옵션 분석:**
- **A와 B**는 AWS KMS 키를 이용해 암호화 설정을 제안하지만, **접근 권한을 제어**하는 것은 S3 버킷과 RDS 데이터베이스의 보안 구성과 관련된 문제입니다. 암호화만으로는 접근 권한 제어를 충족할 수 없습니다.

- **D**는 S3에 대한 VPC 엔드포인트 사용을 포함하므로 S3에 접근을 제한할 수 있지만, ECS 클러스터에서의 접근을 특정할 수 있는 **S3 버킷 정책 설정이 필요하지 않습니다**. 

- **C**는 **S3 버킷 정책으로 ECS 작업 실행 역할만 접근하도록 제한**하고, **RDS 데이터베이스에 VPC 엔드포인트와 보안 그룹을 설정**하여 ECS 클러스터의 서브넷에서만 접근할 수 있도록 설정합니다. 이는 요구사항을 모두 충족하는 최적의 방법입니다.

따라서 정답은 **C**입니다.

ECS에서 S3 버킷에 접근하려면 **S3 버킷 정책**이나 **IAM 역할**을 통해 권한을 설정해야 합니다. 다음 두 가지 접근 방법이 있습니다.

1. **ECS 작업 역할에 S3 접근 권한 추가**  
   ECS 작업에 사용되는 **IAM 역할**에 S3 버킷에 대한 접근 권한을 부여하는 정책을 추가할 수 있습니다. 예를 들어, S3 버킷 내 객체에 읽기 권한이 필요하면 다음과 같은 정책을 추가합니다:
   ```json
   {
     "Version": "2012-10-17",
     "Statement": [
       {
         "Effect": "Allow",
         "Action": [
           "s3:GetObject"
         ],
         "Resource": "arn:aws:s3:::your-bucket-name/*"
       }
     ]
   }
   ```
   이렇게 설정하면 해당 IAM 역할을 사용하는 ECS 작업이 지정된 S3 버킷의 객체에 접근할 수 있습니다.

2. **S3 버킷 정책을 통해 접근 제한**  
   S3 버킷에 직접 **버킷 정책**을 설정해 ECS 작업 역할만 접근할 수 있도록 제한할 수도 있습니다. 이를 위해 S3 버킷 정책에 접근을 허용하는 역할을 지정하여 다음과 같이 설정합니다:
   ```json
   {
     "Version": "2012-10-17",
     "Statement": [
       {
         "Effect": "Allow",
         "Principal": {
           "AWS": "arn:aws:iam::your-account-id:role/your-ecs-task-role"
         },
         "Action": "s3:GetObject",
         "Resource": "arn:aws:s3:::your-bucket-name/*"
       }
     ]
   }
   ```

이 두 가지 설정을 통해 **ECS가 S3 버킷에 안전하게 접근**할 수 있습니다.

# 668
정답은 **D. Create a tag policy in Organizations that has a list of allowed application names.**입니다.

### 해설:

1. **AWS Organizations의 태그 정책**:
   - 태그 정책은 조직 내 여러 계정에서 일관된 태그 관리를 강제하는 데 사용됩니다. `application name` 태그에 대해 허용된 값을 지정하는 태그 정책을 생성함으로써, 조직 내에서 생성되는 모든 리소스가 이 정책을 준수하도록 할 수 있습니다.
   - 이렇게 하면 각 개별 계정이나 리소스에 대해 복잡한 IAM 정책 구성을 필요로 하지 않고도 중앙 집중식으로 태그 준수를 강제할 수 있습니다.

2. **요구사항 충족**:
   - 요구사항은 리소스가 생성될 때 `application name` 태그가 승인된 값으로 지정되어야 한다고 명시합니다. 태그 정책을 사용하여 유효한 애플리케이션 이름 목록을 정의하면 개발 팀이 이 승인된 값으로만 태그를 지정할 수 있도록 보장할 수 있습니다.

### 다른 선택지가 적합하지 않은 이유:

- **A. IAM 그룹을 생성하고 리소스가 생성될 때 application name 태그가 지정되어야 한다는 조건부 허용 정책을 설정하기**:
   - 이 방법은 태그가 지정되어야 한다고 강제할 수 있지만, 애플리케이션 이름 태그에 사용될 수 있는 값을 제한하지 않으므로 요구사항을 완전히 충족하지는 않습니다.

- **B. 모든 리소스에 대해 application name 태그가 있는 경우 거부 정책을 가진 교차 계정 역할을 생성하기**:
   - 이 접근 방식은 애플리케이션 이름 태그가 있는 모든 리소스의 생성을 거부하므로, 태그를 아예 사용할 수 없게 만들고, 승인된 태그를 사용할 수 있도록 허용하지 않습니다. 따라서 승인된 값을 강제하지 않습니다.

- **C. AWS 리소스 그룹에서 모든 계정의 리소스에 태그가 적용되었는지 검증하기 위한 리소스 그룹 생성하기**:
   - 리소스 그룹은 리소스를 구성하고 관리하는 데 도움을 줄 수 있지만, 리소스 생성 시 태그 값을 강제하는 메커니즘을 제공하지 않습니다. 이는 리소스를 관리하는 방법이지 정책을 강제하는 것이 아닙니다.

### 결론:
**AWS Organizations의 태그 정책**을 사용하는 것이 개발 팀이 승인된 애플리케이션 이름 태그로만 리소스를 생성할 수 있도록 보장하는 가장 효율적이고 효과적인 방법입니다. 이는 회사의 요구사항을 중앙 집중식으로 충족하는 방법입니다.


# 671
- AWS Cost Anomaly Detection

# 672
정답은 **B. Configure an AWS Glue crawler to crawl the data. Configure Amazon Athena to query the data.**입니다.

### 해설:

1. **AWS Glue Crawler**:
   - AWS Glue Crawler는 Amazon S3에 저장된 데이터를 자동으로 탐색하여 메타데이터를 생성하고, 이를 기반으로 테이블을 생성합니다. 이 과정은 간단하며, 별도의 수동 개입 없이 자동으로 수행됩니다.

2. **Amazon Athena**:
   - Athena는 S3에 저장된 데이터를 SQL 쿼리를 사용하여 직접 쿼리할 수 있는 서버리스 서비스입니다. 별도의 인프라 관리 없이 즉시 쿼리할 수 있으며, 클릭스트림 데이터를 신속하게 분석할 수 있는 이상적인 선택입니다.
   - Athena는 SQL을 사용하여 데이터를 쿼리할 수 있으므로 사용하기도 쉽고, 결과를 빠르게 얻을 수 있습니다.

3. **다른 옵션들의 한계**:
   - **A. Create external tables in a Spark catalog. Configure jobs in AWS Glue to query the data.**: AWS Glue는 ETL(추출, 변환, 적재) 작업에 적합하지만, Spark를 사용하는 경우에는 별도의 작업을 구성해야 하며, 이로 인해 운영 오버헤드가 증가할 수 있습니다.
   - **C. Create external tables in a Hive metastore. Configure Spark jobs in Amazon EMR to query the data.**: Hive와 EMR을 사용하는 것은 강력하지만, EMR 클러스터를 관리해야 하며, 이는 더 높은 운영 오버헤드를 의미합니다.
   - **D. Configure an AWS Glue crawler to crawl the data. Configure Amazon Kinesis Data Analytics to use SQL to query the data.**: Kinesis Data Analytics는 스트리밍 데이터를 처리하는 데 적합하며, 배치 데이터에 대한 즉각적인 쿼리에는 Athena가 더 적합합니다.

### 결론:
따라서, AWS Glue Crawler를 사용하여 데이터를 탐색하고 Amazon Athena를 통해 쿼리하는 것이 최소한의 운영 오버헤드로 클릭스트림 데이터를 신속하게 분석할 수 있는 최상의 솔루션입니다.


# 673
- ChatGPT 답이 이상함


# 674
주어진 문제에 대한 성능 문제를 해결하기 위한 적절한 조치는 다음과 같습니다:

### 정답:  
**B. Create a read replica for the DB instance. Configure the application to send read traffic to the read replica.**  
- 읽기 부하가 높은 상황에서 데이터베이스에 대한 읽기 복제본을 생성하고, 애플리케이션이 읽기 요청을 해당 복제본으로 전송하도록 구성함으로써 데이터베이스의 성능을 향상시킬 수 있습니다. 이렇게 하면 기본 DB 인스턴스의 읽기 부하가 줄어들어 전반적인 성능이 개선됩니다.

**D. Create an Amazon ElastiCache cluster. Configure the application to cache query results in the ElastiCache cluster.**  
- Amazon ElastiCache 클러스터를 생성하여 애플리케이션에서 쿼리 결과를 캐시하도록 구성함으로써 데이터베이스의 읽기 부하를 줄일 수 있습니다. 캐시된 데이터를 사용하면 DB에 대한 요청 수가 줄어들고, 데이터베이스 성능이 향상됩니다.

### 나머지 옵션에 대한 설명:
- **A. Turn on auto scaling for the DB instance.**
  - RDS DB 인스턴스는 자동 확장을 지원하지 않으므로 이 옵션은 효과적이지 않습니다. 대신 DB 인스턴스에 대한 크기 조정이 필요할 수 있습니다.

- **C. Convert the DB instance to a Multi-AZ DB instance deployment.**
  - Multi-AZ 배포는 고가용성을 제공하지만 성능 개선에는 도움이 되지 않습니다. 주로 장애 조치 시에 유용합니다.

- **E. Configure the Auto Scaling group subnets to ensure that the EC2 instances are provisioned in the same Availability Zone as the DB instance.**
  - EC2 인스턴스와 RDS 인스턴스가 같은 가용 영역에 있을 경우 지연 시간이 감소할 수 있지만, 이는 성능 개선의 주된 해결책이 아닙니다.

따라서, **B**와 **D**가 성능 문제를 해결하는 데 가장 효과적인 선택입니다.


# 676

- CloudWatch vs. CloudTrail

주어진 문제의 요구 사항을 충족하는 솔루션은 다음과 같습니다:

### 정답:
**B. Create a log group in Amazon CloudWatch Logs. Configure VPC Flow Logs to send the log data to the log group. Use Amazon Kinesis Data Firehose to stream the logs from the log group to OpenSearch Service.**

### 해설:
1. **VPC Flow Logs**: VPC 흐름 로그를 설정하면 네트워크 인터페이스의 트래픽 정보를 캡처할 수 있습니다. 이를 통해 인바운드 및 아웃바운드 트래픽에 대한 세부 정보를 수집할 수 있습니다.

2. **CloudWatch Logs**: 흐름 로그 데이터를 Amazon CloudWatch Logs의 로그 그룹으로 보냅니다. CloudWatch Logs는 로그 데이터를 저장하고 관리하는 데 적합합니다.

3. **Kinesis Data Firehose**: CloudWatch Logs에서 수집한 로그를 Amazon OpenSearch Service로 실시간으로 전송하기 위해 Amazon Kinesis Data Firehose를 사용합니다. Kinesis Data Firehose는 데이터를 실시간으로 수집하고 변환하여 여러 목적지로 전송할 수 있는 완전관리형 서비스입니다. 

이 조합은 트래픽 정보를 거의 실시간으로 수집하고 분석할 수 있는 효율적인 방법을 제공합니다.

### 나머지 옵션에 대한 설명:
- **A. Create a log group in Amazon CloudWatch Logs. Configure VPC Flow Logs to send the log data to the log group. Use Amazon Kinesis Data Streams to stream the logs from the log group to OpenSearch Service.**
  - Kinesis Data Streams는 로그를 스트리밍할 수 있지만, OpenSearch Service로의 데이터 전송을 위해 추가적인 구성과 관리가 필요합니다. Firehose가 더 간편한 선택입니다.

- **C. Create a trail in AWS CloudTrail. Configure VPC Flow Logs to send the log data to the trail. Use Amazon Kinesis Data Streams to stream the logs from the trail to OpenSearch Service.**
  - AWS CloudTrail은 API 호출을 모니터링하는 데 사용되며, VPC Flow Logs와 직접적으로 연관되지 않습니다.

- **D. Create a trail in AWS CloudTrail. Configure VPC Flow Logs to send the log data to the trail. Use Amazon Kinesis Data Firehose to stream the logs from the trail to OpenSearch Service.**
  - 이 조합은 잘못된 접근 방식입니다. VPC Flow Logs는 CloudTrail과 함께 사용되지 않으며, CloudTrail은 VPC 흐름 로그를 처리하지 않습니다.

결론적으로, **B**가 주어진 요구 사항을 가장 잘 충족하는 옵션입니다.


# 677
주어진 문제의 요구 사항을 충족하는 솔루션은 다음과 같습니다:

### 정답:
**A. Create a managed node group that contains only Spot Instances.**

### 해설:
1. **비용 효율성**: Spot Instances는 On-Demand Instances에 비해 상당히 낮은 가격으로 제공되므로, 개발 작업을 위해 클러스터를 비정기적으로 사용하는 경우에 가장 비용 효율적인 선택입니다. Spot Instances는 사용하지 않을 때 비용이 발생하지 않으므로, 개발 클러스터에 적합합니다.

2. **EKS 관리 노드 그룹**: 관리 노드 그룹을 사용하면 EKS 클러스터에서 노드의 프로비저닝 및 관리를 AWS에서 자동으로 처리할 수 있습니다. 이는 운영 오버헤드를 줄이는 데 도움이 됩니다.

3. **빈번하지 않은 사용**: 개발 클러스터는 비정기적으로 사용되므로, Spot Instances를 사용하여 예기치 않은 가격 변동이나 일시적인 중단이 발생할 수 있는 점을 감안할 때, 수시로 사용할 수 있는 대안이 됩니다. Spot Instances는 적절한 비용 효율성을 제공하면서도 EKS 클러스터의 요구 사항을 충족합니다.

### 나머지 옵션에 대한 설명:
- **B. Create two managed node groups. Provision one node group with On-Demand Instances. Provision the second node group with Spot Instances.**
  - 이 옵션은 비용 효율성을 감소시킵니다. 두 개의 노드 그룹을 만드는 것은 관리 오버헤드가 증가하고, On-Demand Instances의 추가 비용이 발생합니다.

- **C. Create an Auto Scaling group that has a launch configuration that uses Spot Instances. Configure the user data to add the nodes to the EKS cluster.**
  - 이 방법은 관리 노드 그룹을 사용하지 않으므로, 수동 관리가 필요하고 EKS의 통합된 관리 기능을 활용하지 못합니다. 

- **D. Create a managed node group that contains only On-Demand Instances.**
  - On-Demand Instances는 높은 비용으로 인해 비용 효율성이 떨어집니다. 개발 클러스터에 비정기적으로 사용하는 경우에는 적합하지 않습니다.

결론적으로, **A**가 주어진 요구 사항을 가장 잘 충족하는 비용 효율적인 옵션입니다.


# 678
주어진 문제의 요구 사항을 충족하는 솔루션은 다음과 같습니다:

### 정답:
**B. Create a customer managed key by using AWS Key Management Service (AWS KMS). Use the new key to encrypt the S3 objects by using server-side encryption with AWS KMS keys (SSE-KMS).**

### 해설:
1. **완전한 제어**: 고객 관리 키(customer managed key)를 사용하면 기업이 AWS KMS에서 키를 생성하고 관리할 수 있습니다. 이는 사용자가 키를 생성, 회전 및 비활성화하는 데 필요한 모든 제어 권한을 제공하므로, 민감한 데이터에 대한 보안 요구 사항을 충족합니다.

2. **자동화된 키 회전**: AWS KMS는 고객 관리 키에 대한 자동 키 회전을 지원합니다. 사용자가 이를 설정하면, 키 회전이 자동으로 이루어지며 관리 작업의 수고를 덜 수 있습니다.

3. **S3와의 통합**: SSE-KMS(Server-Side Encryption with AWS KMS) 기능을 사용하면, S3에 저장된 객체를 쉽게 암호화할 수 있습니다. 이는 AWS의 관리형 서비스이므로 추가적인 노력이 필요하지 않습니다.

### 나머지 옵션에 대한 설명:
- **A. Use default server-side encryption with Amazon S3 managed encryption keys (SSE-S3) to store the sensitive data.**
  - SSE-S3는 AWS가 관리하는 키를 사용하므로, 고객은 키를 직접 제어할 수 없습니다. 이는 요구 사항에 부합하지 않습니다.

- **C. Create an AWS managed key by using AWS Key Management Service (AWS KMS). Use the new key to encrypt the S3 objects by using server-side encryption with AWS KMS keys (SSE-KMS).**
  - AWS 관리 키는 AWS가 관리하므로, 사용자가 키를 직접 제어할 수 없습니다. 따라서 이 옵션 역시 적합하지 않습니다.

- **D. Download S3 objects to an Amazon EC2 instance. Encrypt the objects by using customer managed keys. Upload the encrypted objects back into Amazon S3.**
  - 이 방법은 복잡하고, 수동 작업이 많으며, 보안이 충분하지 않을 수 있습니다. 또한 S3의 기존 객체를 관리하는 데 비효율적입니다.

결론적으로, **B**가 요구 사항을 가장 잘 충족하는 솔루션입니다.


# 680
주어진 요구 사항을 충족하는 가장 효율적인 솔루션은 다음과 같습니다:

### 정답:
**A. Create an AWS DataSync location for both the destination S3 bucket and the EFS file system. Create a task for the destination S3 bucket and the EFS file system. Set the transfer mode to transfer only data that has changed.**

### 해설:
1. **AWS DataSync 사용:** DataSync는 데이터 이동을 위한 관리형 서비스로, S3와 EFS 간의 파일 복사 작업을 자동화하고 간소화할 수 있습니다. 이를 통해 파일이 변경될 때만 전송되도록 설정할 수 있어, 불필요한 데이터 전송을 방지할 수 있습니다.

2. **지속적인 복사:** DataSync의 작업을 스케줄링하여 주기적으로 실행하도록 설정하면, 새로운 파일이 추가되거나 기존 파일이 변경될 때마다 자동으로 파일을 복사할 수 있습니다. 이로 인해 운영 오버헤드가 최소화됩니다.

3. **변경된 파일만 복사:** 설정에서 "변경된 데이터만 전송" 모드를 선택하면, 원본 파일이 변경될 경우에만 복사 작업이 수행됩니다. 이는 데이터 전송을 효율적으로 관리하고, 저장 비용을 줄이는 데 도움을 줍니다.

### 다른 옵션 설명:
- **B. Create an AWS Lambda function...**
  - Lambda를 사용하여 S3 이벤트 알림에 따라 파일을 복사하는 방식은 유용하지만, Lambda의 실행 시간이 제한되어 있어 대량의 파일을 처리하는 데 어려움이 있을 수 있습니다. 또한, Lambda 함수의 운영 및 모니터링에 대한 오버헤드가 발생할 수 있습니다.

- **C. Create an AWS DataSync location...**
  - "모든 데이터 전송" 모드를 선택하면, 불필요한 데이터 전송이 발생하여 효율성이 떨어지고 비용이 증가할 수 있습니다. 이는 요구 사항과 일치하지 않습니다.

- **D. Launch an Amazon EC2 instance...**
  - EC2 인스턴스를 사용하여 스크립트를 실행하는 방법은 가능하지만, 관리 및 유지보수의 오버헤드가 발생하고, 인프라를 직접 관리해야 하므로 비효율적일 수 있습니다.

결론적으로, **A** 옵션이 요구 사항을 가장 잘 충족하며, 운영 오버헤드를 최소화하면서 데이터 복사를 자동화할 수 있는 최선의 방법입니다.

# 681
주어진 요구 사항을 충족하는 가장 효율적인 솔루션은 다음과 같습니다:

### 정답:
**A. Create a customer managed key. Use the key to encrypt the EBS volumes.**

### 해설:
1. **고객 관리형 키 (Customer Managed Key):** 고객 관리형 키는 사용자가 키의 생명주기를 관리할 수 있게 해줍니다. 여기에는 키의 생성, 삭제, 사용 및 회전이 포함됩니다. 따라서 사용자는 키의 회전 정책을 직접 설정할 수 있습니다.

2. **EBS 볼륨 암호화:** EBS 볼륨은 고객 관리형 KMS 키로 암호화할 수 있으며, 이로 인해 데이터가 안전하게 보호됩니다. 

3. **최소 운영 오버헤드:** AWS KMS와의 통합을 통해 키의 생성 및 관리를 AWS가 수행하므로, 사용자에게는 최소한의 운영 오버헤드만 요구됩니다. 사용자가 직접 인프라를 관리할 필요가 없기 때문에 효율적입니다.

### 다른 옵션 설명:
- **B. Use an AWS managed key...**
  - AWS 관리형 키는 AWS가 자동으로 관리하는 키입니다. 하지만 이 경우 사용자가 키 회전을 제어할 수 없으므로 요구 사항에 부합하지 않습니다.

- **C. Create an external KMS key...**
  - 외부 KMS 키를 생성하는 것은 복잡성과 추가적인 운영 오버헤드를 초래할 수 있으며, 불필요한 관리 노력을 요구합니다.

- **D. Use an AWS owned key to encrypt the EBS volumes.**
  - AWS 소유 키는 AWS가 관리하지만, 사용자에게는 키에 대한 제어 권한이 없으므로 이 요구 사항을 충족하지 않습니다.

결론적으로, **A** 옵션이 요구 사항을 가장 잘 충족하며, 키 회전 관리 및 데이터 암호화에 대한 제어를 제공하면서 운영 오버헤드를 최소화할 수 있는 최선의 방법입니다.

# 682
주어진 요구 사항을 충족하면서 가장 적은 관리 오버헤드로 데이터 암호화를 강제하는 솔루션은 다음과 같습니다:

### 정답:
**A. Use an IAM policy that allows users to create only encrypted Amazon Elastic Block Store (Amazon EBS) volumes. Use AWS Config and AWS Systems Manager to automate the detection and remediation of unencrypted EBS volumes.**

### 해설:
1. **IAM 정책:** IAM 정책을 사용하여 사용자에게 암호화된 EBS 볼륨만 생성할 수 있는 권한을 부여하면, 처음부터 모든 볼륨이 암호화되도록 강제할 수 있습니다.

2. **AWS Config:** AWS Config를 사용하면 AWS 리소스의 구성 변화를 추적할 수 있습니다. 이를 통해 EBS 볼륨이 암호화되지 않은 경우 이를 자동으로 감지할 수 있습니다.

3. **AWS Systems Manager:** Systems Manager를 통해 비준수 리소스(예: 암호화되지 않은 EBS 볼륨)를 자동으로 수정하는 작업을 설정할 수 있습니다. 이를 통해 자동화된 리메디에이션이 이루어져, 관리 오버헤드가 최소화됩니다.

### 다른 옵션 설명:
- **B. Use AWS Key Management Service...**
  - KMS는 키 관리를 위한 서비스일 뿐, 리소스의 암호화 여부를 감지하고 수정하는 기능은 제공하지 않습니다. Lambda와 EventBridge를 사용할 경우 관리가 복잡해질 수 있습니다.

- **C. Use Amazon Macie...**
  - Amazon Macie는 주로 데이터 보안 및 개인 정보 보호를 위해 사용됩니다. EBS 볼륨의 암호화 상태를 감지하는 데 적합하지 않으며, 또한 시스템 자동화에 대한 관리 오버헤드가 더 많습니다.

- **D. Use Amazon Inspector...**
  - Amazon Inspector는 주로 애플리케이션 보안 및 취약성 평가를 위한 도구입니다. EBS 볼륨의 암호화 여부를 확인하는 데는 적합하지 않으며, 또한 관리 오버헤드가 높습니다.

결론적으로, **A** 옵션이 요구 사항을 가장 잘 충족하며, 암호화를 강제하고 비준수 리소스를 자동으로 감지 및 수정하는데 있어 최소한의 관리 오버헤드를 보장합니다.


# 684
이 문제에서 요구하는 사항을 충족하기 위한 적절한 솔루션은 다음과 같습니다:

### 정답:
**B. Deploy the applications in AWS Local Zones by extending the company's VPC from eu-central-1 to the chosen Local Zone.**

### 해설:
1. **B. Deploy the applications in AWS Local Zones by extending the company's VPC from eu-central-1 to the chosen Local Zone.**
   - **이유:** AWS Local Zones는 특정 지역의 가까운 위치에 배치된 AWS 인프라를 제공하여 지연 시간을 최소화합니다. Local Zone을 사용하면 데이터 및 애플리케이션이 규제를 준수하면서도 높은 성능을 제공할 수 있습니다. 이는 규제 요건을 충족하면서도 single-digit millisecond latency를 보장합니다.

### 다른 옵션 설명:
- **A. Deploy the applications in eu-central-1. Extend the company’s VPC from eu-central-1 to an edge location in Amazon CloudFront.**
  - CloudFront는 콘텐츠 전송 네트워크(CDN)로, 전송 속도를 높이지만, 여전히 주 지역(eu-central-1)에서 애플리케이션이 실행되기 때문에 latency가 요구 사항을 충족하지 않을 수 있습니다.

- **C. Deploy the applications in eu-central-1. Extend the company’s VPC from eu-central-1 to the regional edge caches in Amazon CloudFront.**
  - 이 방법도 마찬가지로 eu-central-1에서 애플리케이션이 실행되므로, 규제 요건을 충족하지 않으며 latency 요구 사항을 충족하지 못할 가능성이 있습니다.

- **D. Deploy the applications in AWS Wavelength Zones by extending the company’s VPC from eu-central-1 to the chosen Wavelength Zone.**
  - AWS Wavelength는 모바일 네트워크에서의 지연 시간을 줄이는 데 최적화된 솔루션입니다. 하지만 이는 특정한 사용 사례(모바일 애플리케이션)에 적합하므로, 일반적인 웹 애플리케이션에 가장 적합한 선택이 아닙니다.

결론적으로, **B** 옵션이 규제 요건을 충족하면서도 요구된 latency를 달성하는 가장 효과적인 방법입니다.

# 685
이 문제의 요구 사항을 충족하기 위해 가장 적합한 솔루션은 다음과 같습니다:

### 정답:
**B. Point the client driver at an RDS proxy endpoint. Deploy the Lambda functions inside a VPC.**

### 해설:
1. **RDS Proxy 사용:** AWS RDS Proxy는 Lambda와 같은 서버리스 애플리케이션이 데이터베이스에 연결할 때 발생할 수 있는 과도한 연결 문제를 해결하는 데 도움을 줍니다. RDS Proxy는 연결 풀링을 통해 Lambda의 연결 수를 줄이고, 데이터베이스에 대한 연결을 관리하여 성능을 향상시킵니다.

2. **Lambda 함수 VPC 배치:** Lambda 함수를 VPC 내부에 배치하면 RDS Proxy에 안전하게 연결할 수 있으며, 데이터베이스와의 연결이 보다 안전하고 제어된 환경에서 이루어집니다.

### 다른 옵션 설명:
- **A. Point the client driver at an RDS custom endpoint. Deploy the Lambda functions inside a VPC.**
  - RDS Custom Endpoint는 여러 데이터베이스 인스턴스를 통합하는 데 유용하지만, 연결 수를 관리하고 과도한 부하를 방지하는 기능은 제공하지 않으므로 적합하지 않습니다.

- **C. Point the client driver at an RDS custom endpoint. Deploy the Lambda functions outside a VPC.**
  - Lambda 함수를 VPC 외부에 배치하면 RDS 인스턴스에 직접 연결할 수 있지만, VPC의 보안 및 데이터베이스 성능을 관리하는 데 도움이 되지 않습니다.

- **D. Point the client driver at an RDS proxy endpoint. Deploy the Lambda functions outside a VPC.**
  - RDS Proxy를 사용하는 것은 좋지만, Lambda 함수를 VPC 외부에 배치하는 것은 보안 및 연결 관리 측면에서 최선의 선택이 아닙니다.

결론적으로, **B** 옵션이 예측 가능한 데이터베이스 성능을 유지하고 Lambda의 과도한 연결로부터 데이터베이스를 보호하는 데 가장 효과적인 방법입니다.


# 687
이 문제의 요구 사항을 충족하기 위해 가장 적합한 두 가지 단계를 선택하면 다음과 같습니다:

### 정답:
**B. Use Amazon SageMaker to train a model by using the historical data in the S3 bucket.**  
**E. Train an Amazon Forecast predictor by using the historical data in the S3 bucket.**

### 해설:
1. **B. Use Amazon SageMaker to train a model by using the historical data in the S3 bucket.**
   - Amazon SageMaker는 머신러닝 모델을 쉽게 생성하고 훈련할 수 있는 관리형 서비스입니다. 이 단계에서는 S3 버킷에 저장된 과거 데이터를 사용하여 예측 모델을 훈련할 수 있습니다. 그러나 SageMaker는 사용자가 모델을 만들고 훈련하는 과정에서 머신러닝 경험이 필요할 수 있습니다.

2. **E. Train an Amazon Forecast predictor by using the historical data in the S3 bucket.**
   - Amazon Forecast는 예측을 자동으로 생성하기 위해 설계된 서비스로, 사용자가 머신러닝에 대한 깊은 지식이 없어도 사용할 수 있는 관리형 솔루션입니다. 이 단계에서는 S3 버킷의 과거 데이터를 사용하여 예측기를 훈련하여 제조 프로세스에 필요한 리소스를 예측할 수 있습니다.

### 다른 옵션 설명:
- **A. Deploy an Amazon SageMaker model. Create a SageMaker endpoint for inference.**
  - SageMaker 모델을 배포하고 엔드포인트를 생성하는 것은 가능하지만, 기본적으로 이 단계는 모델을 훈련한 이후에 이루어져야 하므로 두 번째 단계로 적합하지 않습니다.

- **C. Configure an AWS Lambda function with a function URL that uses Amazon SageMaker endpoints to create predictions based on the inputs.**
  - 이 단계는 SageMaker 엔드포인트에 대한 예측을 생성하기 위한 것이지만, AWS Lambda와 함께 사용할 경우 이미 모델이 훈련되어 있어야 하므로 최초 훈련 단계를 충족하지 못합니다.

- **D. Configure an AWS Lambda function with a function URL that uses an Amazon Forecast predictor to create a prediction based on the inputs.**
  - AWS Lambda를 사용하여 Amazon Forecast 예측기를 사용하는 것은 가능하지만, 예측기를 훈련하기 위해서는 먼저 과거 데이터를 사용하여 훈련해야 하므로 이 단계만으로는 부족합니다.

결론적으로, **B**와 **E** 옵션을 선택하여 요구 사항을 충족하는 것이 가장 효과적입니다.


# 688
네, **IAM Identity Center (AWS SSO)**에서 사용자를 생성할 수 있습니다. AWS IAM Identity Center는 **AWS SSO**의 기능으로, 사용자가 **AWS 애플리케이션**과 **AWS 계정**에 대해 중앙 집중식 인증 및 권한 관리를 할 수 있도록 해줍니다. 사용자는 IAM Identity Center를 통해 생성되며, 이를 통해 **Single Sign-On(SSO)** 기능을 이용하여 여러 AWS 서비스와 애플리케이션에 접근할 수 있습니다.

### IAM Identity Center에서 사용자를 생성하는 방법:
1. **IAM Identity Center 콘솔로 이동**: AWS 관리 콘솔에서 IAM Identity Center 서비스로 이동합니다.
   
2. **사용자 생성**:
   - **사용자 생성** 옵션을 선택하여 새로운 사용자를 생성할 수 있습니다.
   - 사용자의 이름, 이메일 주소 등을 입력하고, 필요에 따라 **임시 자격 증명**을 설정할 수 있습니다.

3. **디렉토리 연동**: 외부 디렉토리(예: **Microsoft Active Directory**, **Azure AD**, **Okta** 등)와 연동하여 **사용자 정보를 동기화**할 수도 있습니다. 이를 통해 기존의 기업 디렉토리에서 관리되는 사용자들을 IAM Identity Center로 가져와 사용할 수 있습니다.

4. **그룹 및 권한 세트 할당**: 사용자를 생성한 후, 해당 사용자에게 **그룹**을 할당하고, **권한 세트**(Permission Sets)를 통해 특정 AWS 계정 및 애플리케이션에 대한 접근 권한을 부여합니다.

5. **SSO 로그인 설정**: 사용자는 생성 후 **AWS SSO**를 통해 로그인하고, SSO로 관리되는 여러 AWS 계정과 애플리케이션에 **단일 로그인으로 접근**할 수 있습니다.

### IAM Identity Center에서 사용자 관리의 장점:
- **중앙화된 관리**: 여러 AWS 계정과 서비스에 대해 하나의 로그인 정보를 사용하여 관리할 수 있습니다.
- **조직 관리**: 사용자를 그룹화하고, **그룹별로 권한을 설정**하여 접근 제어를 간편하게 할 수 있습니다.
- **외부 인증 시스템과의 통합**: 이미 사용 중인 **Active Directory**나 **Azure AD**와 연동하여 추가적인 사용자 관리 작업을 최소화할 수 있습니다.

따라서 **IAM Identity Center에서 직접 사용자를 생성하고 관리**할 수 있으며, 이를 통해 AWS 환경에서의 사용자 접근 및 보안을 효율적으로 관리할 수 있습니다.

# 690
이 요구 사항을 충족하고 데이터 전송의 처리량을 증가시키기 위한 두 가지 솔루션은 다음과 같습니다:

### 정답:
**C. Use S3 multipart uploads.**

**E. Add a random prefix to each object when uploading the files.**

### 해설:

1. **C. Use S3 multipart uploads.**
   - **S3 멀티파트 업로드**를 사용하면 큰 파일을 여러 개의 파트로 나누어 동시에 업로드할 수 있습니다. 이 방식은 업로드 속도를 향상시키고, 전송 중에 오류가 발생했을 경우 특정 파트만 재전송하면 되므로 효율적입니다.

2. **E. Add a random prefix to each object when uploading the files.**
   - S3의 객체 이름은 키를 기반으로 해시되어 분산됩니다. 따라서 **랜덤 프리픽스**를 추가하면 객체를 서로 다른 물리적 서버에 분산 저장하여 병렬 처리 속도를 높일 수 있습니다. 이는 S3에서의 요청 처리 성능을 향상시킵니다.

### 다른 옵션 설명:
- **A. Use the S3 bucket access point instead of accessing the S3 bucket directly.**
  - S3 버킷 액세스 포인트는 데이터 액세스를 관리하기 쉽게 만들어 주지만, 처리량을 직접적으로 증가시키는 것은 아닙니다.

- **B. Upload the files into multiple S3 buckets.**
  - 여러 S3 버킷에 업로드하는 것은 관리의 복잡성을 증가시키며, 반드시 처리량을 증가시키는 방법은 아닙니다.

- **D. Fetch multiple byte-ranges of an object in parallel.**
  - 객체의 여러 바이트 범위를 병렬로 가져오는 것은 다운로드 성능을 개선할 수 있지만, 파일 업로드와 다운로드 시에는 멀티파트 업로드가 더 유리합니다.

결론적으로, **C**와 **E**가 전송 처리량을 증가시키는 가장 효과적인 솔루션입니다.


# 692
가장 높은 성능의 경험을 제공하기 위해 AWS Route 53에서 사용할 수 있는 구성은 다음과 같습니다:

### 정답:
**A. Create an A record with a latency policy.**

### 해설:

1. **A record with a latency policy**:
   - **지연 시간 정책**을 사용하는 A 레코드는 클라이언트의 요청을 가장 낮은 지연 시간을 제공하는 AWS 리전으로 라우팅합니다. 이 방식은 여러 리전에서 애플리케이션을 배포할 때 사용자가 가장 빠르게 응답을 받을 수 있도록 도와줍니다. 각 리전의 지연 시간을 측정하여 최적의 리전을 선택하므로, 사용자에게 가장 높은 성능을 제공합니다.

### 다른 옵션 설명:
- **B. Create an A record with a geolocation policy**:
  - **지리적 위치 정책**은 사용자의 위치에 따라 특정 리전으로 트래픽을 라우팅합니다. 이는 특정 지역의 사용자에게는 유용할 수 있지만, 반드시 최적의 성능을 제공하지는 않습니다.

- **C. Create a CNAME record with a failover policy**:
  - **장애 조치 정책**은 기본 리전에서 문제가 발생할 경우 다른 리전으로 트래픽을 전환하는 데 사용됩니다. 성능 개선보다는 고가용성을 보장하는 데 중점을 둡니다.

- **D. Create a CNAME record with a geoproximity policy**:
  - **지리적 근접성 정책**은 특정 리전에 가까운 사용자에게 트래픽을 라우팅할 수 있지만, 항상 지연 시간을 기준으로 최적의 성능을 보장하지는 않습니다.

결론적으로, **A**의 지연 시간 정책을 사용하는 것이 트래픽을 가장 빠르게 처리할 수 있는 최적의 방법입니다.


# 693
가장 적은 운영 오버헤드로 높은 가용성과 최종 일관성을 충족하는 솔루션은 다음과 같습니다:

### 정답:
**D. Modify the Auto Scaling group to use EC2 instances across three Availability Zones. Migrate the embedded NoSQL database to Amazon DynamoDB by using AWS Database Migration Service (AWS DMS).**

### 해설:

1. **고가용성**:
   - **Auto Scaling 그룹을 수정하여 3개의 가용 영역(AZ)에서 EC2 인스턴스를 사용하게 하면** 애플리케이션이 가용성 영역 간에 분산되어 높은 가용성을 확보할 수 있습니다. 이렇게 하면 한 개의 AZ에 장애가 발생하더라도 애플리케이션이 계속 작동할 수 있습니다.

2. **DynamoDB로의 마이그레이션**:
   - **DynamoDB는 완전 관리형 NoSQL 데이터베이스 서비스로, 자동으로 스케일링을 지원하고 높은 가용성과 내구성을 제공합니다.** 또한 DynamoDB는 **Eventually Consistent** 모델을 지원하여 사용자가 설정한 요구사항에 부합합니다.
   - **AWS Database Migration Service (AWS DMS)를 사용하면** 기존의 내장 NoSQL 데이터베이스에서 DynamoDB로 데이터 마이그레이션을 쉽게 수행할 수 있으며, 이 과정에서 운영 오버헤드를 최소화할 수 있습니다.

### 다른 옵션 설명:
- **A. Replace the ALB with a Network Load Balancer. Maintain the embedded NoSQL database with its replication service on the EC2 instances**:
  - 네트워크 로드 밸런서를 사용하면 트래픽 처리 성능은 개선될 수 있지만, 내장 NoSQL 데이터베이스의 유지 관리가 필요하여 운영 오버헤드가 증가합니다.

- **B. Replace the ALB with a Network Load Balancer. Migrate the embedded NoSQL database to Amazon DynamoDB by using AWS Database Migration Service (AWS DMS)**:
  - 이 옵션은 DynamoDB로의 마이그레이션은 좋지만, 고가용성을 제공하기 위해 AZ를 수정해야 하므로 운영 오버헤드가 증가합니다.

- **C. Modify the Auto Scaling group to use EC2 instances across three Availability Zones. Maintain the embedded NoSQL database with its replication service on the EC2 instances**:
  - EC2 인스턴스를 3개의 AZ에 배포하는 것은 고가용성을 제공하지만, 내장 NoSQL 데이터베이스를 유지 관리하는 것은 운영 오버헤드를 증가시킵니다.

결론적으로, **D** 옵션이 높은 가용성과 최종 일관성을 달성하는 동시에 운영 오버헤드를 최소화하는 데 가장 적합합니다.


# 698
이 문제의 요구사항에 가장 적합한 솔루션은 다음과 같습니다:

### 정답:
**B. Create an Amazon Elastic File System (Amazon EFS) file system. Register the file system in a StorageClass object on an EKS cluster. Use the same file system for all containers.**

### 해설:

1. **EFS의 공유 가능성**:
   - Amazon EFS는 여러 EC2 인스턴스와 컨테이너가 동시에 접근할 수 있는 완전 관리형 파일 스토리지입니다. 이를 통해 여러 애플리케이션 컨테이너가 데이터를 공유하고 동시에 읽고 쓸 수 있습니다.

2. **고가용성 및 내결함성**:
   - EFS는 자동으로 데이터 복제를 통해 고가용성과 내결함성을 제공합니다. 여러 가용 영역(AZ)에서 자동으로 데이터를 저장하므로 장애 발생 시에도 데이터의 접근성을 유지합니다.

3. **운영 오버헤드 최소화**:
   - EFS를 사용하면 스토리지의 관리와 복잡성을 줄일 수 있습니다. EFS는 자동으로 확장되며, 용량을 미리 프로비저닝할 필요가 없습니다.

### 다른 옵션 설명:
- **A. Create Amazon Elastic Block Store (Amazon EBS) volumes**:
  - EBS는 하나의 EC2 인스턴스에서만 접근할 수 있기 때문에, 여러 컨테이너가 동시에 사용할 수 없습니다. EBS Multi-Attach를 통해 여러 인스턴스에서 접근할 수 있지만, Fargate에서는 지원되지 않습니다.

- **C. Create an Amazon Elastic Block Store (Amazon EBS) volume**:
  - EBS 볼륨은 한 컨테이너에서만 사용 가능하며, 공유할 수 없습니다. 여러 컨테이너가 동시에 접근할 수 없으므로 요구사항을 충족하지 않습니다.

- **D. Create Amazon Elastic File System (Amazon EFS) file systems**:
  - 이 옵션은 EFS의 장점을 활용하지만, 여러 EFS 파일 시스템을 생성할 필요가 없습니다. 하나의 EFS 파일 시스템을 공유하여 여러 컨테이너에서 사용할 수 있습니다. 따라서 불필요한 복잡성을 추가하는 방식입니다.

결론적으로, **B** 옵션은 EKS에서 애플리케이션의 데이터 지속성을 위해 고가용성과 내결함성을 갖춘 스토리지 솔루션을 제공하며, 운영 오버헤드를 최소화할 수 있는 가장 적절한 선택입니다.


# 699
이 문제의 요구사항에 가장 적합한 솔루션은 다음과 같습니다:

### 정답:
**B. Use Amazon Elastic Container Service (Amazon ECS) with an AWS Fargate launch type. Create an Amazon Elastic File System (Amazon EFS) volume. Add the EFS volume as a persistent storage volume mounted in the containers.**

### 해설:

1. **완전 관리형 서비스**:
   - AWS Fargate는 서버를 관리할 필요 없이 컨테이너를 실행할 수 있는 완전 관리형 서비스입니다. 사용자는 인프라를 관리할 필요가 없으며, 필요한 리소스를 AWS가 자동으로 프로비저닝하고 관리합니다.

2. **지속적 데이터 저장**:
   - Amazon EFS는 여러 컨테이너가 동시에 접근할 수 있는 파일 스토리지입니다. 이 경우, EFS 볼륨을 컨테이너에 마운트하여 데이터의 지속성을 보장할 수 있습니다.

3. **스케일링**:
   - EFS는 자동으로 확장되며, 필요한 용량에 맞게 동적으로 조정되기 때문에 데이터의 크기와 관계없이 유연하게 대응할 수 있습니다.

### 다른 옵션 설명:
- **A. Use Amazon Elastic Kubernetes Service (Amazon EKS) with self-managed nodes**:
  - EKS는 관리형 Kubernetes 서비스이지만, self-managed nodes를 사용할 경우 서버를 관리해야 하므로 요구사항에 부합하지 않습니다.

- **C. Use Amazon Elastic Container Service (Amazon ECS) with an AWS Fargate launch type. Create an Amazon S3 bucket**:
  - Amazon S3는 객체 스토리지로, 직접적으로 컨테이너에서 파일 시스템으로 마운트할 수 없습니다. EFS와 달리 S3는 파일 시스템 접근 방식을 지원하지 않기 때문에 지속적인 데이터 저장에 적합하지 않습니다.

- **D. Use Amazon Elastic Container Service (Amazon ECS) with an Amazon EC2 launch type**:
  - EC2 launch type은 서버를 관리해야 하며, 따라서 완전 관리형 솔루션의 요구사항에 부합하지 않습니다. EFS를 사용할 수 있지만, EC2 관리가 필요하므로 이 옵션은 적합하지 않습니다.

결론적으로, **B** 옵션이 요구사항을 충족하는 가장 적절한 선택입니다. AWS Fargate와 Amazon EFS를 사용하여 서버와 스토리지 인프라를 관리할 필요 없이 지속 가능한 데이터 저장을 제공할 수 있습니다.


# 700
이 문제에서 요구하는 높은 가용성과 최소 지연 시간을 제공하기 위해 적절한 솔루션은 다음과 같습니다:

### 정답:
**C. Create an AWS Global Accelerator accelerator to route traffic to the load balancers in each Region.**  
**D. Configure Amazon Route 53 to use a geolocation routing policy to distribute the traffic.**

### 해설:

1. **AWS Global Accelerator**:
   - **C** 옵션은 AWS Global Accelerator를 사용하여 전 세계적으로 분산된 애플리케이션의 트래픽을 최적의 경로로 라우팅하는 방법입니다. Global Accelerator는 Amazon의 글로벌 네트워크를 활용하여 TCP 및 UDP 트래픽을 빠르고 안정적으로 전달합니다. 이를 통해 사용자는 최적의 AWS 리전으로 연결되어 지연 시간이 최소화되고 가용성이 증가합니다.

2. **Amazon Route 53 지리적 라우팅**:
   - **D** 옵션은 Amazon Route 53의 지리적 라우팅 정책을 사용하여 사용자의 위치에 따라 트래픽을 각 리전의 로드 밸런서로 분산하는 방법입니다. 이를 통해 지리적으로 가까운 리전으로 트래픽을 보내서 응답 시간을 단축시키고 사용자의 경험을 개선할 수 있습니다.

### 다른 옵션 설명:
- **A. Create internal Network Load Balancers in front of the application in each Region**:
  - Internal Network Load Balancer는 인터넷 트래픽을 처리하지 않으며, 외부에서 접근할 수 있는 서비스에 적합하지 않습니다.

- **B. Create external Application Load Balancers in front of the application in each Region**:
  - Application Load Balancer는 웹 애플리케이션에 적합하지만, TCP와 UDP 프로토콜을 모두 처리하기에는 제약이 있습니다. TCP 및 UDP 트래픽을 처리하려면 Network Load Balancer가 더 적합합니다.

- **E. Configure Amazon CloudFront to handle the traffic and route requests to the application in each Region**:
  - CloudFront는 주로 HTTP/HTTPS 트래픽을 위한 콘텐츠 배포 네트워크입니다. TCP 및 UDP를 직접 처리할 수 없으므로 이 시나리오에 적합하지 않습니다.

결론적으로, **C**와 **D** 옵션을 결합하여 글로벌 사용자를 위한 높은 가용성과 최소 지연 시간을 보장하는 것이 가장 효과적입니다.


# 702
정답은 **B. Create an Amazon S3 bucket. Import the data into the S3 bucket. Configure an Amazon FSx for Lustre file system, and integrate it with the S3 bucket. Access the FSx for Lustre file system from the HPC cluster instances.**입니다.

### 이유:
1. **고성능 컴퓨팅(HPC) 워크로드**에 요구되는 **일관된 서브밀리초 지연 시간과 높은 처리량**을 지원하기 위해서는 고속 파일 시스템이 필요합니다. **Amazon FSx for Lustre**는 고성능 컴퓨팅 워크로드를 위해 최적화된 파일 시스템으로, **서브밀리초 지연 시간**과 **초당 수십 기가바이트의 처리량**을 제공할 수 있어 요구 사항에 적합합니다.

2. **데이터 통합**: Amazon FSx for Lustre는 Amazon S3와 원활하게 통합할 수 있습니다. S3 버킷에 데이터를 저장한 후 FSx for Lustre 파일 시스템과 연결하면, S3의 데이터를 빠르게 캐싱하여 HPC 클러스터가 요구하는 높은 성능을 제공합니다.

3. **비용 효율성 및 확장성**: FSx for Lustre를 사용하여 S3와 통합하면 필요한 데이터만 캐싱하여 비용을 절감하면서도 필요할 때 고속으로 접근할 수 있습니다.

### 다른 옵션 분석:
- **A. AWS Storage Gateway (File Gateway)**는 주로 온프레미스와 S3 간의 파일 공유를 위해 설계되었습니다. **일관된 서브밀리초 지연 시간**을 보장하기 어려우며, HPC 워크로드에 적합하지 않습니다.
  
- **C. Amazon EFS**는 확장성과 파일 공유가 필요한 범용 워크로드에 적합하지만, HPC 워크로드가 요구하는 서브밀리초 지연 시간과 고성능을 제공하기엔 부족할 수 있습니다.

- **D. FSx for Lustre를 직접 사용하는 방법**은 데이터의 직접 전송 방법이 명확히 기술되지 않아 S3 버킷에 데이터를 임포트한 후 통합하는 **B 옵션**이 더 적합해 보입니다.

따라서, **B 옵션**이 이 요구 사항을 가장 효율적으로 충족할 수 있습니다.

# 705
이 문제는 Amazon RDS for MySQL에서 Amazon Aurora PostgreSQL DB 클러스터로 데이터베이스를 마이그레이션하면서 **데이터 변경 사항을 복제**하는 방법을 묻고 있습니다. Amazon RDS MySQL에서 Aurora PostgreSQL로의 마이그레이션이기 때문에, 서로 다른 데이터베이스 엔진을 지원해야 하며 데이터 동기화가 필요합니다.

각 선택지를 검토해 보겠습니다:

1. **A. AWS DMS Schema Conversion으로 데이터베이스 객체 변환**  
   AWS DMS Schema Conversion은 서로 다른 DB 엔진 간의 스키마 변환을 자동화합니다. MySQL과 PostgreSQL은 스키마 구조가 다르기 때문에, 이 변환이 필요합니다. 이는 마이그레이션 작업의 필수 단계로 적합합니다.

2. **B. AWS DMS Schema Conversion으로 RDS for MySQL DB 인스턴스에서 Aurora PostgreSQL 읽기 전용 복제본 생성**  
   이 옵션은 정확하지 않습니다. DMS는 읽기 전용 복제본을 생성하지 않으며, 읽기 전용 복제본을 만들기 위해서는 데이터베이스 간 호환이 필요합니다. RDS MySQL과 Aurora PostgreSQL 간에는 직접적인 읽기 복제가 불가능합니다.

3. **C. Aurora MySQL 읽기 전용 복제본을 RDS for MySQL DB 인스턴스로 구성**  
   이 옵션은 MySQL 데이터베이스 간에만 지원되며, PostgreSQL 마이그레이션과는 관련이 없습니다.

4. **D. AWS DMS 작업을 정의하고 CDC(데이터 변경 캡처) 활성화**  
   AWS DMS의 CDC(변경 데이터 캡처) 기능은 소스 데이터베이스(MySQL)에서 발생하는 실시간 변경 사항을 타겟 데이터베이스(PostgreSQL)로 복제합니다. 마이그레이션 중에 실시간으로 데이터 동기화가 필요하므로 이 단계는 필수적입니다.

5. **E. Aurora PostgreSQL 읽기 전용 복제본을 독립형 DB 클러스터로 승격**  
   MySQL과 PostgreSQL 간에는 직접적인 읽기 복제본 구성이 불가능하므로 이 옵션은 적합하지 않습니다.

**정답: A와 D**

**해설:**  
1. **A**는 MySQL과 PostgreSQL 간의 데이터베이스 스키마 변환을 자동화하여 데이터베이스 객체를 Aurora PostgreSQL로 변환하는 단계입니다.
2. **D**는 CDC 기능을 통해 실시간으로 변경 사항을 반영하여, 마이그레이션 중에 데이터 일관성을 유지할 수 있게 합니다.

따라서 AWS DMS를 통해 스키마 변환과 CDC 작업을 함께 수행하는 것이 MySQL에서 Aurora PostgreSQL로 마이그레이션하는 최적의 방법입니다.

# 709
이 문제는 특정 크기의 EC2 인스턴스가 비프로덕션(nonproduction) 계정에서 생성되지 않도록 **서비스 제어 정책(SCP)**을 설정하는 방법을 묻고 있습니다. SCP는 AWS Organizations에서 계정의 서비스 및 API 호출을 제한할 수 있으며, 이 회사는 프로덕션과 비프로덕션 계정을 분리하여 비프로덕션 계정에만 제한을 적용하고자 합니다. 각 선택지를 검토해 보겠습니다.

1. **A. SCP를 조직의 루트 OU에 연결**  
   루트 OU에 SCP를 연결하면 조직 전체에 정책이 적용됩니다. 이는 비프로덕션 계정뿐만 아니라 프로덕션 계정에도 영향을 미치기 때문에 적절하지 않습니다.

2. **B. SCP를 세 개의 비프로덕션 계정에 연결**  
   SCP를 각 비프로덕션 계정에 개별적으로 연결하면, 비프로덕션 계정에만 제한이 적용되므로 요구 사항에 맞는 해결책이 됩니다.

3. **C. SCP를 Organizations 관리 계정에 연결**  
   관리 계정에 SCP를 연결하는 것은 계정 제어에 영향을 미치지 않으며, 관리 계정은 SCP의 적용 대상이 아니기 때문에 올바른 방법이 아닙니다.

4. **D. 프로덕션 계정을 위한 OU 생성, SCP 연결 및 프로덕션 계정을 새로운 OU로 이동**  
   이 옵션은 프로덕션 계정에 대한 별도의 OU를 만들고 프로덕션 계정만을 그곳으로 이동하여, 나머지 계정을 비프로덕션 계정으로 구분할 수 있습니다. SCP를 프로덕션 OU에 연결하는 것은 필요하지 않으므로, 이 선택지는 적절하지 않습니다.

5. **E. 필요한 계정용 OU 생성, SCP 연결 및 비프로덕션 계정을 새 OU로 이동**  
   비프로덕션 계정용 OU를 생성하고 해당 OU에 SCP를 연결하면, 비프로덕션 계정에만 정책이 적용되므로 요구 사항을 충족할 수 있는 올바른 방법입니다.

**정답: B와 E**

**해설:**  
1. **B**는 비프로덕션 계정에만 정책을 개별적으로 연결하여 제한을 적용하는 방식입니다.
2. **E**는 비프로덕션 계정을 위한 별도의 OU를 만들어 해당 OU에 SCP를 연결함으로써 비프로덕션 계정에만 제한을 적용할 수 있습니다.

따라서 비프로덕션 계정에만 EC2 인스턴스 크기 제한을 설정하려면 **B와 E**를 사용하는 것이 가장 적합합니다.

# 712
이 문제는 **VPC와 온프레미스 데이터 센터 간의 VPN 연결**을 통해 온프레미스 서비스와 안전하게 통신하기 위해 **Route 53을 사용해 VPC에서 사설 DNS 레코드로 온프레미스 서비스에 접근**하는 방법을 묻고 있습니다.

각 선택지를 검토해 보겠습니다.

1. **A. Route 53 Resolver 아웃바운드 엔드포인트 생성, 리졸버 규칙 생성 및 VPC에 연관**  
   Route 53 Resolver 아웃바운드 엔드포인트는 VPC 내 리졸버가 온프레미스 DNS에 쿼리를 전달할 수 있도록 설정합니다. 온프레미스 DNS 서버로 요청을 전달하려면 아웃바운드 엔드포인트와 리졸버 규칙이 필요하며, 이 설정이 가장 적합한 옵션입니다.

2. **B. Route 53 Resolver 인바운드 엔드포인트 생성, 리졸버 규칙 생성 및 VPC에 연관**  
   인바운드 엔드포인트는 온프레미스 DNS 서버가 VPC 내 도메인에 대한 쿼리를 보낼 수 있도록 합니다. 그러나 문제는 VPC에서 온프레미스 서비스와 통신해야 하는 상황이므로, 아웃바운드 엔드포인트가 필요합니다. 따라서 이 옵션은 적합하지 않습니다.

3. **C. Route 53 사설 호스티드 존 생성 및 VPC에 연관**  
   사설 호스티드 존은 VPC 내에서만 사용 가능하며, 온프레미스 DNS 서버와의 통합은 불가능합니다. VPC 내에서만 DNS 조회가 가능하므로 온프레미스와의 통신을 위한 요구 사항을 충족하지 못합니다.

4. **D. Route 53 퍼블릭 호스티드 존 생성 및 각 서비스에 대한 레코드 생성**  
   퍼블릭 호스티드 존을 사용하면 인터넷을 통해 DNS 쿼리가 노출되므로 보안에 취약하고, 온프레미스 서비스와의 사설 통신에는 적합하지 않습니다.

**정답: A**

**해설:**  
Route 53 Resolver 아웃바운드 엔드포인트와 리졸버 규칙을 사용하면, VPC 내의 리졸버가 온프레미스 DNS 서버에 쿼리를 전달할 수 있어 온프레미스 서비스와의 안전한 사설 통신이 가능합니다. 이는 요구 사항을 가장 안전하고 효율적으로 충족하는 해결책입니다.

# 714
이 문제는 EC2 인스턴스의 과부하를 방지하고 부하 분산을 효과적으로 처리하기 위한 최적의 솔루션을 선택하는 것입니다. 주어진 선택지 중에서, **부하 분산 알고리즘**과 **CloudWatch 메트릭**을 적절히 활용하는 것이 중요합니다.

### 분석

- **기본적인 요구 사항**: 
  - 과부하가 걸린 EC2 인스턴스로의 새로운 요청을 방지하고, 시스템의 전체 성능을 유지해야 합니다.
  - CloudWatch 메트릭을 사용하여 인스턴스의 상태를 모니터링하고, 이를 기반으로 요청을 분산해야 합니다.

### 선택지 분석

1. **A. Use the round robin routing algorithm based on the RequestCountPerTarget and ActiveConnectionCount CloudWatch metrics.**
   - 라운드 로빈 방식은 단순히 요청을 순서대로 분산시키는 방법으로, 과부하 인스턴스를 고려하지 않습니다. ActiveConnectionCount를 사용하긴 하지만, RequestCountPerTarget를 기반으로 하는 것은 최적의 선택이 아닙니다.

2. **B. Use the least outstanding requests algorithm based on the RequestCountPerTarget and ActiveConnectionCount CloudWatch metrics.**
   - "Least Outstanding Requests" 알고리즘은 현재 처리 중인 요청 수를 기준으로 인스턴스에 요청을 할당하는 방법입니다. RequestCountPerTarget과 ActiveConnectionCount를 함께 사용하여 과부하 인스턴스에 요청을 보내지 않도록 할 수 있습니다. 이는 요청이 가장 적게 남아 있는 인스턴스로 요청을 보내는 효과적인 방법입니다.

3. **C. Use the round robin routing algorithm based on the RequestCount and TargetResponseTime CloudWatch metrics.**
   - 이 방법 역시 라운드 로빈 방식을 사용하며, 요청 수와 응답 시간을 고려하지만, 과부하 인스턴스를 피하는 데 효과적이지 않습니다.

4. **D. Use the least outstanding requests algorithm based on the RequestCount and TargetResponseTime CloudWatch metrics.**
   - 이 알고리즘은 가장 적은 남은 요청을 기반으로 인스턴스를 선택합니다. 그러나 TargetResponseTime만으로는 과부하를 피하는 데 한계가 있을 수 있습니다.

### 결론

**정답**: **B. Use the least outstanding requests algorithm based on the RequestCountPerTarget and ActiveConnectionCount CloudWatch metrics.**

이 선택지는 **현재 처리 중인 요청 수**와 **각 EC2 인스턴스의 연결 수**를 모두 고려하여 과부하 인스턴스를 피할 수 있도록 도와줍니다. 따라서 과부하가 발생하는 인스턴스에 새로운 요청이 전달되지 않도록 보장하며, 응답 시간을 최적화할 수 있습니다.

# 715
이 문제에서는 **Compute Savings Plans**의 커버리지 감소 시 알림을 받기 위한 효율적인 방법을 찾아야 합니다. 주어진 선택지 중에서 각 솔루션의 효율성과 운영 효율성을 분석해 보겠습니다.

### 선택지 분석

1. **A. Create a daily budget for the Savings Plans by using AWS Budgets. Configure the budget with a coverage threshold to send notifications to the appropriate email message recipients.**
   - AWS Budgets를 사용하여 예산을 설정하고 커버리지 임계값에 도달했을 때 알림을 보낼 수 있습니다. 그러나 Savings Plans에 대한 직접적인 모니터링 기능이 제한적일 수 있습니다.

2. **B. Create a Lambda function that runs a coverage report against the Savings Plans. Use Amazon Simple Email Service (Amazon SES) to email the report to the appropriate email message recipients.**
   - Lambda 함수를 사용하여 커버리지 보고서를 실행하고 이메일로 전송하는 방법입니다. 하지만, 이는 수동으로 구성해야 하고 운영 복잡성이 증가할 수 있습니다.

3. **C. Create an AWS Budgets report for the Savings Plans budget. Set the frequency to daily.**
   - AWS Budgets 리포트를 생성하여 커버리지를 모니터링할 수 있지만, 커버리지 감소에 대한 실시간 알림 기능은 제공하지 않을 수 있습니다.

4. **D. Create a Savings Plans alert subscription. Enable all notification options. Enter an email address to receive notifications.**
   - Savings Plans의 알림 구독을 생성하면, 커버리지와 관련된 알림을 즉시 받을 수 있습니다. AWS가 제공하는 이 기능은 자동으로 처리되므로 운영 효율성이 높습니다.

### 결론

**정답**: **D. Create a Savings Plans alert subscription. Enable all notification options. Enter an email address to receive notifications.**

이 선택지는 **Savings Plans**와 관련된 모든 알림을 자동으로 받을 수 있는 가장 운영 효율적인 방법입니다. 사용자는 커버리지 감소 시 즉시 알림을 받게 되므로, 문제를 신속하게 해결할 수 있습니다.

# 717
이 문제는 기존 온프레미스 ERP 시스템과 통합할 수 있는 AWS에서의 애플리케이션 마이그레이션을 다루고 있습니다. 이 애플리케이션은 SFTP 프로토콜을 사용하여 주문 파일을 처리하고, 보안과 복원력을 유지해야 합니다. 각 옵션을 분석해 보겠습니다.

### 선택지 분석

1. **A. Create an AWS Transfer Family SFTP internet-facing server in two Availability Zones. Use Amazon S3 storage. Create an AWS Lambda function to process order files. Use S3 Event Notifications to send s3:ObjectCreated:* events to the Lambda function.**
   - SFTP 서버를 인터넷에 노출하고, Amazon S3를 사용하여 파일을 저장합니다. S3의 객체 생성 이벤트를 통해 Lambda 함수를 트리거할 수 있어 효율적입니다. 그러나 보안 측면에서 인터넷에 노출된 SFTP 서버는 추가적인 주의가 필요합니다.

2. **B. Create an AWS Transfer Family SFTP internet-facing server in one Availability Zone. Use Amazon Elastic File System (Amazon EFS) storage. Create an AWS Lambda function to process order files. Use a Transfer Family managed workflow to invoke the Lambda function.**
   - EFS를 사용하여 SFTP 서버를 설정하는 방법입니다. 하지만 하나의 가용 영역에만 위치하므로, 복원력 측면에서 취약합니다.

3. **C. Create an AWS Transfer Family SFTP internal server in two Availability Zones. Use Amazon Elastic File System (Amazon EFS) storage. Create an AWS Step Functions state machine to process order files. Use Amazon EventBridge Scheduler to invoke the state machine to periodically check Amazon EFS for order files.**
   - 내부 서버를 두 개의 가용 영역에서 운영하며, EFS를 사용합니다. Step Functions를 통해 파일 처리 프로세스를 자동화하지만, 주기적으로 파일을 확인하는 방식은 즉각적인 처리를 요구하는 애플리케이션에는 비효율적일 수 있습니다.

4. **D. Create an AWS Transfer Family SFTP internal server in two Availability Zones. Use Amazon S3 storage. Create an AWS Lambda function to process order files. Use a Transfer Family managed workflow to invoke the Lambda function.**
   - 내부 SFTP 서버를 두 개의 가용 영역에서 운영하며, Amazon S3를 사용합니다. Transfer Family 관리형 워크플로우를 통해 Lambda 함수를 호출하여 파일을 즉시 처리할 수 있습니다. 이 옵션은 보안, 복원성 및 즉각적인 파일 처리 요구 사항을 모두 충족합니다.

### 결론

**정답**: **D. Create an AWS Transfer Family SFTP internal server in two Availability Zones. Use Amazon S3 storage. Create an AWS Lambda function to process order files. Use a Transfer Family managed workflow to invoke the Lambda function.**

이 솔루션은 내부 서버를 통해 보안을 강화하고, 두 개의 가용 영역에서 운영하여 복원력을 확보하며, 관리형 워크플로우를 통해 즉각적인 파일 처리를 지원하므로 요구 사항에 가장 잘 부합합니다.

# 718
이 문제는 온프레미스에서 데이터 처리 요구 사항을 유지하면서 확장 가능하고 운영 복잡성을 줄이는 솔루션을 찾는 것입니다. 각 선택지를 분석해 보겠습니다.

### 선택지 분석

1. **A. Use AWS Site-to-Site VPN to access the on-premises Hadoop Distributed File System (HDFS) data and application. Use an Amazon EMR cluster to process the data.**
   - AWS Site-to-Site VPN을 사용하여 온프레미스 HDFS에 접근하고 Amazon EMR 클러스터를 사용하여 데이터를 처리하는 방법입니다. 그러나 이는 여전히 온프레미스 인프라에 의존하며, 데이터 전송의 지연이 발생할 수 있습니다.

2. **B. Use AWS DataSync to connect to the on-premises Hadoop Distributed File System (HDFS) cluster. Create an Amazon EMR cluster to process the data.**
   - AWS DataSync를 사용하여 온프레미스 HDFS와 연결하고, Amazon EMR 클러스터를 생성하여 데이터를 처리하는 방법입니다. 하지만 데이터 처리가 클라우드에서 이루어지므로, "온프레미스에서 데이터 처리를 유지해야 한다"는 요구 사항을 충족하지 않습니다.

3. **C. Migrate the Apache Hadoop application and the Apache Spark application to Amazon EMR clusters on AWS Outposts. Use the EMR clusters to process the data.**
   - AWS Outposts에서 EMR 클러스터를 사용하여 온프레미스에서 Hadoop 및 Spark 애플리케이션을 실행하는 방법입니다. 이는 데이터 처리를 온프레미스에서 유지할 수 있으므로 요구 사항에 부합합니다. AWS Outposts는 AWS 서비스를 온프레미스에서 제공하여 운영 복잡성을 줄일 수 있습니다.

4. **D. Use an AWS Snowball device to migrate the data to an Amazon S3 bucket. Create an Amazon EMR cluster to process the data.**
   - AWS Snowball 장치를 사용하여 데이터를 Amazon S3로 마이그레이션한 후 EMR 클러스터에서 처리하는 방법입니다. 하지만 데이터 처리를 온프레미스에서 유지할 수 없으므로 요구 사항을 충족하지 않습니다.

### 결론

**정답**: **C. Migrate the Apache Hadoop application and the Apache Spark application to Amazon EMR clusters on AWS Outposts. Use the EMR clusters to process the data.**

이 솔루션은 온프레미스에서 데이터 처리를 유지하면서도 확장성과 운영 복잡성을 줄일 수 있는 가장 적합한 방법입니다. AWS Outposts를 사용하면 AWS의 관리형 서비스를 온프레미스 환경에서 활용할 수 있습니다.

# 723
이 문제는 AWS Systems Manager를 사용하여 EC2 인스턴스를 패치하면서 실행 중인 애플리케이션에 영향을 주지 않도록 하는 방법을 찾고 있습니다. 각 선택지를 분석해 보겠습니다.

### 선택지 분석

1. **A. Create a new IAM role. Attach the AmazonSSMManagedInstanceCore policy to the new IAM role. Attach the new IAM role to the EC2 instances and the existing IAM role.**
   - 새로운 IAM 역할을 생성하고 `AmazonSSMManagedInstanceCore` 정책을 추가하는 것은 EC2 인스턴스가 Systems Manager와 통신할 수 있도록 하는 방법입니다. 그러나, IAM 역할은 한 번에 하나만 연결될 수 있으므로, 기존 IAM 역할과 새 역할을 동시에 사용할 수 없습니다. 이 선택지는 요구 사항을 충족하지 않습니다.

2. **B. Create an IAM user. Attach the AmazonSSMManagedInstanceCore policy to the IAM user. Configure Systems Manager to use the IAM user to manage the EC2 instances.**
   - IAM 사용자를 생성하고 그 사용자에게 `AmazonSSMManagedInstanceCore` 정책을 연결하는 것은 올바른 접근 방식이 아닙니다. EC2 인스턴스는 IAM 역할을 통해 AWS 서비스와 통신해야 하므로, IAM 사용자로 관리할 수 없습니다. 이 선택지도 요구 사항을 충족하지 않습니다.

3. **C. Enable Default Host Configuration Management in Systems Manager to manage the EC2 instances.**
   - Default Host Configuration Management는 AWS Systems Manager에서 EC2 인스턴스를 관리하는 데 사용되는 기본 설정입니다. 이 방법은 EC2 인스턴스가 Systems Manager와 통신할 수 있도록 하며, 인스턴스를 패치하는 데 적합합니다. 그러나 이 선택지는 다른 선택지에 비해 명확한 방법을 제시하지 않으므로, 구체적인 솔루션으로 보기는 어렵습니다.

4. **D. Remove the existing policies from the existing IAM role. Add the AmazonSSMManagedInstanceCore policy to the existing IAM role.**
   - 기존 IAM 역할에서 다른 정책을 제거하고 `AmazonSSMManagedInstanceCore` 정책을 추가하는 것은 EC2 인스턴스가 Systems Manager와 통신할 수 있도록 할 수 있습니다. 그러나 다른 정책을 제거하면 애플리케이션에 필요한 권한이 사라질 수 있으므로, 이 방법은 불필요한 리스크를 초래할 수 있습니다.

### 결론

**정답**: **C. Enable Default Host Configuration Management in Systems Manager to manage the EC2 instances.**

이 솔루션은 EC2 인스턴스를 패치할 수 있도록 하면서도 기존 애플리케이션에 대한 영향을 최소화할 수 있는 방법입니다. 다만, EC2 인스턴스가 `AmazonSSMManagedInstanceCore` 정책이 연결된 IAM 역할을 가지고 있어야만 합니다.

# 728
정답은 **C. Deploy AWS Storage Gateway using stored volumes to store data locally. Use Storage Gateway to asynchronously back up point-in-time snapshots of the data to Amazon S3.** 입니다.

각 옵션을 분석해 보면 다음과 같습니다:

1. **Option A (Amazon S3 Glacier Vault with expedited retrieval)**:
   - Amazon S3 Glacier는 주로 장기 저장 및 저렴한 보관을 위한 서비스로, 데이터를 즉시 복구하는 데 제한이 있습니다. 따라서 즉각적인 데이터 복구가 필요하고, 비용을 절감하려는 요구 사항에 적합하지 않습니다.

2. **Option B (AWS Storage Gateway with cached volumes)**:
   - 이 옵션은 AWS S3를 기본 저장소로 사용하면서, 가장 자주 사용되는 데이터의 캐시를 온프레미스에 저장합니다. 하지만 이 경우에는 온프레미스에 데이터를 완전히 저장하는 것이 아니므로, 주어진 요구사항인 **로컬 데이터 저장 및 즉각적인 데이터 접근**에 부적합합니다.

3. **Option C (AWS Storage Gateway with stored volumes)**:
   - 이 옵션은 온프레미스에서 데이터를 로컬에 완전히 저장하고, 비동기적으로 AWS S3에 백업합니다. **즉각적인 데이터 접근을 온프레미스에서 제공**하고 **추가적인 대역폭 비용을 최소화**하면서 AWS에 안전하게 백업할 수 있는 좋은 방법입니다.

4. **Option D (AWS Direct Connect with AWS Storage Gateway stored volumes)**:
   - Direct Connect는 AWS와 온프레미스 간의 전용 네트워크 연결을 제공하지만, 비용이 발생할 수 있으며 이 문제에서는 Direct Connect를 활용해야 한다는 구체적인 요구사항이 없습니다. 따라서 Direct Connect는 필수적이지 않습니다.

따라서, 요구 사항을 충족하는 최적의 솔루션은 **Option C**입니다.

# 733
정답은 **B. Enable the Amazon RDS Protection feature in Amazon GuardDuty for the member accounts of the organization.** 입니다.

각 옵션을 분석해 보면 다음과 같습니다:

1. **Option A (Attach service control policies (SCPs) to the root of the organization)**:
   - SCP는 AWS 리소스에 대한 사용 권한을 제어하는 데 유용하지만, 특정 활동(예: 로그인 시도)을 모니터링하거나 감지하는 용도로는 적합하지 않습니다. 따라서 실패한 로그인 시도 식별에 적절하지 않습니다.

2. **Option B (Enable the Amazon RDS Protection feature in Amazon GuardDuty)**:
   - GuardDuty의 RDS Protection 기능은 데이터베이스에서 발생하는 비정상적인 활동(예: 비정상적이거나 악의적인 로그인 시도)을 자동으로 감지하고 경고할 수 있습니다. 이 기능은 조직 내 여러 계정의 데이터베이스에서 비정상적인 로그인을 효과적으로 감지하고 경고를 제공하는 데 적합하며, 관리 효율성도 높습니다.

3. **Option C (Publish Aurora general logs to CloudWatch Logs and export to S3)**:
   - 이 방법은 Aurora의 일반 로그를 CloudWatch Logs에 게시하고 S3에 중앙에서 저장할 수 있지만, 비정상적인 로그인 시도를 감지하려면 추가적인 분석 작업이 필요합니다. 로그 분석은 수동으로 설정하고 운영해야 하므로, 관리 효율성이 떨어질 수 있습니다.

4. **Option D (Publish Aurora PostgreSQL database events in CloudTrail to S3)**:
   - CloudTrail을 사용하여 Aurora PostgreSQL 이벤트를 중앙의 S3 버킷으로 전달할 수 있지만, CloudTrail에서는 데이터베이스 로그인과 관련된 이벤트는 포착되지 않습니다. 따라서 이 방법으로 로그인 실패나 비정상적인 활동을 추적하는 데는 한계가 있습니다.

따라서 가장 효율적인 솔루션은 **Option B**입니다. GuardDuty의 RDS Protection 기능을 통해 비정상적인 로그인 시도를 자동으로 감지하고 경고를 받을 수 있어 운영 효율성을 크게 향상할 수 있습니다.

# 734
정답은 **D. Connect the existing Direct Connect connection to a Direct Connect gateway. Route traffic from the virtual private gateways of the VPCs in each Region to the Direct Connect gateway.** 입니다.

각 옵션을 분석해 보면 다음과 같습니다:

1. **Option A (Inter-Region VPC peering)**:
   - Inter-Region VPC 피어링은 두 VPC 간에 직접 연결을 설정하는 방법이지만, 스케일링에 한계가 있으며, 각 VPC 간에 피어링을 별도로 설정해야 하므로 운영 오버헤드가 큽니다. 또한, 피어링을 통해 온프레미스 데이터 센터와의 연결을 지원하지 않으므로 요구 사항에 맞지 않습니다.

2. **Option B (Private virtual interfaces to eu-west-2 VPCs)**:
   - us-east-1의 Direct Connect에서 eu-west-2의 VPC로 프라이빗 가상 인터페이스를 만드는 것은 가능한 방법이지만, Region 간의 Direct Connect 연결을 위해 별도의 구성이 필요하며 스케일링이 어렵고 관리 부담이 큽니다.

3. **Option C (Fully meshed VPN network with AWS VPN CloudHub)**:
   - AWS VPN CloudHub를 통해 VPN 네트워크를 구성할 수 있지만, VPN 네트워크를 유지 관리하는 작업이 필요하고 성능 및 확장성 측면에서 Direct Connect를 사용하는 것보다 비효율적일 수 있습니다.

4. **Option D (Direct Connect Gateway)**:
   - Direct Connect 게이트웨이를 사용하여 두 Region의 VPC들과 온프레미스 데이터 센터 간의 연결을 중앙에서 관리할 수 있습니다. Direct Connect 게이트웨이는 여러 VPC와의 연결을 지원하며, 추가적인 설정 없이 두 Region 간 및 온프레미스와의 연결을 쉽게 확장할 수 있습니다. 이 방법은 스케일링이 용이하며 운영 오버헤드도 최소화할 수 있습니다.

따라서 가장 효율적이고 확장 가능한 솔루션은 **Option D**입니다. Direct Connect 게이트웨이를 통해 여러 VPC 및 두 데이터 센터를 연결함으로써 요구 사항을 충족할 수 있습니다.

# 735
정답은 **A. Push score updates to Amazon Kinesis Data Streams. Process the updates in Kinesis Data Streams with AWS Lambda. Store the processed updates in Amazon DynamoDB.** 입니다.

각 옵션을 분석해 보면 다음과 같습니다:

1. **Option A (Kinesis Data Streams + Lambda + DynamoDB)**:
   - **Kinesis Data Streams**는 대규모 트래픽 스파이크를 처리할 수 있는 스트리밍 데이터 서비스로, 메시지가 도착한 순서대로 데이터를 처리할 수 있습니다. **AWS Lambda**와 통합하여 서버를 관리할 필요 없이 실시간으로 데이터를 처리할 수 있습니다.
   - **DynamoDB**는 고가용성을 제공하며, 관리 오버헤드가 적고 대규모 읽기/쓰기 트래픽을 쉽게 처리할 수 있어 리더보드 데이터를 저장하는 데 적합합니다.
   - 이 구성은 높은 확장성과 함께 관리 오버헤드를 최소화하며, 문제의 요구 사항을 충족합니다.

2. **Option B (Kinesis Data Streams + EC2 Auto Scaling + Redshift)**:
   - Kinesis Data Streams는 적합한 선택이지만, **EC2 인스턴스를 사용한 처리**는 서버 관리 오버헤드가 증가합니다. **Amazon Redshift**는 데이터 웨어하우스로 설계되어 리더보드와 같은 실시간 읽기/쓰기 성능에 적합하지 않습니다.

3. **Option C (SNS + Lambda + SQL database on EC2)**:
   - **Amazon SNS**는 메시지를 순서 없이 전달하므로, 데이터가 수신된 순서대로 처리되지 않을 수 있습니다. 또한, SQL 데이터베이스를 **EC2에서 직접 관리**하면 관리 오버헤드가 큽니다.

4. **Option D (SQS + EC2 Auto Scaling + RDS Multi-AZ)**:
   - SQS는 메시지의 순서를 보장하지 않기 때문에, **수신된 순서대로 처리해야 한다**는 요구 사항을 충족하지 못합니다. 또한, EC2 인스턴스를 이용한 Auto Scaling은 관리 오버헤드가 큽니다.

따라서 **Option A**가 가장 적합한 솔루션입니다. Kinesis Data Streams와 AWS Lambda를 활용하여 실시간 데이터 처리와 순서 보장을 모두 충족하면서, DynamoDB를 통해 고가용성의 리더보드를 손쉽게 유지할 수 있습니다.


# 736
이 문제에서는 여러 개의 AWS 계정에 분산된 로그 데이터를 중앙의 S3 버킷에 모아 분석하고, 로그 데이터가 us-west-2 리전을 벗어나지 않도록 하며, 최소한의 운영 오버헤드와 비용을 유지하는 것이 목표입니다. 각 선택지의 장단점을 분석해보겠습니다.

### 선택지 분석

1. **A. S3 라이프사이클 정책 사용**
   - S3 라이프사이클 정책은 객체를 이동하거나 삭제하는 데 유용하지만, 한 버킷에서 다른 버킷으로 객체를 복사하는 기능은 제공하지 않습니다.
   - 따라서 이 방법으로는 요구 사항을 충족할 수 없습니다.

2. **B. S3 동일 리전 복제(Same-Region Replication) 사용**
   - S3 동일 리전 복제(SRR)는 S3 버킷 내 데이터를 같은 리전의 다른 버킷으로 자동으로 복사할 수 있는 기능입니다.
   - 이 방법은 로그가 us-west-2 리전을 벗어나지 않도록 하며, 복제를 자동화하여 운영 오버헤드를 줄여줍니다.
   - 단, 동일 리전 복제에 추가 비용이 발생하지만, Lambda 함수나 매일 수동으로 데이터를 복사하는 것보다 운영 효율성이 높습니다.
   - **결론적으로, 요구 사항을 충족하며 효율적인 비용 구조를 제공합니다.**

3. **C. PutObject API를 사용하여 매일 데이터를 복사하는 스크립트 작성**
   - 매일 모든 로그를 수동으로 복사하는 스크립트를 실행하는 것은 유지 관리에 높은 오버헤드가 필요하고, 실시간 로그 전송이 불가능하여 실시간 분석에 부적합합니다.
   - 효율성이 떨어지고, 장기적으로 관리에 부담이 됩니다.

4. **D. Lambda 함수를 사용하여 S3 이벤트 발생 시 로그 복사**
   - Lambda 함수가 s3:ObjectCreated:* 이벤트를 감지하여 로그를 복사하는 방식은 실시간 데이터 복사와 처리에는 적합합니다.
   - 하지만 Lambda 함수는 각 계정에 설정이 필요하므로 초기 설정 작업이 요구됩니다.
   - 로그가 자주 생성될 경우 Lambda 호출 비용이 누적되어 비용이 증가할 수 있습니다.

### 정답

**정답: B. Use S3 Same-Region Replication to replicate logs from the S3 buckets to another S3 bucket in us-west-2. Use this S3 bucket for log analysis.**

### 해설

S3 동일 리전 복제(SRR)를 사용하면 각 계정에서 중앙 로그 버킷으로 자동 복제할 수 있어 운영 오버헤드가 낮고 관리가 용이합니다. 로그 데이터가 리전을 벗어나지 않으며, 실시간 분석에는 다소 부족할 수 있지만 최소한의 설정으로 로그 복사가 이루어져 비용과 운영 효율성이 균형을 이루는 솔루션입니다.


# 737
이 문제에서는 훈련 비디오를 전 세계의 학생들에게 제공하는 애플리케이션이 있으며, 콘텐츠 개발자가 비디오를 업로드하는 요구 사항을 충족하면서 유럽과 아시아 지역의 S3 버킷으로 데이터를 복제해야 합니다. 최소한의 애플리케이션 변경으로 이러한 요구 사항을 충족하는 조합을 선택해야 합니다.

### 선택지 분석

A. **us-east-2 S3 버킷에서 eu-west-2 S3 버킷으로의 단방향 복제를 구성하고, us-east-2 S3 버킷에서 ap-southeast-1 S3 버킷으로의 단방향 복제를 구성합니다.**  
- **해결책**: 이 옵션은 두 개의 단방향 복제를 설정하여 모든 지역에서 필요한 데이터를 복제할 수 있습니다. 개발자가 eu-west-2 또는 ap-southeast-1 지역에서 비디오를 업로드할 때 빠른 응답 속도를 제공합니다.

B. **us-east-2 S3 버킷에서 eu-west-2 S3 버킷으로의 단방향 복제를 구성하고, eu-west-2 S3 버킷에서 ap-southeast-1 S3 버킷으로의 단방향 복제를 구성합니다.**  
- **해결책**: 이 옵션은 한 단계 더 나아가서, eu-west-2에서 ap-southeast-1으로 복제하므로, 모든 지역에서 데이터가 최신 상태로 유지될 수 있습니다. 그러나 이러한 방식은 처음부터 복잡성을 증가시킵니다.

C. **모든 세 지역의 S3 버킷 간에 양방향 복제를 구성합니다.**  
- **해결책**: 양방향 복제는 데이터의 동기화를 보장하지만, 관리가 복잡하고 애플리케이션에 더 많은 변경을 요구할 수 있습니다.

D. **S3 멀티 리전 액세스 포인트를 생성하고, 비디오 스트리밍을 위해 애플리케이션을 멀티 리전 액세스 포인트의 ARN을 사용하도록 수정합니다. 비디오 업로드를 위해 애플리케이션을 수정하지 않습니다.**  
- **해결책**: 멀티 리전 액세스 포인트를 사용하면 스트리밍에 대한 지연 시간을 최소화할 수 있지만, 업로드에는 영향을 미치지 않습니다.

E. **S3 멀티 리전 액세스 포인트를 생성하고, 비디오 스트리밍과 업로드 모두에 대해 애플리케이션을 멀티 리전 액세스 포인트의 ARN을 사용하도록 수정합니다.**  
- **해결책**: 이 옵션은 모든 지역에서 업로드와 스트리밍을 효율적으로 처리할 수 있지만, 애플리케이션의 변경이 더 많아질 수 있습니다.

### 결론

**정답: A, D**  
- A 옵션을 선택하여 us-east-2에서 eu-west-2 및 ap-southeast-1로의 단방향 복제를 설정하고, D 옵션을 통해 S3 멀티 리전 액세스 포인트를 생성하여 비디오 스트리밍에 적용하면, 최소한의 애플리케이션 변경으로 모든 요구 사항을 충족할 수 있습니다. 개발자는 업로드 시 느린 대기 시간의 영향을 받지 않으며, 학생들은 빠른 스트리밍을 경험할 수 있습니다.

# 738
문제의 요구사항은 **가장 낮은 업로드 지연 시간**으로 콘텐츠를 업로드하고, 콘텐츠를 **사용자와 가까운 AWS 리전**에 저장하여 사용자가 콘텐츠에 빠르게 접근할 수 있도록 하는 것입니다.

### 정답: **D**

---

### 해설:

1. **D. 사용자와 가까운 리전에 Amazon S3에 콘텐츠를 업로드하고 저장. 여러 CloudFront 배포 사용**
   - 이 옵션은 **사용자와 가장 가까운 AWS 리전**에 S3 버킷을 배치하여 지연 시간을 최소화하며, **여러 CloudFront 배포**를 통해 각 리전의 콘텐츠를 빠르게 캐시하고 제공할 수 있습니다.
   - 사용자 위치에 맞춰 리전을 선택하므로, **가장 낮은 지연 시간**을 보장하고 사용자가 콘텐츠를 빠르게 소비할 수 있게 합니다.

---

### 다른 보기가 정답이 될 수 없는 이유:

#### A. **Amazon S3에 콘텐츠를 업로드 및 저장하고, CloudFront를 사용하여 업로드**
   - **CloudFront는 업로드 지연을 최적화하는 데 적합하지 않으며**, 다운로드 요청을 위한 캐시 기능을 주로 제공합니다.
   - CloudFront로의 업로드 요청은 지연 시간이 더 길어질 수 있어 문제에서 요구하는 최소 지연 업로드 요구사항에 적합하지 않습니다.

#### B. **Amazon S3에 콘텐츠를 업로드 및 저장하고, S3 Transfer Acceleration 사용**
   - **S3 Transfer Acceleration**은 전 세계적으로 분산된 사용자에게 최적화된 경로를 통해 데이터를 업로드할 수 있도록 해주지만, **로컬 AWS 리전에서 소비되는 경우가 대부분**인 이 시나리오에는 적합하지 않습니다.
   - Transfer Acceleration을 사용하면 추가 비용이 발생하며, 로컬 리전에 직접 업로드하는 것보다 성능이 나을 이유가 적습니다.

#### C. **사용자와 가까운 리전에 있는 EC2 인스턴스에 콘텐츠를 업로드한 후 Amazon S3로 복사**
   - 이 방법은 복잡성이 높고 관리 오버헤드가 큽니다. 또한, **EC2 인스턴스와 S3 간의 추가 데이터 전송 작업**이 필요하므로 지연 시간이 길어질 수 있습니다.
   - 최종 저장소가 S3임을 고려할 때, **직접 S3에 업로드하는 방법**이 더 적합합니다.

---

이로 인해, **D 옵션**이 사용자 가까운 리전에 콘텐츠를 업로드 및 저장하여 최소한의 지연 시간으로 사용자 경험을 최적화하는 최적의 선택입니다.


# 739
이 문제는 **서버리스 아키텍처에 메시지를 라우팅하고 필터링**할 수 있는 솔루션을 찾는 것입니다. 요구사항은 **메시지 필터링 기능을 지원하고, 대상 Lambda 함수에 필요한 메시지만 전송**하는 것입니다. 또한, **운영 오버헤드가 최소화**된 솔루션이 필요합니다.

### 정답: **B**

---

### 해설:

1. **B. API Gateway REST API에서 Amazon EventBridge로 요청을 보냄. EventBridge에서 대상 Lambda 함수를 호출하도록 구성**
   - EventBridge는 **메시지 필터링 및 라우팅 기능을 기본적으로 제공**하여 각 Lambda 함수가 필요한 메시지만 받을 수 있도록 설정할 수 있습니다.
   - 또한 **EventBridge와 Lambda 함수의 통합이 원활하고**, 서버리스 아키텍처에서 관리가 쉬워 운영 오버헤드가 낮습니다.
   - **즉, 필터링 요구사항을 충족하면서 최소한의 운영 오버헤드로 메시지를 처리할 수 있는 최적의 솔루션**입니다.

---

### 다른 보기가 정답이 될 수 없는 이유:

#### A. **API Gateway REST API에서 Amazon SNS 주제로 요청을 보내고, SQS 대기열을 SNS 주제에 구독. Lambda 함수가 SQS 대기열을 폴링**
   - Amazon SNS는 SQS와 결합하면 메시지를 여러 대기열로 전달할 수 있지만, **메시지 필터링을 위해 추가 설정이 필요**하여 관리 오버헤드가 증가합니다.
   - 각 Lambda 함수가 필요한 메시지만 필터링하려면 SQS 대기열을 따로 설정하고 폴링해야 하므로, B보다 운영 오버헤드가 높습니다.

#### C. **API Gateway REST API에서 Amazon MSK로 요청을 보내고, MSK가 메시지를 Lambda 함수로 게시하도록 구성**
   - **Amazon MSK는 Apache Kafka를 관리형으로 제공**하지만, 운영과 관리가 복잡해지고 **운영 오버헤드가 커질 수 있습니다**.
   - 또한, 필터링 기능을 지원하려면 추가적인 설정이 필요합니다. 따라서 이 문제에서 요구하는 최소 운영 오버헤드와는 맞지 않습니다.

#### D. **API Gateway REST API에서 여러 SQS 대기열로 요청을 보내고, Lambda 함수가 각 SQS 대기열을 폴링**
   - 여러 SQS 대기열을 사용하여 각 Lambda 함수가 필요한 메시지를 처리할 수는 있지만, **각 대기열을 폴링하기 위한 추가 작업이 필요**합니다.
   - 메시지 필터링을 위한 별도 구성을 요구하므로 B보다 운영 오버헤드가 더 높습니다.

---

결론적으로 **EventBridge는 필터링 기능을 쉽게 제공하며 Lambda와의 통합이 간단**하여, **운영 오버헤드를 최소화하면서 요구 사항을 충족하는 가장 적절한 선택**입니다.

# 740
이 문제에서는 **기존의 암호화되지 않은 객체와 미래에 업로드될 객체를 모두 고객 제공 키(SSE-C)로 암호화**해야 합니다. **모든 객체를 암호화**하는 방법과 **기본 암호화 설정**을 통해 새 객체가 자동으로 암호화되도록 해야 합니다.

### 정답: **A**

---

### 해설:

1. **A. S3 Inventory 보고서를 통해 암호화되지 않은 객체 목록을 필터링하고, S3 Batch Operations 작업을 구성하여 해당 객체를 SSE-C로 암호화. S3 기본 암호화 기능을 사용하여 고객 제공 키(SSE-C)로 암호화되도록 설정**
   - 이 솔루션은 기존의 암호화되지 않은 객체와 향후 업로드될 객체 모두에 **SSE-C 암호화 적용**을 보장합니다.
   - **S3 Inventory**는 객체 목록과 메타데이터를 제공하며, S3 Batch Operations를 통해 대규모 객체 집합에 대해 일괄 암호화 작업을 수행할 수 있습니다.
   - 또한, **S3 기본 암호화** 설정을 통해 새로 업로드되는 객체가 자동으로 고객 제공 키(SSE-C)로 암호화되므로, 요구사항을 모두 충족합니다.

---

### 다른 보기가 정답이 될 수 없는 이유:

#### B. **S3 Storage Lens를 사용하여 암호화되지 않은 버킷을 식별하고, S3 기본 암호화를 AWS KMS 키(SSE-KMS)로 설정**
   - 이 옵션은 S3 Storage Lens를 사용하여 암호화되지 않은 버킷을 찾을 수 있지만, 문제의 요구사항인 **고객 제공 키(SSE-C)**를 지원하지 않습니다.
   - **SSE-KMS를 사용한 암호화 설정**은 고객 제공 키를 요구하는 문제의 조건에 맞지 않습니다.

#### C. **AWS 사용량 보고서를 통해 암호화되지 않은 객체 목록을 필터링하고, AWS Batch를 사용하여 객체를 SSE-KMS로 암호화. 기본 암호화를 SSE-KMS로 설정**
   - AWS Batch를 사용해 암호화할 수는 있지만, 이 옵션도 **SSE-KMS를 사용하여 암호화**하므로 문제의 조건인 SSE-C를 충족하지 않습니다.

#### D. **AWS 사용량 보고서를 통해 암호화되지 않은 객체 목록을 필터링하고, 기본 암호화를 SSE-C로 설정**
   - 기본 암호화 설정만으로는 기존의 암호화되지 않은 객체를 처리하지 않기 때문에, **기존의 객체를 암호화할 방법이 없습니다**.
   - 문제의 요구사항인 **기존 및 새로운 객체 모두를 암호화**할 수 없으므로 조건에 맞지 않습니다.

---

따라서, **A 옵션이 기존 및 새 객체를 모두 고객 제공 키(SSE-C)로 암호화하는 요구사항을 충족**하며, 이 문제에 대한 최적의 솔루션입니다.

# 741
이 시나리오에서는 회사의 도메인 이름 레코드를 호스팅하는 DNS 제공자가 중단을 경험하고 있으며, AWS에서 더 복원력이 있는 관리형 DNS 서비스로 마이그레이션하려고 합니다. 가장 빠르게 DNS 호스팅 서비스를 마이그레이션하는 방법을 찾고 있습니다.

### 정답:
**A. Create an Amazon Route 53 public hosted zone for the domain name. Import the zone file containing the domain records hosted by the previous provider.**

### 해설:
1. **공개 호스티드 존 생성**:
   - Amazon Route 53에서 공개 호스티드 존을 생성하면 인터넷에서 접근 가능한 도메인 이름을 위한 DNS 서비스를 제공할 수 있습니다. 이는 웹사이트와 같이 공개적으로 액세스할 수 있는 리소스에 적합합니다.

2. **존 파일 가져오기**:
   - 이전 제공자가 호스팅하는 도메인 레코드를 포함하는 존 파일을 가져오면, 기존의 DNS 설정을 빠르게 복원하고, DNS 레코드를 수동으로 입력할 필요 없이 신속하게 마이그레이션할 수 있습니다.

이 방법은 Amazon Route 53의 안정성과 확장성을 활용하여 DNS 서비스를 신속하게 이전할 수 있는 간단하고 효과적인 방법입니다.

### 오답 해설:

- **B. Create an Amazon Route 53 private hosted zone for the domain name. Import the zone file containing the domain records hosted by the previous provider.**
   - **설명**: 프라이빗 호스티드 존은 VPC 내에서만 사용할 수 있으며, 공개적으로 액세스할 수 있는 웹사이트에 대해 적합하지 않습니다. 따라서 이 방법은 웹사이트에 접근하는 데 필요한 DNS 서비스를 제공하지 않습니다.

- **C. Create a Simple AD directory in AWS. Enable zone transfer between the DNS provider and AWS Directory Service for Microsoft Active Directory for the domain records.**
   - **설명**: Simple AD는 DNS 관리 기능을 제공하지 않으며, Active Directory의 영역 전송은 복잡성을 추가하고, 빠른 마이그레이션에 적합하지 않습니다.

- **D. Create an Amazon Route 53 Resolver inbound endpoint in the VPC. Specify the IP addresses that the provider's DNS will forward DNS queries to. Configure the provider's DNS to forward DNS queries for the domain to the IP addresses that are specified in the inbound endpoint.**
   - **설명**: Route 53 Resolver는 주로 VPC 내의 DNS 쿼리를 처리하기 위해 사용됩니다. 외부 DNS 제공자의 쿼리를 수신하기 위한 구성은 필요하지 않으며, 이 방법은 복잡하고 빠른 마이그레이션에 적합하지 않습니다.

### 결론
따라서, **A**의 방법이 AWS에서 더 복원력이 있는 관리형 DNS 서비스로 신속하게 마이그레이션하는 데 가장 적합한 솔루션입니다.

# 743
### 정답: **D**

---

### 해설:

1. **D. AWS에서 제공하는 루트 인증서를 다운로드하고, RDS 인스턴스에 대한 모든 연결에 인증서를 제공**
   - Amazon RDS는 **TLS/SSL 암호화를 통해 데이터 전송 중 보호**를 지원합니다. AWS는 MySQL과 같은 RDS 인스턴스를 위한 **루트 인증서**를 제공하며, 이를 사용하여 **연결 시 데이터 전송 중 암호화**를 활성화할 수 있습니다.
   - 이 방법은 **기존 인스턴스를 유지하면서도 전송 중 암호화를 추가**할 수 있으므로, 요구 사항을 충족하고 변경 사항을 최소화하는 적절한 선택입니다.

---

### 다른 보기가 정답이 될 수 없는 이유:

#### A. **IAM 데이터베이스 인증 활성화**
   - IAM 데이터베이스 인증은 **인증 방식을 강화**하는 데 도움이 되지만, 데이터 전송 중 암호화에는 영향을 미치지 않습니다. 따라서 전송 중 암호화를 위한 요구 사항을 충족하지 않습니다.

#### B. **자가 서명 인증서 제공 후 RDS 인스턴스에 대한 모든 연결에서 사용**
   - 자가 서명 인증서는 AWS에서 제공하는 인증서만큼 안전하지 않으며, **AWS에서 권장하는 방식도 아닙니다**.
   - AWS가 제공하는 인증서를 사용하는 것이 보안과 관리 측면에서 더 적절합니다.

#### C. **RDS 인스턴스의 스냅샷을 생성하고, 암호화가 활성화된 새 인스턴스로 복원**
   - 이 방법은 **암호화를 추가하기 위해 인스턴스를 재배포하는 방식**으로, 데이터 전송 중 암호화와는 관련이 없습니다.
   - 또한 **전송 중 암호화 요구 사항**을 충족하지 않고, 추가 작업과 다운타임이 발생할 수 있습니다.

---

**결론적으로 D 옵션**이 RDS 연결에 필요한 **AWS 제공 인증서를 통해 데이터 전송 중 암호화를 쉽게 구현할 수 있는 방법**이므로, 이 문제에 대한 최적의 솔루션입니다.

# 744
### 정답: **A**

---

### 해설:

1. **A. Network Load Balancer와 연결된 Elastic IP 주소 사용**
   - **Network Load Balancer (NLB)**는 **고정된 IP 주소**를 사용할 수 있는 유일한 Elastic Load Balancing 옵션입니다. NLB에 **Elastic IP 주소를 할당**하면, 이 주소를 클라이언트의 방화벽에 등록할 수 있으므로 **IP 주소 기반의 접근 제한**이 필요한 경우에 적합합니다.
   - 이는 클라이언트가 IP 주소를 고정하여 접근할 수 있는 유일한 AWS ELB 옵션이므로, 문제의 요구사항을 충족합니다.

---

### 다른 보기가 정답이 될 수 없는 이유:

#### B. **Application Load Balancer(ALB)와 연결된 Elastic IP 주소 사용**
   - **Application Load Balancer는 Elastic IP 주소를 지원하지 않으며**, 각 요청 시 동적으로 할당된 IP를 사용합니다. 이로 인해 클라이언트의 방화벽에 IP를 고정 등록하는 요구사항을 충족하지 않습니다.

#### C. **Amazon Route 53에 A 레코드 설정 후 Elastic IP 주소로 지정**
   - Route 53에 **A 레코드를 설정하여 고정된 IP 주소를 사용할 수는 있지만**, 이 방식은 ELB와의 통합이 아니므로 로드 밸런싱의 이점을 제공하지 않습니다.
   - 또한, **EC2 인스턴스에 직접 연결하는 것은 가용성과 확장성 측면에서 비효율적**입니다.

#### D. **퍼블릭 IP 주소가 있는 EC2 인스턴스를 ELB 앞에 프록시로 구성**
   - EC2 인스턴스를 프록시로 사용하는 것은 관리와 확장성 측면에서 비효율적이며, **단일 장애점(SPOF)**이 될 수 있습니다.
   - NLB와 Elastic IP 조합이 더 효율적이며 AWS에서 권장하는 방식입니다.

---

결론적으로, **Network Load Balancer와 Elastic IP 주소를 사용한 A 옵션**이 IP 주소 고정 요구사항을 만족하면서 로드 밸런싱을 지원하는 최적의 솔루션입니다.

# 745
### 정답: **B**

---

### 해설:

1. **B. IAM 사용자를 생성하여 일상적인 관리 작업을 수행하고, 루트 사용자에게 다중 인증(MFA) 활성화**
   - **루트 사용자**는 AWS 계정의 전체 권한을 가진 가장 권위 있는 사용자입니다. 루트 사용자는 일반적으로 일상적인 관리 작업에 사용해서는 안 되며, 대신 **IAM 사용자를 생성하여 필요한 권한을 부여**해야 합니다.
   - **다중 인증(MFA)**를 활성화함으로써 루트 사용자의 보안을 크게 향상시킬 수 있습니다. MFA를 통해 루트 사용자의 로그인 시 추가적인 인증 절차가 요구되므로 계정이 더 안전해집니다.

---

### 다른 보기가 정답이 될 수 없는 이유:

#### A. **IAM 사용자를 생성하고 루트 사용자 비활성화**
   - **루트 사용자는 비활성화할 수 없습니다**. AWS는 루트 사용자 계정을 항상 활성 상태로 유지해야 하며, 계정의 기본적인 설정 및 관리에 필요합니다. 대신 IAM 사용자를 생성하고 루트 사용자 사용을 최소화해야 합니다.

#### C. **루트 사용자에 대한 액세스 키 생성 후 일상적인 관리 작업에 액세스 키 사용**
   - **루트 사용자에게 액세스 키를 생성하는 것은 권장되지 않습니다**. 루트 사용자에게 액세스 키를 부여하면 보안 위험이 증가합니다. 대신 IAM 사용자를 생성하고 그 사용자에게 필요한 권한을 부여하여 액세스 키를 사용하는 것이 더 안전합니다.

#### D. **루트 사용자 자격 증명을 가장 수석 솔루션 아키텍트에게 제공 후 루트 사용자 사용**
   - **루트 사용자 계정을 다른 사용자에게 제공하는 것은 매우 위험**하며, 루트 사용자는 전체 AWS 계정에 대한 권한을 가지므로 이러한 접근은 보안 위협을 초래합니다. 루트 사용자 대신 IAM 사용자를 생성하고 관리하는 것이 좋습니다.

---

결론적으로, **B 옵션**이 루트 사용자의 보안을 강화하는 데 가장 적합한 솔루션이며, **IAM 사용자 생성과 다중 인증 활성화**가 필수적입니다.

# 746
### 정답: **A, C**

---

### 해설:

1. **A. 각 EC2 인스턴스에서 향상된 네트워킹을 활성화하고 구성**
   - **향상된 네트워킹**은 EC2 인스턴스에서 네트워크 성능을 크게 향상시킵니다. 이는 높은 대역폭과 낮은 대기 시간을 제공하여 실시간 데이터 스트리밍 처리에 적합합니다.

2. **C. EC2 인스턴스를 클러스터 배치 그룹에 배치**
   - **클러스터 배치 그룹**은 인스턴스를 단일 가용 영역 내에서 물리적으로 가까운 위치에 배치합니다. 이는 노드 간의 네트워크 지연을 줄이고 높은 대역폭을 제공하여 실시간 처리 성능을 향상시킵니다.

---

### 다른 보기가 정답이 될 수 없는 이유:

#### B. EC2 인스턴스를 별도의 계정에 그룹화
   - **별도의 계정에 인스턴스를 그룹화하는 것**은 네트워크 지연을 줄이지 않으며, 오히려 여러 계정 간의 통신에서 추가적인 복잡성을 초래할 수 있습니다.

#### D. 각 EC2 인스턴스에 여러 개의 탄력적 네트워크 인터페이스 부착
   - 여러 개의 **탄력적 네트워크 인터페이스**를 부착하는 것은 특정 상황에서 유용할 수 있지만, 기본적으로 **네트워크 대역폭을 증가시키는 데 큰 영향을 미치지 않습니다**. 실시간 데이터 처리에 필요한 **지연 시간 감소에는 한계가 있습니다**.

#### E. Amazon EBS 최적화 인스턴스 유형 사용
   - **EBS 최적화 인스턴스 유형**은 EBS 볼륨과의 성능을 향상시키지만, 이는 주로 스토리지 성능과 관련이 있습니다. 네트워크 지연을 줄이는데 직접적인 영향을 미치지 않으므로, 실시간 데이터 스트리밍의 요구를 충족하는 데는 부족합니다.

---

결론적으로, **A와 C 옵션**이 네트워크 성능을 최적화하고 낮은 대기 시간을 유지하여 실시간 데이터 처리를 지원하는 최적의 솔루션입니다.

# 747
### 정답: **C**

---

### 해설:

1. **C. AWS DataSync를 사용하여 Amazon FSx for Windows File Server로 데이터 마이그레이션**
   - **AWS DataSync**는 대량의 데이터 및 파일을 AWS로 쉽게 전송할 수 있는 서비스입니다. SMB 기반 파일 스토리지에서 데이터를 효율적으로 마이그레이션할 수 있습니다.
   - **Amazon FSx for Windows File Server**는 SMB 프로토콜을 지원하므로, 기존의 파일 저장소를 그대로 사용할 수 있으며, 애플리케이션 변경 없이 데이터를 접근할 수 있습니다. 이 방식은 비즈니스 애플리케이션의 연속성을 보장하면서 운영 오버헤드를 최소화할 수 있습니다.

---

### 다른 보기가 정답이 될 수 없는 이유:

#### A. AWS Direct Connect를 사용하여 Amazon S3로 데이터 마이그레이션
   - **AWS Direct Connect**는 네트워크 연결을 제공하지만, **작은 파일을 대량으로 처리하는 데는 적합하지 않습니다**. S3는 객체 스토리지이므로 기존의 SMB 기반 파일 구조를 그대로 유지하는 것이 어렵고, 애플리케이션 변경이 필요할 수 있습니다.

#### B. AWS DataSync를 사용하여 Amazon FSx for Lustre로 데이터 마이그레이션
   - **Amazon FSx for Lustre**는 고성능 컴퓨팅을 위한 파일 시스템으로, **SMB 기반의 기존 스토리지와 호환되지 않**습니다. 또한, Lustre는 일반적으로 고속 처리와 대량의 데이터를 처리하는 용도로 설계되었지만, 기존의 파일 접근 방식에 적합하지 않을 수 있습니다.

#### D. AWS Direct Connect를 사용하여 온프레미스 파일 스토리지를 AWS Storage Gateway 볼륨 게이트웨이로 마이그레이션
   - **AWS Storage Gateway의 볼륨 게이트웨이는 블록 스토리지**로 설계되었으며, SMB 기반의 파일 스토리지와는 다르게 작동합니다. 이는 파일 기반 데이터 접근에 적합하지 않고, 복잡한 파일 구조와 큰 데이터 양을 처리하기에 비효율적일 수 있습니다.

---

결론적으로, **C 옵션**이 기존의 SMB 기반 스토리지와의 호환성을 유지하며 데이터를 효율적으로 마이그레이션하고 운영 오버헤드를 최소화하는 최적의 솔루션입니다.

# 748
### 정답: **A**

---

### 해설:

1. **A. CloudWatch 교차 계정 가시성을 모니터링 계정에서 활성화하고, 각 AWS 계정에서 데이터를 모니터링 계정과 공유하기 위해 제공된 AWS CloudFormation 템플릿을 배포**
   - **CloudWatch 교차 계정 가시성** 기능을 사용하면 여러 AWS 계정에서 CloudWatch 메트릭 및 로그를 통합하여 모니터링 계정에서 시각화할 수 있습니다. 이 방법은 각 계정에서 모니터링 계정으로 데이터를 효율적으로 수집하고 시각화할 수 있도록 지원합니다.
   - 제공된 CloudFormation 템플릿을 사용하면 각 계정에서 필요한 리소스 및 권한을 설정하는 과정을 자동화하여 운영 오버헤드를 줄일 수 있습니다.

---

### 다른 보기가 정답이 될 수 없는 이유:

#### B. 서비스 제어 정책(SCP)을 설정하여 모니터링 계정의 CloudWatch 접근 권한 제공
   - SCP는 AWS Organizations에서 계정 또는 OU에 대한 서비스 접근을 제어하는 데 사용됩니다. 하지만 SCP를 설정하는 것만으로는 CloudWatch의 가시성을 확보할 수 없으며, 데이터 공유를 위해 추가적인 설정이 필요합니다.

#### C. 모니터링 계정에 새로운 IAM 사용자를 구성하고, 각 AWS 계정에서 CloudWatch 데이터에 접근할 수 있도록 IAM 정책 구성
   - 새로운 IAM 사용자를 만들고 정책을 구성하는 방식은 가능하지만, 이는 수동적인 접근 방식으로 **각 계정에서 직접 데이터를 수집하여 모니터링 계정으로 보내는 방식**이 아니므로 효율적이지 않습니다.

#### D. 모니터링 계정에 새로운 IAM 사용자 생성 후, 각 AWS 계정에 교차 계정 IAM 정책 생성
   - 이 방법은 여러 IAM 정책을 수동으로 구성하고 관리해야 하므로, 운영 오버헤드가 증가합니다. 데이터의 자동 수집 및 시각화를 위한 전반적인 솔루션이 아닙니다.

---

결론적으로, **A 옵션**이 교차 계정의 CloudWatch 데이터를 효율적으로 수집하고 모니터링 계정에서 시각화할 수 있는 가장 적합한 솔루션입니다.

# 750
### 정답: **C**

---

### 해설:

1. **C. AWS IAM Identity Center (AWS Single Sign-On) 구성 후 기존 IdP에 연결하고 사용자를 프로비저닝**
   - **AWS IAM Identity Center**는 AWS의 사용자 관리 및 Single Sign-On(SSO) 솔루션으로, 기존의 **IdP와 통합하여 사용자를 프로비저닝**할 수 있습니다. 이를 통해 여러 AWS 계정에 대한 접근을 중앙 집중식으로 관리할 수 있으며, 수천 명의 직원에게 효율적으로 접근 권한을 부여할 수 있습니다. 이 방법은 사용자 경험을 향상시키고 관리 오버헤드를 줄입니다.

---

### 다른 보기가 정답이 될 수 없는 이유:

#### A. 필요한 AWS 계정에 대한 IAM 사용자 생성 후 기존 IdP와 연결
   - **IAM 사용자 생성은 대규모 조직에서 비효율적**이며, 사용자가 수천 명일 경우 각각의 IAM 사용자를 관리하는 것은 관리 오버헤드를 증가시킵니다. 또한, **IdP와 IAM 사용자의 연결**은 복잡성을 추가합니다.

#### B. AWS 계정 루트 사용자 설정 후 이메일 주소와 비밀번호를 기존 IdP에서 동기화
   - 루트 사용자 계정은 **보안상 권장되지 않으며**, 여러 계정에 대한 접근 관리를 비효율적으로 만듭니다. 루트 계정은 최소한으로 사용해야 하며, 사용자 인증 관리를 위해서는 적합하지 않습니다.

#### D. AWS Resource Access Manager (AWS RAM)를 사용하여 AWS 계정에 대한 접근 공유
   - AWS RAM은 리소스 공유에 사용되지만, **인증 및 사용자 관리 기능을 제공하지 않습니다**. 기존 IdP를 통한 사용자 인증을 구현하기 위해서는 IAM Identity Center와 같은 솔루션이 필요합니다.

---

결론적으로, **C 옵션**이 기존 IdP를 활용하여 효율적이고 안전한 사용자 인증 및 접근 관리를 제공하는 최적의 솔루션입니다.

# 751
### 정답: **C**

---

### 해설:

1. **C. AdministratorAccess 아이덴티티 기반 정책을 IAM 사용자 그룹에 연결하고, 다섯 명의 지정된 직원 IAM 사용자를 IAM 사용자 그룹에 배치**
   - **AdministratorAccess 정책**은 AWS 계정의 모든 서비스와 리소스에 대한 전체 접근 권한을 부여합니다. IAM 사용자 그룹에 이 정책을 연결하면 그룹에 속한 모든 IAM 사용자(즉, 다섯 명의 직원)가 자동으로 이 권한을 상속받게 됩니다. 이를 통해 관리가 간편해지며, 필요한 권한을 효율적으로 부여할 수 있습니다.

---

### 다른 보기가 정답이 될 수 없는 이유:

#### A. AdministratorAccess 리소스 기반 정책을 IAM 사용자 그룹에 연결
   - **리소스 기반 정책**은 주로 S3 버킷과 같은 특정 리소스에 직접 연결되며, IAM 사용자 그룹에는 적용될 수 없습니다. IAM 사용자 그룹에는 **아이덴티티 기반 정책**이 필요합니다.

#### B. SystemAdministrator 아이덴티티 기반 정책을 IAM 사용자 그룹에 연결
   - **SystemAdministrator 정책**은 AWS 서비스에 대한 전반적인 관리 권한을 제공하지만, **AdministratorAccess 정책**만큼 포괄적인 권한을 제공하지 않으며, 모든 AWS 리소스에 대한 접근을 보장하지 않습니다.

#### D. SystemAdministrator 리소스 기반 정책을 IAM 사용자 그룹에 연결
   - 리소스 기반 정책은 IAM 사용자 그룹에 연결할 수 없습니다. 또한, SystemAdministrator 정책이 더 제한적이므로, 요구사항을 충족하지 못합니다.

---

결론적으로, **C 옵션**이 다섯 명의 직원에게 필요한 모든 권한을 부여하는 최적의 솔루션입니다.


# 752
### 정답: **A** 및 **D**

---

### 해설:

1. **A. AWS Lambda를 아키텍처의 컴퓨팅 레이어에 사용**
   - **AWS Lambda**는 서버리스 컴퓨팅 서비스로, 인프라 관리가 필요 없습니다. Lambda를 사용하면 애플리케이션의 각 레이어에서 필요한 기능을 자동으로 확장하고 관리할 수 있으며, 요청이 있을 때마다 코드를 실행합니다. 이는 운영 오버헤드를 줄이는 데 유리합니다.

2. **D. Amazon Simple Queue Service (Amazon SQS) FIFO 큐를 컴퓨팅 레이어 간의 메시징 구성 요소로 사용**
   - **SQS FIFO 큐**는 **정확히 한 번**(exactly-once) 배달을 보장하며, 메시지가 삽입된 순서대로 처리되도록 보장합니다. 따라서, 결제 처리와 같이 메시지의 순서와 정확한 배달이 중요한 애플리케이션에 적합합니다. SQS는 또한 인프라 관리의 필요성을 줄여줍니다.

---

### 다른 보기가 정답이 될 수 없는 이유:

#### B. Amazon EC2 인스턴스를 아키텍처의 컴퓨팅 레이어에 사용
   - **EC2 인스턴스는 인프라 관리가 필요**합니다. 서버를 직접 관리해야 하며, 운영 체제 및 소프트웨어 패치, 확장 등 다양한 관리 작업이 요구됩니다. 이는 최소한의 인프라 관리 요구 사항에 부합하지 않습니다.

#### C. Amazon Simple Notification Service (Amazon SNS)를 컴퓨팅 레이어 간의 메시징 구성 요소로 사용
   - **SNS는 게시-구독 모델을 사용**하므로, 메시지가 여러 구독자에게 전달됩니다. SNS는 메시지의 정확한 한 번 전달을 보장하지 않기 때문에, 결제 처리와 같이 메시지의 중복 처리가 허용되지 않는 경우에는 적합하지 않습니다.

#### E. Amazon Elastic Kubernetes Service (Amazon EKS)를 기반으로 하는 컨테이너를 아키텍처의 컴퓨팅 레이어에 사용
   - **EKS는 Kubernetes를 관리하는 서비스로**, 여전히 인프라 및 컨테이너 관리를 요구합니다. Kubernetes 클러스터를 운영하는 것은 상대적으로 복잡하며, 최소한의 관리 요구 사항에 부합하지 않습니다.

---

결론적으로, **A 옵션**과 **D 옵션**이 정확히 한 번 전달을 보장하면서 인프라 관리 요구를 최소화하는 최적의 조합입니다.

# 756
### 정답: **A**

---

### 해설:

1. **A. Object Lambda Access Point를 생성하고, AWS Lambda 함수를 만들어 파일을 읽을 때 PII를 마스킹합니다. 외부 서비스 제공자가 Object Lambda Access Point에 접근하도록 지시합니다.**
   - **Object Lambda Access Point**는 Amazon S3에 저장된 객체에 대해 실시간으로 데이터를 변환할 수 있는 기능을 제공합니다. 이를 통해 Lambda 함수가 PII를 마스킹하면서 외부 서비스 제공자가 필요한 샘플 대화를 안전하게 접근할 수 있도록 할 수 있습니다.
   - 이 방법은 PII를 노출하지 않으면서도 **운영 오버헤드를 최소화**하며, 수요에 따라 확장 가능합니다. Lambda 함수는 자동으로 스케일링되므로 대화 수가 증가하더라도 성능 저하 없이 처리할 수 있습니다.

---

### 다른 보기가 정답이 될 수 없는 이유:

#### B. Amazon EC2 인스턴스에서 배치 프로세스를 생성
   - EC2 인스턴스를 사용하는 방법은 **운영 관리 오버헤드**가 높습니다. 인스턴스를 지속적으로 운영하고 모니터링해야 하며, 스케일링에도 추가 작업이 필요합니다. 또한, 모든 파일을 정기적으로 읽어야 하므로 리소스 낭비가 발생할 수 있습니다.

#### C. Amazon EC2 인스턴스에서 웹 애플리케이션을 생성
   - 웹 애플리케이션을 운영하면 UI와 서버 관리의 복잡성이 증가합니다. 또한, PII를 마스킹하는 기능을 직접 구현해야 하므로 보안과 유지 관리에 추가적인 노력이 필요합니다. 또한, 외부 서비스 제공자가 직접 접근해야 하므로 보안 관리가 더 복잡해질 수 있습니다.

#### D. Amazon DynamoDB 테이블을 생성하고 Lambda 함수를 사용
   - DynamoDB에 데이터를 저장하는 방법은 좋은 선택일 수 있지만, 모든 새 파일을 처리하고 비PII 데이터를 저장하는 Lambda 함수를 계속 실행해야 하므로 **운영 오버헤드**가 증가할 수 있습니다. 추가적으로, DynamoDB의 관리와 쿼리 처리도 고려해야 하므로 복잡성이 증가합니다.

---

결론적으로, **A 옵션**은 PII를 안전하게 처리하면서 최소한의 운영 오버헤드로 요구사항을 충족할 수 있는 최적의 솔루션입니다.

# 757
### 정답: **C**

---

### 해설:

1. **C. Create an Amazon CloudWatch alarm to recover the EC2 instance in case of failure.**
   - CloudWatch 알람을 설정하면 EC2 인스턴스에 문제가 발생했을 때 자동으로 복구할 수 있는 조치를 취할 수 있습니다. 예를 들어, EC2 인스턴스가 비정상 상태로 전환되면 CloudWatch가 감지하여 해당 인스턴스를 자동으로 재시작할 수 있습니다. 이는 **복구 시간을 개선**하는 데 도움을 주며, 시스템이 한 대의 인스턴스에서만 실행되더라도 기본적인 복원력을 제공할 수 있습니다.

---

### 다른 보기가 정답이 될 수 없는 이유:

#### A. Enable termination protection for the EC2 instance.
   - **종료 보호**는 인스턴스가 실수로 종료되는 것을 방지하는 기능입니다. 그러나 이 기능은 **복구 시간**을 개선하는 데 직접적인 영향을 미치지 않습니다. 인스턴스가 다운되거나 문제가 발생했을 때 자동 복구를 제공하지 않습니다.

#### B. Configure the EC2 instance for Multi-AZ deployment.
   - **Multi-AZ 배포**는 Amazon RDS와 같은 서비스에 적용되는 개념으로, EC2 인스턴스에는 적용되지 않습니다. EC2 인스턴스는 여러 가용 영역에서 실행할 수 없으므로 이 옵션은 불가능합니다.

#### D. Launch the EC2 instance with two Amazon Elastic Block Store (Amazon EBS) volumes that use RAID configurations for storage redundancy.
   - RAID 구성을 사용하는 EBS 볼륨을 두 개 사용하는 것은 **데이터의 내결함성을 향상**시킬 수는 있지만, 인스턴스가 다운되었을 때 **자동으로 복구**되도록 설정할 수는 없습니다. 이 방법은 애플리케이션이 여전히 한 인스턴스에서만 실행되고 있기 때문에 복구 시간을 개선하는 데 효과적이지 않습니다.

---

결론적으로, **C 옵션**이 가장 적합한 해결책으로, EC2 인스턴스의 복구 시간을 최소화하고 신뢰성을 높이는 데 도움이 됩니다.

# 759
이 문제에서 요구사항은 다음과 같습니다:

1. 사용자 구매 후 5분 이내에 영화 스트리밍 콘텐츠를 제공해야 합니다.
2. 20년 이하의 최신 영화에 대한 수요가 더 높습니다.
3. 수요에 따라 호스팅 서비스 비용을 최소화해야 합니다.

이 요구 사항을 고려할 때 각 옵션을 평가해 보겠습니다:

### 옵션 분석

A. **Store all media content in Amazon S3. Use S3 Lifecycle policies to move media data into the Infrequent Access tier when the demand for a movie decreases.**
   - 이 옵션은 모든 콘텐츠를 S3에 저장하고 수요가 줄어들면 Infrequent Access로 이동합니다. 그러나 영화의 스트리밍 요구 사항에 따라 S3 Standard-IA는 적합하지 않으며, 특히 5분 이내에 콘텐츠를 제공하는 것에는 제한적일 수 있습니다.

B. **Store newer movie video files in S3 Standard. Store older movie video files in S3 Standard-infrequent Access (S3 Standard-IA). When a user orders an older movie, retrieve the video file by using standard retrieval.**
   - 최신 영화는 S3 Standard에 저장하고, 20년 이상의 영화는 S3 Standard-IA에 저장합니다. Standard-IA는 표준 검색 속도를 제공하므로 이 옵션은 5분 이내에 콘텐츠를 제공할 수 있습니다. 또한, 수요가 낮은 오래된 영화에 대한 비용 절감도 가능하므로 적절한 선택입니다.

C. **Store newer movie video files in S3 Intelligent-Tiering. Store older movie video files in S3 Glacier Flexible Retrieval. When a user orders an older movie, retrieve the video file by using expedited retrieval.**
   - 최신 영화는 Intelligent-Tiering에 저장하고, 오래된 영화는 Glacier Flexible Retrieval에 저장합니다. Glacier는 기본적으로 저렴한 저장소이지만, 스트리밍을 위해서는 긴 검색 시간이 필요합니다. 이 옵션은 5분 이내에 제공할 수 없으므로 적합하지 않습니다.

D. **Store newer movie video files in S3 Standard. Store older movie video files in S3 Glacier Flexible Retrieval. When a user orders an older movie, retrieve the video file by using bulk retrieval.**
   - 최신 영화는 S3 Standard에 저장하고, 오래된 영화는 Glacier Flexible Retrieval에 저장하는 옵션입니다. Glacier의 경우 표준 검색은 최대 수 시간까지 걸릴 수 있으며, 5분 이내에 제공할 수 없습니다. 따라서 이 옵션도 부적합합니다.

### 결론

위의 분석에 따르면 **B** 옵션이 가장 적합합니다. 

**B. Store newer movie video files in S3 Standard. Store older movie video files in S3 Standard-infrequent Access (S3 Standard-IA). When a user orders an older movie, retrieve the video file by using standard retrieval.** 

이 방법은 최신 영화에 대해 높은 성능을 제공하고, 오래된 영화에 대해 비용 효율적인 저장 옵션을 제공합니다.

# 761
이 요구 사항에서 회사는 온프레미스 LDAP 디렉터리 서비스를 사용하여 AWS Management Console에 대한 사용자 인증을 수행해야 하며, 해당 디렉터리 서비스가 SAML과 호환되지 않습니다. 각 옵션을 분석하여 요구 사항을 충족하는 최적의 솔루션을 찾아보겠습니다.

### 옵션 분석

A. **Enable AWS IAM Identity Center (AWS Single Sign-On) between AWS and the on-premises LDAP.**
   - AWS IAM Identity Center는 SAML 기반의 인증을 지원합니다. 그러나 요구 사항에 명시된 것처럼 LDAP이 SAML과 호환되지 않으므로 이 옵션은 적합하지 않습니다.

B. **Create an IAM policy that uses AWS credentials, and integrate the policy into LDAP.**
   - IAM 정책을 LDAP에 통합하는 것은 불가능합니다. LDAP는 AWS IAM과 통합되어 작동하지 않으므로 이 옵션도 적합하지 않습니다.

C. **Set up a process that rotates the IAM credentials whenever LDAP credentials are updated.**
   - 이 옵션은 IAM 자격 증명을 수동으로 관리해야 하므로 운영 오버헤드가 증가합니다. 또한, LDAP의 변경 사항에 따라 IAM 자격 증명을 자동으로 업데이트하는 것은 복잡한 프로세스가 될 수 있습니다. 따라서 이 방법도 비효율적입니다.

D. **Develop an on-premises custom identity broker application or process that uses AWS Security Token Service (AWS STS) to get short-lived credentials.**
   - 이 옵션은 온프레미스에서 사용자 인증을 처리하는 맞춤형 애플리케이션을 개발하는 것을 의미합니다. 이 애플리케이션은 LDAP에서 사용자 자격 증명을 가져와 AWS STS를 통해 짧은 수명의 자격 증명을 요청할 수 있습니다. 이렇게 하면 LDAP과 AWS 간의 호환성 문제를 해결하고 AWS Management Console에 대한 액세스를 안전하게 제공할 수 있습니다.

### 결론

위의 분석에 따르면 **D** 옵션이 가장 적합합니다.

**D. Develop an on-premises custom identity broker application or process that uses AWS Security Token Service (AWS STS) to get short-lived credentials.**

이 방법은 LDAP과 AWS 간의 연결을 적절하게 처리하면서, 사용자가 AWS Management Console에 인증할 수 있도록 하는 유연하고 안전한 솔루션을 제공합니다.

# 762
회사는 중요한 데이터를 포함한 여러 개의 Amazon Machine Images (AMIs)를 사용하고 있으며, AMIs가 실수로 삭제되는 경우 신속하고 효율적으로 복구할 수 있는 솔루션을 구현하고자 합니다. 각 옵션을 분석하여 가장 적합한 솔루션을 찾겠습니다.

### 옵션 분석

A. **Create Amazon Elastic Block Store (Amazon EBS) snapshots of the AMIs. Store the snapshots in a separate AWS account.**
   - EBS 스냅샷을 사용하여 AMI를 백업할 수 있지만, AMI는 이미 EBS 볼륨을 기반으로 하므로 스냅샷을 생성하는 것만으로는 완전한 AMI 복구를 보장하지 않습니다. 또한, 별도의 AWS 계정에 저장하면 관리가 복잡해질 수 있습니다.

B. **Copy all AMIs to another AWS account periodically.**
   - 주기적으로 모든 AMI를 다른 AWS 계정으로 복사하는 것은 AMI의 손실에 대한 대비책이 될 수 있지만, 이 방법은 수동 작업이 필요하고 정기적으로 실행해야 하므로 운영 오버헤드가 증가할 수 있습니다.

C. **Create a retention rule in Recycle Bin.**
   - AWS의 Recycle Bin 기능을 사용하면 삭제된 리소스를 복구할 수 있는 좋은 방법이 됩니다. 이 방법은 AMI의 삭제를 감지하고, 설정된 보존 기간 동안 삭제된 AMI를 복구할 수 있습니다. 운영 오버헤드가 낮고 간편하게 관리할 수 있습니다.

D. **Upload the AMIs to an Amazon S3 bucket that has Cross-Region Replication.**
   - AMI를 S3 버킷에 업로드하는 것은 가능하지만, AMI는 EC2와 관련된 리소스이므로 직접적으로 S3에 업로드하거나 Cross-Region Replication을 사용할 수 없습니다. 이 방법은 AMI 복구에 적합하지 않습니다.

### 결론

이 분석에 따르면 **C** 옵션이 가장 적합합니다.

**C. Create a retention rule in Recycle Bin.**

이 방법은 AMI가 삭제된 경우 신속하게 복구할 수 있도록 하며, 운영 오버헤드가 가장 낮은 솔루션입니다. Recycle Bin을 사용하면 삭제된 AMI를 간편하게 관리할 수 있습니다.

# 765
이 시나리오에서는 다른 회사가 개발 팀의 Amazon SQS 큐에 액세스할 수 있도록 하면서도 그들의 AWS 계정 권한을 유지하고 싶어합니다. 가장 적절한 방법을 선택하기 위해 각 옵션을 살펴보겠습니다.

### 옵션 분석

A. **Create an instance profile that provides the other company access to the SQS queue.**
   - 인스턴스 프로파일은 EC2 인스턴스에 IAM 역할을 부여하기 위해 사용됩니다. 다른 회사의 SQS 큐 접근 권한을 제공하는 데 적합하지 않습니다.

B. **Create an IAM policy that provides the other company access to the SQS queue.**
   - IAM 정책은 특정 사용자, 그룹 또는 역할에 권한을 부여하는 데 사용됩니다. 그러나 다른 회사의 AWS 계정에 IAM 정책을 적용할 수 없기 때문에 이 옵션은 해당 회사에 대한 직접적인 액세스를 제공하는 데 적합하지 않습니다.

C. **Create an SQS access policy that provides the other company access to the SQS queue.**
   - SQS 접근 정책을 사용하면 특정 AWS 계정이나 IAM 사용자에게 SQS 큐에 대한 권한을 부여할 수 있습니다. 이 옵션은 다른 회사가 자신의 AWS 계정 권한을 포기하지 않고도 SQS 큐에 접근할 수 있도록 하는 가장 적합한 방법입니다.

D. **Create an Amazon Simple Notification Service (Amazon SNS) access policy that provides the other company access to the SQS queue.**
   - SNS 접근 정책은 SNS와 관련된 권한을 제어합니다. SQS 큐에 대한 액세스를 제공하기 위한 방법이 아니므로 이 옵션은 적절하지 않습니다.

### 결론

가장 적합한 솔루션은 **C. Create an SQS access policy that provides the other company access to the SQS queue.**입니다.

이 접근 방식을 통해 개발 팀의 AWS 계정 내 SQS 큐에 대한 액세스를 다른 회사에 부여할 수 있으며, 다른 회사는 자신의 AWS 계정 권한을 유지하면서 큐에 액세스할 수 있습니다.

# 767
이 시나리오에서는 제약회사가 방대한 양의 데이터를 생성하고 있으며, 연구원들이 데이터의 하위 집합에 즉시 접근할 수 있는 방법을 원하고 있습니다. 그러나 전체 데이터셋을 매일 사용할 필요는 없습니다. 현재 데이터는 온프레미스 스토리지 어레이에 저장되어 있으며, 회사는 지속적인 자본 비용을 줄이기를 원합니다.

### 옵션 분석

A. **Run AWS DataSync as a scheduled cron job to migrate the data to an Amazon S3 bucket on an ongoing basis.**
   - 이 방법은 데이터를 Amazon S3로 지속적으로 전송할 수 있지만, 즉각적인 데이터 접근성 요구 사항에 최적화되어 있지 않습니다. 데이터를 전송한 후에는 S3에서 데이터에 접근해야 하므로, 데이터에 대한 낮은 지연 시간을 보장하지 않습니다.

B. **Deploy an AWS Storage Gateway file gateway with an Amazon S3 bucket as the target storage. Migrate the data to the Storage Gateway appliance.**
   - 파일 게이트웨이는 온프레미스 애플리케이션이 Amazon S3에 직접 접근할 수 있도록 하는 좋은 방법입니다. 이는 파일 시스템을 사용하여 S3에 데이터를 저장하며, 데이터 접근성이 향상됩니다. 즉각적인 데이터 접근이 필요한 경우 유용합니다.

C. **Deploy an AWS Storage Gateway volume gateway with cached volumes with an Amazon S3 bucket as the target storage. Migrate the data to the Storage Gateway appliance.**
   - 볼륨 게이트웨이는 블록 저장소를 제공하며, 캐시된 볼륨을 사용하면 온프레미스 환경에서 데이터에 대한 낮은 지연 시간을 유지할 수 있습니다. 그러나 이 경우는 전체 데이터셋에 대한 지속적인 접근성을 보장하지 않을 수 있습니다.

D. **Configure an AWS Site-to-Site VPN connection from the on-premises environment to AWS. Migrate data to an Amazon Elastic File System (Amazon EFS) file system.**
   - 이 방법은 EFS를 통해 데이터를 액세스할 수 있지만, AWS와 온프레미스 간의 VPN 연결은 추가적인 관리 작업을 요구합니다. 또한, EFS는 일관된 데이터 접근성이 필요할 때 유용하지만, 비용 측면에서 효율적이지 않을 수 있습니다.

### 결론

가장 적합한 솔루션은 **B. Deploy an AWS Storage Gateway file gateway with an Amazon S3 bucket as the target storage. Migrate the data to the Storage Gateway appliance.**입니다.

이 방법은 데이터의 하위 집합에 즉시 접근할 수 있도록 하며, 데이터는 Amazon S3에 안전하게 저장됩니다. 또한, 지속적인 자본 비용을 줄일 수 있는 효율적인 방법입니다.

# 768
이 시나리오에서는 회사가 Amazon DynamoDB 테이블의 데이터를 관리하며, 마지막 24시간 이내의 어떤 시점으로든 테이블을 되돌릴 수 있는 방법을 요구하고 있습니다. 운영 오버헤드를 최소화하면서 이러한 요구를 충족하는 솔루션을 찾아야 합니다.

### 옵션 분석

A. **Configure point-in-time recovery for the table.**
   - DynamoDB의 포인트 인 타임 복구(Point-in-Time Recovery, PITR)를 설정하면 테이블의 모든 변경사항을 기록하여 24시간 이내의 특정 시점으로 되돌릴 수 있습니다. 이 기능은 자동으로 관리되므로 운영 오버헤드가 거의 없습니다.

B. **Use AWS Backup for the table.**
   - AWS Backup을 사용하여 DynamoDB 테이블의 백업을 수행할 수 있지만, 이 경우 백업 주기를 설정해야 하며, 즉각적인 복구는 보장되지 않습니다. 운영 오버헤드가 상대적으로 더 클 수 있습니다.

C. **Use an AWS Lambda function to make an on-demand backup of the table every hour.**
   - AWS Lambda 함수를 사용하여 매시간 테이블의 백업을 생성하는 방법은 유연성을 제공하지만, 이 또한 추가적인 관리 및 비용이 발생합니다. 운영 오버헤드가 증가할 수 있습니다.

D. **Turn on streams on the table to capture a log of all changes to the table in the last 24 hours. Store a copy of the stream in an Amazon S3 bucket.**
   - 스트림을 사용하면 테이블에 대한 변경 사항을 기록할 수 있지만, 이러한 변경 사항을 통해 이전 상태로 되돌리는 과정은 추가적인 복잡성을 수반할 수 있습니다. 운영 오버헤드가 더 클 수 있습니다.

### 결론

가장 적합한 솔루션은 **A. Configure point-in-time recovery for the table.**입니다.

이 방법은 DynamoDB의 내장 기능을 활용하여 운영 오버헤드 없이 요구 사항을 충족합니다. 포인트 인 타임 복구를 설정하면 마지막 24시간 이내의 어떤 시점으로든 테이블을 간편하게 되돌릴 수 있습니다.

# 770
이 시나리오에서는 회사가 AWS에서 애플리케이션을 실행하는 데 드는 비용을 최적화하고자 하며, 프로덕션 인스턴스는 항상 사용되고, 비프로덕션 인스턴스는 주중 비즈니스 시간 동안만 사용된다는 점을 고려해야 합니다.

### 옵션 분석

A. **Use On-Demand Instances for the production instances. Use Dedicated Hosts for the nonproduction instances on weekends only.**
   - 프로덕션 인스턴스에 온디맨드 인스턴스를 사용하는 것은 유연성을 제공하지만, 비프로덕션 인스턴스에 대한 전반적인 비용 최적화에는 효과적이지 않을 수 있습니다. 주말 동안만 전용 호스트를 사용하는 것도 비효율적입니다.

B. **Use Reserved Instances for the production instances and the nonproduction instances. Shut down the nonproduction instances when not in use.**
   - 프로덕션 인스턴스와 비프로덕션 인스턴스 모두에 예약 인스턴스를 사용하는 것은 장기적으로 비용을 절감할 수 있습니다. 하지만 비프로덕션 인스턴스를 사용하지 않는 주말 동안에도 비용이 발생합니다.

C. **Use Compute Savings Plans for the production instances. Use On-Demand Instances for the nonproduction instances. Shut down the nonproduction instances when not in use.**
   - 프로덕션 인스턴스에 대한 컴퓨트 세이빙 플랜을 사용하면 장기적으로 비용을 절감할 수 있으며, 비프로덕션 인스턴스에 온디맨드 인스턴스를 사용하고 필요하지 않을 때 종료하는 것은 비효율적인 비용을 줄일 수 있습니다.

D. **Use Dedicated Hosts for the production instances. Use EC2 Instance Savings Plans for the nonproduction instances.**
   - 전용 호스트는 고정된 리소스에 대해 높은 비용이 발생할 수 있으며, 비프로덕션 인스턴스에 대한 EC2 인스턴스 세이빙 플랜은 추가적인 비용 절감이 가능하지만, 비효율적인 리소스 사용이 우려됩니다.

### 결론

가장 비용 효율적인 솔루션은 **C. Use Compute Savings Plans for the production instances. Use On-Demand Instances for the nonproduction instances. Shut down the nonproduction instances when not in use.**입니다.

이 방법은 프로덕션 인스턴스에서 세이빙 플랜을 사용하여 비용을 절감하고, 비프로덕션 인스턴스를 필요할 때만 사용하여 불필요한 비용을 최소화합니다.

# 771
이 문제에 대한 정답은 **C**입니다.

### 해설:

1. **요구사항 분석**:
   - Oracle 관계형 데이터베이스에서 Amazon Aurora PostgreSQL로 데이터를 마이그레이션해야 합니다.
   - 마이그레이션 중에 발생하는 소스 데이터베이스의 변경 사항을 캡처해야 합니다.

2. **각 옵션 분석**:
   - **A**: AWS SCT를 사용하여 스키마를 변환하고 AWS DMS의 전체 데이터 마이그레이션 작업을 사용하여 데이터를 마이그레이션합니다. 하지만 이 방법은 변경 사항을 캡처하지 않으므로 요구사항을 충족하지 않습니다.
   
   - **B**: AWS DataSync를 사용하여 데이터를 Amazon S3 버킷으로 마이그레이션한 후, Aurora PostgreSQL에 S3 데이터를 가져옵니다. 이 방법은 변경 사항을 캡처하지 않기 때문에 요구사항을 충족하지 않습니다.
   
   - **C**: AWS SCT를 사용하여 Oracle 스키마를 Aurora PostgreSQL 스키마로 변환하고, AWS DMS를 사용하여 기존 데이터를 마이그레이션하고 ongoing changes를 복제합니다. 이 방법은 요구사항을 충족합니다.
   
   - **D**: AWS Snowball 장치를 사용하여 데이터를 Amazon S3 버킷으로 마이그레이션한 후, Aurora PostgreSQL에 S3 데이터를 가져옵니다. 이 방법 역시 변경 사항을 캡처하지 않으므로 요구사항을 충족하지 않습니다.

3. **결론**:
   - 따라서, **C** 옵션이 요구사항을 가장 잘 충족하는 솔루션입니다. AWS SCT를 사용하여 스키마를 변환하고, AWS DMS를 통해 데이터 마이그레이션과 변경 사항 캡처를 동시에 수행할 수 있습니다.

# 772
   이 문제에 대한 정답은 **A**와 **B**입니다.

### 해설:

1. **요구사항 분석**:
   - Docker 컨테이너로 구축된 애플리케이션을 AWS Cloud에서 실행해야 함.
   - 관리형 서비스를 사용하여 애플리케이션을 호스팅해야 함.
   - 개별 컨테이너 서비스의 수요에 따라 적절하게 스케일 인/아웃해야 함.
   - 추가적인 운영 오버헤드나 관리할 인프라가 없어야 함.

2. **각 옵션 분석**:
   - **A. Use Amazon Elastic Container Service (Amazon ECS) with AWS Fargate**:
     - AWS Fargate는 서버리스 컨테이너 실행 서비스로, 인프라를 관리할 필요 없이 컨테이너를 실행할 수 있습니다. 자동으로 스케일링이 가능하며, 운영 오버헤드가 적습니다.
   
   - **B. Use Amazon Elastic Kubernetes Service (Amazon EKS) with AWS Fargate**:
     - Amazon EKS와 AWS Fargate를 함께 사용하면 Kubernetes를 관리할 필요 없이 컨테이너를 실행할 수 있습니다. EKS의 관리형 Kubernetes 클러스터에서 Fargate를 사용하여 자동으로 스케일링하며, 추가적인 운영 오버헤드가 없습니다.
   
   - **C. Provision an Amazon API Gateway API. Connect the API to AWS Lambda to run the containers**:
     - AWS Lambda는 서버리스 컴퓨팅 서비스를 제공하지만, Lambda는 일반적으로 컨테이너를 직접 실행하지 않으며, Lambda 함수는 특정한 이벤트에 반응하여 실행됩니다. 이 방식은 요구사항에 맞지 않습니다.
   
   - **D. Use Amazon Elastic Container Service (Amazon ECS) with Amazon EC2 worker nodes**:
     - 이 옵션은 Amazon ECS를 사용할 수 있지만, EC2 작업 노드를 사용하면 인프라를 관리해야 하므로 운영 오버헤드가 발생합니다. 따라서 요구사항에 부합하지 않습니다.
   
   - **E. Use Amazon Elastic Kubernetes Service (Amazon EKS) with Amazon EC2 worker nodes**:
     - EKS와 EC2 작업 노드를 사용할 경우에도 인프라를 관리해야 하므로 운영 오버헤드가 발생합니다. 요구사항에 맞지 않습니다.

3. **결론**:
   - 따라서, **A**와 **B** 옵션이 요구사항을 모두 충족하는 솔루션입니다. 두 옵션 모두 관리형 서비스를 사용하며, 컨테이너의 수요에 따라 자동으로 스케일링할 수 있습니다.

# 773
   이 문제에 대한 정답은 **D**입니다.

### 해설:

1. **요구사항 분석**:
   - 이커머스 회사는 시즌 세일을 진행하며, 웹사이트가 갑작스러운 트래픽 증가를 관리할 수 있어야 합니다.
   - 비용 효율적인 솔루션이 필요합니다.

2. **각 옵션 분석**:
   - **A. Create an Auto Scaling group that is large enough to handle peak traffic load. Stop half of the Amazon EC2 instances. Configure the Auto Scaling group to use the stopped instances to scale out when traffic increases.**  
     - 이 방법은 정기적으로 비활성 상태로 있는 EC2 인스턴스를 유지해야 하므로 비용 효율적이지 않습니다. Auto Scaling은 정지된 인스턴스를 사용할 수 없으며, 적절한 대응을 하지 못합니다.
  
   - **B. Create an Auto Scaling group for the website. Set the minimum size of the Auto Scaling group so that it can handle high traffic volumes without the need to scale out.**  
     - 이 방법은 최소 크기를 고정함으로써 오히려 필요 이상의 인스턴스를 유지하게 되어 비용이 증가할 수 있습니다. 트래픽 변화에 따라 적절한 스케일링이 이루어지지 않을 수 있습니다.

   - **C. Use Amazon CloudFront and Amazon ElastiCache to cache dynamic content with an Auto Scaling group set as the origin. Configure the Auto Scaling group with the instances necessary to populate CloudFront and ElastiCache. Scale in after the cache is fully populated.**  
     - CloudFront와 ElastiCache를 사용하는 방법은 캐시된 콘텐츠의 전송 속도를 향상시킬 수 있지만, 초기 설정 및 캐시 생성에 대한 추가적인 복잡성이 발생합니다. 이 경우 비용 효율성과 운영 간편성에서 제한적일 수 있습니다.

   - **D. Configure an Auto Scaling group to scale out as traffic increases. Create a launch template to start new instances from a preconfigured Amazon Machine Image (AMI).**  
     - 이 방법은 트래픽이 증가함에 따라 Auto Scaling 그룹이 자동으로 인스턴스를 확장하도록 설정합니다. 사전 구성된 AMI를 사용하여 새로운 인스턴스를 빠르게 시작할 수 있으므로 빠른 응답성을 보장하고, 필요할 때만 인스턴스를 실행하게 되어 비용 효율적인 솔루션이 됩니다.

3. **결론**:
   - 따라서, **D** 옵션이 요구사항을 가장 잘 충족하며, 비용 효율적인 솔루션으로 트래픽 증가를 효과적으로 처리할 수 있습니다. Auto Scaling 그룹을 통해 트래픽 증가에 대응하여 자동으로 인스턴스를 추가하고, 필요 시 인스턴스를 줄일 수 있습니다.


# 774
정답은 **B**입니다.

### 해설:

1. **요구사항 분석**:
   - 보안 그룹 규칙에서 `0.0.0.0/0`을 통해 SSH 접속을 허용하지 않도록 해야 합니다.
   - 규칙 위반 시 알림을 받아야 하며, 최소한의 운영 오버헤드를 원합니다.

2. **각 옵션 분석**:
   - **A. Write an AWS Lambda script that monitors security groups for SSH being open to 0.0.0.0/0 addresses and creates a notification every time it finds one.**  
     - Lambda 함수를 작성하여 보안 그룹을 주기적으로 모니터링할 수는 있지만, 스크립트를 작성하고 관리해야 하므로 오버헤드가 발생합니다. 운영 측면에서 자동화된 AWS Config 관리 규칙보다 비효율적입니다.

   - **B. Enable the restricted-ssh AWS Config managed rule and generate an Amazon Simple Notification Service (Amazon SNS) notification when a noncompliant rule is created.**  
     - AWS Config의 관리 규칙인 `restricted-ssh` 규칙을 사용하여 보안 그룹의 SSH 접근을 모니터링할 수 있습니다. 규칙 위반 시 자동으로 SNS 알림을 설정할 수 있어, 최소한의 운영 오버헤드로 요구 사항을 충족합니다. 이 옵션은 AWS가 제공하는 기본 규칙을 사용하므로 관리가 쉽습니다.

   - **C. Create an IAM role with permissions to globally open security groups and network ACLs. Create an Amazon Simple Notification Service (Amazon SNS) topic to generate a notification every time the role is assumed by a user.**  
     - IAM 역할을 생성해 권한을 제한할 수 있지만, 보안 그룹의 SSH 규칙을 모니터링하는 데 적합하지 않습니다. 역할이 사용될 때마다 알림이 가는 구조로는 요구사항을 효율적으로 충족하지 못합니다.

   - **D. Configure a service control policy (SCP) that prevents non-administrative users from creating or editing security groups. Create a notification in the ticketing system when a user requests a rule that needs administrator permissions.**  
     - SCP를 사용해 권한을 제한할 수 있지만, SCP는 AWS Organizations에서 조직 전체의 권한 제어를 위해 사용되며 SSH 규칙을 특정 CIDR에 맞춰 제한하는 데는 부적합합니다. 이 옵션은 요구사항과 맞지 않습니다.

3. **결론**:
   - **B 옵션**이 최소한의 운영 오버헤드로 요구사항을 가장 효율적으로 충족합니다. `restricted-ssh` 관리 규칙은 AWS Config에서 자동으로 위반을 모니터링하고, 알림을 설정할 수 있습니다.


# 775
서비스 간 HTTPS 통신을 제공하고 서비스 검색을 위한 서비스 레지스트리를 최소한의 관리 오버헤드로 설계하는 가장 적합한 솔루션은 **B. VPC Lattice 서비스 네트워크 생성**입니다.

### 설명:

**B. VPC Lattice 서비스 네트워크 생성. 마이크로서비스를 서비스 네트워크와 연결. 각 서비스에 대한 HTTPS 리스너 정의. 마이크로서비스 컴퓨팅 리소스를 대상으로 등록. 서비스와 통신해야 하는 VPC 식별. 해당 VPC를 서비스 네트워크와 연결.**

- **서비스 간 통신**: VPC Lattice는 VPC 네트워킹의 복잡성을 추상화하여 마이크로서비스가 HTTPS를 통해 안전하게 통신할 수 있도록 간소화합니다. 별도의 로드 밸런서나 피어링 연결을 설정할 필요가 없습니다.
  
- **서비스 레지스트리**: VPC Lattice는 내장된 서비스 검색 기능을 제공하여 마이크로서비스가 서로 쉽게 발견하고 연결될 수 있게 합니다. 별도의 서비스 레지스트리를 필요로 하지 않습니다.

- **관리 오버헤드**: 이 솔루션은 VPC Lattice가 네트워킹 레이어(서비스 검색 및 안전한 통신 포함)를 관리하므로 관리 오버헤드가 가장 적습니다. 팀은 복잡한 네트워킹 구성 대신 마이크로서비스에 집중할 수 있습니다.

### 다른 옵션과의 비교:

- **A. 검사 VPC 생성**: 이 솔루션은 보안 검사를 제공하지만, 별도의 검사 VPC, 트랜짓 게이트웨이, 방화벽 규칙 관리를 요구하여 복잡성을 증가시킵니다. 따라서 관리 오버헤드가 커집니다.

- **C. 네트워크 로드 밸런서(NLB) 생성**: 이 접근 방식은 각 마이크로서비스에 대한 추가 설정이 필요하고 NLB 및 VPC 엔드포인트 관리를 포함하게 되어 복잡성과 오버헤드가 증가합니다.

- **D. VPC 간 피어링 연결 생성**: 이 솔루션은 여러 피어링 연결, 프리픽스 목록, 라우팅 테이블 관리를 요구하여 복잡성을 더합니다. 마이크로서비스 및 계정 수가 증가할수록 관리가 어려워질 수 있습니다.

### 결론:

**VPC Lattice**를 사용하는 것은 회사가 최소한의 관리 오버헤드로 마이크로서비스 통신 및 서비스 검색을 효율적으로 관리할 수 있게 하여, 제시된 요구 사항에 가장 적합한 솔루션입니다.

# 779
이 문제의 요구 사항을 충족하는 최선의 솔루션은 **A. Mount the EFS file system in read-only mode from within the EC2 instances**입니다.

### 해설

1. **읽기 전용으로 마운트**:
   - Amazon EFS 파일 시스템을 EC2 인스턴스에서 읽기 전용 모드로 마운트하면, 애플리케이션이 파일 시스템을 읽을 수는 있지만 수정하거나 삭제할 수는 없습니다. 이 방법은 애플리케이션이 데이터셋에 대한 변경 권한을 가지지 않도록 직접적인 통제를 제공합니다.

### 다른 선택지의 문제점

- **B. Create a resource policy for the EFS file system that denies the elasticfilesystem:ClientWrite action to the IAM roles that are attached to the EC2 instances**:
   - EFS는 IAM 리소스 정책을 지원하지 않습니다. 따라서, 리소스 정책을 통해 직접적으로 EFS의 파일에 대한 쓰기 권한을 차단할 수 없습니다.

- **C. Create an identity policy for the EFS file system that denies the elasticfilesystem:ClientWrite action on the EFS file system**:
   - IAM 정책은 EFS에 대한 접근을 제어하는 데 유용하지만, 파일 시스템을 읽기 전용으로 마운트하는 것과 같은 직접적인 효과를 제공하지는 않습니다. 이 방법만으로는 애플리케이션의 파일 수정 가능성을 완전히 차단할 수 없습니다.

- **D. Create an EFS access point for each application. Use Portable Operating System Interface (POSIX) file permissions to allow read-only access to files in the root directory**:
   - EFS 접근 포인트를 사용하여 POSIX 권한을 설정하는 것도 가능하지만, 이 방법은 구현이 복잡하고, 읽기 전용으로 파일 시스템을 마운트하는 것보다 관리 오버헤드가 더 클 수 있습니다.

### 결론
따라서, **A** 옵션이 가장 간단하고 효과적인 방법으로, 애플리케이션이 데이터셋을 변경할 수 없도록 보장합니다. EFS를 읽기 전용 모드로 마운트함으로써, 모든 데이터의 무결성을 유지하면서 필요한 데이터 접근을 제공할 수 있습니다.

# 780
   정답은 **A**입니다.

### 해설:

1. **요구사항 분석**:
   - 외부 벤더가 회사의 AWS 계정에 접근해야 하지만, 벤더가 별도의 AWS 계정을 소유하고 있으므로 IAM 사용자 접근이 적합하지 않습니다.
   - 외부 벤더에게 필요한 최소 권한만 제공하고, 보안이 높은 접근 방식을 사용하는 것이 중요합니다.

2. **각 옵션 분석**:
   - **A. Create an IAM role in the company’s account to delegate access to the vendor’s IAM role. Attach the appropriate IAM policies to the role for the permissions that the vendor requires.**  
     - 회사 계정에 IAM 역할을 생성하여 벤더의 IAM 역할에 위임하도록 설정할 수 있습니다. 이 접근 방식은 IAM 역할 간의 신뢰 관계를 활용하여 벤더가 자신의 계정에서 역할을 가정하여 필요한 권한을 얻도록 합니다. 이 방식은 안전하며, 벤더에게 최소 권한만 부여하는데 적합합니다.

   - **B. Create an IAM user in the company’s account with a password that meets the password complexity requirements. Attach the appropriate IAM policies to the user for the permissions that the vendor requires.**  
     - IAM 사용자를 생성하여 벤더에게 공유하는 방식은 보안에 취약하며, 특히 외부 계정에서 접근하는 자동화 도구에는 부적합합니다. 따라서 이 방법은 비추천됩니다.

   - **C. Create an IAM group in the company’s account. Add the automated tool’s IAM user from the vendor account to the group. Attach the appropriate IAM policies to the group for the permissions that the vendor requires.**  
     - AWS IAM 그룹은 외부 계정의 사용자를 직접 추가할 수 없습니다. 이 옵션은 기술적으로 불가능합니다.

   - **D. Create an IAM user in the company’s account that has a permission boundary that allows the vendor’s account. Attach the appropriate IAM policies to the user for the permissions that the vendor requires.**  
     - 권한 경계를 사용한 IAM 사용자 설정은 외부 벤더의 접근을 제한하는 데 부적절하며, 역할 대신 IAM 사용자를 생성하여 보안성을 낮춥니다.

3. **결론**:
   - **A 옵션**이 가장 안전하고 적합한 솔루션입니다. IAM 역할을 이용한 교차 계정 액세스는 보안성이 높고, 최소 권한 원칙을 적용하여 외부 벤더의 접근을 관리할 수 있습니다.

# 781
   정답은 **A**입니다.

### 해설:

1. **요구사항 분석**:
   - 각 부서별로 클라우드 비용에 대한 책임을 지고, 전체 예산의 60%에 도달하면 CFO에게 알림을 보내야 합니다.
   - 비용 추적을 위해 각 리소스에 대한 소유자를 식별할 수 있어야 하고, 예산 초과 시 경고를 받을 수 있는 알림 기능이 필요합니다.

2. **옵션 분석**:
   - **A. Use cost allocation tags on AWS resources to label owners. Create usage budgets in AWS Budgets. Add an alert threshold to receive notification when spending exceeds 60% of the budget.**  
     - 비용 할당 태그를 통해 AWS 리소스에 소유자 레이블을 추가하여 부서별로 리소스 사용을 추적할 수 있습니다. AWS Budgets를 이용해 각 부서의 예산을 설정하고, 지출이 예산의 60%를 초과할 경우 알림을 생성할 수 있습니다. 이 방법은 비용 관리를 위한 실질적인 접근법을 제공합니다.

   - **B. Use AWS Cost Explorer forecasts to determine resource owners. Use AWS Cost Anomaly Detection to create alert threshold notifications when spending exceeds 60% of the budget.**  
     - Cost Explorer는 예산 예측에 유용하지만, 비용 할당 태그만큼 리소스 소유자를 세부적으로 추적하지 않습니다. Cost Anomaly Detection은 예상 지출에 대한 비정상적인 지출에 대한 알림을 제공하지만, 예산의 특정 비율에 도달했을 때 알림을 보내는 기능과는 다릅니다.

   - **C. Use cost allocation tags on AWS resources to label owners. Use AWS Support API on AWS Trusted Advisor to create alert threshold notifications when spending exceeds 60% of the budget.**  
     - AWS Trusted Advisor와 Support API는 특정한 비용 초과 알림보다는 리소스 최적화와 모범 사례 권장 사항에 중점을 둡니다. 따라서 예산 사용 비율 경고를 설정하는 데 적합하지 않습니다.

   - **D. Use AWS Cost Explorer forecasts to determine resource owners. Create usage budgets in AWS Budgets. Add an alert threshold to receive notification when spending exceeds 60% of the budget.**  
     - Cost Explorer는 리소스 소유자 추적을 목적으로 하기보다는 지출 예측에 중점을 둡니다. AWS Budgets를 이용한 예산 설정 및 경고 기능은 유용하나, 리소스별 소유자 추적에는 부족함이 있습니다.

3. **결론**:
   - **A 옵션**이 가장 적합한 솔루션입니다. 비용 할당 태그를 통해 리소스별 소유자를 명확히 구분하고, AWS Budgets의 알림 기능을 통해 예산 60% 도달 시 경고 알림을 설정할 수 있어 요구사항을 완벽히 충족합니다.


# 782
정답은 **B**입니다.

### 해설:

1. **요구사항 분석**:
   - 웹 애플리케이션은 회사 내부에서만 접근 가능해야 하므로 인터넷에서 접근할 수 없도록 해야 합니다.
   - 웹 애플리케이션의 보안 패치를 인터넷에서 다운로드할 수 있어야 합니다.
   - 회사는 AWS Site-to-Site VPN 연결을 통해 VPC와 회사의 사무실 네트워크를 연결해 놓았습니다.

2. **옵션 분석**:
   - **A. Deploy the web application on Amazon EC2 instances in public subnets behind a public Application Load Balancer (ALB). Attach an internet gateway to the VPC. Set the inbound source of the ALB's security group to 0.0.0.0/0.**  
     - ALB가 퍼블릭 ALB이며, 보안 그룹의 인바운드 규칙이 0.0.0.0/0로 설정되어 있습니다. 이 경우 애플리케이션이 인터넷에 공개되므로 보안 요구 사항을 충족하지 않습니다.

   - **B. Deploy the web application on Amazon EC2 instances in private subnets behind an internal Application Load Balancer (ALB). Deploy NAT gateways in public subnets. Attach an internet gateway to the VPC. Set the inbound source of the ALB's security group to the company's office network CIDR block.**  
     - 웹 애플리케이션을 프라이빗 서브넷의 EC2 인스턴스에 배포하고, 내부용 ALB를 사용해 회사 네트워크에서만 접근 가능하도록 구성합니다.
     - NAT 게이트웨이를 퍼블릭 서브넷에 배치하여 EC2 인스턴스가 보안 패치를 인터넷에서 다운로드할 수 있도록 합니다. 이 설정은 요구사항을 충족합니다.

   - **C. Deploy the web application on Amazon EC2 instances in public subnets behind an internal Application Load Balancer (ALB). Deploy NAT gateways in private subnets. Attach an internet gateway to the VPC. Set the outbound destination of the ALB’s security group to the company's office network CIDR block.**  
     - NAT 게이트웨이를 프라이빗 서브넷에 배치하는 것은 일반적인 패턴에 부합하지 않으며, EC2 인스턴스가 인터넷에 접근하기 어렵게 됩니다. 또한 퍼블릭 서브넷에서 내부용 ALB를 사용하는 설정은 보안 요구 사항을 충족하지 않습니다.

   - **D. Deploy the web application on Amazon EC2 instances in private subnets behind a public Application Load Balancer (ALB). Attach an internet gateway to the VPC. Set the outbound destination of the ALB’s security group to 0.0.0.0/0.**  
     - 퍼블릭 ALB는 인터넷에서 접근이 가능해지므로, 웹 애플리케이션이 외부에 노출될 위험이 있습니다. 따라서 보안 요구 사항에 부합하지 않습니다.

3. **결론**:
   - **B 옵션**이 요구 사항을 가장 잘 충족합니다. 내부용 ALB를 사용하여 회사 네트워크에서만 접근할 수 있도록 하고, NAT 게이트웨이를 통해 프라이빗 서브넷의 EC2 인스턴스가 필요한 패치를 인터넷에서 받을 수 있도록 구성함으로써 보안을 유지하면서 요구 사항을 충족할 수 있습니다.


# 783
정답은 **D. Amazon Quantum Ledger Database (Amazon QLDB)** 입니다.

### 해설:

1. **요구사항 분석**:
   - 애플리케이션 데이터를 AWS 관리형 서비스로 마이그레이션하고, 데이터 변경에 대한 불변적이고 암호학적으로 검증 가능한 로그가 필요합니다.
   - 운영 지원이 최소화되길 원하며, 이는 데이터의 정확성, 투명성, 변경 기록을 위한 이력 관리에 중점을 둡니다.

2. **옵션 분석**:
   - **A. Amazon Redshift**  
     - Amazon Redshift는 데이터 웨어하우스 서비스로, 대규모 데이터 분석에 적합하지만 데이터 변경 로그 기능이 없고, 불변 기록을 위한 이력 관리 기능이 부족합니다.
  
   - **B. Amazon Neptune**  
     - Amazon Neptune은 그래프 데이터베이스로, 연결된 데이터를 관리하는 데 최적화되어 있습니다. 하지만 불변성 및 변경에 대한 암호학적 검증이 필요한 회계 데이터에는 적합하지 않습니다.
  
   - **C. Amazon Timestream**  
     - Amazon Timestream은 시계열 데이터베이스로, 데이터 변경 이력 추적 및 불변성 요구사항을 만족시키기 어렵습니다.
  
   - **D. Amazon Quantum Ledger Database (Amazon QLDB)**  
     - Amazon QLDB는 불변의 원장을 제공하는 관리형 원장 데이터베이스입니다. 이 서비스는 변경 불가능한 데이터 기록을 보장하고, 모든 변경 사항에 대해 암호학적으로 검증 가능한 로그를 제공합니다.
     - QLDB는 데이터 변경 기록을 자동으로 관리하고, 불변 로그를 유지하며, 운영 지원이 거의 필요하지 않으므로 요구사항을 가장 잘 충족시킵니다.

3. **결론**:
   - **D 옵션**이 가장 비용 효율적이면서 요구사항을 충족하는 선택입니다. QLDB는 원장의 불변성, 투명성, 데이터 변경 기록을 제공하여 회사의 회계 데이터에 대한 변경 추적 및 감사 기능을 지원합니다.

# 786
정답은 **B. AWS Migration Hub와 AWS Application Discovery Service를 사용하는 것**입니다.

### 해설

1. **요구사항 분석**:
   - 온프레미스 서버와 워크로드의 사용량과 구성 데이터를 수집하여 AWS로의 마이그레이션을 계획하려고 합니다.

2. **옵션 분석**:
   - **A. AWS Migration Hub와 AWS Systems Manager**  
     - AWS Systems Manager는 서버를 관리하고 구성하는 데 유용하지만, 온프레미스 서버의 사용량과 구성을 자동으로 분석하여 마이그레이션 계획을 세우는 데는 적합하지 않습니다.

   - **B. AWS Migration Hub와 AWS Application Discovery Service**  
     - AWS Application Discovery Service는 온프레미스 서버의 구성 및 사용량 데이터를 수집하고 이를 AWS Migration Hub로 통합할 수 있습니다. 이를 통해 온프레미스 자원을 AWS로 이전하는 데 필요한 계획을 수립하는 데 적합한 데이터를 제공할 수 있습니다.
     - Application Discovery Service는 자동으로 서버 메타데이터, 구성, 사용률 등을 수집하여 마이그레이션 요구사항을 충족합니다.

   - **C. AWS Schema Conversion Tool과 AWS Trusted Advisor**  
     - AWS Trusted Advisor는 AWS 환경의 모범 사례를 제공하지만, 온프레미스 환경에 대한 데이터를 수집하는 기능이 없습니다.

   - **D. AWS Schema Conversion Tool과 AWS Database Migration Service**  
     - AWS DMS는 데이터베이스 마이그레이션에 사용되며, 일반적인 서버나 워크로드 데이터 수집에는 적합하지 않습니다.

3. **결론**:
   - **B 옵션**이 가장 적합합니다. AWS Application Discovery Service와 AWS Migration Hub를 사용하면 온프레미스 환경에서 워크로드의 구성 및 사용량을 효과적으로 수집하여 AWS로의 마이그레이션 계획을 세울 수 있습니다.


# 787
정답은 **A. AWS Organizations 관리 계정에서 AWS Control Tower 환경을 배포하고, AWS Security Hub 및 AWS Control Tower Account Factory를 활성화하는 것**입니다.

### 해설

1. **요구사항 분석**:
   - 모든 API 호출과 로그인 활동을 감사할 수 있어야 하고, 모든 계정이 AWS Foundational Security Best Practices(FSBP) 표준을 준수하는지 모니터링해야 합니다.
   - 최소한의 운영 오버헤드와 비용을 원하는 상황입니다.

2. **옵션 분석**:
   - **A. AWS Control Tower 환경을 AWS Organizations 관리 계정에 배포**  
     - **AWS Control Tower**는 관리형 서비스로 다중 계정을 위한 거버넌스, 보안, 모니터링을 설정하고 운영을 간소화합니다. Account Factory를 통해 새 계정을 쉽게 생성하고 규정을 준수하도록 설정할 수 있습니다.
     - **AWS Security Hub**와 통합하여 각 계정이 AWS Foundational Security Best Practices(FSBP) 표준을 준수하는지 모니터링할 수 있습니다.
     - 관리 계정에 Control Tower를 배포하는 것은 최상의 관리 및 보안 모니터링을 위한 권장 설정입니다.

   - **B. AWS Control Tower를 Organizations의 멤버 계정에 배포**  
     - AWS Control Tower를 멤버 계정에 배포하는 것도 가능하지만, 관리 계정에 배포하는 것이 중앙 관리 및 감사에 적합합니다.
   
   - **C와 D. AWS Managed Services (AMS) Accelerate를 사용하여 다중 계정 랜딩 존(MALZ) 구축**  
     - AMS Accelerate는 관리형 서비스로 높은 수준의 보안을 제공하지만, Control Tower보다 복잡하며 비용이 추가될 수 있습니다.
     - MALZ는 AWS Security Hub나 GuardDuty를 통해 보안 모니터링을 제공하지만, Control Tower만큼의 자동화된 계정 생성 및 관리 기능을 제공하지 않습니다.

3. **결론**:
   - **A 옵션**이 최적입니다. AWS Control Tower를 AWS Organizations의 관리 계정에 배포하면 다중 계정 환경을 손쉽게 관리할 수 있고, AWS Security Hub와 함께 사용하여 FSBP 준수 여부를 모니터링할 수 있습니다. 이 방식은 최소한의 운영 오버헤드로 요구 사항을 충족합니다.

# 788
정답은 **C. AWS Glue 크롤러를 사용하여 S3 버킷에서 테이블 메타데이터를 저장하고 검색하며, Amazon Athena를 사용해 SQL 문을 직접 실행하는 것**입니다.

### 해설

1. **요구사항 분석**:
   - 10TB 크기의 Parquet 포맷의 로그 파일을 Amazon S3에 저장하고 있으며, SQL을 통해 간헐적으로 분석이 필요합니다.
   - 최소 비용으로 요구를 충족시킬 솔루션이 필요합니다.

2. **옵션 분석**:
   - **A. Amazon Aurora MySQL 데이터베이스**  
     - 데이터를 S3에서 Aurora로 마이그레이션해야 하므로 시간이 많이 걸리고 추가적인 비용이 발생합니다.
     - Aurora MySQL은 고정된 비용이 발생하는 관리형 DB이므로 간헐적인 분석에는 비효율적입니다.

   - **B. Amazon Redshift와 Redshift Spectrum**  
     - Redshift Spectrum을 사용하면 S3의 데이터를 직접 쿼리할 수 있습니다.
     - 그러나 Amazon Redshift 클러스터 자체가 고정 비용을 발생시키기 때문에, 간헐적인 쿼리 요구 사항에는 다소 비효율적입니다.

   - **C. AWS Glue와 Amazon Athena**  
     - AWS Glue 크롤러로 S3의 Parquet 데이터를 자동으로 스캔하고 메타데이터를 카탈로그화하여 쉽게 접근할 수 있습니다.
     - **Amazon Athena**는 S3의 데이터를 직접 쿼리할 수 있으며, 사용한 만큼만 비용이 청구되므로 간헐적인 SQL 분석 작업에 매우 적합한 선택입니다.
   
   - **D. Amazon EMR과 Apache Spark SQL**  
     - Amazon EMR은 데이터 분석 및 처리에 효율적이나, 클러스터를 구성하고 관리하는 데 추가 비용과 시간이 필요합니다. 간헐적인 분석을 위한 요구 사항을 충족하기엔 과도한 비용이 발생할 수 있습니다.

3. **결론**:
   - **C 옵션**은 AWS Glue와 Amazon Athena를 사용해 S3에 있는 데이터를 직접 SQL로 쿼리할 수 있어 관리가 용이하고, 사용한 만큼만 비용이 발생하므로 가장 비용 효율적인 솔루션입니다.

# 789
정답은 **D. 서비스 제어 정책(SCP)을 사용하여 비준수 상태로 이어지는 EC2 인스턴스 및 IAM 리소스의 작업을 차단하는 것**입니다.

### 해설

1. **요구사항 분석**:
   - AWS CloudFormation 스택에서 IAM 리소스의 인라인 정책에 “*”가 포함된 경우와, 퍼블릭 IP가 할당된 EC2 인스턴스의 배포를 방지해야 합니다.
   - AWS Control Tower가 활성화된 AWS Organizations 환경에서 이 요구사항을 충족해야 합니다.

2. **옵션 분석**:
   - **A. AWS Control Tower의 사전 예방적 제어**  
     - Control Tower는 사전 예방적 제어를 통해 일부 제한적인 규정 준수를 강제할 수 있지만, 특정 리소스 속성(예: 인라인 정책에서 “*” 또는 퍼블릭 IP가 있는 EC2 인스턴스)에 대해 세부적으로 차단하는 것은 SCP를 통해 더 직접적으로 설정할 수 있습니다.

   - **B. AWS Control Tower의 탐지적 제어**  
     - 탐지적 제어는 비준수 리소스를 사후에 탐지하고 알림을 줄 수 있으나, 실제 배포를 사전에 차단하지는 않습니다. 따라서 이 방법은 요구사항을 직접적으로 충족하지 못합니다.

   - **C. AWS Config 규칙과 Systems Manager**  
     - AWS Config와 Systems Manager의 조합으로 비준수 리소스를 식별하고 제거할 수는 있지만, 이는 비준수 상태를 사전에 방지하기보다는 사후 처리하는 방식이므로 운영적 오버헤드가 발생할 수 있습니다.

   - **D. 서비스 제어 정책(SCP)**  
     - SCP는 Organizations의 관리 계정을 통해 비준수 IAM 리소스 생성 및 퍼블릭 IP가 있는 EC2 인스턴스 생성과 같은 특정 작업을 사전에 차단할 수 있습니다.
     - SCP는 강력한 제어를 제공하며, 조직의 모든 계정에 적용되어 CloudFormation을 통해 생성된 리소스에 대한 제어가 가능하므로 요구사항을 충족하는 최적의 솔루션입니다.

3. **결론**:
   - **D 옵션**은 SCP를 사용해 비준수 상태로 이어지는 EC2와 IAM 리소스에 대한 작업을 사전에 차단하므로, 요구사항을 가장 효율적이고 확실하게 충족할 수 있습니다.

# 790
정답은 **B. 여러 가용 영역(AZ)에서 프라이빗 서브넷에 Amazon EC2 Auto Scaling을 구성**하고, **E. 퍼블릭 서브넷에 Application Load Balancer(ALB)를 구성하여 웹 트래픽을 분산**하는 것입니다.

### 해설

1. **요구사항 분석**:
   - 높은 가용성과 확장성을 확보하여 증가하는 사용자 수요를 처리해야 하며, 애플리케이션을 재작성하지 않고 해결해야 합니다.
   - 현재 애플리케이션은 단일 퍼블릭 서브넷의 EC2 인스턴스에서 작동하고 있으며, 현재 구조로는 확장성이 부족합니다.

2. **옵션 분석**:
   - **A. 컴퓨팅 최적화 인스턴스로 교체**  
     - 컴퓨팅 최적화 인스턴스로 교체하면 일시적으로 성능이 개선될 수 있지만, 이는 확장성과 고가용성을 보장하지 못합니다. 
   
   - **B. 여러 AZ의 프라이빗 서브넷에 EC2 Auto Scaling 구성**  
     - Auto Scaling을 통해 트래픽 증가에 따라 인스턴스를 자동으로 확장할 수 있으며, 여러 가용 영역을 사용하여 고가용성을 확보할 수 있습니다.
     - 보안과 접근 제어를 위해 인스턴스를 프라이빗 서브넷에 배치하는 것이 권장됩니다.

   - **C. 퍼블릭 서브넷에 NAT 게이트웨이 구성**  
     - NAT 게이트웨이는 프라이빗 서브넷에서 아웃바운드 인터넷 트래픽을 지원하는 역할을 하며, 외부에서 웹 요청을 처리하는 기능은 수행하지 않습니다.

   - **D. 메모리 최적화 인스턴스로 교체**  
     - 메모리 최적화 인스턴스로 교체해도 A와 마찬가지로 확장성과 고가용성을 확보하는 데는 부족합니다.

   - **E. 퍼블릭 서브넷에 Application Load Balancer(ALB) 구성**  
     - ALB는 트래픽을 여러 EC2 인스턴스에 분산하여 확장성과 고가용성을 제공하므로, 트래픽 급증에 따른 대응이 가능해집니다.

3. **결론**:
   - **B**와 **E** 옵션의 조합으로, **Auto Scaling을 통해 인스턴스 확장 및 가용성 확보**와 **ALB를 통한 트래픽 분산**이 가능해져 요구사항을 충족시킬 수 있습니다.

# 791
정답은 **D. AWS Key Management Service (AWS KMS) 키를 생성하고, Lambda 함수에서 KMS 키를 사용하여 환경 변수를 저장하고 암호화하는 암호화 헬퍼를 활성화하는 것**입니다.

### 해설

1. **요구사항 분석**:
   - 개발자들이 AWS Lambda 함수의 환경 변수를 평문으로 볼 수 없도록 해야 합니다. 이는 민감한 정보나 보안 키 등을 포함할 수 있는 환경 변수의 안전한 저장을 요구합니다.

2. **옵션 분석**:
   - **A. Lambda 함수 대신 Amazon EC2 인스턴스에 코드를 배포**  
     - EC2 인스턴스를 사용하더라도 환경 변수를 보호하는 데 대한 직접적인 해결책은 제공하지 않으며, 운영 복잡성이 증가합니다.

   - **B. Lambda 함수에 SSL 암호화를 구성하여 AWS CloudHSM을 사용하여 환경 변수를 저장하고 암호화**  
     - SSL 암호화는 데이터 전송 중의 보안은 제공하지만, Lambda 환경 변수를 저장하는 방식에는 직접적인 해결책이 아닙니다. 또한, CloudHSM은 복잡성이 높고 관리 오버헤드가 큽니다.

   - **C. AWS Certificate Manager (ACM)에서 인증서를 생성하고 Lambda 함수에서 인증서를 사용하여 환경 변수를 암호화**  
     - ACM은 TLS/SSL 인증서 관리와 관련된 서비스이며, 환경 변수를 암호화하는 데 적합하지 않습니다.

   - **D. AWS KMS 키를 생성하고, Lambda 함수에서 KMS 키를 사용하여 환경 변수를 저장하고 암호화하는 암호화 헬퍼를 활성화**  
     - AWS KMS는 암호화 키를 관리하고, Lambda 함수에서 환경 변수를 안전하게 암호화하고 복호화하는 데 사용할 수 있습니다. KMS를 사용하면 환경 변수를 평문으로 저장하지 않고 안전하게 보호할 수 있으며, 필요할 때만 복호화하여 사용할 수 있습니다.

3. **결론**:
   - **D** 옵션은 개발자들이 환경 변수를 평문으로 볼 수 없도록 하면서도, Lambda 함수의 환경 변수 보호 요구사항을 충족시키는 가장 안전하고 효율적인 방법입니다.


# 792
정답은 **A. Amazon Cognito 사용자 풀을 구성하여 사용자 인증을 처리하고, Amazon API Gateway REST API와 Cognito 인증자를 구현하는 것**입니다.

### 해설

1. **요구사항 분석**:
   - 다수의 사용자가 RESTful API에 접근할 수 있도록 하고, 사용자는 인증 서비스로 인증을 받아야 합니다. 여기서 중요한 요소는 사용자 인증과 API 관리의 효율성입니다.

2. **옵션 분석**:
   - **A. Amazon Cognito 사용자 풀을 구성하여 사용자 인증. Amazon API Gateway REST API와 Cognito 인증자를 구현**  
     - Amazon Cognito는 사용자 인증 및 관리에 특화된 서비스로, 사용자 풀을 통해 사용자 등록, 로그인 및 관리를 쉽게 처리할 수 있습니다. API Gateway와 통합하여 RESTful API에 대한 액세스를 안전하게 관리할 수 있습니다. 이 조합은 운영 효율성이 높고, 사용자 인증을 간단하게 처리할 수 있습니다.

   - **B. Amazon Cognito ID 풀을 구성하여 사용자 인증. Amazon API Gateway HTTP API와 Cognito 인증자를 구현**  
     - ID 풀은 인증된 사용자의 리소스에 대한 액세스를 관리하는 데 사용됩니다. 하지만 RESTful API를 제공하는 데는 사용자 풀보다 사용자 풀이 더 적합합니다.

   - **C. AWS Lambda 함수를 구성하여 사용자 인증을 처리. Amazon API Gateway REST API와 Lambda 인증자를 구현**  
     - Lambda 함수를 사용하여 인증을 처리할 수 있지만, 별도로 인증 로직을 구현해야 하므로 운영 오버헤드가 증가합니다. Lambda 인증자는 관리해야 할 추가적인 구성 요소가 필요합니다.

   - **D. IAM 사용자를 구성하여 사용자 인증을 처리. Amazon API Gateway HTTP API와 IAM 인증자를 구현**  
     - IAM 사용자 인증은 주로 AWS 리소스에 대한 액세스 관리에 적합하지만, 일반 사용자에 대한 인증 및 관리에는 비효율적일 수 있습니다. 일반 사용자 인증에 IAM을 사용하는 것은 복잡성을 높일 수 있습니다.

3. **결론**:
   - **A** 옵션은 Amazon Cognito를 사용하여 사용자 인증을 효율적으로 관리하고, Amazon API Gateway와의 통합을 통해 RESTful API를 안전하게 제공하는 가장 효과적인 방법입니다. 이 솔루션은 운영 효율성이 높고, 사용자 관리 및 인증을 간소화할 수 있습니다.

# 793
정답은 **C**입니다.

### 정답 분석
**C.** 이 솔루션은 Amazon EventBridge 규칙을 사용하여 KMS `DeleteKey` 작업이 수행될 때 트리거되도록 설정합니다. EventBridge 규칙은 AWS Systems Manager Automation의 런북(runbook)을 실행하도록 구성되어 있어, KMS 키 삭제를 자동으로 취소할 수 있습니다. 또한, EventBridge 규칙에서 SNS를 사용해 관리자에게 이메일 알림을 보냅니다. 이 솔루션은 AWS의 기본 제공 기능들을 조합해 간단하고, 운영 오버헤드가 적으며 자동화 수준이 높아 요구사항을 충족합니다.

### 다른 선택지 검토
- **A.** AWS Config 규칙을 생성하고 EventBridge 규칙과 연동하여 KMS 키 삭제를 취소하는 방식입니다. 하지만 AWS Config 규칙을 추가로 설정해야 하므로 운영 오버헤드가 증가할 수 있습니다.
  
- **B.** Lambda 함수를 사용해 삭제 작업을 방지하는 솔루션입니다. 그러나 Lambda 함수를 작성하고, CloudWatch 알람과 EventBridge 규칙을 설정해야 하므로 운영 오버헤드가 큽니다.
  
- **D.** CloudTrail과 CloudWatch 로그 그룹, CloudWatch 알람을 설정하여 모니터링하는 방식입니다. 그러나 이 솔루션은 KMS 키 삭제를 막을 수 없고, 단순히 경고를 보내는 역할만 합니다.

따라서 **C**는 최소한의 운영 오버헤드로 요구 사항(삭제 방지 및 알림)을 모두 충족할 수 있는 최적의 솔루션입니다.

# 795
정답은 **B. Create an Amazon FSx for Lustre file system. Configure the file system with scratch storage.**와 **D. Launch Amazon EC2 instances. Attach an Elastic Fabric Adapter (EFA) to the instances.**입니다.

### 해설

1. **HPC 환경 최적화 요구사항**:
   - HPC 환경에서는 높은 성능과 빠른 데이터 전송을 위한 최적화가 필수적입니다. 이는 일반적으로 네트워킹과 스토리지 성능을 향상시키는 방법으로 접근해야 합니다.

2. **옵션 분석**:
   - **A. Create an accelerator in AWS Global Accelerator. Configure custom routing for the accelerator.**  
     - AWS Global Accelerator는 지리적으로 분산된 애플리케이션의 성능을 향상시키는 데 유용하지만, HPC 환경의 네트워킹 최적화에는 적합하지 않습니다.

   - **B. Create an Amazon FSx for Lustre file system. Configure the file system with scratch storage.**  
     - Amazon FSx for Lustre는 HPC 작업을 위한 고성능 파일 시스템을 제공하며, 스크래치 스토리지와 통합하여 데이터 집합의 빠른 입출력을 지원합니다. 이는 HPC 환경에서 매우 중요한 성능 요소입니다.

   - **C. Create an Amazon CloudFront distribution. Configure the viewer protocol policy to be HTTP and HTTPS.**  
     - Amazon CloudFront는 콘텐츠 배포 네트워크(CDN)로 주로 사용되며, HPC 환경의 직접적인 네트워킹이나 스토리지 성능 향상에는 기여하지 않습니다.

   - **D. Launch Amazon EC2 instances. Attach an Elastic Fabric Adapter (EFA) to the instances.**  
     - Elastic Fabric Adapter (EFA)는 HPC 환경에서 낮은 대기 시간과 높은 대역폭을 제공하는 네트워크 인터페이스입니다. 이는 HPC 작업의 성능을 크게 향상시킬 수 있는 핵심 요소입니다.

   - **E. Create an AWS Elastic Beanstalk deployment to manage the environment.**  
     - AWS Elastic Beanstalk는 웹 애플리케이션 배포 및 관리에 적합한 서비스로, HPC 환경을 최적화하는 데는 적합하지 않습니다.

3. **결론**:
   - **B**와 **D**는 모두 HPC 환경에서 요구되는 높은 성능과 최적화를 제공할 수 있는 솔루션입니다. FSx for Lustre는 스토리지 성능을 최적화하고, EFA는 네트워킹 성능을 최적화하여 HPC 환경을 성공적으로 지원합니다.

# 797
정답은 **A. Set up a backup administrator account that the company can use to log in if the company loses the MFA device.**입니다.

### 해설

1. **문제의 요구사항**:
   - MFA 장치를 분실했을 경우, AWS 계정 루트 사용자에 대한 접근을 잃지 않도록 보장하는 솔루션이 필요합니다.

2. **옵션 분석**:
   - **A. Set up a backup administrator account that the company can use to log in if the company loses the MFA device.**  
     - 이 옵션은 MFA 장치를 잃어버린 경우에 대비하여 백업 관리자 계정을 설정하는 것입니다. 이렇게 하면 루트 계정 접근이 불가능해질 경우에도 이 계정을 통해 AWS 리소스에 접근할 수 있습니다. 이는 안전하고 효과적인 방법입니다.

   - **B. Add multiple MFA devices for the root user account to handle the disaster scenario.**  
     - AWS에서는 루트 사용자 계정에 대해 하나의 MFA 장치만 허용하므로 이 옵션은 현실적으로 불가능합니다.

   - **C. Create a new administrator account when the company cannot access the root account.**  
     - 루트 계정에 접근할 수 없는 경우 새 관리자를 만드는 것은 어렵고, 이는 문제가 발생했을 때의 긴급 대응책으로 적절하지 않습니다.

   - **D. Attach the administrator policy to another IAM user when the company cannot access the root account.**  
     - IAM 사용자에게 관리자 정책을 부여하는 것은 유용하지만, 루트 계정에 대한 직접적인 접근 문제를 해결하지 못합니다. 루트 계정은 AWS 계정의 모든 권한을 가지고 있으므로, 이를 잃어버리는 상황에서 IAM 사용자로는 루트 계정을 복구할 수 없습니다.

3. **결론**:
   - **A**는 다른 대안들에 비해 안전하고 실용적인 접근법입니다. 백업 관리자 계정을 설정함으로써 MFA 장치가 분실되더라도 AWS 리소스에 계속 접근할 수 있는 방법을 제공하여, 비즈니스 연속성을 보장할 수 있습니다.



# 798
정답은 **B. Create an Amazon Simple Notification Service (Amazon SNS) topic. Choose an endpoint protocol. Subscribe the partners to the topic. Publish user IDs to the topic when the company gives users points.**입니다.

### 해설

1. **문제의 요구사항**:
   - 사용자가 포인트를 받을 때마다 HTTP 엔드포인트를 통해 사용자 ID를 알리는 알림 시스템이 필요합니다.
   - 여러 파트너가 참여하고 있어 확장 가능하고 빠르게 파트너를 추가할 수 있는 아키텍처를 원합니다.

2. **옵션 분석**:
   - **A. Create an Amazon Timestream database to keep a list of affiliated partners. Implement an AWS Lambda function to read the list. Configure the Lambda function to send user IDs to each partner when the company gives users points.**  
     - 이 옵션은 데이터베이스와 Lambda 함수를 사용해야 하므로 구현 복잡성이 증가합니다. 새로운 파트너를 추가하는 작업이 다소 복잡할 수 있습니다.

   - **B. Create an Amazon Simple Notification Service (Amazon SNS) topic. Choose an endpoint protocol. Subscribe the partners to the topic. Publish user IDs to the topic when the company gives users points.**  
     - SNS를 사용하면 HTTP(S) 엔드포인트에 쉽게 파트너를 추가할 수 있습니다. 파트너가 SNS 주제에 구독하고 사용자가 포인트를 받을 때마다 알림을 받을 수 있어 확장성과 구현의 용이성 면에서 가장 적합한 솔루션입니다.

   - **C. Create an AWS Step Functions state machine. Create a task for every affiliated partner. Invoke the state machine with user IDs as input when the company gives users points.**  
     - Step Functions는 복잡한 워크플로를 구성하는 데 적합하지만, 매번 새로운 파트너를 추가할 때마다 상태 머신을 수정해야 하므로 관리 오버헤드가 발생합니다.

   - **D. Create a data stream in Amazon Kinesis Data Streams. Implement producer and consumer applications. Store a list of affiliated partners in the data stream. Send user IDs when the company gives users points.**  
     - Kinesis를 사용하는 것은 유연성을 제공하지만, 데이터 스트림을 관리하고 프로듀서 및 컨슈머 애플리케이션을 구현하는 데 상당한 작업이 필요합니다.

3. **결론**:
   - **B**는 SNS를 활용하여 파트너를 쉽게 추가하고 관리할 수 있는 방식으로, 사용자가 포인트를 받을 때마다 간편하게 사용자 ID를 전송할 수 있어 요구사항을 충족합니다. 따라서 구현 노력과 확장성 측면에서 가장 적합한 솔루션입니다.

# 799
**정답은 A입니다.**

각 옵션을 분석해 보면:

### A. **S3 Event Notifications, AWS Lambda, Amazon Comprehend**
- **S3 Event Notifications**를 사용하여 S3 버킷에 **PutObject** 요청이 발생할 때마다 **AWS Lambda** 함수를 트리거합니다.
- Lambda 함수는 **Amazon Comprehend**를 사용하여 텍스트에서 음식 재료 이름을 추출합니다. **Amazon Comprehend**는 자연어 처리를 위한 관리형 서비스로, 텍스트에서 중요한 정보를 추출하는 데 사용됩니다. 이 서비스는 사전 훈련된 모델을 제공하므로, 머신 러닝에 대한 지식 없이도 사용할 수 있습니다.
- 추출된 재료 이름은 **DynamoDB** 테이블에 저장됩니다.

이 방법은 비용 효율적이고, 관리가 용이하며, 머신 러닝 지식 없이도 사용할 수 있는 **Amazon Comprehend**를 활용하여 요구 사항을 충족할 수 있습니다.

### B. **Amazon EventBridge, AWS Lambda, Amazon Forecast**
- **Amazon Forecast**는 시계열 예측을 위한 서비스로, 레시피의 재료 추출에는 적합하지 않습니다. 이 서비스는 주로 과거 데이터를 기반으로 미래를 예측하는 데 사용되므로 재료 추출과는 관련이 없습니다.
- 이 옵션은 목적에 맞지 않으며, **Forecast**를 사용하는 것은 불필요한 비용을 초래할 수 있습니다.

### C. **S3 Event Notifications, AWS Lambda, Amazon Polly, SNS**
- 이 옵션은 **Amazon Polly**를 사용하여 레시피 텍스트를 **음성 파일로 변환**한 뒤, 이를 직원들이 듣고 재료를 추출하여 점수를 계산하는 방식입니다. 이 방법은 불필요하게 복잡하고 비효율적입니다.
- 또한, 이 방법은 자동화된 처리에 적합하지 않으며, **비용이 많이 들고 운영이 복잡**할 수 있습니다.

### D. **Amazon EventBridge, AWS Lambda, Amazon SageMaker**
- **Amazon SageMaker**는 기계 학습 모델을 훈련시키고 배포하는 서비스로, 이 문제에 대한 해결책으로는 과도한 리소스와 비용이 발생할 수 있습니다. SageMaker는 훈련된 모델이 없으면 사용하기가 복잡하고, 개발자가 머신 러닝 지식 없이 쉽게 사용할 수 있는 서비스는 아닙니다.
- 또한, 이 옵션은 **비효율적이고 관리 오버헤드가 많습니다**.

### 결론:
**Option A**가 가장 적합합니다. **Amazon Comprehend**는 텍스트에서 유용한 정보를 추출하는 데 필요한 기능을 제공하며, **AWS Lambda**와 **S3 Event Notifications**를 결합하여 자동화된, 효율적인 솔루션을 구현할 수 있습니다.

# 800
이 시나리오에서는 AWS Lambda 함수가 주 AWS 계정의 VPC 내에서 실행되며, Amazon EFS 파일 시스템에 액세스해야 하는데, 이 파일 시스템은 다른 AWS 계정에 위치하고 있습니다. 이 요구 사항을 충족하는 가장 비용 효율적인 솔루션을 찾아야 합니다.

### 정답:
**B. Create a VPC peering connection between the VPCs that are in the primary account and the secondary account.**

### 해설:
1. **B. Create a VPC peering connection between the VPCs that are in the primary account and the secondary account.**
   - **설명**: VPC 피어링 연결을 설정하면 두 VPC 간의 사설 IP 주소를 사용하여 통신할 수 있습니다. Lambda 함수가 주 계정의 VPC에서 실행되고, EFS 파일 시스템이 보조 계정의 VPC에 위치하므로, VPC 피어링은 Lambda 함수가 EFS에 안전하게 액세스할 수 있는 간단하고 비용 효율적인 방법입니다. 이 방법은 데이터 전송 비용이 발생하지만, 다른 솔루션보다 훨씬 간단하고 유지 관리가 용이합니다.

### 오답 해설:

- **A. Create a new EFS file system in the primary account. Use AWS DataSync to copy the contents of the original EFS file system to the new EFS file system.**
   - **설명**: 새로운 EFS 파일 시스템을 생성하고 기존 파일 시스템의 내용을 복사하는 것은 시간과 비용이 많이 소모되는 작업입니다. 또한, 이는 파일 시스템을 동기화해야 하므로 유지 관리와 관련된 추가 작업이 필요합니다.

- **C. Create a second Lambda function in the secondary account that has a mount that is configured for the file system. Use the primary account's Lambda function to invoke the secondary account's Lambda function.**
   - **설명**: 보조 계정에서 별도의 Lambda 함수를 만들고 이를 호출하는 것은 복잡성을 추가합니다. 두 계정 간의 호출 및 권한 설정이 필요하며, 추가적인 관리 오버헤드가 발생합니다.

- **D. Move the contents of the file system to a Lambda layer. Configure the Lambda layer's permissions to allow the company's secondary account to use the Lambda layer.**
   - **설명**: Lambda 레이어를 사용하여 파일 시스템의 내용을 이동하는 것은 해당 파일의 크기 및 업데이트 빈도에 따라 비효율적일 수 있습니다. 레이어는 주로 코드나 라이브러리와 같은 정적 자산을 공유하는 데 사용되며, 동적으로 변경되는 파일에 대한 액세스를 제공하지 않습니다.

### 결론
따라서 **B**의 VPC 피어링을 설정하는 것이 이 시나리오에서 요구 사항을 충족하는 가장 비용 효율적이고 효과적인 방법입니다. 이를 통해 Lambda 함수가 다른 계정의 EFS에 직접 액세스할 수 있게 됩니다.

# 801
정답은 **D. Encrypt the data at the company's data center before storing the data in the S3 bucket** 입니다.

### 해설
이 문제에서는 **고객이 AWS 클라우드 외부에서 암호화 키를 관리**해야 한다는 조건이 있습니다. 이를 충족하려면 데이터를 AWS 외부에서 먼저 암호화한 후, 암호화된 상태로 S3 버킷에 저장해야 합니다.

각 선택지를 분석해 보겠습니다:

- **A. AWS KMS 고객 관리 키로 암호화**  
  AWS KMS의 고객 관리 키(CMK)를 사용하면 키를 직접 관리할 수 있지만, AWS KMS 자체는 AWS 클라우드 내에서 운영됩니다. 따라서 이 선택지는 "AWS 클라우드 외부에서 키 관리" 요구 사항을 충족하지 못합니다.

- **B. AWS 관리 키로 암호화**  
  AWS 관리 키는 AWS가 암호화 및 키 관리를 자동으로 수행하므로 고객이 키를 제어할 수 없습니다. 이 역시 요구 사항을 충족하지 못합니다.

- **C. 기본 SSE 암호화 사용**  
  기본 서버 측 암호화(SSE)를 사용하면 AWS가 키를 자동으로 관리하고, 이 경우 고객이 키를 관리할 수 없으므로 조건에 맞지 않습니다.

- **D. 데이터 센터에서 데이터 암호화 후 S3에 저장**  
  데이터를 클라우드 외부(즉, 회사의 데이터 센터)에서 암호화하면 고객이 키를 완전히 제어할 수 있습니다. 이는 AWS 클라우드 외부에서 키를 관리해야 한다는 요구 사항을 만족하므로 정답입니다.

따라서 **정답은 D**입니다.


# 802
정답은 **D**입니다.

### 정답 분석
**D.** 이 솔루션은 Amazon API Gateway를 사용하여 모바일 장치에서 결제 알림을 수신하는 API를 생성합니다. 그런 다음 AWS Lambda 함수를 호출하여 결제 알림을 검증하고, 백엔드 애플리케이션에 알림을 보냅니다. 백엔드 애플리케이션은 Amazon ECS에서 AWS Fargate를 사용하여 배포됩니다. 

- **운영 오버헤드 최소화**: AWS Lambda는 서버리스 컴퓨팅 모델로, 인프라를 관리할 필요가 없습니다. API Gateway와 Lambda를 사용하면 결제 알림의 수신과 검증이 자동화되고, 관리할 서버가 없습니다. 
- **확장성**: Fargate를 사용하면 백엔드 애플리케이션의 컴퓨팅과 메모리 리소스를 필요에 따라 자동으로 조정할 수 있습니다.

### 다른 선택지 검토
- **A.** Amazon SQS와 EventBridge를 사용하여 결제 알림을 처리하는 구조입니다. 하지만 EKS를 사용하여 백엔드 애플리케이션을 배포하는 것은 인프라 관리를 요구하므로 운영 오버헤드가 증가합니다.
  
- **B.** API Gateway와 AWS Step Functions를 사용하는 방법으로, 상태 기계의 복잡성으로 인해 관리해야 할 요소가 늘어나고, EKS를 사용하여 인프라를 관리해야 하므로 운영 오버헤드가 높습니다.
  
- **C.** SQS와 EventBridge를 활용하여 결제 알림을 처리하는 방식이지만, EC2 Spot Instances를 사용하여 백엔드 애플리케이션을 배포하는 것은 관리의 복잡성을 증가시키고, Spot Instances의 가용성 문제로 인해 예기치 않은 중단이 발생할 수 있습니다.

### 결론
**D**는 서버리스 아키텍처를 활용하고, Fargate를 통해 인프라 관리를 최소화하며, 요구사항에 맞는 최적의 솔루션입니다. 결제 알림 처리 및 검증의 간소화, 운영 오버헤드 최소화, 백엔드 처리의 유연성을 모두 충족합니다.


# 803
이 문제의 요구 사항에 가장 적합한 솔루션은 **A. Configure Amazon Cognito user pools for user authentication. Enable the risk-based adaptive authentication feature with multifactor authentication (MFA)**입니다.

### 해설

1. **Amazon Cognito User Pools**:
   - Amazon Cognito는 사용자 인증 및 관리 솔루션을 제공하며, 사용자가 로그인을 할 때 신원을 확인하고 관리할 수 있는 기능을 제공합니다. User Pools는 애플리케이션 사용자에게 등록, 로그인, 및 MFA와 같은 기능을 제공하는데 최적화되어 있습니다.

2. **Risk-based Adaptive Authentication**:
   - 이 기능은 사용자가 로그인을 시도할 때 그 로그인 시도가 비정상적일 경우, 즉 예상하지 못한 지리적 위치, IP 주소, 또는 기기에서 로그인을 시도하는 경우, 추가적인 인증 절차를 요구할 수 있도록 설정할 수 있습니다. 이러한 위험 기반 인증은 두 번째 인증 수단을 필요로 하며, 이는 MFA를 활성화하는 것과 관련이 있습니다.

3. **확장성**:
   - Amazon Cognito는 수백만 명의 사용자에게 확장할 수 있는 기능을 갖추고 있어 대규모 애플리케이션에서 수많은 사용자 계정을 안전하게 관리할 수 있습니다.

### 다른 선택지의 문제점

- **B. Configure Amazon Cognito identity pools for user authentication. Enable multi-factor authentication (MFA)**: 
   - Identity Pools는 주로 인증된 사용자에게 AWS 리소스에 대한 권한을 부여하는 데 사용됩니다. MFA 기능은 User Pools에서 보다 효율적으로 관리됩니다.

- **C. Configure AWS Identity and Access Management (IAM) users for user authentication. Attach an IAM policy that allows the AllowManageOwnUserMFA action**: 
   - IAM은 주로 AWS 리소스에 대한 액세스를 관리하는 데 사용되며, 사용자 인증 솔루션으로는 적합하지 않습니다. 또한 IAM은 수백만 사용자를 지원하는 데에 비효율적입니다.

- **D. Configure AWS IAM Identity Center (AWS Single Sign-On) authentication for user authentication. Configure the permission sets to require multi-factor authentication (MFA)**: 
   - AWS IAM Identity Center는 SSO를 위한 솔루션이지만, 사용자 인증에 대해 보다 깊은 통제를 요구하는 애플리케이션에는 적합하지 않을 수 있습니다. 사용자 기반의 위험 기반 인증을 지원하지 않습니다.

### 결론
따라서, **A** 옵션이 요구 사항을 가장 잘 충족시키며, Amazon Cognito User Pools를 통해 두 번째 인증을 유연하게 구현하고 대규모 사용자 기반을 지원할 수 있습니다.


# 804
정답은 **C. Run a daily AWS Glue job to transform the data and load the data into Amazon Redshift Serverless. Use Amazon Redshift ML to create and train the ML models.**입니다.

### 해설
이 문제에서는 다음 요구 사항을 충족하는 솔루션을 찾아야 합니다:
1. **데이터 변환 및 로드**: S3의 데이터를 변환하여 데이터 웨어하우스로 로드
2. **대규모 병렬 처리 (MPP)**: 데이터 웨어하우스는 MPP를 지원해야 함
3. **머신 러닝 모델 생성 및 훈련**: 데이터 분석가가 SQL을 사용해 모델을 생성하고 훈련
4. **서버리스 서비스**: 가능하면 서버리스 AWS 서비스 사용

각 옵션을 분석해 보겠습니다.

- **옵션 A**: Amazon EMR은 서버리스가 아니며 관리해야 할 클러스터가 필요합니다. 또한, Redshift는 MPP를 제공하지만 Redshift Serverless를 명시하지 않아 서버리스 요구 사항을 완전히 충족하지 않습니다.
  
- **옵션 B**: Amazon Aurora Serverless는 MPP 기능이 부족하며 대규모 데이터 웨어하우스로 사용하기엔 적합하지 않습니다.

- **옵션 C**: AWS Glue는 서버리스 데이터 통합 서비스로 S3에서 데이터를 변환하고 Redshift Serverless에 로드할 수 있습니다. Amazon Redshift는 MPP 기능을 제공하며, Redshift ML을 통해 SQL을 사용해 모델을 생성하고 훈련할 수 있어 요구 사항에 가장 적합합니다.

- **옵션 D**: Athena는 MPP 기능을 일부 지원하지만 데이터 웨어하우스로서의 기능과 성능이 제한적입니다. 또한, Athena ML은 Redshift ML만큼 지원되지 않습니다.

따라서 **옵션 C**가 요구 사항을 가장 효율적으로 충족하는 솔루션입니다.


# 805
정답은 **C. Install an AWS Outposts rack in the company's data center.**입니다.

### 해설
이 문제의 요구 사항을 분석해보면 다음과 같은 핵심 요건을 충족해야 합니다:
1. **로컬 데이터 센터에서 데이터 유지**: 모든 데이터가 온프레미스에 저장되어야 하며, 클라우드나 원격 사이트에 저장할 수 없음.
2. **Amazon EKS 및 AWS 관리 서비스 사용**: Amazon EKS와 AWS의 관리형 서비스를 온프레미스에서 사용할 수 있어야 함.

각 옵션을 검토해 보겠습니다:

- **옵션 A (AWS Local Zones)**: AWS Local Zones는 AWS 리전의 확장으로, 사용자에게 가까운 위치에서 지연 시간이 낮은 서비스를 제공하지만, 여전히 AWS 데이터 센터와 연결된 클라우드 인프라를 기반으로 합니다. 따라서 데이터가 온프레미스에만 저장되는 것은 불가능합니다.

- **옵션 B (AWS Snowmobile)**: Snowmobile은 대규모 데이터 이전을 위해 설계된 물리적 데이터 전송 서비스로, 보통 대량의 데이터를 AWS 클라우드로 이동하기 위해 사용됩니다. 로컬 데이터 센터에서 지속적으로 데이터를 유지하고 실행하기 위한 서비스가 아니므로 요구 사항을 충족하지 않습니다.

- **옵션 C (AWS Outposts)**: AWS Outposts는 AWS의 인프라와 서비스를 온프레미스 환경에서 직접 실행할 수 있도록 설계되었습니다. Outposts는 Amazon EKS와 같은 AWS 관리형 서비스를 온프레미스에서 실행할 수 있도록 하며, 데이터를 로컬 데이터 센터에 유지할 수 있습니다. 따라서 데이터 저장 요구 사항과 AWS 관리형 서비스 사용 요구 사항을 모두 충족할 수 있습니다.

- **옵션 D (AWS Snowball Edge)**: Snowball Edge는 일시적인 데이터 저장과 처리를 위해 설계된 장비로, 지속적으로 온프레미스 인프라에서 EKS와 같은 AWS 서비스를 실행하기에는 적합하지 않습니다.

따라서, **옵션 C (AWS Outposts)**가 회사의 요구 사항을 가장 적절하게 충족합니다.


# 807
정답은 **D. Configure provisioned concurrency for the Lambda functions. Increase the memory according to AWS Compute Optimizer recommendations.**입니다.

### 해설
이 문제에서는 다음 요구 사항을 충족하는 솔루션을 찾아야 합니다:
1. **비용 절감**: 컴퓨팅 비용을 줄여야 함.
2. **서비스 지연 시간 유지**: 고객에게 적절한 지연 시간을 유지해야 함.
3. **CPU 집약적인 코드 처리**: Lambda 함수가 CPU 집약적인 작업을 수행하는 만큼 적절한 메모리 및 성능 최적화가 필요함.

각 옵션을 분석해보겠습니다:

- **옵션 A**: 예약된 동시성을 설정하면 Lambda 함수가 일정 수의 동시 요청을 수용할 수 있습니다. 그러나 메모리를 줄이면 CPU 성능도 감소할 수 있으며, 이는 서비스 지연 시간에 부정적인 영향을 미칠 수 있습니다. 

- **옵션 B**: 예약된 동시성을 설정하는 것은 좋은 선택이지만 메모리를 줄이는 것은 CPU 성능에 부정적인 영향을 미칠 수 있습니다. AWS Compute Optimizer의 권장 사항에 따라 메모리를 증가시키는 것이 좋습니다.

- **옵션 C**: 프로비저닝된 동시성을 사용하면 사전에 Lambda 함수가 준비되어 지연 시간을 줄일 수 있지만, 메모리를 줄이면 성능이 저하되어 CPU 집약적인 작업을 처리하는 데 비효율적일 수 있습니다.

- **옵션 D**: 프로비저닝된 동시성을 설정하면 Lambda 함수가 항상 준비 상태에 있게 되어 서비스 지연 시간이 감소합니다. AWS Compute Optimizer의 권장 사항에 따라 메모리를 늘리면 CPU 성능이 향상되고 비용 절감이 가능하므로 CPU 집약적인 작업을 더 효율적으로 처리할 수 있습니다. 

따라서 **옵션 D**가 컴퓨팅 비용을 줄이고 서비스 지연 시간을 유지하는 데 가장 적합한 솔루션입니다.


# 808
정답은 **A. Use Amazon Elastic Container Registry (Amazon ECR) as a private image repository to store the container images. Specify scan on push filters for the ECR basic scan.**입니다.

### 해설
이 문제에서 요구되는 사항은 다음과 같습니다:
1. **ECS 작업 정의에서 사용하는 컨테이너 이미지의 취약점을 스캔해야 함.**
2. **새로 생성된 컨테이너 이미지도 스캔해야 함.**

각 옵션을 분석해보겠습니다:

- **옵션 A**: Amazon ECR을 사용하여 컨테이너 이미지를 저장하고, ECR의 "push 시 스캔" 기능을 사용하여 취약점을 자동으로 스캔할 수 있습니다. 이 방법은 ECS와의 통합이 원활하며, 컨테이너 이미지가 푸시될 때마다 자동으로 스캔이 이루어지므로 최소한의 변경으로 요구 사항을 충족할 수 있습니다.

- **옵션 B**: S3 버킷에 컨테이너 이미지를 저장하고 Amazon Macie를 사용하여 스캔하는 것은 추가적인 설정이 필요하며, Macie는 데이터 보호에 중점을 두고 있어 이미지 취약점 스캔에 최적화되어 있지 않습니다.

- **옵션 C**: EKS로 워크로드를 전환하는 것은 대규모 변경을 요구하며, ECS에서 EKS로의 전환은 복잡성과 운영상의 오버헤드를 증가시킬 수 있습니다. 이 옵션 또한 ECR의 푸시 스캔 기능을 활용할 수 있지만, EKS로의 전환이 필요하므로 바람직하지 않습니다.

- **옵션 D**: S3 버킷에서 Lambda 함수를 호출하여 Amazon Inspector를 사용하여 스캔하는 것은 복잡한 설정을 요구하며, 운영상의 오버헤드가 커질 수 있습니다. 특히 ECS 환경에서 이미지 스캔을 위한 설정이 필요하므로 추가적인 변경이 필요합니다.

따라서 **옵션 A**가 가장 간단하고 효과적인 해결책입니다. Amazon ECR의 기본 스캔 기능을 사용하면 컨테이너 이미지를 효율적으로 관리하고 자동으로 취약점을 스캔할 수 있습니다.


# 809
정답은 **B. Configure Amazon EventBridge Scheduler to match incoming AWS Batch job SUCCEEDED events. Configure an AWS Lambda function to invoke the third-party API by using a username and password. Set the Lambda function as the EventBridge rule target.**입니다.

### 해설
이 문제의 요구 사항은 다음과 같습니다:
1. AWS Batch 작업이 성공할 때 트리거되는 서버리스 솔루션이 필요함.
2. 트리거된 후에는 HTTP API를 통해 인증된 요청을 보내야 함.

각 옵션을 분석해보겠습니다:

- **옵션 A**: EventBridge API destination을 사용하여 AWS Batch job의 성공 이벤트를 API로 직접 전송할 수 있지만, EventBridge의 API destination은 기본적으로 사용자 이름과 비밀번호를 지원하지 않기 때문에 인증이 필요한 경우 적합하지 않습니다.

- **옵션 B**: EventBridge Scheduler를 사용하여 AWS Batch job이 성공했을 때 이벤트를 감지하고, AWS Lambda 함수를 트리거합니다. Lambda 함수에서 HTTP API를 호출할 수 있으며, 사용자 이름과 비밀번호를 사용하여 인증을 수행할 수 있습니다. 이 솔루션은 서버리스이며, 요구 사항에 적합합니다.

- **옵션 C**: AWS Batch job이 API Gateway REST API로 이벤트를 전송하고, HTTP 프록시 통합을 설정하여 외부 API를 호출하는 방법입니다. 하지만, API Gateway가 인증을 처리하지 않기 때문에 사용자 이름과 비밀번호를 직접 전달하는 방식은 적합하지 않습니다.

- **옵션 D**: AWS Batch job이 API Gateway REST API로 이벤트를 전송하고 Lambda 함수가 HTTP 요청을 처리하는 방법입니다. 이 옵션은 Lambda를 사용하므로 인증을 처리할 수 있지만, API Gateway의 추가적인 구성 및 오버헤드가 필요할 수 있습니다.

따라서 **옵션 B**가 가장 간단하고 효과적인 해결책으로, AWS Batch job이 성공할 때 이벤트를 감지하고 Lambda 함수를 통해 API 호출을 수행하여 요구 사항을 충족할 수 있습니다.

# 810
### 문제 분석
이 문제는 **회사가 벤더의 AWS 계정에서 호스팅되는 Amazon RDS for MySQL 데이터베이스**에 접근하려는 상황입니다. 회사의 VPC에는 **인터넷 게이트웨이**, **AWS Direct Connect** 연결, 또는 **AWS Site-to-Site VPN 연결**이 없다는 조건이 주어집니다. 따라서 외부 네트워크와 연결 없이 **벤더의 데이터베이스에 안전하게 접근할 방법**을 찾는 것이 핵심입니다.

### 각 옵션 분석

#### A. Instruct the vendor to sign up for the AWS Hosted Connection Direct Connect Program. Use VPC peering to connect the company's VPC and the vendor's VPC.
- **단점**:
  - **Direct Connect**는 온프레미스 데이터 센터와 AWS 간의 연결을 제공하는 서비스입니다. 이 경우, **Direct Connect**는 회사의 VPC와 벤더의 VPC 간의 연결을 위한 최적의 방법이 아닙니다.
  - 또한, **Direct Connect**에 대한 설정은 복잡하고 비용이 많이 들 수 있습니다.
  - VPC 피어링은 가능하지만, **Direct Connect Program**을 사용하려면 여러 복잡한 절차와 설정이 필요하므로 이 방법은 **비효율적**입니다.

#### B. Configure a client VPN connection between the company's VPC and the vendor's VPC. Use VPC peering to connect the company's VPC and the vendor's VPC.
- **단점**:
  - **Client VPN**은 주로 사용자가 온프레미스에서 VPC에 접근할 때 사용하는 방식입니다. 회사의 VPC와 벤더의 VPC 간의 **클라이언트 VPN 연결**은 권장되지 않습니다.
  - **VPC 피어링**은 서로 다른 VPC 간에 네트워크 연결을 설정할 수 있지만, **클라이언트 VPN**을 사용하는 방식은 관리와 확장성에서 비효율적일 수 있습니다.

#### C. Instruct the vendor to create a Network Load Balancer (NLB). Place the NLB in front of the Amazon RDS for MySQL database. Use AWS PrivateLink to integrate the company's VPC and the vendor's VPC.
- **장점**:
  - **AWS PrivateLink**는 **VPC 간 프라이빗 연결**을 제공하며, 이 방법은 벤더의 데이터베이스에 대한 **안전하고 확장 가능한 접근**을 가능하게 합니다.
  - 벤더가 **Network Load Balancer (NLB)**를 앞에 배치하면, 회사는 **프라이빗 링크**를 통해 데이터베이스에 접근할 수 있습니다. **PrivateLink**는 두 VPC 간의 트래픽을 **프라이빗하게 처리**하므로, 인터넷을 통한 접근을 방지하고 보안을 강화할 수 있습니다.
  - **운영 효율성**이 뛰어나며, **AWS 인프라 내에서 안전한 연결**을 제공합니다.
  
#### D. Use AWS Transit Gateway to integrate the company's VPC and the vendor's VPC. Use VPC peering to connect the company’s VPC and the vendor’s VPC.
- **단점**:
  - **AWS Transit Gateway**는 여러 VPC 간에 **중앙 집중식 연결**을 제공하는 서비스입니다. 하지만 회사의 VPC와 벤더의 VPC 간 연결을 설정하려면 **VPC 피어링**을 사용해야 하며, Transit Gateway는 이 경우 과도한 옵션일 수 있습니다.
  - 이 방식은 **복잡성**을 증가시키고 **비용 효율적이지 않을 수** 있습니다.
  - Transit Gateway는 여러 VPC 간의 연결을 다루는 데 유용하지만, 이 시나리오에서는 과도하게 복잡하고 비용이 많이 드는 해결책이 될 수 있습니다.

### 정답
**C. Instruct the vendor to create a Network Load Balancer (NLB). Place the NLB in front of the Amazon RDS for MySQL database. Use AWS PrivateLink to integrate the company's VPC and the vendor's VPC.**

### 해설
- **AWS PrivateLink**는 **프라이빗 네트워크 연결**을 제공하는 최적의 방법입니다. 벤더가 **Network Load Balancer (NLB)**를 사용하여 **RDS** 뒤에 배치하면, 회사는 **PrivateLink**를 통해 벤더의 데이터베이스에 안전하게 연결할 수 있습니다.
- 이 방법은 **인터넷을 통해 데이터를 전송하지 않으며**, **프라이빗한 연결**을 보장하고, **보안과 성능** 측면에서 유리합니다.

# 812
이 문제에서는 데이터 레이크에서 Apache Parquet 형식으로 수집된 데이터를 변환하여 S3 버킷에 저장하는 과정에서 코드가 필요 없는 솔루션을 요구하고 있습니다. 또한 데이터 계보(data lineage)와 데이터 프로파일링(data profiling) 기능을 제공하며, 변환 단계를 직원들과 공유할 수 있어야 합니다. 각 선택지를 분석해 보겠습니다.

### 선택지 분석

A. **AWS Glue Studio 시각적 캔버스를 구성하여 데이터를 변환하고, AWS Glue 작업을 사용하여 변환 단계를 직원들과 공유합니다.**  
- **해결책**: AWS Glue Studio는 코드 없이 데이터를 시각적으로 변환할 수 있는 기능을 제공합니다. 변환 작업을 AWS Glue 작업으로 실행하고 결과를 공유할 수 있어 데이터 계보와 데이터 프로파일링도 지원됩니다.

B. **Amazon EMR Serverless를 구성하여 데이터를 변환하고, EMR Serverless 작업을 사용하여 변환 단계를 직원들과 공유합니다.**  
- **해결책**: EMR Serverless는 데이터 처리를 위해 사용될 수 있지만, 주로 코드 기반 접근 방식이 필요하며, 비코드 솔루션을 요구하는 상황에 맞지 않습니다.

C. **AWS Glue DataBrew를 구성하여 데이터를 변환하고, DataBrew 레시피를 사용하여 변환 단계를 직원들과 공유합니다.**  
- **해결책**: AWS Glue DataBrew는 비코드로 데이터를 변환하고, 레시피를 통해 변환 단계를 공유할 수 있는 훌륭한 솔루션입니다. 데이터 계보와 프로파일링 기능도 제공합니다.

D. **Amazon Athena 테이블을 생성하고, Athena SQL 쿼리를 작성하여 데이터를 변환하고, Athena SQL 쿼리를 직원들과 공유합니다.**  
- **해결책**: Athena는 SQL 쿼리를 통해 데이터를 분석할 수 있지만, 코드가 필요하며, 데이터 변환 프로세스를 비코드로 관리하고 공유하는 데는 적합하지 않습니다.

### 결론

**정답: C**  
- **AWS Glue DataBrew**를 사용하는 것이 요구 사항을 가장 잘 충족합니다. DataBrew는 비코드로 데이터 변환을 지원하며, 데이터 계보와 프로파일링 기능을 제공하고, 레시피를 통해 변환 단계를 쉽게 공유할 수 있습니다.


# 813
이 문제에서는 개발 팀이 특정 개발 EC2 인스턴스에 접근하여 웹 애플리케이션의 새로운 기능을 테스트할 수 있도록 Amazon Route 53 호스팅 영역을 사용하여 접근을 설정하는 요구 사항이 있습니다. 이 솔루션은 개발 인스턴스가 교체되더라도 자동으로 해당 인스턴스로 라우팅되어야 합니다. 각 선택지를 분석해 보겠습니다.

### 선택지 분석

A. **개발 웹사이트에 대한 A 레코드를 생성하고 ALB를 값으로 설정합니다. ALB에서 개발 웹사이트에 대한 요청을 개발 인스턴스가 포함된 대상 그룹으로 전달하는 리스너 규칙을 생성합니다.**  
- **해결책**: 이 옵션은 ALB를 통해 개발 웹사이트에 대한 요청을 처리할 수 있으며, ALB가 요청을 올바른 대상 그룹으로 전달합니다. 개발 인스턴스가 변경되더라도 ALB에 설정된 대상 그룹만 수정하면 되므로 요구 사항을 충족합니다.

B. **개발 인스턴스를 공인 IP 주소로 재생성합니다. 개발 웹사이트에 대한 A 레코드를 생성하고, 개발 인스턴스의 공인 IP 주소를 값으로 설정합니다.**  
- **해결책**: 이 방법은 공인 IP 주소를 사용하여 직접 인스턴스에 접근하게 되지만, 인스턴스가 교체되면 IP 주소도 변경되므로 자동 라우팅의 요구 사항을 충족하지 않습니다.

C. **개발 웹사이트에 대한 A 레코드를 생성하고 ALB를 값으로 설정합니다. ALB에서 개발 웹사이트에 대한 요청을 개발 인스턴스의 공인 IP 주소로 리디렉션하는 리스너 규칙을 생성합니다.**  
- **해결책**: ALB를 사용하지만 공인 IP 주소로 리디렉션하는 것은 인스턴스가 변경될 때마다 수정해야 하므로 자동 라우팅 요구 사항에 맞지 않습니다.

D. **모든 인스턴스를 동일한 대상 그룹에 배치합니다. 개발 웹사이트에 대한 A 레코드를 생성하고 값을 ALB로 설정합니다. ALB에서 개발 웹사이트에 대한 요청을 해당 대상 그룹으로 전달하는 리스너 규칙을 생성합니다.**  
- **해결책**: 모든 인스턴스를 동일한 대상 그룹에 배치하는 것은 가능하지만, 특정 개발 인스턴스에만 접근할 수 없고, 모든 인스턴스로 요청이 분산될 수 있습니다. 이는 개발팀이 원할 때 특정 인스턴스를 테스트할 수 있는 요구 사항을 충족하지 않습니다.

### 결론

**정답: A**  
- **ALB를 통해 개발 웹사이트에 대한 요청을 처리하고, ALB의 리스너 규칙을 사용하여 개발 인스턴스가 포함된 대상 그룹으로 요청을 전달하는** 것이 가장 적합한 솔루션입니다. 이를 통해 개발 인스턴스가 변경되더라도 ALB와 대상 그룹 구성을 수정하는 것으로 자동으로 라우팅을 유지할 수 있습니다.


# 820
이 문제에서는 레거시 애플리케이션의 수백 개의 cron 작업을 AWS로 마이그레이션할 때 최소한의 리팩토링으로 스케줄링하고 실행할 수 있는 솔루션을 요구합니다. 각 옵션을 분석해 보겠습니다.

### 선택지 분석

A. **cron 작업을 위한 컨테이너 이미지를 생성합니다. Amazon EventBridge Scheduler를 사용하여 반복 일정을 생성하고, cron 작업 태스크를 AWS Lambda 함수로 실행합니다.**  
- **해결책**: AWS Lambda는 짧은 시간 동안 실행되는 작업에 적합하지만, cron 작업이 여러 개의 다양한 스케줄로 실행되어야 하기 때문에 Lambda의 시간 제한(최대 15분)에 부합하지 않을 수 있습니다. 이 옵션은 일정한 작업의 시간 제약으로 인해 완전한 솔루션이 아닙니다.

B. **cron 작업을 위한 컨테이너 이미지를 생성합니다. AWS Batch를 사용하여 Amazon ECS에서 스케줄링 정책으로 cron 작업을 실행합니다.**  
- **해결책**: AWS Batch는 대량의 작업을 처리할 수 있는 좋은 옵션이지만, 스케줄링이 EventBridge Scheduler처럼 간단하게 설정되지는 않으므로 추가적인 관리가 필요할 수 있습니다. 특히 복잡한 스케줄링이 필요한 경우 불편할 수 있습니다.

C. **cron 작업을 위한 컨테이너 이미지를 생성합니다. Amazon EventBridge Scheduler를 사용하여 반복 일정을 생성하고, cron 작업 태스크를 AWS Fargate에서 실행합니다.**  
- **해결책**: AWS Fargate는 서버리스 컨테이너 실행을 지원하며, EventBridge Scheduler를 사용하면 다양한 스케줄로 cron 작업을 쉽게 설정할 수 있습니다. 최소한의 리팩토링으로 cron 작업을 실행할 수 있는 좋은 솔루션입니다.

D. **cron 작업을 위한 컨테이너 이미지를 생성하고, AWS Step Functions에서 대기 상태를 사용하여 cron 작업을 지정된 시간에 실행하는 워크플로우를 생성합니다. RunTask 작업을 사용하여 cron 작업 태스크를 AWS Fargate에서 실행합니다.**  
- **해결책**: Step Functions는 작업의 흐름을 제어하는 데 유용하지만, cron 작업이 많을 경우 복잡해질 수 있습니다. 또한 대기 상태를 추가하는 것은 불필요한 복잡성을 초래할 수 있습니다.

### 결론

**정답: C**  
- **Amazon EventBridge Scheduler를 사용하여 반복 일정을 생성하고 cron 작업 태스크를 AWS Fargate에서 실행하는** 것이 이 요구 사항을 가장 잘 충족하는 솔루션입니다. EventBridge Scheduler는 다양한 스케줄로 cron 작업을 설정할 수 있으며, Fargate는 컨테이너를 서버리스로 실행하므로 관리 부담을 최소화할 수 있습니다.


# 825
이 문제에서는 Amazon S3 버킷으로 데이터를 마이그레이션할 때 데이터가 S3 버킷 내에서 암호화되어 있어야 하며, 암호화 키가 매년 자동으로 회전되어야 한다고 요구합니다. 각 옵션을 분석하여 요구 사항을 충족하는 솔루션을 찾아보겠습니다.

### 선택지 분석

A. **Migrate the data to the S3 bucket. Use server-side encryption with Amazon S3 managed keys (SSE-S3). Use the built-in key rotation behavior of SSE-S3 encryption keys.**  
- **해결책**: SSE-S3는 Amazon S3가 관리하는 기본 암호화 방법으로, 사용자가 별도로 키를 관리할 필요가 없습니다. 그러나 SSE-S3는 자동으로 키를 회전하지 않습니다. 따라서 키 회전 요구 사항을 충족하지 않습니다.

B. **Create an AWS Key Management Service (AWS KMS) customer managed key. Enable automatic key rotation. Set the S3 bucket's default encryption behavior to use the customer managed KMS key. Migrate the data to the S3 bucket.**  
- **해결책**: AWS KMS의 고객 관리 키를 사용하여 자동 키 회전을 설정하면 요구 사항을 충족합니다. 이 방법은 S3 버킷에서 데이터를 암호화하고 키를 자동으로 회전할 수 있는 가장 좋은 방법입니다.

C. **Create an AWS Key Management Service (AWS KMS) customer managed key. Set the S3 bucket's default encryption behavior to use the customer managed KMS key. Migrate the data to the S3 bucket. Manually rotate the KMS key every year.**  
- **해결책**: 이 방법은 KMS 키를 수동으로 회전해야 하므로 자동 회전 요구 사항을 충족하지 않습니다.

D. **Use customer key material to encrypt the data. Migrate the data to the S3 bucket. Create an AWS Key Management Service (AWS KMS) key without key material. Import the customer key material into the KMS key. Enable automatic key rotation.**  
- **해결책**: 이 옵션은 고객 키 소재를 사용하여 데이터를 암호화하는 복잡한 절차를 요구합니다. 또한, KMS 키에 대해 고객 키 소재를 가져오는 과정이 필요하므로 운영 복잡성이 높아집니다.

### 결론
**정답: B**  
- AWS KMS의 고객 관리 키를 생성하고 자동 키 회전을 활성화한 후, S3 버킷의 기본 암호화 동작을 해당 KMS 키를 사용하도록 설정하면 매년 자동으로 키를 회전하고 데이터를 안전하게 암호화할 수 있습니다. 이는 최소한의 운영 오버헤드로 요구 사항을 충족하는 방법입니다.


# 826
이 문제에서는 회사가 온프레미스 Microsoft Active Directory에서 AWS로 애플리케이션을 마이그레이션하고, 여러 AWS 계정에서 단일 사인온(SSO) 솔루션을 구현해야 하며, 사용자를 온프레미스 Active Directory에서 계속 관리해야 한다는 요구 사항이 있습니다. 각 선택지를 분석해 보겠습니다.

### 선택지 분석

A. **Create an Enterprise Edition Active Directory in AWS Directory Service for Microsoft Active Directory. Configure the Active Directory to be the identity source for AWS IAM Identity Center.**  
- **해결책**: AWS Directory Service의 Enterprise Edition Active Directory를 사용하면 AWS IAM Identity Center와 통합할 수 있지만, 기존의 온프레미스 Active Directory를 관리하는 요구 사항을 충족하지 않습니다. 이 경우 온프레미스 AD와의 통합을 위해 추가 설정이 필요합니다.

B. **Enable AWS IAM Identity Center. Configure a two-way forest trust relationship to connect the company's self-managed Active Directory with IAM Identity Center by using AWS Directory Service for Microsoft Active Directory.**  
- **해결책**: 이 옵션은 온프레미스 Active Directory와 AWS IAM Identity Center 간의 두 방향의 포리스트 신뢰 관계를 설정하는 방법을 제공합니다. 이 방법을 통해 기존 Active Directory 사용자 및 그룹을 AWS IAM Identity Center와 통합하여 SSO 솔루션을 구현할 수 있습니다. 따라서 요구 사항을 잘 충족합니다.

C. **Use AWS Directory Service and create a two-way trust relationship with the company's self-managed Active Directory.**  
- **해결책**: 이 방법은 온프레미스 Active Directory와 AWS Directory Service 간의 두 방향 신뢰 관계를 설정하는 방법을 설명합니다. 그러나 IAM Identity Center와 통합하는 방법은 제공하지 않으며, 단일 사인온 요구 사항을 충족하지 않습니다.

D. **Deploy an identity provider (IdP) on Amazon EC2. Link the IdP as an identity source within AWS IAM Identity Center.**  
- **해결책**: EC2에서 IdP를 배포하는 것은 가능하지만, 이는 추가적인 관리 및 유지보수가 필요하며 복잡성을 증가시킵니다. 또한 기존 온프레미스 Active Directory와의 통합을 다루지 않습니다.

### 결론
**정답: B**  
- AWS IAM Identity Center를 활성화하고, 회사의 온프레미스 Active Directory와 IAM Identity Center를 AWS Directory Service for Microsoft Active Directory를 통해 두 방향의 포리스트 신뢰 관계를 설정하면, 기존 사용자 및 그룹 관리를 유지하면서 모든 AWS 계정에서 단일 사인온 솔루션을 구현할 수 있습니다. 이 방법은 요구 사항을 효과적으로 충족합니다.


# 828
이 문제에서는 금융 서비스 회사가 AWS에서 보안 통제를 설계하고 이를 확인할 수 있는 증거를 제공해야 하며, NIST 및 PCI DSS와 같은 산업 표준을 준수해야 한다고 요구하고 있습니다. 수백 개의 AWS 계정을 모니터링하여 보안 통제가 올바르게 구현되고 작동하는지를 확인해야 합니다. 각 선택지를 분석해 보겠습니다.

### 선택지 분석

A. **Designate one account as the Amazon Inspector delegated administrator account from the Organizations management account. Integrate Inspector with Organizations to discover and scan resources across all AWS accounts. Enable Inspector industry standards for NIST and PCI DSS.**  
- **해결책**: Amazon Inspector는 보안 평가 및 취약점 관리를 위한 도구입니다. 그러나, Inspector는 보안 통제의 실행 상태를 모니터링하는 것보다 보안 취약성을 평가하는 데 중점을 두고 있으므로, 현재 통제가 작동하고 있는지를 확인하는 데는 적합하지 않습니다.

B. **Designate one account as the Amazon GuardDuty delegated administrator account from the Organizations management account. In the designated GuardDuty administrator account, enable GuardDuty to protect all member accounts. Enable GuardDuty industry standards for NIST and PCI DSS.**  
- **해결책**: GuardDuty는 AWS 리소스에 대한 위협 탐지 및 모니터링을 제공하는 서비스입니다. 그러나 GuardDuty는 보안 통제의 구현 상태를 직접적으로 확인하기 위한 도구가 아니므로, NIST 및 PCI DSS 준수를 위한 감사 증거를 제공하는 데 적합하지 않습니다.

C. **Configure an AWS CloudTrail organization trail in the Organizations management account. Designate one account as the compliance account. Enable CloudTrail security standards for NIST and PCI DSS in the compliance account.**  
- **해결책**: AWS CloudTrail은 AWS 계정의 API 호출을 기록하여 감사 및 보안 분석을 지원합니다. 하지만 CloudTrail 자체는 보안 통제의 현재 상태를 모니터링하거나 평가하는 데 필요한 기능이 부족합니다.

D. **Designate one account as the AWS Security Hub delegated administrator account from the Organizations management account. In the designated Security Hub administrator account, enable Security Hub for all member accounts. Enable Security Hub standards for NIST and PCI DSS.**  
- **해결책**: AWS Security Hub는 다양한 AWS 서비스 및 타사 도구로부터 보안 상태를 집계하고, 여러 보안 표준(NIST, PCI DSS 등)을 기준으로 현재 보안 통제를 평가할 수 있습니다. Security Hub는 통제 상태를 중앙에서 모니터링하고, 감사 목적으로 필요한 정보를 제공할 수 있는 강력한 솔루션입니다.

### 결론
**정답: D**  
- AWS Security Hub를 사용하여 모든 AWS 계정의 보안 상태를 모니터링하고, NIST 및 PCI DSS 기준을 활성화하면, 현재 보안 통제가 구현되고 있는지를 확인하고 감사 요구 사항을 충족할 수 있습니다. Security Hub는 통합된 보안 관리를 제공하여, 여러 계정에서의 보안 통제를 효율적으로 확인할 수 있습니다.


# 831
회사가 온프레미스 환경과 AWS 간에 안전한 연결을 필요로 하며, 이 연결은 높은 대역폭이 필요하지 않고 소량의 트래픽을 처리해야 하며, 신속하게 설정해야 한다고 요구하고 있습니다. 각 선택지를 분석해 보겠습니다.

### 선택지 분석

A. **Implement a client VPN.**  
- **해결책**: 클라이언트 VPN은 개별 사용자들이 AWS 리소스에 안전하게 접근할 수 있도록 도와주지만, 온프레미스 환경과 AWS 간의 연결을 설정하기 위해서는 적합하지 않습니다.

B. **Implement AWS Direct Connect.**  
- **해결책**: AWS Direct Connect는 온프레미스 데이터 센터와 AWS 간의 전용 네트워크 연결을 제공하는 서비스로, 높은 대역폭과 안정성을 제공하지만, 설정 비용이 높고 시간이 많이 소요되므로 이 경우에는 적합하지 않습니다.

C. **Implement a bastion host on Amazon EC2.**  
- **해결책**: 바스천 호스트는 보안적으로 제한된 서버에 SSH 또는 RDP를 통해 접속할 수 있도록 하는 방법입니다. 그러나 이것은 온프레미스 환경과 AWS 간의 연결을 직접적으로 설정하는 방법이 아니므로 이 요구 사항을 충족하지 않습니다.

D. **Implement an AWS Site-to-Site VPN connection.**  
- **해결책**: AWS Site-to-Site VPN은 온프레미스 네트워크와 AWS 간의 안전한 연결을 설정하는 데 적합하며, 소량의 트래픽을 처리할 수 있습니다. 이 방법은 설정이 비교적 간단하고 비용이 저렴하여 요구 사항을 충족합니다.

### 결론
**정답: D**  
- AWS Site-to-Site VPN 연결을 구현하면, 온프레미스 환경과 AWS 간의 안전한 연결을 신속하게 설정할 수 있으며, 높은 대역폭이 필요하지 않고 소량의 트래픽을 처리하는 요구 사항에도 적합합니다. 따라서 이 방법이 가장 비용 효율적입니다.

# 832
회사가 온프레미스 SFTP 파일 전송 솔루션을 AWS로 마이그레이션하여 파일 전송 솔루션을 확장하고 Amazon S3를 사용하여 비용을 최적화하려고 합니다. 회사의 직원은 온프레미스 Microsoft Active Directory(AD)의 자격 증명을 사용하여 새 솔루션에 접근할 수 있어야 하며, 기존의 인증 및 파일 액세스 메커니즘을 유지하고자 합니다. 각 선택지를 분석해 보겠습니다.

### 선택지 분석

A. **Configure an S3 File Gateway. Create SMB file shares on the file gateway that use the existing Active Directory to authenticate.**  
- **해결책**: S3 File Gateway는 Amazon S3와 온프레미스 애플리케이션 간의 통합을 제공하지만, SMB 파일 공유에 적합합니다. SFTP 솔루션을 제공하지 않으므로 이 요구 사항을 충족하지 않습니다.

B. **Configure an Auto Scaling group with Amazon EC2 instances to run an SFTP solution. Configure the group to scale up at 60% CPU utilization.**  
- **해결책**: 이 방법은 SFTP 솔루션을 구축할 수 있지만, EC2 인스턴스를 관리해야 하고, 온프레미스 AD와의 통합을 수동으로 설정해야 하므로 운영 오버헤드가 높아질 수 있습니다. 따라서 요구 사항에 적합하지 않습니다.

C. **Create an AWS Transfer Family server with SFTP endpoints. Choose the AWS Directory Service option as the identity provider. Use AD Connector to connect the on-premises Active Directory.**  
- **해결책**: AWS Transfer Family를 사용하여 SFTP 서버를 생성하고, AD Connector를 통해 온프레미스 AD에 연결함으로써 기존의 인증 방식을 유지할 수 있습니다. 이 방법은 운영 오버헤드가 낮고 AWS의 관리형 서비스로 효율적입니다.

D. **Create an AWS Transfer Family SFTP endpoint. Configure the endpoint to use the AWS Directory Service option as the identity provider to connect to the existing Active Directory.**  
- **해결책**: 이 방법도 SFTP 엔드포인트를 생성하고 AWS Directory Service를 사용하여 기존 AD에 연결할 수 있습니다. 하지만 이 선택지는 AWS Transfer Family 서버를 생성하는 방법을 명확히 언급하지 않으므로 C와 같은 수준의 명확함을 제공하지 않을 수 있습니다.

### 결론
**정답: C**  
- AWS Transfer Family 서버를 SFTP 엔드포인트로 생성하고, AD Connector를 사용하여 온프레미스 Active Directory에 연결하는 방법은 기존 인증 및 파일 액세스 메커니즘을 유지하면서 최소한의 운영 오버헤드로 요구 사항을 충족합니다. 이는 AWS의 관리형 서비스로서 효율적이며, 확장성과 비용 최적화도 가능합니다.

# 833
이 회사는 주문 생성 후 여러 검증 단계를 거쳐야 하는 이벤트 기반 주문 처리 시스템을 설계하고 있습니다. 각 검증 단계는 독립적이며, 각각의 검증 단계에서 필요한 주문 이벤트 정보의 서브셋만 접근할 수 있어야 합니다. 또한 구성 요소가 느슨하게 결합되어 미래의 비즈니스 변경에 유연하게 대응할 수 있어야 합니다. 각 선택지를 분석해 보겠습니다.

### 선택지 분석

A. **Create an Amazon Simple Queue Service (Amazon SQS) queue for each validation step. Create a new Lambda function to transform the order data to the format that each validation step requires and to publish the messages to the appropriate SQS queues. Subscribe each validation step Lambda function to its corresponding SQS queue.**
   - **해결책**: 각 검증 단계에 대해 개별 SQS 큐를 만들고, 데이터 형식을 변환한 후 각 큐로 메시지를 발행하여 각 검증 Lambda 함수가 자신의 큐에 연결됩니다. 하지만 이 방법은 SQS 큐와 변환 Lambda 함수를 각각 추가로 설정해야 하므로 운영 오버헤드가 높아질 수 있습니다.

B. **Create an Amazon Simple Notification Service (Amazon SNS) topic. Subscribe the validation step Lambda functions to the SNS topic. Use message body filtering to send only the required data to each subscribed Lambda function.**
   - **해결책**: SNS 주제를 사용하여 각 검증 Lambda 함수를 구독시키고, 메시지 필터링을 통해 각 함수가 필요한 데이터만 수신하게 할 수 있습니다. 하지만 SNS는 Pub/Sub 방식이라 각 검증 단계의 특정 정보 필터링에는 적합하지 않으며, 독립적인 이벤트 처리에도 제한적입니다.

C. **Create an Amazon EventBridge event bus. Create an event rule for each validation step. Configure the input transformer to send only the required data to each target validation step Lambda function.**
   - **해결책**: EventBridge 이벤트 버스를 사용하여 각 검증 단계마다 이벤트 규칙을 생성하고, 입력 변환기를 구성하여 필요한 데이터만 각 검증 Lambda 함수로 전송합니다. EventBridge는 이벤트 필터링 및 전환에 강력하며, 독립적으로 검증 단계를 구성할 수 있어 느슨한 결합을 구현하는 데 적합합니다. 운영 오버헤드도 최소화됩니다.

D. **Create an Amazon Simple Queue Service (Amazon SQS) queue. Create a new Lambda function to subscribe to the SQS queue and to transform the order data to the format that each validation step requires. Use the new Lambda function to perform synchronous invocations of the validation step Lambda functions in parallel on separate threads.**
   - **해결책**: 단일 SQS 큐와 변환 Lambda 함수를 사용하여 데이터 형식을 맞춘 후 각 검증 Lambda 함수를 동기 호출하는 방식입니다. 그러나 동기 호출 방식은 독립적인 이벤트 처리를 어렵게 하며, 비동기 이벤트 구독이 필요한 요구 사항을 충족하지 못합니다.

### 결론
**정답: C**  
EventBridge 이벤트 버스를 사용하여 이벤트 규칙과 입력 변환기를 통해 각 검증 단계가 필요한 데이터만 받을 수 있도록 하는 방식이 가장 적합합니다. EventBridge는 느슨한 결합 구조를 유지하면서 각 검증 단계를 독립적으로 처리할 수 있게 하며, 운영 오버헤드를 최소화할 수 있습니다.


# 835
**문제 분석:**
이 회사는 온프레미스 네트워크를 AWS 클라우드로 확장하면서 AWS Direct Connect 연결을 사용하고 있습니다. 온프레미스 네트워크는 직접 인터넷에 접근할 수 없고, Amazon S3 버킷에 접근해야 합니다. 이때 비용 효율적인 솔루션이 필요합니다.

### 선택지 분석

**A. Create a public virtual interface (VIF). Route the AWS traffic over the public VIF.**
   - Public VIF를 사용하면 AWS 퍼블릭 서비스에 접근할 수 있습니다. 하지만 퍼블릭 VIF를 사용하면 트래픽이 인터넷을 통해 전송되어 보안 요구사항에 적합하지 않습니다.

**B. Create a VPC and a NAT gateway. Route the AWS traffic from the on-premises network to the NAT gateway.**
   - NAT 게이트웨이를 사용하면 VPC 내부에서 S3와 같은 퍼블릭 서비스에 접근할 수 있습니다. 하지만 NAT 게이트웨이는 비용이 발생하며, 특히 지속적인 데이터 전송이 있는 경우 비용이 높아질 수 있습니다. 이 방식은 비용 효율적이지 않습니다.

**C. Create a VPC and an Amazon S3 interface endpoint. Route the AWS traffic from the on-premises network to the S3 interface endpoint.**
   - S3 인터페이스 엔드포인트를 사용하면 VPC에서 S3에 프라이빗 연결을 통해 접근할 수 있습니다. 온프레미스 트래픽을 Direct Connect를 통해 VPC로 라우팅하여 S3 엔드포인트로 접근하면 비용 효율적이고 안전하게 S3에 접근할 수 있습니다.

**D. Create a VPC peering connection between the on-premises network and Direct Connect. Route the AWS traffic over the peering connection.**
   - VPC 피어링은 VPC 간 연결에 적합하며 온프레미스와 VPC 간의 연결 방식으로는 사용되지 않습니다. Direct Connect 자체가 이미 VPC와 온프레미스 네트워크 간의 연결을 제공합니다.

### 결론
**정답: C**

VPC 내에 Amazon S3 인터페이스 엔드포인트를 생성하고, Direct Connect를 통해 온프레미스 네트워크에서 S3 인터페이스 엔드포인트로 라우팅하는 것이 가장 비용 효율적이고 보안 요구 사항을 충족하는 방법입니다.

# 836
**문제 분석:**
이 회사는 두 개의 AWS 리전(Region)에서 웹사이트를 운영하며 트래픽을 분산하고자 합니다. 또한, 장애 복구 목적에 따라 웹사이트가 정상적으로 작동하지 않는 리전에서는 트래픽을 제공하지 않아야 합니다.

### 선택지 분석

**A. An Amazon Route 53 simple routing policy**
   - 단순 라우팅(Simple Routing)은 단일 레코드에서 여러 IP 주소로 트래픽을 분배할 수 있지만, 상태 확인 기능을 제공하지 않으므로 웹사이트가 정상적으로 작동하지 않는 리전으로 트래픽을 차단할 수 없습니다. 따라서 이 옵션은 요구사항을 충족하지 않습니다.

**B. An Amazon Route 53 multivalue answer routing policy**
   - 멀티밸류 응답 라우팅(Multivalue Answer Routing)은 여러 값(예: 여러 IP 주소)을 반환할 수 있으며, 상태 확인 기능을 제공하여 건강하지 않은 리전으로 트래픽을 보내지 않을 수 있습니다. 따라서 요구사항을 충족할 수 있습니다.

**C. An Application Load Balancer in one Region with a target group that specifies the EC2 instance IDs from both Regions**
   - ALB는 단일 리전에서만 작동하며, 여러 리전에 걸쳐 있는 인스턴스를 대상으로 사용할 수 없습니다. 따라서 이 옵션은 두 리전에 있는 인스턴스에 대한 트래픽 분산을 제공하지 못합니다.

**D. An Application Load Balancer in one Region with a target group that specifies the IP addresses of the EC2 instances from both Regions**
   - ALB는 여러 리전의 IP 주소를 대상으로 하는 구성을 지원하지 않습니다. 이 옵션 역시 두 리전 간의 트래픽 분산 요구사항을 충족하지 못합니다.

### 결론
**정답: B**

Amazon Route 53의 멀티밸류 응답 라우팅(Multivalue Answer Routing)을 사용하면 각 리전에 대한 상태 확인을 설정할 수 있고, 건강하지 않은 리전에 대한 트래픽을 차단할 수 있습니다. 또한 두 리전에 트래픽을 분산하여 성장을 수용하고, 장애 복구 요구사항을 충족할 수 있습니다.

# 837
**문제 분석:**
회사의 애플리케이션이 Amazon EC2 인스턴스에서 실행되고 있으며, Amazon EBS를 사용해 파일을 저장하고 있습니다. 직원들이 25GB 이상의 파일을 저장하고 검색할 때 가용성 문제가 발생하고 있습니다. 이 문제를 해결하기 위해 파일을 여러 EC2 인스턴스와 여러 가용 영역(AZ)에서 사용할 수 있어야 하며, EC2 인스턴스 간에 파일을 전송하지 않아야 합니다.

### 선택지 분석

**A. Migrate all the files to an Amazon S3 bucket. Instruct the employees to access the files from the S3 bucket.**
   - Amazon S3는 객체 스토리지로서, 여러 EC2 인스턴스 및 가용 영역에서 파일을 쉽게 공유할 수 있습니다. 25GB 이상의 대용량 파일도 저장하고 액세스할 수 있지만, S3는 파일 시스템 인터페이스를 제공하지 않으므로 애플리케이션이 파일 시스템 접근 방식을 필요로 할 경우 적합하지 않습니다.

**B. Take a snapshot of the existing EBS volume. Mount the snapshot as an EBS volume across the EC2 instances. Instruct the employees to access the files from the EC2 instances.**
   - EBS 볼륨은 단일 EC2 인스턴스에만 연결될 수 있어 여러 인스턴스에서 동시에 접근할 수 없습니다. 또한 EBS 스냅샷을 직접 마운트할 수 없습니다. 따라서 요구사항을 충족하지 못합니다.

**C. Mount an Amazon Elastic File System (Amazon EFS) file system across all the EC2 instances. Instruct the employees to access the files from the EC2 instances.**
   - Amazon EFS는 완전관리형 네트워크 파일 시스템으로, 여러 EC2 인스턴스와 여러 가용 영역에서 동시에 마운트할 수 있습니다. 또한 파일 시스템 접근 방식을 제공하므로 대용량 파일(25GB 이상)을 공유하고 저장하기에 적합합니다. 요구사항을 충족하는 최적의 솔루션입니다.

**D. Create an Amazon Machine Image (AMI) from the EC2 instances. Configure new EC2 instances from the AMI that use an instance store volume. Instruct the employees to access the files from the EC2 instances.**
   - 인스턴스 스토어는 EC2 인스턴스가 중지되거나 종료될 때 데이터가 사라지며, 데이터는 특정 인스턴스에서만 사용할 수 있습니다. 여러 인스턴스 간 파일을 공유하려는 요구사항을 충족하지 못합니다.

### 결론
**정답: C**

Amazon EFS는 여러 EC2 인스턴스에서 동시에 접근할 수 있는 공유 파일 시스템으로, 여러 가용 영역을 지원하며 파일 시스템 인터페이스를 제공합니다. 따라서 회사의 요구사항을 충족하는 가장 적합한 솔루션입니다.

# 841
정답은 **B. 현재 EBS 스냅샷 정책을 유지하고, 월별 스냅샷을 Amazon EBS Snapshots Archive에 7년 보존하는 새 정책을 추가**하는 것입니다.

설명:

- **옵션 A**: Amazon S3 Glacier Deep Archive는 매우 저렴한 저장 옵션이지만, EBS 스냅샷을 S3 Glacier Deep Archive로 직접 복사하는 것은 지원되지 않습니다. 따라서, 이 옵션은 실현 불가능합니다.

- **옵션 B**: Amazon EBS Snapshots Archive는 장기 보관을 위해 설계된 스냅샷 보관 옵션으로, 표준 스냅샷보다 비용이 저렴하며 EBS 스냅샷을 유지할 수 있습니다. 월별 스냅샷을 EBS Snapshots Archive로 이동하여 7년간 보관하는 것이 비용 효율적이고, EBS 환경 내에서 관리할 수 있어 관리가 간편합니다.

- **옵션 C**: 월별 스냅샷을 표준 EBS 스냅샷에 7년간 유지하는 것은 비용이 많이 들 수 있습니다. Amazon EBS Snapshots Archive를 사용하는 것이 장기 보관 시 더 비용 효율적입니다.

- **옵션 D**: EBS Direct API로 매달 전체 스냅샷을 Amazon S3에 저장하는 방식은 데이터 관리가 복잡해지며 비용이 많이 듭니다. 또한, 이 방식은 EBS 스냅샷을 직접 S3에 저장하는 것보다 효율적이지 않습니다.

**결론**: **옵션 B**가 장기 보관에 대한 요구 사항을 비용 효율적으로 충족하는 가장 적합한 솔루션입니다.

# 842
정답은 **D. AWS Backup을 사용하여 백업 계획을 생성하고, 이를 통해 데이터를 다른 리전으로 복제하는 방법**이 가장 적합합니다.

### 해설
- **D. AWS Backup을 사용하여 EFS 파일 시스템을 백업하고 복제**: AWS Backup을 사용하여 백업 계획에 따라 EFS 데이터를 다른 리전으로 자동으로 복제할 수 있습니다. AWS Backup은 관리형 서비스로 백업과 복제를 자동화하며 비용 효율적입니다. EFS와 통합되어 있고, 별도 스크립트나 인프라 설정 없이 간단하게 리전 간 데이터 복제를 설정할 수 있습니다.

### 다른 선택지 분석
- **A. EFS-to-EFS 백업 솔루션**: 이 솔루션은 사용자가 직접 설정하는 커스텀 솔루션으로 관리 부담이 더 크며, 비용 효율성도 떨어질 수 있습니다.
- **B. EFS에서 S3로 데이터 복사 후 S3 크로스 리전 복제**: 이 방법은 EFS 데이터를 S3로 옮기는 추가 과정이 필요하며, 매일 데이터를 복사하는 스크립트 관리와 크로스 리전 복제 비용이 추가될 수 있습니다.
- **C. Cross-Region VPC 피어링 후 rsync 스크립트로 데이터 복사**: VPC 피어링을 통한 데이터 복사는 추가적인 네트워크 비용이 발생하고, 데이터 복제를 위한 rsync 스크립트를 관리해야 하므로 운영 부담이 큽니다.

따라서 **AWS Backup을 사용한 D 선택지가 비용 효율적이면서도 관리 부담이 적은 최적의 솔루션**입니다.


# 844
이 문제에서 가장 적합한 서비스는 **D. AWS Storage Gateway**입니다.

### 해설:
- **AWS Storage Gateway**는 온프레미스 환경과 AWS 간의 데이터 전송을 용이하게 해주는 하이브리드 클라우드 스토리지 서비스입니다. 특히, SMB 파일 공유를 통해 파일을 AWS에 저장할 수 있는 기능을 제공하여, 기존의 애플리케이션 코드 수정을 최소화하면서도 파일을 AWS로 자동으로 복사할 수 있게 합니다. 이를 통해 저지연 연결을 유지하면서도 클라우드 스토리지로 파일을 이전할 수 있습니다.

### 다른 선택지 분석:
- **A. Amazon Elastic File System (Amazon EFS)**: EFS는 파일 스토리지 서비스지만, 직접적으로 온프레미스 파일을 EFS로 전송하는 기능을 제공하지 않기 때문에, 이를 위해서는 추가적인 솔루션이 필요합니다.
- **B. Amazon FSx for Windows File Server**: FSx는 Windows 환경에 최적화된 파일 서버이지만, AWS와의 연동을 위해 별도의 코드 수정이 필요할 수 있습니다. 또한, SMB 공유에 대한 지원은 있지만, 기존 애플리케이션과의 통합이 AWS Storage Gateway만큼 용이하지 않습니다.
- **C. AWS Snowball**: Snowball은 대량의 데이터를 온프레미스에서 AWS로 물리적으로 이전하는 데 적합하지만, 일상적인 파일 생성 및 복사와 같은 지속적인 데이터 전송에는 적합하지 않습니다. 이 경우, 기존 애플리케이션의 지속적인 파일 생성 및 이동 요구 사항을 충족하지 못합니다.

따라서, **AWS Storage Gateway**가 기존의 SMB 파일 공유와의 통합을 통해 가장 적합하고 효율적인 솔루션입니다.


# 846
이 문제에서 요구하는 요구 사항을 충족하는 가장 적절한 솔루션은 **B. Create a recurring scheduled action to scale up the Auto Scaling group before the expected period of peak demand**입니다.

### 해설:
- **B. Create a recurring scheduled action to scale up the Auto Scaling group before the expected period of peak demand**: 이 옵션은 예상되는 트래픽 스파이크가 발생하기 전에 Auto Scaling 그룹의 용량을 사전적으로 증가시킬 수 있는 계획적인 조치를 설정하는 것입니다. 이를 통해 피크 수요 기간 동안 사용자에게 미치는 성능 영향을 최소화할 수 있습니다. 이 방법은 이미 예측된 트래픽에 기반하여 사전 대응할 수 있는 가장 효과적인 방법입니다.

### 다른 선택지 분석:
- **A. Create an Amazon CloudWatch alarm to scale up the EC2 instances when CPU utilization exceeds 90%**: 이 옵션은 수요가 급증했을 때 자동으로 인스턴스를 확장하지만, 트래픽 스파이크가 발생한 후에 대응하는 것이므로, 이미 성능 저하가 발생할 수 있습니다.
  
- **C. Increase the minimum and maximum number of EC2 instances in the Auto Scaling group during the peak demand period**: 이 방법은 수동으로 인스턴스 수를 조정해야 하므로, 예측된 트래픽을 효과적으로 처리하기 위해 사전에 조치를 취하는 방법이 아닙니다.
  
- **D. Configure an Amazon Simple Notification Service (Amazon SNS) notification to send alerts when there are autoscaling:EC2_INSTANCE_LAUNCH events**: 이 옵션은 EC2 인스턴스가 시작될 때 알림을 제공하지만, 이를 통해 성능을 향상시키는 직접적인 방법이 아닙니다.

따라서, **B** 옵션이 트래픽 스파이크를 효과적으로 처리하기 위한 사전 대응 전략으로 가장 적합합니다.


# 850
이 문제의 요구 사항을 충족하고 운영 오버헤드를 최소화할 수 있는 가장 적절한 솔루션은 **B. Use Amazon Neptune to store the data. Use SPARQL to query the data to identify security risks**입니다.

### 해설:
- **B. Use Amazon Neptune to store the data. Use SPARQL to query the data to identify security risks**: Amazon Neptune은 그래프 데이터베이스 서비스로, IT 인프라의 리소스를 그래프 구조로 모델링하여 관계를 시각화하고 분석할 수 있습니다. SPARQL 쿼리를 사용하여 리소스 간의 관계를 쉽게 탐색하고 보안 위험을 식별할 수 있습니다. 이러한 그래프 기반 접근 방식은 복잡한 관계를 효율적으로 처리할 수 있어 IT 인프라의 보안 정책을 집행하는 데 유리합니다.

### 다른 선택지 분석:
- **A. Use Amazon RDS to store the data. Use SQL to query the data to identify security risks**: RDS는 관계형 데이터베이스로, 복잡한 관계를 처리하기에는 한계가 있을 수 있습니다. SQL 쿼리는 데이터 관계를 탐색하는 데 상대적으로 불편할 수 있습니다.

- **C. Use Amazon Redshift to store the data. Use SQL to query the data to identify security risks**: Redshift는 데이터 웨어하우스 서비스로 대량의 데이터를 분석하는 데 적합하지만, 실시간 쿼리에는 최적화되어 있지 않습니다. IT 인프라 맵을 효율적으로 탐색하고 실시간으로 보안 위험을 식별하기에는 적합하지 않습니다.

- **D. Use Amazon DynamoDB to store the data. Use PartiQL to query the data to identify security risks**: DynamoDB는 NoSQL 데이터베이스로 빠른 읽기 및 쓰기 성능을 제공하지만, 그래프 구조를 다루는 데는 한계가 있으며, 관계를 탐색하는 데는 비효율적일 수 있습니다.

따라서, **B** 옵션은 IT 인프라의 복잡한 관계를 효율적으로 관리하고 보안 위험을 식별하기에 가장 적합한 솔루션입니다.

# 852
정답은 **B. Amazon Elastic File System (Amazon EFS) 파일 시스템에 웹사이트 자산을 저장하고, 각 EC2 인스턴스가 EFS 파일 시스템을 로컬에 마운트하도록 구성하는 것**입니다.

설명:

- **옵션 A**: EC2 사용자 데이터를 통해 최신 인스턴스에서만 자산을 업데이트하거나, ALB를 특정 인스턴스로 라우팅하도록 구성하는 방식은 관리가 복잡하고 확장성이 떨어집니다. 또한, 각 인스턴스에서 콘텐츠를 쉽게 공유하는 방법이 아니며, 요구되는 ‘최소 지연 시간’을 달성하기 어렵습니다.

- **옵션 B**: Amazon EFS는 여러 인스턴스가 동시에 액세스할 수 있는 공유 파일 시스템을 제공하며, 지연 시간 없이 실시간으로 업데이트된 데이터를 모든 인스턴스가 공유할 수 있도록 합니다. EFS는 다수의 EC2 인스턴스에서 웹사이트 자산을 공유하는 데 최적화된 솔루션으로, 별도의 데이터 동기화 작업이 필요 없으므로 관리가 간편하고 지연 시간이 최소화됩니다.

- **옵션 C**: S3와 EC2 간의 자산 동기화는 매번 데이터를 다운로드하고 동기화하는 과정에서 지연이 발생할 수 있습니다. 또한, S3와 EC2 간의 지속적인 동기화는 데이터 갱신 주기를 보장할 수 없으므로, 콘텐츠 업데이트에 지연이 발생할 가능성이 있습니다.

- **옵션 D**: EBS 스냅샷을 사용하여 각 인스턴스에 자산을 로드하는 방식은 스냅샷이 고정된 시점의 데이터를 제공하기 때문에, 실시간 업데이트가 필요한 웹사이트 콘텐츠와는 맞지 않습니다. 또한 새로운 인스턴스마다 스냅샷을 복원하고 부착해야 하므로 지연 시간이 길어집니다.

**결론**: 옵션 B의 EFS를 사용한 방식이 여러 EC2 인스턴스 간에 콘텐츠를 실시간으로 공유하고, 최소한의 지연 시간과 관리 작업으로 요구사항을 충족하는 최적의 솔루션입니다.


# 854
정답은 **C. Configure the DB cluster to use IAM database authentication. Create a database user to use with IAM authentication. Associate a role with the EC2 instances to allow applications on the instances to access the database.**입니다.

### 설명
문제의 요구사항은 **정적 자격 증명을 유지하지 않고, EC2 인스턴스가 Amazon Aurora 데이터베이스에 안전하게 인증하도록 하는 것**입니다. 각 옵션을 분석해 보면 다음과 같습니다:

- **A 옵션:** CloudFormation 템플릿에 데이터베이스 사용자 이름과 암호를 매개변수로 추가하는 방법은 정적 자격 증명을 유지하게 되므로, 보안 및 유지 관리 요구사항에 적합하지 않습니다.

- **B 옵션:** AWS Systems Manager Parameter Store에 자격 증명을 저장하면 보안은 강화되지만, 여전히 정적 자격 증명을 유지하게 됩니다. 문제에서 요구하는 "정적 자격 증명 유지 회피" 조건에 부합하지 않습니다.

- **C 옵션 (정답):** **IAM 데이터베이스 인증을 사용하여 IAM 역할로 데이터베이스에 액세스하도록 구성**하는 방식은 정적 자격 증명 없이 EC2 인스턴스가 안전하게 데이터베이스에 인증할 수 있는 방법입니다. IAM 역할을 EC2 인스턴스에 연결함으로써 자격 증명 관리의 운영 부담을 줄일 수 있습니다.

- **D 옵션:** IAM 데이터베이스 인증을 위해 IAM 사용자를 생성하고 해당 사용자를 EC2 인스턴스에 연결하는 방법은 정답과 유사해 보이지만, **IAM 역할**을 사용하여 EC2 인스턴스에 자격 증명을 부여하는 것이 더 일반적이고, 보안 측면에서 권장됩니다. IAM 사용자를 개별적으로 생성하여 연결하는 것보다 **IAM 역할을 사용하는 것이 더 효율적이며 운영 부담이 적습니다**.

따라서, **정적 자격 증명 없이 IAM 역할을 사용하여 안전하게 인증할 수 있는 C 옵션이 가장 적합**합니다.


# 855
정답은 **C. Request an Amazon issued public certificate from AWS Certificate Manager (ACM) in the us-east-1 Region.**입니다.

### 설명
Amazon CloudFront 배포에서 사용자 지정 도메인 이름을 사용할 때, SSL/TLS 인증서를 구성하여 HTTPS로 보안을 설정할 수 있습니다. AWS에서는 **AWS Certificate Manager (ACM)**을 통해 무료로 퍼블릭 SSL/TLS 인증서를 발급받을 수 있으며, 이를 CloudFront와 함께 사용할 수 있습니다.

각 옵션을 분석해 보면 다음과 같습니다:

- **A 옵션:** **프라이빗 인증서**는 AWS Certificate Manager Private Certificate Authority(ACM PCA)를 통해 발급되며 추가 비용이 발생합니다. 따라서 프라이빗 인증서를 사용하면 비용이 추가되므로 적합하지 않습니다.

- **B 옵션:** 프라이빗 인증서를 us-west-1 리전에서 발급하더라도 여전히 ACM PCA 비용이 발생합니다. CloudFront에서 사용하는 퍼블릭 인증서와는 다릅니다.

- **C 옵션 (정답):** **퍼블릭 인증서**를 us-east-1 리전에서 요청하면 비용이 발생하지 않습니다. CloudFront는 ACM에서 발급된 퍼블릭 인증서를 us-east-1 리전에서 사용할 때 최적의 호환성을 제공하므로, 이 리전에서 발급한 퍼블릭 인증서를 사용하는 것이 적합합니다.

- **D 옵션:** us-west-1 리전에서 퍼블릭 인증서를 요청하는 경우, CloudFront와의 호환성 문제로 인해 인증서를 사용할 수 없습니다. CloudFront는 **us-east-1 리전**에서 발급된 퍼블릭 인증서만 지원합니다.

따라서, **비용 없이 SSL/TLS 인증서를 설정하려면 us-east-1 리전에서 퍼블릭 인증서를 요청하는 C 옵션이 가장 적합**합니다.


# 856
정답은 **D. Generate a presigned URL that has the required access to the location of the report on the S3 bucket. Share the presigned URL with the external consultant.** 입니다.

### 설명:

**프리사인드 URL (Presigned URL)** 은 특정 객체에 대해 임시로 액세스할 수 있는 URL을 제공하는 방법입니다. 이 URL을 사용하면 S3 버킷의 전체 권한을 공개하지 않고도 특정 파일에 대한 접근 권한을 부여할 수 있습니다. 이 방법의 장점은 다음과 같습니다:

- **운영 효율성**: 프리사인드 URL을 생성하는 것은 간단하고, IAM 사용자나 S3 버킷 설정을 변경할 필요가 없습니다.
- **임시 액세스**: 프리사인드 URL은 만료 시간을 설정할 수 있어(예: 7일) 외부 컨설턴트가 지정된 기간 동안만 액세스할 수 있습니다.
- **정확한 접근 제어**: URL은 특정 객체에만 접근할 수 있도록 제한되므로, 연례 보고서에만 접근을 허용하고 다른 데이터는 보호할 수 있습니다.

### 다른 옵션이 잘못된 이유:

- **A. 새로운 S3 버킷을 만들고, 이를 공용 정적 웹사이트로 설정한 후, 운영 데이터를 새로운 버킷으로 이동하고 외부 컨설턴트에게 S3 웹사이트 URL을 공유합니다.**
  - 새로운 버킷을 만들고 데이터를 이동하는 것은 불필요한 작업이며, 버킷을 공용으로 설정하는 것은 보안상 위험합니다. 단지 하나의 보고서에 접근하기 위한 방법으로는 과도한 해결책입니다.

- **B. S3 버킷에 대한 공용 액세스를 7일 동안 허용하고, 외부 컨설턴트가 감사 작업을 완료한 후 액세스를 제거합니다.**
  - S3 버킷 전체에 대해 공용 액세스를 허용하는 것은 보안상 위험합니다. 모든 데이터가 외부에 공개되므로, 특정 파일만 접근하도록 하는 프리사인드 URL 방식보다 관리가 더 복잡하고 위험할 수 있습니다.

- **C. 새로운 IAM 사용자를 만들고, 해당 사용자에게 S3 버킷의 보고서에 대한 액세스 권한을 부여한 후, 액세스 키를 외부 컨설턴트에게 제공하고, 7일 후 액세스 키를 회수합니다.**
  - 새로운 IAM 사용자를 만들고 액세스 키를 관리하는 것은 복잡하고, 프리사인드 URL을 사용하여 특정 객체에 대해 임시로 액세스를 부여하는 방법에 비해 효율성이 떨어집니다.

결론적으로, **프리사인드 URL** (옵션 D)은 특정 파일에 대해 임시적이고 제한적인 액세스를 제공하는 가장 효율적이고 안전한 방법입니다.

# 858
- terminate는 종료하다여


# 859
정답은 **A. Use the Trusted Advisor recommendations in the management account.**와 **C. Review the Trusted Advisor checks for Amazon RDS Reserved Instance Optimization.**입니다.

### 설명

AWS Trusted Advisor는 비용 최적화를 포함한 다양한 권장 사항을 제공하여, RDS 비용을 줄일 수 있는 방법을 제안합니다. 각 옵션을 살펴보면 다음과 같습니다:

- **A. Use the Trusted Advisor recommendations in the management account.**  
  관리 계정에서는 조직의 모든 멤버 계정의 Trusted Advisor 권장 사항을 확인할 수 있습니다. 이를 통해, 금융 팀이 모든 RDS 인스턴스에 대한 비용 최적화 권장 사항을 한 곳에서 검토할 수 있습니다.

- **B. Use the Trusted Advisor recommendations in the member accounts where the RDS DB instances are running.**  
  멤버 계정에서 Trusted Advisor 권장 사항을 확인할 수 있지만, 관리 계정에서 모든 멤버 계정을 조회할 수 있으므로 개별적으로 확인할 필요는 없습니다.

- **C. Review the Trusted Advisor checks for Amazon RDS Reserved Instance Optimization.**  
  **RDS 예약 인스턴스 최적화**는 On-Demand 인스턴스를 예약 인스턴스로 전환하여 비용을 절감할 수 있는지를 확인하는 Trusted Advisor 검사입니다. RDS 인스턴스의 높은 사용률을 고려할 때, 예약 인스턴스를 사용하면 비용을 절감할 가능성이 높습니다.

- **D. Review the Trusted Advisor checks for Amazon RDS Idle DB Instances.**  
  **RDS 유휴 DB 인스턴스** 검사는 사용률이 낮은 RDS 인스턴스를 확인하는 것이지만, 문제에서 설명된 RDS 인스턴스는 "높은 사용률"을 보이므로 유휴 인스턴스와는 무관합니다.

- **E. Review the Trusted Advisor checks for compute optimization. Crosscheck the results by using AWS Compute Optimizer.**  
  **Compute Optimizer**는 EC2 인스턴스와 같은 컴퓨팅 자원의 최적화에 집중하므로, RDS 인스턴스에는 적합하지 않습니다.

따라서, **관리 계정에서 Trusted Advisor 권장 사항을 사용하고, RDS 예약 인스턴스 최적화 검사를 검토하는 것이 요구사항에 가장 적합**합니다.


# 861
주어진 시나리오는 온프레미스 MySQL 데이터베이스를 AWS로 이전하는 과정에서 클라이언트-대응 애플리케이션으로부터의 높은 쓰기 작업량으로 인해 성능 문제가 발생할 수 있다는 우려가 있는 상황입니다. 아래는 제시된 옵션들에 대한 분석입니다.

### 옵션 분석

**A. Provision an Amazon RDS for MySQL DB instance with Provisioned IOPS SSD storage. Monitor write operation metrics by using Amazon CloudWatch. Adjust the provisioned IOPS if necessary.**  
- **장점**: 
  - Provisioned IOPS SSD 스토리지는 높은 성능을 제공하며, 많은 쓰기 작업을 효율적으로 처리할 수 있습니다.
  - Amazon RDS를 사용하면 관리, 백업, 스케일링이 간편해집니다.
  - CloudWatch 모니터링을 통해 성능 메트릭에 따라 사전 조정을 할 수 있습니다.
- **단점**: 
  - General Purpose SSD보다 비용이 더 높지만, 높은 쓰기 작업량에 필요한 성능을 제공합니다.

**B. Provision an Amazon RDS for MySQL DB instance with General Purpose SSD storage. Place an Amazon ElastiCache cluster in front of the DB instance. Configure the application to query ElastiCache instead.**  
- **장점**: 
  - ElastiCache는 데이터베이스의 읽기 트래픽을 오프로드하여 읽기 성능을 향상시킬 수 있습니다.
- **단점**: 
  - 이 옵션은 주로 읽기 성능을 개선하는 데 초점을 맞추고 있으며, 높은 쓰기 작업량에 대한 직접적인 최적화를 제공하지 않습니다. General Purpose SSD는 높은 쓰기 부하를 처리하기에 충분하지 않을 수 있습니다.

**C. Provision an Amazon DocumentDB (with MongoDB compatibility) instance with a memory optimized instance type. Monitor Amazon CloudWatch for performance-related issues. Change the instance class if necessary.**  
- **장점**: 
  - DocumentDB는 문서 지향 데이터에 최적화되어 있으며 높은 성능을 처리할 수 있습니다.
- **단점**: 
  - MySQL 데이터베이스를 위한 것이 아니므로 현재 사용 사례에 적합하지 않습니다.

**D. Provision an Amazon Elastic File System (Amazon EFS) file system in General Purpose performance mode. Monitor Amazon CloudWatch for IOPS bottlenecks. Change to Provisioned Throughput performance mode if necessary.**  
- **장점**: 
  - EFS는 확장 가능한 파일 저장 서비스로, 파일 저장 필요에 유용할 수 있습니다.
- **단점**: 
  - EFS는 MySQL 데이터베이스를 직접 관리하는 데 적합하지 않으며, 높은 쓰기 작업을 효과적으로 최적화하지 않습니다.

### 추천 솔루션

**A. Provision an Amazon RDS for MySQL DB instance with Provisioned IOPS SSD storage. Monitor write operation metrics by using Amazon CloudWatch. Adjust the provisioned IOPS if necessary.**

### 정당화
- **높은 쓰기 성능**: Provisioned IOPS SSD 스토리지는 높은 입출력 작업을 처리하기 위해 특별히 설계되었으므로, 애플리케이션의 높은 쓰기 작업량에 적합합니다.
- **관리의 용이성**: Amazon RDS는 백업, 패치 및 장애 조치를 관리하여 운영 부담을 줄입니다.
- **확장성**: RDS는 필요에 따라 스토리지와 컴퓨트 리소스를 조정할 수 있습니다.
- **모니터링**: CloudWatch 통합을 통해 아키텍트는 성능 메트릭을 적극적으로 모니터링하고 리소스를 미리 조정하여 최적의 성능을 보장할 수 있습니다.

결론적으로, 옵션 A는 MySQL 데이터베이스를 이전하면서 높은 쓰기 트래픽으로 인한 성능 문제를 해결하는 데 가장 적합한 솔루션입니다.


# 862
정답은 **D. 애플리케이션이 AWS Key Management Service (AWS KMS)에 저장된 키를 사용하여 클라이언트 측 암호화를 사용하고, 애플리케이션이 S3 버킷에 보관할 아카이브 파일을 저장하도록 구성하는 방법**입니다.

설명:

- **옵션 A**: 클라이언트 측 암호화는 애플리케이션에서 데이터를 암호화하고 S3에 업로드할 때 암호화된 데이터를 저장하는 방식입니다. 하지만 **Amazon S3 관리형 키**(SSE-S3)를 사용하는 경우, S3에서 암호화 키를 관리하므로 제어 권한이 부족해집니다. 이를 통해 "데이터가 암호화되기 전에 제3자가 접근할 수 없다"는 요구 사항을 충족하지 못할 수 있습니다. 따라서 제3자가 데이터에 접근할 가능성이 있습니다.

- **옵션 B**: 서버 측 암호화(SSE-KMS)는 S3에 저장된 데이터를 암호화하지만, **S3에 업로드될 때 암호화된 데이터가 암호화된 이후**에 제어됩니다. 이 방법은 **데이터가 S3에 도달한 후 암호화**되므로 제3자가 데이터가 S3에 저장되기 전에 접근할 수 있습니다. 이 방식은 요구 사항을 충족하지 못합니다.

- **옵션 C**: 이 옵션은 **이중 암호화**를 사용한다고 언급되어 있으나, 실제로 "이중 암호화"는 필요하지 않으며, 불필요한 복잡성을 추가할 수 있습니다. 기본적으로 S3 서버 측 암호화가 충분히 요구 사항을 충족할 수 있습니다. 또한, **이중 암호화**는 암호화가 두 번 이루어지는 구조로 해석될 수 있지만, 추가적인 보안이 필요하지 않다면 이 방식은 과도한 방법입니다.

- **옵션 D**: **클라이언트 측 암호화**는 데이터가 S3에 업로드되기 전에 애플리케이션에서 데이터를 암호화하는 방식입니다. AWS KMS를 사용하여 암호화 키를 관리하는 경우, 애플리케이션이 데이터가 S3에 업로드되기 전에 **데이터를 암호화**할 수 있습니다. 이를 통해 **제3자가 데이터에 접근하기 전에 암호화**가 이루어지므로, 요구 사항을 완전히 충족할 수 있습니다.

**결론**: 옵션 D는 **클라이언트 측 암호화**와 **AWS KMS 키 관리**를 통해 데이터를 암호화하기 전에 제3자가 접근할 수 없도록 보장하므로 요구 사항을 가장 잘 충족하는 솔루션입니다.
- **민감한 데이터 보호**: 클라이언트 측 암호화를 통해 데이터가 AWS로 전송되기 전에 암호화되어 제3자가 접근할 수 없습니다.
- **키 관리**: AWS KMS를 사용하여 암호화 키를 안전하게 관리할 수 있으며, 애플리케이션에서 필요한 경우 쉽게 접근할 수 있습니다.
- **보안성**: 이 방법은 데이터 보안을 강화하며, 데이터 전송 및 저장 과정에서 민감한 데이터를 보호하는 데 적합합니다.

결론적으로, 옵션 D는 회사의 요구 사항을 충족하는 가장 적합한 솔루션입니다.

# 863
### 옵션 분석

**A. Write an AWS Lambda function to create an RDS snapshot every day.**  
- **장점**: 
  - Lambda는 서버리스로 운영되므로 관리 부담이 적습니다.
  - 백업 프로세스를 자동화할 수 있습니다.
- **단점**: 
  - Lambda를 설정하고 유지 관리해야 하며, 별도의 코드 관리가 필요합니다.

**B. Modify the RDS database to have a retention period of 30 days for automated backups.**  
- **장점**: 
  - 자동화된 백업을 활성화하고 RDS가 자동으로 매일 백업을 생성합니다.
  - 설정이 간단하고 관리 오버헤드가 거의 없습니다.
  - 30일 간의 백업을 자동으로 관리합니다.
- **단점**: 
  - 필요에 따라 추가적인 수동 스냅샷을 생성해야 할 수 있습니다.

**C. Use AWS Systems Manager Maintenance Windows to modify the RDS backup retention period.**  
- **장점**: 
  - 관리 작업을 예약할 수 있는 유연성이 있습니다.
- **단점**: 
  - Maintenance Windows는 주로 유지 관리 작업을 예약하는 데 사용되며, 매일의 스냅샷을 생성하는 데는 적합하지 않습니다. 이 방법은 추가적인 복잡성을 초래할 수 있습니다.

**D. Create a manual snapshot every day by using the AWS CLI. Modify the RDS backup retention period.**  
- **장점**: 
  - 수동으로 백업을 관리할 수 있습니다.
- **단점**: 
  - 매일 수동으로 스냅샷을 생성해야 하며, 이는 관리 오버헤드가 큽니다. 자동화가 없으므로 운영 부담이 증가합니다.

### 추천 솔루션

**B. Modify the RDS database to have a retention period of 30 days for automated backups.**

### 정당화
- **최소 운영 오버헤드**: RDS의 자동 백업 기능을 활성화하면 백업 생성 및 관리가 자동으로 이루어지므로 운영 부담이 최소화됩니다.
- **규제 요구 사항 충족**: 자동화된 백업은 데이터베이스가 변경될 때마다 스냅샷을 생성하고, 30일간의 보존을 보장하여 규제 요구 사항을 충족합니다.
- **간편한 관리**: 추가적인 Lambda 함수나 수동 작업이 필요하지 않아 설정과 유지 관리가 간편합니다.

결론적으로, 옵션 B는 요구 사항을 충족하는 가장 효율적인 솔루션입니다.

# 868
The scenario involves a global company that needs to identify all Amazon S3 buckets that are not versioning-enabled across AWS Regions. Let's analyze the options provided:

### 옵션 분석

**A. Use the AWS Management Console to manually check each S3 bucket's versioning status across Regions.**  
- **장점**: 
  - 직접적인 방법으로 버전 관리 상태를 확인할 수 있습니다.
- **단점**: 
  - 수많은 S3 버킷을 수동으로 검사해야 하므로 비효율적이고 시간이 많이 걸립니다.
  - 글로벌 스케일에서 비효율적입니다.

**B. Use Amazon S3 Storage Lens to identify all S3 buckets that are not versioning-enabled across Regions.**  
- **장점**: 
  - S3 Storage Lens는 S3 버킷의 메트릭과 사용량 데이터를 시각화하여, 버전 관리가 활성화되지 않은 버킷을 쉽게 식별할 수 있도록 도와줍니다.
  - 여러 Region에 걸쳐 버킷 상태를 한눈에 볼 수 있어 매우 효율적입니다.
- **단점**: 
  - 추가적인 설정이 필요할 수 있지만, 장기적으로 관리가 용이합니다.

**C. Enable IAM Access Analyzer for S3 to identify all S3 buckets that are not versioning-enabled across Regions.**  
- **장점**: 
  - IAM Access Analyzer는 S3 버킷의 접근 제어와 관련된 보안 문제를 분석할 수 있습니다.
- **단점**: 
  - 버전 관리 활성화 여부를 직접적으로 식별하지 않으므로 요구 사항을 충족하지 않습니다.

**D. Create an S3 Multi-Region Access Point to identify all S3 buckets that are not versioning-enabled across Regions.**  
- **장점**: 
  - 여러 Region에서 S3 버킷에 대한 접근을 중앙 집중화할 수 있습니다.
- **단점**: 
  - Multi-Region Access Point는 버전 관리 활성화 여부를 직접적으로 식별하는 데 사용되지 않으므로 요구 사항을 충족하지 않습니다.

### 추천 솔루션

**B. Use Amazon S3 Storage Lens to identify all S3 buckets that are not versioning-enabled across Regions.**

### 정당화
- **효율성**: S3 Storage Lens는 S3 버킷의 사용량 및 메트릭을 분석하여 버전 관리 활성화 여부를 손쉽게 확인할 수 있도록 도와줍니다.
- **전역 분석**: 여러 Region에 걸쳐 있는 S3 버킷을 한 번에 모니터링할 수 있는 기능을 제공합니다.
- **자동화된 관리**: 추가적인 수동 검사 없이 자동으로 버킷 상태를 분석할 수 있어 운영 오버헤드를 줄일 수 있습니다.

결론적으로, 옵션 B는 요구 사항을 충족하는 가장 효과적인 솔루션입니다.

# 870
정답은 **C. Create an IAM role in the Production account. Define a trust policy that specifies the Development account. Allow developers to assume the role.** 입니다.

### 설명:

**IAM 역할 (IAM Role)** 을 사용하여 다른 AWS 계정 간에 권한을 위임할 수 있습니다. 이 방식은 보안과 관리 측면에서 매우 유연하고 효율적입니다. 각 계정의 사용자에게 필요한 권한을 제공하고, 개발자들이 다른 계정에서 리소스에 접근할 수 있도록 허용하는 방법입니다.

1. **Production 계정에 IAM 역할 생성**: Production 계정에서 역할을 생성하고, 이 역할에 필요한 권한을 부여합니다. 예를 들어, 코드 배포를 위해 S3, EC2, Lambda와 같은 서비스에 접근할 수 있는 권한을 부여할 수 있습니다.
   
2. **신뢰 정책 (Trust Policy) 정의**: 이 역할이 `Development` 계정에서 사용될 수 있도록 신뢰 정책을 설정합니다. 이를 통해 `Development` 계정의 사용자들이 `Production` 계정에서 역할을 `가정 (assume)` 할 수 있게 됩니다.

3. **역할을 개발자에게 위임**: `Development` 계정의 두 명의 개발자에게 해당 역할을 가정할 수 있는 권한을 부여합니다. 이렇게 하면 개발자들이 Production 계정의 리소스에 안전하게 접근할 수 있습니다.

### 다른 옵션들이 잘못된 이유:

- **A. 각 계정에서 정책 문서를 만들어 개발자에게 정책을 할당합니다.**
  - 이 방법은 두 계정 간에 권한을 안전하게 공유하는 방법이 아닙니다. 권한을 여러 개발자에게 개별적으로 할당하는 것은 관리가 복잡하고, 계정 간의 접근을 쉽게 제어하기 어렵습니다.

- **B. Development 계정에 IAM 역할을 만들고, Production 계정에 접근할 수 있도록 권한을 부여하여 개발자가 역할을 가정할 수 있도록 합니다.**
  - IAM 역할을 `Development` 계정에 만든 후 `Production` 계정에 접근을 허용하는 방식은, 실제 요구 사항과는 반대 방향입니다. `Production` 계정에서 권한을 부여하는 것이 필요합니다.

- **D. Production 계정에 IAM 그룹을 만들고, 해당 그룹을 신뢰 정책의 원칙으로 추가하여 개발자를 그룹에 추가합니다.**
  - IAM 그룹은 사용자를 관리하는 데 유용하지만, 계정 간 역할 전환을 위한 방법으로는 부적합합니다. 신뢰 정책은 주로 IAM 역할에서 설정되며, 그룹은 해당 용도에 맞지 않습니다.

따라서, **IAM 역할**을 사용하여 `Production` 계정에서 `Development` 계정의 개발자들이 역할을 가정하고 필요한 권한을 부여하는 방식이 가장 적합한 솔루션입니다.

# 872
정답은 **D. Create an organization in AWS Organizations in the management account with the default policy. Create a service control policy (SCP) that denies the launch of large EC2 instances, and apply it to the AWS accounts.** 입니다.

### 설명:

**AWS Organizations**는 여러 AWS 계정을 중앙에서 관리하고, 각 계정에 대한 제어를 설정할 수 있는 기능을 제공합니다. 이 중 **Service Control Policies (SCPs)**는 특정 AWS 계정 또는 조직 단위(OU)에 대해 리소스를 생성하거나 특정 서비스를 사용할 수 있는 권한을 제한할 수 있습니다.

1. **AWS Organizations 사용**: 여러 AWS 계정을 포함하는 조직을 만들고, 관리 계정에서 전체 계정에 대한 정책을 설정할 수 있습니다.

2. **SCP(서비스 제어 정책) 설정**: SCP를 사용하여 EC2 인스턴스의 크기와 같은 특정 리소스에 대한 제한을 설정할 수 있습니다. 예를 들어, EC2 인스턴스의 크기가 특정 범위를 넘지 않도록 SCP를 설정할 수 있습니다.

3. **조직 단위에 SCP 적용**: SCP는 AWS 계정에 직접 적용하거나 특정 조직 단위(OU)에 적용할 수 있습니다. 이를 통해 팀원들이 EC2 인스턴스의 크기 제한을 우회하지 못하게 할 수 있습니다.

이 방식은 **최소한의 운영 오버헤드**로 여러 계정에 대해 일관된 정책을 설정할 수 있으며, AWS Organizations에서 한 번만 설정하면 됩니다.

### 다른 옵션들의 문제점:

- **A. Update the IAM policies to deny the launch of large EC2 instances. Apply the policies to all users.**
  - IAM 정책은 특정 사용자나 그룹에 적용되므로 전체 계정에 걸쳐 일관되게 적용하려면 여러 사용자의 IAM 정책을 관리해야 합니다. 이 방법은 계정 수가 많아지면 관리 오버헤드가 증가합니다.

- **B. Define a resource in AWS Resource Access Manager that prevents the launch of large EC2 instances.**
  - AWS Resource Access Manager는 리소스 공유를 관리하는 도구로, EC2 인스턴스와 같은 자원의 크기 제한을 설정하는 데 사용되지 않습니다.

- **C. Create an IAM role in each account that denies the launch of large EC2 instances. Grant the developers IAM group access to the role.**
  - IAM 역할을 각 계정에 생성하는 방식은 관리가 복잡해질 수 있으며, 특히 여러 계정과 환경을 관리할 때 일관되게 적용하는 데 어려움이 있을 수 있습니다.

따라서 **SCP를 활용하는 방법(D)**이 여러 계정에서 EC2 인스턴스 크기 제한을 설정하는 데 가장 효율적이고 관리 오버헤드를 최소화할 수 있는 방법입니다.

# 876
- AD냐, BD냐 그것이 문제로다
- GPT는 AD라고 함

# 877
이 문제에서는 **낮은 트래픽(월 100회 미만의 방문)**과 **비용 효율성**이 중요한 요소입니다. 따라서 비용이 많이 들고 불필요한 서비스를 피하고, 간단하고 서버리스 솔루션을 선택하는 것이 가장 적합합니다.

---

### 정답:
**B. Create an Amazon API Gateway endpoint that returns the contact form from an AWS Lambda function. Configure another Lambda function on the API Gateway to publish a message to an Amazon Simple Notification Service (Amazon SNS) topic.**

---

### 해설:

- **B. Amazon API Gateway와 AWS Lambda를 사용하여 동적 컨택트 폼을 구현하고 Amazon SNS를 통해 알림을 설정합니다.**
   - **설명**: API Gateway와 Lambda를 조합하면 서버리스로 동적 기능을 구현할 수 있어 비용 효율적입니다. 첫 번째 Lambda 함수는 API Gateway를 통해 클라이언트로부터 데이터를 수집하고, 두 번째 Lambda 함수는 Amazon SNS로 메시지를 전송하여 이메일 알림을 보내게 합니다. 이 솔루션은 트래픽이 적고 유지보수 부담이 적은 환경에 적합합니다.

---

### 오답 해설:

- **A. Amazon ECS를 사용하여 동적 컨택트 폼을 호스팅하고, Amazon SES와 타사 이메일 제공자를 연결합니다.**
   - **설명**: Amazon ECS는 컨테이너 기반 서비스로, 작은 규모의 트래픽에 대응하기에는 과도한 설정과 비용이 요구됩니다. Amazon SES와 타사 이메일 제공자를 연결하는 것은 필요 이상의 복잡한 설정입니다.

- **C. AWS Amplify Hosting을 사용하여 정적 및 동적 콘텐츠를 호스팅하고, Amazon SQS를 통해 메시지를 전달합니다.**
   - **설명**: AWS Amplify는 서버리스로 웹 애플리케이션을 호스팅할 수 있지만, Amazon SQS는 알림 기능에 적합하지 않습니다. Amazon SNS를 사용하는 것이 더 효율적이며 단순합니다.

- **D. Amazon EC2 인스턴스에서 Windows Server와 IIS를 사용하여 웹사이트를 호스팅하고, Amazon WorkMail과 연동하여 이메일 알림을 설정합니다.**
   - **설명**: Amazon EC2에서 Windows Server를 사용하여 사이트를 호스팅하는 것은 비용이 많이 들며, 사이트 방문이 적은 상황에서 과도한 리소스입니다. 서버리스 및 S3와 같은 정적 호스팅보다 비효율적입니다.

---

따라서 비용 효율성과 간소함을 고려할 때, **정답은 B**입니다.

# 878
**정답**: **A. Configure each AWS account to use a single email address that the company manages. Ensure that all account owners can access the email account to receive notifications. Configure alternate contacts for each AWS account with corresponding distribution lists for the billing team, the security team, and the operations team for each business unit.**

---

### 해설:

각 AWS 계정에서 알림을 특정 팀에 맞게 전달하고, 동시에 보안성을 유지하려면, 루트 사용자 이메일 대신 **알림 목적별로 대체 연락처(Alternate Contacts)를 설정**하는 것이 좋습니다. AWS 계정의 루트 사용자 이메일 주소는 민감한 정보가 포함될 수 있기 때문에, 보안성과 관리 용이성을 위해 특정 팀에 대한 알림만 받을 수 있는 대체 연락처로 구성하는 것이 필요합니다.

1. **A. 단일 관리 이메일 계정을 사용하여 각 계정 소유자가 접근 가능하게 하고, 대체 연락처를 구성하여 각 비즈니스 단위의 결제, 보안, 운영 팀용 배포 리스트를 사용한다.**
   - **설명**: 모든 계정의 루트 이메일로 하나의 관리 이메일을 사용하는 것은 알림 수신 및 계정 소유자의 접근성을 모두 보장합니다. 대체 연락처를 통해 결제, 보안, 운영 팀별 알림을 설정함으로써 중요한 알림이 특정 팀에 맞춰 전달됩니다. 이는 보안성이 뛰어나고 팀별로 알림을 받기 쉬운 구조입니다.

---

### 오답 해설:

- **B. 각 비즈니스 단위에 대해 별도의 이메일 배포 리스트를 사용하고, 알림에 응답할 수 있는 관리 이메일을 구성하며, 각 팀에 맞는 대체 연락처를 설정한다.**
   - **설명**: 각 계정에 대해 별도의 배포 리스트를 사용하는 것은 관리 복잡도를 높이며, 알림 관리가 어려워질 수 있습니다. 이 방법은 불필요한 설정과 복잡성을 유발할 수 있습니다.

- **C. 각 계정의 루트 사용자 이메일 주소를 비즈니스 단위의 담당자 개인 이메일로 설정하고, 각 팀에 맞는 대체 연락처를 설정한다.**
   - **설명**: 개인 이메일을 루트 이메일로 설정하는 것은 보안 위험이 있으며, 담당자 변경 시 이메일을 변경해야 하는 번거로움이 있습니다. 알림 목적에 맞는 대체 연락처가 필요하지만, 루트 사용자 이메일을 개인 이메일로 설정하는 것은 보안상 권장되지 않습니다.

- **D. 중앙 메일박스로 전달되는 이메일 별칭을 사용하여 루트 사용자 이메일을 구성하고, 대체 연락처를 통해 각 팀의 단일 배포 리스트를 사용한다.**
   - **설명**: 모든 알림이 중앙 메일박스로 집약되기 때문에 각 팀에 맞는 적절한 알림 분배가 어렵습니다. 알림 목적별로 대체 연락처를 구성하는 방식이 더 효과적입니다.

---

**따라서 정답은 A**로, 단일 관리 이메일 계정과 대체 연락처 설정이 가장 안전하고 효율적인 솔루션입니다.


# 881
- AC? AE?

이 시나리오에서는 높은 트래픽을 받는 정적 웹사이트의 성능을 개선하면서도 배포 후 몇 분 이내에 사용자가 최신 콘텐츠를 받을 수 있도록 보장해야 합니다. 이를 위해서는 적절한 캐싱 전략을 구현해야 합니다.

### 정답:
**A. Set the CloudFront default TTL to 2 minutes.**  
**E. Add a Cache-Control max-age directive of 24 hours to the objects in Amazon S3. On deployment, create a CloudFront invalidation to clear any changed files from edge caches.**

---

### 해설:

1. **A. Set the CloudFront default TTL to 2 minutes.**  
   - **설명**: CloudFront의 기본 TTL을 2분으로 설정하면, CloudFront가 엣지 캐시에 콘텐츠를 최대 2분 동안 저장하게 됩니다. 이는 사용자에게 캐시된 콘텐츠를 제공하되, 새로운 콘텐츠가 배포되면 약 2분 후에 사용자가 업데이트된 콘텐츠를 받을 수 있도록 합니다. 이 설정은 성능을 개선하면서도 신선도를 유지하는 데 도움이 됩니다.

2. **E. Add a Cache-Control max-age directive of 24 hours to the objects in Amazon S3. On deployment, create a CloudFront invalidation to clear any changed files from edge caches.**  
   - **설명**: S3 객체에 `Cache-Control max-age` 지시어를 24시간으로 설정하면, 클라이언트와 CloudFront가 해당 객체를 24시간 동안 캐시할 수 있습니다. 그러나 배포 시 CloudFront의 무효화(invalidation)를 사용하여 변경된 파일을 엣지 캐시에서 삭제할 수 있습니다. 이렇게 하면 오래된 캐시된 콘텐츠를 신속하게 제거하고, 사용자에게 최신 콘텐츠를 제공할 수 있습니다.

### 오답 해설:

- **B. Set a default TTL of 2 minutes on the S3 bucket.**  
   - **설명**: S3 버킷에는 TTL 설정이 적용되지 않습니다. TTL은 주로 CloudFront와 관련이 있으며, S3에서는 캐시 제어 헤더를 설정해야 합니다.

- **C. Add a Cache-Control private directive to the objects in Amazon S3.**  
   - **설명**: `Cache-Control: private`는 캐시를 브라우저 개인 캐시에서만 사용할 수 있도록 제한합니다. 이는 일반적으로 공유 캐시(예: CloudFront)에서는 사용되지 않으므로, 성능 개선에 기여하지 않습니다.

- **D. Create an AWS Lambda@Edge function to add an Expires header to HTTP responses. Configure the function to run on viewer response.**  
   - **설명**: Lambda@Edge를 사용하여 Expires 헤더를 추가할 수 있지만, 이 방법은 불필요하게 복잡할 수 있습니다. 기본 TTL 설정과 Cache-Control 헤더를 적절히 활용하는 것이 더 효율적이고 간단합니다.

---

따라서 **A와 E**의 조합이 성능 개선과 신선도 유지를 동시에 충족하는 최적의 솔루션입니다.


# 885
Selected Answer: CD
It's pretty obvious, although it's called: Machine Learning Savings Plans for Amazon SageMaker (C)
For the compute workloads we need a compute savings plan, that covers all the 3 compute options we use here (EC2, Lambda and Fargate) (D)

# 886
정답은 **B. Babelfish를 Aurora PostgreSQL에서 활성화하여 애플리케이션의 SQL 쿼리를 실행**과 **C. AWS Schema Conversion Tool (AWS SCT)와 AWS Database Migration Service (AWS DMS)를 사용하여 데이터베이스 스키마와 데이터를 마이그레이션**입니다.

### 설명:

- **옵션 B: Babelfish를 Aurora PostgreSQL에서 활성화하여 애플리케이션의 SQL 쿼리를 실행**
  - **Babelfish for Aurora PostgreSQL**은 Microsoft SQL Server의 T-SQL 쿼리를 PostgreSQL에서 실행할 수 있게 해주는 기능입니다. Babelfish를 사용하면 SQL Server 애플리케이션을 **PostgreSQL로의 데이터베이스 마이그레이션을 최소화하면서** 코드 변경 없이 사용할 수 있습니다. 이를 통해 **SQL Server의 쿼리**가 Aurora PostgreSQL에서 그대로 실행될 수 있습니다.

- **옵션 C: AWS Schema Conversion Tool (AWS SCT)와 AWS Database Migration Service (AWS DMS)를 사용하여 데이터베이스 스키마와 데이터를 마이그레이션**
  - **AWS Schema Conversion Tool (AWS SCT)**는 SQL Server의 스키마를 PostgreSQL에 맞게 변환하는 데 사용할 수 있습니다. 또한, **AWS Database Migration Service (AWS DMS)**는 데이터 마이그레이션을 지원하며, 실시간 데이터 동기화가 가능합니다. 이 두 가지 도구를 사용하면 데이터베이스 마이그레이션을 **효율적이고 안전하게** 수행할 수 있습니다.

### 나머지 옵션에 대한 설명:

- **옵션 A: AWS Schema Conversion Tool (AWS SCT)를 사용하여 애플리케이션의 SQL 쿼리를 재작성**
  - **AWS SCT**는 데이터베이스 스키마와 쿼리 변환을 지원하지만, **애플리케이션 코드의 SQL 쿼리 재작성**을 자동으로 처리하지 않습니다. 애플리케이션 코드에서 직접 SQL 쿼리를 변경하는 작업은 **수동으로 해야** 하므로 이 방법은 전체적인 요구사항을 충족하지 않습니다.

- **옵션 D: Amazon RDS Proxy를 사용하여 애플리케이션을 Aurora PostgreSQL에 연결**
  - **Amazon RDS Proxy**는 데이터베이스 연결 풀링 기능을 제공하여 데이터베이스 연결을 관리할 수 있지만, SQL Server에서 PostgreSQL로의 **마이그레이션 문제**를 해결하는 데는 적합하지 않습니다. 이 옵션은 주로 성능과 연결 관리를 위한 도구로 사용됩니다.

- **옵션 E: AWS Database Migration Service (AWS DMS)를 사용하여 애플리케이션의 SQL 쿼리를 재작성**
  - **AWS DMS**는 데이터베이스의 마이그레이션을 돕는 서비스로, **SQL 쿼리를 재작성하지 않습니다**. 이 서비스는 데이터의 복제 및 마이그레이션을 주로 처리하며, 애플리케이션의 쿼리를 자동으로 수정하는 기능은 제공하지 않습니다.

### 결론:
**옵션 B와 C**는 **애플리케이션 코드 변경을 최소화하면서 SQL Server에서 PostgreSQL로의 마이그레이션을 효율적으로 수행**하는 최적의 방법입니다.

# 887
정답은 **A. Configure the EC2 account attributes to always encrypt new EBS volumes**입니다.

이 옵션은 **모든 새로 생성되는 EBS 볼륨이 자동으로 암호화**되도록 보장하며, EBS 볼륨 암호화를 활성화하기 위해 별도의 작업을 최소화할 수 있습니다. EC2 계정 속성에서 EBS 볼륨을 기본적으로 암호화하도록 설정하면, 새로 생성되는 모든 EBS 볼륨이 자동으로 암호화되며 암호화되지 않은 볼륨이 생성되는 것을 방지할 수 있습니다.

각 옵션을 살펴보면:

- **A. Configure the EC2 account attributes to always encrypt new EBS volumes**: 이 옵션은 EC2 계정 속성에서 EBS 기본 암호화를 설정하여 모든 새로 생성되는 EBS 볼륨이 자동으로 암호화되도록 보장합니다. 이는 요구사항을 충족하는 가장 간단하고 효율적인 솔루션입니다.

- **B. Use AWS Config. Configure the encrypted-volumes identifier. Apply the default AWS Key Management Service (AWS KMS) key**: AWS Config를 사용하여 암호화된 볼륨을 모니터링할 수 있지만, Config는 기존의 규정 준수 상태를 평가할 뿐 새 볼륨 생성 시 기본적으로 암호화되도록 강제할 수는 없습니다.

- **C. Configure AWS Systems Manager to create encrypted copies of the EBS volumes. Reconfigure the EC2 instances to use the encrypted volumes**: 이 방법은 기존 비암호화 볼륨을 암호화할 수 있지만, 새로 생성되는 모든 EBS 볼륨이 자동으로 암호화되도록 보장하지는 않습니다.

- **D. Create a customer managed key in AWS Key Management Service (AWS KMS). Configure AWS Migration Hub to use the key when the company migrates workloads**: Migration Hub와 KMS 키를 사용하는 방법은 마이그레이션 중에 특정 키로 암호화를 설정할 수는 있지만, 모든 새 EBS 볼륨에 대한 기본 암호화를 설정할 수 있는 방법은 아닙니다.

따라서, **A 옵션이 모든 새 EBS 볼륨을 자동으로 암호화하고 암호화되지 않은 볼륨의 생성을 방지하는 가장 적합한 솔루션**입니다.

# 888
정답은 **A. Use a data stream in Amazon Kinesis Data Streams in on-demand mode to capture the clickstream data. Use AWS Lambda to process the data in real time**입니다.

이 솔루션은 클릭스트림 데이터를 실시간으로 캡처하고 처리하는 데 적합하며, **Kinesis Data Streams의 온디맨드 모드**는 트래픽이 변동할 때 자동으로 확장되어 다양한 수준의 트래픽을 유연하게 처리할 수 있습니다. 또한, **AWS Lambda를 통해 실시간 데이터 처리**가 가능하며, Lambda는 필요에 따라 자동으로 확장되므로 데이터 처리에 유연한 솔루션을 제공합니다.

각 옵션을 분석해보면:

- **A. Amazon Kinesis Data Streams in on-demand mode + AWS Lambda**: Kinesis Data Streams의 온디맨드 모드는 자동으로 확장되어 트래픽 변동에 따라 처리량을 조절할 수 있습니다. 또한, AWS Lambda와 결합하면 실시간으로 데이터를 분석하고 처리할 수 있어 클릭스트림 데이터 요구사항에 잘 맞습니다.

- **B. Amazon Kinesis Data Firehose + AWS Glue**: Kinesis Data Firehose는 실시간 스트리밍 데이터 처리보다는 데이터 수집 및 배치 저장에 최적화되어 있습니다. AWS Glue는 배치 기반의 ETL 작업에 더 적합하며, 실시간 분석을 위한 최적의 선택은 아닙니다.

- **C. Amazon Kinesis Video Streams + AWS Glue**: Kinesis Video Streams는 영상 스트리밍 데이터를 처리하기 위한 서비스로, 클릭스트림과 같은 이벤트 데이터 처리에는 적합하지 않습니다.

- **D. Amazon Managed Service for Apache Flink + AWS Lambda**: Amazon Managed Service for Apache Flink는 Kinesis Data Streams나 Kafka 스트림의 데이터를 실시간으로 분석하는 데 사용되며, 자체적으로 클릭스트림 데이터를 캡처하는 기능은 없습니다. 이 옵션은 데이터 캡처에 적합하지 않으므로 요구사항을 충족하지 못합니다.

따라서, **A 옵션이 변동하는 트래픽에 맞춰 자동으로 확장되는 실시간 데이터 캡처와 처리를 제공하는 가장 적합한 솔루션**입니다.

# 889
정답은 **B. Use AWS Batch to run the application. Use an AWS Step Functions state machine to invoke the AWS Batch job every 4 hours**입니다.

이 솔루션은 **AWS Batch를 사용하여 CPU 집약적인 ETL 작업을 효율적으로 처리**할 수 있습니다. AWS Batch는 컴퓨팅 자원을 자동으로 프로비저닝하고, 단기적으로 실행되는 작업에 적합한 인스턴스를 활용하여 비용을 최적화할 수 있습니다. 또한, **AWS Step Functions**를 사용하여 정기적으로 AWS Batch 작업을 예약할 수 있어 4시간마다 실행되는 ETL 작업에 적합한 솔루션입니다.

각 옵션을 분석해 보면:

- **A. AWS Lambda와 CloudWatch Logs**: Lambda는 CPU 집약적인 작업보다는 짧고 가벼운 작업에 적합합니다. Lambda 함수는 단일 인스턴스에서 제한된 CPU 자원을 사용하며, 실행 시간과 메모리 사용량 제한이 있어 고성능이 필요한 작업에는 적합하지 않습니다.

- **B. AWS Batch와 Step Functions**: AWS Batch는 CPU 집약적인 작업과 스케줄링에 최적화된 서비스로, 매 4시간마다 ETL 작업을 실행하는 데 적합합니다. 또한, Step Functions를 사용하여 작업을 쉽게 예약할 수 있습니다.

- **C. AWS Fargate와 EventBridge**: Fargate는 컨테이너 작업을 실행할 때 적합하지만, 이 경우 단순히 CPU 집약적인 작업을 위해 EC2 인스턴스를 선택하는 것이 더 효율적입니다. Fargate는 비용 효율 면에서 상대적으로 불리할 수 있습니다.

- **D. EC2 Spot Instances와 CodeDeploy**: Spot Instances는 비용을 절감할 수 있지만, 실행 중단 가능성이 있어 예약된 작업의 신뢰성을 보장하기 어렵습니다. 또한 CodeDeploy는 배포 자동화에는 적합하나 정기적인 작업 스케줄링에는 적합하지 않습니다.

따라서, **B 옵션**이 CPU 집약적인 ETL 애플리케이션을 4시간마다 안정적으로 실행하는 가장 적합한 솔루션입니다.

# 890
정답은 **A. Set up an ECS cluster that uses the AWS Fargate launch type for the cloud application containers. Use an Amazon ECS Anywhere external launch type for the on-premises application containers.**와 **B. Set up an Application Load Balancer for cloud ECS services.**입니다.

### 설명:

- **A. ECS 클러스터를 설정하고, AWS Fargate 런치 타입을 사용하여 클라우드 애플리케이션 컨테이너를 실행합니다. ECS Anywhere 외부 런치 타입을 사용하여 온프레미스 애플리케이션 컨테이너를 실행합니다.**
  - **ECS Anywhere**는 온프레미스 환경에서 ECS를 실행할 수 있게 해주는 기능입니다. 이를 통해 온프레미스에서 실행되는 컨테이너와 클라우드에서 실행되는 ECS 컨테이너를 동일한 ECS 클러스터에서 관리할 수 있습니다. **AWS Fargate**는 서버리스 컨테이너 실행 환경으로, 클라우드에서 애플리케이션 컨테이너를 자동으로 확장할 수 있습니다.

- **B. 클라우드 ECS 서비스에 대한 애플리케이션 로드 밸런서를 설정합니다.**
  - **Application Load Balancer**(ALB)는 HTTP/HTTPS 트래픽에 최적화된 로드 밸런서로, ECS 서비스에서 실행되는 컨테이너들에 대한 HTTP 트래픽을 분배하는 데 사용됩니다. 클라우드 환경에서 ECS 서비스를 로드 밸런싱하려면 ALB가 적합합니다.

### 각 옵션 분석:

- **A. (정답)**: 이 옵션은 클라우드와 온프레미스 환경에서 모두 확장 가능한 ECS 기반 컨테이너를 설정하는 데 적합합니다. **ECS Anywhere**와 **Fargate**는 서로 다른 환경에서 실행되는 컨테이너를 쉽게 관리할 수 있게 해줍니다.

- **B. (정답)**: ALB는 HTTP 트래픽을 처리하는 데 최적화되어 있으며, ECS 서비스와 잘 통합됩니다. 클라우드 내의 ECS 서비스에 대한 HTTP 요청을 로드 밸런싱하려면 ALB를 사용하는 것이 적합합니다.

- **C. 네트워크 로드 밸런서를 설정하는 옵션은** 주로 TCP 트래픽을 처리할 때 유용하지만, 이 질문에서는 **HTTP 트래픽**을 처리해야 하므로 **ALB가 더 적합**합니다.

- **D. Fargate를 사용하여 클라우드 및 온프레미스 컨테이너를 모두 실행하는 옵션은** **온프레미스 환경에서 Fargate를 사용할 수 없음**을 고려할 때 적합하지 않습니다. 온프레미스에서는 **ECS Anywhere** 외부 런치 타입을 사용해야 합니다.

- **E. EC2 런치 타입을 사용하는 옵션은** 클라우드에서 EC2 인스턴스에서 ECS 컨테이너를 실행하는 방법이지만, 온프레미스 환경에서 ECS Anywhere의 Fargate 런치 타입을 사용할 수 없으므로 이 옵션은 적합하지 않습니다.

따라서 **A와 B** 옵션이 요구 사항을 가장 잘 충족하는 솔루션입니다.


# 893
정답은 **A. Use AWS Control Tower to deploy accounts. Create a networking account that has a VPC with private subnets and public subnets. Use AWS Resource Access Manager (AWS RAM) to share the subnets with the workload accounts.**

### 이유:
**AWS Control Tower**는 여러 AWS 계정을 중앙에서 관리하고, **자동화된 보안 제어(guardrails)**를 적용하는 데 최적화된 서비스입니다. 이 솔루션은 여러 계정을 설정하고, 네트워크와 보안을 일관되게 관리하는 데 필요한 **최소한의 운영 오버헤드**로 요구 사항을 충족할 수 있습니다.

#### 각 옵션 분석:
- **A. Use AWS Control Tower to deploy accounts. Create a networking account that has a VPC with private subnets and public subnets. Use AWS Resource Access Manager (AWS RAM) to share the subnets with the workload accounts.**
  - **AWS Control Tower**를 사용하여 계정을 생성하고, **네트워킹 계정**에서 VPC를 중앙 관리하며, **AWS RAM**을 통해 해당 VPC를 **작업 부하 계정**과 공유하는 방식은 **중앙 집중식 네트워크 관리**와 **보안 제어(guardrails)**를 동시에 해결할 수 있습니다. 이 방식은 **운영 오버헤드가 최소화**되며, 여러 계정의 네트워크를 효율적으로 관리할 수 있습니다.

- **B. Use AWS Organizations to deploy accounts. Create a networking account that has a VPC with private subnets and public subnets. Use AWS Resource Access Manager (AWS RAM) to share the subnets with the workload accounts.**
  - **AWS Organizations**는 계정을 관리하는 데 좋은 서비스지만, **보안 제어**와 **자동화된 가드레일**을 설정하는 데는 **AWS Control Tower**보다 운영상 더 많은 노력이 필요합니다. 또한 **Control Tower**는 보안 정책과 관리 작업을 자동화하여 더 적은 오버헤드로 관리할 수 있습니다.

- **C. Use AWS Control Tower to deploy accounts. Deploy a VPC in each workload account. Configure each VPC to route through an inspection VPC by using a transit gateway attachment.**
  - 이 방법은 **VPC를 각 작업 부하 계정에 배포**하고 **트랜짓 게이트웨이를 사용**하여 트래픽을 **검사 VPC**로 라우팅하는 방식입니다. 이 방식은 네트워크 트래픽을 검사하는 데 유용할 수 있지만, 각 계정에 VPC를 배치하는 데 더 많은 리소스와 관리가 필요합니다. 여러 계정을 중앙에서 관리하는 데는 **A 옵션**이 더 효율적입니다.

- **D. Use AWS Organizations to deploy accounts. Deploy a VPC in each workload account. Configure each VPC to route through an inspection VPC by using a transit gateway attachment.**
  - **AWS Organizations**를 사용하여 계정을 생성하고 각 계정에 VPC를 배포하는 방식은 **관리 복잡성**이 증가합니다. 트랜짓 게이트웨이를 설정하는 것은 네트워크 관리의 복잡도를 높이므로, **A 옵션**이 더 적합합니다.

### 결론:
**A 옵션**은 **AWS Control Tower**를 사용하여 계정을 배포하고, **네트워킹 계정**을 중앙에서 관리하면서 **AWS RAM**을 통해 서브넷을 공유하는 방식으로, **자동화된 보안 제어**와 **최소한의 운영 오버헤드**를 실현할 수 있는 가장 효율적인 방법입니다.


# 894
정답은 **A. Move the website to an Amazon S3 bucket. Configure an Amazon CloudFront distribution for the S3 bucket.**

### 이유:
이 시나리오에서 **웹사이트는 정적 콘텐츠**를 제공하며, **트래픽이 증가**하고 있어 **비용을 최소화**하려고 합니다. 이 경우, **Amazon S3**와 **Amazon CloudFront**를 사용하면 비용 효율적인 솔루션을 제공할 수 있습니다.

#### 각 옵션 분석:
- **A. Move the website to an Amazon S3 bucket. Configure an Amazon CloudFront distribution for the S3 bucket.**
  - **Amazon S3**는 **정적 웹사이트 호스팅**에 최적화된 서비스로, **정적 콘텐츠**를 저장하고 제공하는 데 매우 효율적입니다. 또한 **CloudFront**는 **콘텐츠 전송 네트워크(CDN)** 서비스로, 웹사이트의 정적 콘텐츠를 **전 세계적으로 빠르게 캐싱**하고 제공하여 **응답 속도**를 개선하고 **호스팅 비용**을 절감할 수 있습니다. 이 방식은 특히 **트래픽 증가**에 효과적이며, **비용 효율적**입니다.

- **B. Move the website to an Amazon S3 bucket. Configure an Amazon ElastiCache cluster for the S3 bucket.**
  - **Amazon ElastiCache**는 **캐싱 서비스**로 주로 데이터베이스나 애플리케이션 성능을 개선하는 데 사용됩니다. 정적 콘텐츠 호스팅에 ElastiCache를 사용하는 것은 **불필요**하며, **CloudFront**를 사용하는 것이 더 적합합니다.

- **C. Move the website to AWS Amplify. Configure an ALB to resolve to the Amplify website.**
  - **AWS Amplify**는 **프론트엔드 웹 애플리케이션**을 배포하는 데 적합한 서비스입니다. 하지만 **ALB**는 **동적 콘텐츠**를 처리하는 데 주로 사용되며, **정적 웹사이트 호스팅**에 Amplify와 ALB를 결합하는 것은 **불필요하고 복잡**할 수 있습니다.

- **D. Move the website to AWS Amplify. Configure EC2 instances to cache the website.**
  - **AWS Amplify**는 정적 웹사이트를 배포하는 데 적합하지만, **EC2 인스턴스를 사용해 캐시**하는 것은 **비효율적**입니다. Amplify는 자동으로 **CDN**을 제공하여 캐싱을 처리하므로 EC2 인스턴스를 추가로 사용하는 것보다 더 효율적입니다.

### 결론:
웹사이트가 **정적 콘텐츠**를 제공하고 **트래픽 증가**를 다루려면, **Amazon S3**에 웹사이트를 호스팅하고, **CloudFront**로 콘텐츠를 캐싱하여 **비용 효율적**이고 **성능이 향상된** 솔루션을 사용할 수 있습니다.

# 900
정답은 **A. Set up an ECS cluster that uses the AWS Fargate launch type for the cloud application containers. Use an Amazon ECS Anywhere external launch type for the on-premises application containers.**와 **B. Set up an Application Load Balancer for cloud ECS services.**입니다.

### 이유:

- **A. Set up an ECS cluster that uses the AWS Fargate launch type for the cloud application containers. Use an Amazon ECS Anywhere external launch type for the on-premises application containers.**
  - **AWS Fargate**는 **서버리스 컨테이너 서비스**로, ECS 클러스터 내에서 **클라우드 애플리케이션** 컨테이너를 **자동으로 관리**해주며, **온프레미스 환경**에서는 **Amazon ECS Anywhere**를 사용하여 기존 온프레미스 컨테이너를 **ECS 클러스터에 통합**할 수 있습니다. 이로써 **하이브리드 환경**에서 동일한 ECS 클러스터를 사용하여 **애플리케이션을 실행**할 수 있습니다.

- **B. Set up an Application Load Balancer for cloud ECS services.**
  - **Application Load Balancer (ALB)**는 **HTTP/HTTPS 트래픽**에 대해 로드 밸런싱을 제공하는 서비스로, **클라우드 ECS 서비스**에서 **HTTP 트래픽을 처리**하는 데 매우 적합합니다. 이를 통해 **자동 스케일링**된 ECS 컨테이너에 트래픽을 효과적으로 분배할 수 있습니다.

### 다른 옵션 분석:

- **C. Set up a Network Load Balancer for cloud ECS services.**
  - **Network Load Balancer (NLB)**는 **TCP/UDP 트래픽**을 처리하는 데 적합하며, **HTTP 트래픽**을 로드 밸런싱하는 데는 **Application Load Balancer**가 더 적합합니다.

- **D. Set up an ECS cluster that uses the AWS Fargate launch type. Use Fargate for the cloud application containers and the on-premises application containers.**
  - **AWS Fargate**는 **클라우드에서만** 사용할 수 있으며, **온프레미스 환경**에서는 사용할 수 없습니다. **Amazon ECS Anywhere**를 사용해야 하므로 이 옵션은 적합하지 않습니다.

- **E. Set up an ECS cluster that uses the Amazon EC2 launch type for the cloud application containers. Use Amazon ECS Anywhere with an AWS Fargate launch type for the on-premises application containers.**
  - 이 옵션은 **온프레미스** 환경에 Fargate를 사용할 수 없으므로 적합하지 않습니다. **EC2 launch type**을 사용할 경우에도, 온프레미스에서 **ECS Anywhere**를 사용하여 컨테이너를 관리해야 합니다.

### 결론:
클라우드에서 **AWS Fargate**를 사용하고, 온프레미스에서 **ECS Anywhere**를 사용하여 애플리케이션 컨테이너를 실행하며, **Application Load Balancer (ALB)**를 사용해 **HTTP 트래픽**을 처리하는 방법이 가장 적합한 솔루션입니다.

# 903
정답은 **A. Create dedicated S3 access points and access point policies for each application.**

### 이유:
Amazon S3 Access Points는 S3 버킷에 대한 액세스를 **보다 세분화된 방식**으로 제어할 수 있는 기능을 제공합니다. 각 **애플리케이션별로 전용 S3 액세스 포인트를 생성**하고, 이를 통해 애플리케이션에 **특정 접두사(prefix)만을 제한적으로 액세스**할 수 있습니다. **Access Point Policies**를 사용하여 각 애플리케이션의 액세스를 **세밀하게 제어**할 수 있습니다.

이 방법은 **관리의 복잡성**을 줄이고, **최소한의 운영 오버헤드**로 **애플리케이션별**로 액세스를 제어할 수 있는 효율적인 방법입니다.

### 다른 옵션 분석:
- **B. Create an S3 Batch Operations job to set the ACL permissions for each object in the S3 bucket.**
  - **S3 Batch Operations**는 많은 객체에 대한 **일괄 처리 작업**을 수행하는 데 유용하지만, **동적이고 지속적인 액세스 제어**에는 적합하지 않습니다. 또한 각 애플리케이션에 대해 **접두사별로 액세스를 제한하는 작업**을 실시간으로 처리하기 어렵습니다.

- **C. Replicate the objects in the S3 bucket to new S3 buckets for each application. Create replication rules by prefix.**
  - 객체를 **새로운 S3 버킷으로 복제**하는 방식은 **운영 오버헤드**가 크고, **데이터 복제 비용**이 발생하며, **접근 제어**를 **각 버킷에 따로 관리**해야 하므로 비효율적입니다.

- **D. Replicate the objects in the S3 bucket to new S3 buckets for each application. Create dedicated S3 access points for each application.**
  - 이 방법도 객체를 **새로운 S3 버킷으로 복제**하는 것을 포함하고 있어 **운영 복잡성**이 높고, **데이터 복제 비용**이 발생합니다. 또한 **각 버킷에 대한 액세스 포인트를 설정**하는 작업은 관리 비용을 증가시킬 수 있습니다.

### 결론:
**S3 액세스 포인트**를 사용하여 각 애플리케이션에 대해 **특정 접두사에 대한 액세스를 제한**하는 방식이 **최소한의 운영 오버헤드**로 요구사항을 충족하는 가장 **효율적이고 관리가 용이한 방법**입니다.

# 906
정답은 **C. Create a 7-day EBS snapshot retention rule in Recycle Bin and apply the rule for all snapshots.**

### 이유:
**EBS 스냅샷 리사이클 빈 (Recycle Bin)** 기능을 사용하면 **스냅샷 삭제를 실수로 수행한 경우** 일정 기간 동안 삭제된 스냅샷을 복구할 수 있습니다. AWS는 삭제된 EBS 스냅샷을 **리사이클 빈**에 보관하며, 이를 통해 실수로 삭제된 스냅샷을 **최대 7일** 동안 복구할 수 있습니다.

리사이클 빈의 **7일 보존 규칙**을 설정하면, **스냅샷이 삭제된 후에도 7일간 복구할 수 있는 기회**를 제공하여 데이터 손실을 방지하고, **EBS 스냅샷을 영구 보존하지 않으면서도 안전성을 보장**할 수 있습니다.

### 다른 옵션 분석:

- **A. Change the IAM policy of the user to deny EBS snapshot deletion.**
  - IAM 정책을 변경하여 **스냅샷 삭제를 막을 수**는 있지만, 이 방법은 **직원이나 다른 사용자가 실수로 삭제하는 것을 방지**할 수는 있지만, **기존 스냅샷의 삭제와 관련된 문제가 이미 발생**한 경우에는 복구가 불가능합니다. 따라서 삭제된 스냅샷을 복구하는 데는 도움이 되지 않습니다.

- **B. Copy the EBS snapshots to another AWS Region after completing the snapshots daily.**
  - EBS 스냅샷을 다른 **AWS 리전으로 복사**하는 방법은 스냅샷의 **위험을 분산**시키는 방법이지만, **복사 후 삭제된 스냅샷의 복구**를 위한 효율적인 방법은 아닙니다. 또한, **리전 간 복사** 작업은 **비용**과 **복잡성**을 증가시킬 수 있습니다.

- **D. Copy EBS snapshots to Amazon S3 Standard-Infrequent Access (S3 Standard-IA).**
  - EBS 스냅샷을 **S3로 복사**하는 것은 **S3에서 데이터를 보관**하는 방법이지만, **EBS 스냅샷을 직접적으로 S3에 저장**하는 것은 **EBS와 S3의 관리 방식이 다르기 때문에** 복잡하고 비효율적일 수 있습니다. 또한, **S3에 스냅샷을 저장하는 방법**은 스냅샷의 **복구**를 용이하게 하지 않습니다.

### 결론:
**EBS 스냅샷 리사이클 빈**을 사용하여 **삭제된 스냅샷을 일정 기간 보존**하는 것이 가장 **효율적이고 관리가 용이한 방법**입니다. 7일 동안 삭제된 스냅샷을 복구할 수 있기 때문에 **데이터 손실을 방지**할 수 있으며, **개발 노력도 최소화**할 수 있습니다.

# 908
정답은 **A. Confirm that AWS Systems Manager Agent (SSM Agent) is installed on all instances. Assign an instance profile with the necessary policy to connect to Systems Manager. Use AWS IAM Identity Center to provide the external support engineers console access. Use Systems Manager Session Manager to assign the required permissions.**

이 방법은 외부 지원 엔지니어들이 AWS Management Console에 접근할 수 있도록 AWS IAM Identity Center를 사용하고, 시스템에 접근할 때는 SSH 없이 AWS Systems Manager의 Session Manager를 사용해 EC2 인스턴스에 보안된 방식으로 접근할 수 있게 합니다. SSM을 사용하면 SSH 키나 별도의 bastion host를 구성할 필요 없이, 관리가 용이하고 보안성이 높습니다.

# 910
웹 애플리케이션의 성능을 2분 이내의 세분화된 단위로 분석해야 한다면 가장 적합한 선택은 다음과 같습니다:

**B. 모든 EC2 인스턴스에서 세부 모니터링을 활성화하고, Amazon CloudWatch 지표를 사용하여 추가 분석을 수행합니다.**

### 설명:
- **EC2 세부 모니터링 활성화**: EC2 인스턴스에 대해 세부 모니터링을 활성화하면 기본적으로 1분 간격으로 지표를 수집할 수 있습니다. (기본값은 5분 간격) 이렇게 하면 웹 애플리케이션의 성능을 세밀하게 모니터링할 수 있어, 예를 들어 판매량 증가가 예상되는 휴일 주말에 발생할 수 있는 문제를 파악할 수 있습니다.
  
- **Amazon CloudWatch 지표**: CloudWatch는 EC2의 세부 모니터링과 직접 연결되어 CPU 사용률, 디스크 I/O, 네트워크 트래픽 등과 같은 중요한 시스템 수준 데이터를 제공합니다. 이러한 데이터를 실시간으로 또는 일정 기간에 걸쳐 분석하여 성능 문제나 병목 현상을 파악할 수 있습니다.

### 다른 옵션이 덜 적합한 이유:

- **A. Amazon CloudWatch 로그를 Amazon Redshift로 전송하고, Amazon QuickSight로 추가 분석을 수행**: 이 방법은 로그 데이터를 분석하는 데 중점을 두고 있으며 성능 모니터링에 필요한 실시간 세분화된 분석을 제공하기에는 적합하지 않습니다. 로그 집계 및 분석 과정이 추가되어 실시간 성능 모니터링에는 불필요한 단계가 많습니다.

- **C. AWS Lambda 함수를 생성하여 EC2 로그를 Amazon CloudWatch Logs에서 가져오고, Amazon CloudWatch 지표를 사용하여 추가 분석을 수행**: 이 방법도 유효할 수 있지만, 불필요하게 복잡합니다. Lambda를 사용하여 로그를 가져와 분석하는 방식은 CloudWatch 지표만 사용하는 것보다 번거롭고 직접적이지 않습니다.

- **D. EC2 로그를 Amazon S3로 전송하고, Amazon Redshift에서 S3 버킷에서 로그를 가져와 원시 데이터를 처리하고 Amazon QuickSight로 분석**: 이 방법은 여러 단계를 거쳐 로그를 다른 서비스들(S3, Redshift, QuickSight) 간에 이동시키는 방식으로, 실시간 성능 분석에는 적합하지 않습니다. 추가적인 지연이 발생할 수 있습니다.

따라서 **EC2의 세부 모니터링을 활성화하고 CloudWatch 지표를 사용하는 방법**이 가장 적합하고 효율적인 방식입니다.

# 913
정답은 **A. Create an IAM resource policy for the Lambda function that allows Amazon SNS to invoke the function.** 와 **D. Use an Amazon EventBridge rule in the production account to capture the SNS topic notifications. Configure the EventBridge rule to forward notifications to the Lambda function that is in the administrator account.** 입니다.

### 설명:
- **A. Create an IAM resource policy for the Lambda function that allows Amazon SNS to invoke the function.**  
  Lambda 함수가 다른 계정에서 SNS를 통해 호출될 수 있도록 IAM 리소스 정책을 작성하여 SNS가 Lambda를 호출할 수 있게 해야 합니다.

- **D. Use an Amazon EventBridge rule in the production account to capture the SNS topic notifications. Configure the EventBridge rule to forward notifications to the Lambda function that is in the administrator account.**  
  EventBridge는 SNS 메시지를 캡처하고 다른 AWS 계정에 있는 Lambda 함수를 트리거하는 데 유용한 서비스를 제공합니다. 이 방법은 SNS에서 Lambda로 직접 메시지를 전달하는 대신 EventBridge를 활용하여 메시지를 전달할 수 있습니다. 

이 두 가지 방법을 사용하면, SNS 메시지를 다른 계정에 있는 Lambda 함수로 안전하고 효율적으로 전달할 수 있습니다.


# 918
정답은 **A. Use an archive tool to group the files into large objects. Use DataSync to migrate the objects. Store the objects in S3 Glacier Instant Retrieval for the first year. Use a lifecycle configuration to transition the files to S3 Glacier Deep Archive after 1 year with a retention period of 7 years.** 입니다.

### 설명:
- **S3 Glacier Instant Retrieval**는 데이터를 바로 사용할 수 있으면서 비용이 저렴한 저장 클래스입니다. 처음 1년 동안 파일을 자주 액세스해야 하므로, 이 저장 클래스를 사용하여 데이터를 즉시 사용할 수 있게 합니다.
  
- 1년 후, **S3 Glacier Deep Archive**로 자동 전환되도록 라이프사이클 정책을 설정할 수 있습니다. S3 Glacier Deep Archive는 가장 저렴한 저장 옵션으로, 7년간 아카이빙이 필요할 때 적합합니다.

- **파일을 큰 객체로 그룹화**하는 것은 여러 작은 파일을 하나의 객체로 묶어 저장하여 데이터 전송 및 저장을 최적화할 수 있도록 합니다.

이 솔루션은 비용 효율적으로 요구 사항을 충족할 수 있으며, 파일을 초기 1년 동안 빠르게 액세스할 수 있도록 하고, 그 후에는 장기 보관용으로 저비용 스토리지로 전환됩니다.

# 919
정답은 **A. Add more Provisioned IOPS SSD (io1) EBS volumes. Use OS commands to create a Logical Volume Management (LVM) stripe.** 입니다.

### 설명:
- **LVM 스트라이핑**을 사용하면 여러 EBS 볼륨을 결합하여 성능을 개선할 수 있습니다. LVM을 통해 여러 Provisioned IOPS SSD (io1) EBS 볼륨을 하나의 논리적 볼륨으로 결합하면 IOPS 성능을 향상시킬 수 있습니다. 이는 스토리지 성능을 병렬화하여 더 높은 IOPS와 더 빠른 속도를 제공합니다.

### 이유:
- **B. Increase the Provisioned IOPS SSD (io1) EBS volume to more than 64,000 IOPS.**: io1 볼륨은 최대 64,000 IOPS까지 지원하며, 볼륨 크기에 따라 지원되는 최대 IOPS가 달라집니다. 하지만 볼륨 크기만 늘리면 성능이 크게 향상되지는 않습니다.
  
- **C. Increase the size of the Provisioned IOPS SSD (io1) EBS volume to 2 TB.**: 볼륨 크기를 늘리면 IOPS는 늘어나겠지만, 단일 EBS 볼륨의 성능 향상은 제한적일 수 있습니다. 여러 볼륨을 사용하는 것이 더 효과적입니다.

- **D. Change the EC2 Linux instance to a storage optimized instance type.**: 스토리지 최적화 인스턴스로 변경하면 성능이 향상될 수 있지만, 기존의 io1 EBS 볼륨을 활용하는 방법을 변경하지 않으면 큰 개선을 기대하기 어렵습니다.

따라서 **A** 옵션처럼 LVM 스트라이핑을 통해 여러 볼륨을 결합하는 것이 성능 향상에 가장 효과적입니다.