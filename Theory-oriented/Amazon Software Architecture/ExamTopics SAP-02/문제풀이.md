# 1
- 정답: A

# 7
좋은 지적입니다! AWS Lambda는 **최대 실행 시간이 15분**으로 제한되기 때문에, 장시간 실행이 필요한 워크로드에는 적합하지 않습니다. 이를 고려하면 정답은 달라질 수 있습니다. 각 옵션을 다시 검토하고 답을 수정하겠습니다.  

---

### 수정된 분석

#### **A. Lambda + API Gateway**  
- **제약사항**: Lambda의 15분 실행 제한 때문에, 작업이 장시간 지속되거나 복잡한 연산이 포함된 경우 부적합합니다.  
- **결론**: 제한 시간으로 인해 적합하지 않음.

---

#### **B. ECS + Fargate (정답)**  
- **장점**:  
  1. ECS는 컨테이너 기반 워크로드를 안정적으로 처리할 수 있는 관리형 서비스입니다.  
  2. Fargate를 사용하면 서버를 프로비저닝하거나 관리할 필요가 없습니다.  
  3. 가변적인 부하를 처리하기 위해 **자동 확장** 기능을 활용할 수 있습니다.  
  4. ECR에서 컨테이너 이미지를 손쉽게 배포할 수 있습니다.  
  5. ECS는 Lambda의 시간 제한 없이 장시간 실행 가능한 작업에 적합합니다.  
- **단점**:  
  1. Lambda보다 기본 운영 비용이 더 높습니다.  
  2. 두 개의 로드 밸런서가 필요해 약간의 복잡성이 추가됩니다.  

- **결론**: Lambda의 시간 제한을 회피하면서 서버리스에 가까운 운영 환경을 제공하므로, 적합한 선택입니다.  

---

#### **C. EKS + Fargate**  
- **장점**:  
  1. Kubernetes 기반으로 워크로드를 세밀하게 제어할 수 있습니다.  
  2. Fargate를 활용하여 서버리스처럼 관리할 수 있습니다.  
- **단점**:  
  1. Kubernetes는 설정과 운영 관리가 ECS에 비해 더 복잡합니다.  
  2. 소규모 환경에서 Kubernetes는 과도한 솔루션일 가능성이 높습니다.  

- **결론**: EKS는 ECS보다 복잡성과 비용이 더 높아, 이 경우에는 적합하지 않습니다.  

---

#### **D. Elastic Beanstalk**  
- **장점**:  
  1. 컨테이너 기반 워크로드도 Elastic Beanstalk에서 지원 가능.  
  2. 배포 프로세스가 간단하며, 프로덕션과 테스트 환경을 별도로 설정할 수 있습니다.  
- **단점**:  
  1. 서버리스 솔루션이 아니므로 인프라를 계속 실행해야 합니다.  
  2. 비용 효율성이 Lambda나 ECS에 비해 떨어질 가능성이 큽니다.  

- **결론**: 서버리스 요구사항에는 적합하지 않습니다.  

---

### 최종 정답: **B. ECS + Fargate**  
**해설**:  
Lambda의 15분 실행 제한을 해결하면서 서버 관리 부담을 최소화하고, 가변 부하를 효율적으로 처리할 수 있는 솔루션입니다. ECS와 Fargate를 활용하면 자동 확장 및 컨테이너 중심의 아키텍처로 장시간 실행 가능한 애플리케이션을 지원할 수 있습니다.  

# 8
### 정답: **B**  

---

### 해설:  

이 문제의 핵심은 **RTO(복구 목표 시간)를 15분 미만으로 줄이고, 예산 제한에 맞춘 자동 장애 조치(failover)를 구현**하는 것입니다. 각 옵션을 분석하여 가장 적합한 솔루션을 선택해 보겠습니다.

---

#### **A. Route 53 지연 시간 기반 라우팅 + Lambda + CloudWatch**
- **장점**:
  - CloudWatch 경보를 사용해 HTTP 5XX 오류를 감지하고 Lambda 함수를 호출하여 장애 조치를 자동화할 수 있습니다.
  - Route 53의 지연 시간 기반 라우팅 정책은 두 리전 간 트래픽을 분산시킬 수 있습니다.
- **단점**:
  - **지연 시간 기반 라우팅 정책**은 주 리전이 비정상적인 상태일 경우에도 트래픽이 해당 리전으로 계속 전송될 수 있습니다. 이는 장애 조치가 제대로 작동하지 않을 가능성이 있습니다.
  - 지연 시간 기반 라우팅은 장애 조치를 위한 정책이 아니므로, 이 솔루션은 요구사항에 적합하지 않습니다.

- **결론**:
  장애 조치(failover)에 적합하지 않으므로, 정답이 될 수 없습니다.

---

#### **B. Route 53 장애 조치 정책 + Lambda + Health Check**
- **장점**:
  1. Route 53의 **장애 조치 정책(failover policy)**을 사용하면, 주 리전의 상태 확인(Health Check) 실패 시 백업 리전으로 트래픽을 자동으로 전환할 수 있습니다.
  2. 상태 확인이 실패하면 Amazon SNS를 통해 Lambda 함수가 트리거되고, 읽기 복제본을 승격 및 Auto Scaling 그룹 값을 수정하여 백업 리전을 활성화합니다.
  3. 요구사항인 **15분 이하의 RTO**를 만족합니다.
  4. 예산을 고려한 **비용 효율적인 비활성-활성(active-passive) 전략**입니다.
- **단점**:
  - 초기 설정이 약간 복잡할 수 있지만, 운영 중 복잡성은 크지 않습니다.

- **결론**:
  Route 53의 장애 조치 정책과 Lambda 기반의 자동화된 작업이 조화를 이루어 요구사항에 가장 적합합니다.  

---

#### **C. Auto Scaling + 지연 시간 기반 라우팅 + 크로스 리전 복제**
- **장점**:
  - 크로스 리전 복제를 통해 데이터 동기화를 유지할 수 있습니다.
- **단점**:
  1. **지연 시간 기반 라우팅**은 장애 조치와는 관련이 없으므로, 주 리전이 비정상이어도 트래픽이 전송될 수 있습니다.
  2. 읽기 복제본을 제거하고 독립형 RDS 인스턴스를 추가하는 것은 설정이 복잡하고 비용이 증가합니다.
  3. 크로스 리전 복제는 스냅샷과 Amazon S3를 사용하므로 실시간 데이터 복제를 보장하지 못해 **데이터 손실 가능성**이 존재합니다.

- **결론**:
  장애 조치 요구사항을 충족하지 못하며, 비용과 복잡성이 증가하므로 적합하지 않습니다.

---

#### **D. Global Accelerator + Lambda + CloudWatch**
- **장점**:
  - Global Accelerator는 두 ALB를 대상으로 트래픽을 분산할 수 있으며, ALB 비정상 상태를 감지하면 자동으로 백업 리전으로 전환합니다.
- **단점**:
  1. Global Accelerator는 **추가 비용**이 발생합니다. 예산이 제한된 상황에서는 부적합합니다.
  2. Global Accelerator는 주로 **저지연 및 고가용성 요구사항**에 사용되며, 이 문제의 장애 조치 요구사항에는 과도한 솔루션입니다.

- **결론**:
  비용이 높고, 요구사항을 충족하기 위해 반드시 필요한 서비스가 아니므로 적합하지 않습니다.

---

### 최종 평가:
**옵션 B**는 Route 53의 장애 조치 정책과 Lambda를 활용해 비용 효율적이고 신뢰성 있는 자동 장애 조치를 제공하므로, 요구사항에 가장 적합한 솔루션입니다.  

# 9
### 정답: **A, D, F**

---

### 해설:  

이 문제는 애플리케이션 인프라의 **고가용성**과 **장애 복구 능력**을 개선하기 위해 아키텍처를 설계하는 것이 핵심입니다. 주어진 조건에 따라 각 옵션을 평가해보겠습니다.

---

#### **A. Elastic Load Balancer + Auto Scaling 그룹 (정답)**
- **장점**:
  1. Elastic Load Balancer(ELB)를 사용하면 트래픽이 여러 EC2 인스턴스에 분산되어 **단일 인스턴스 장애로 인한 다운타임을 방지**할 수 있습니다.
  2. Auto Scaling 그룹을 최소 2개의 인스턴스로 설정하면 한 인스턴스가 장애를 일으키더라도 다른 인스턴스가 애플리케이션을 유지할 수 있습니다.
- **단점**: 추가 비용이 발생할 수 있지만, 고가용성을 제공하는 데 필수적입니다.
- **결론**: ELB와 Auto Scaling은 EC2 인스턴스의 장애 복구를 보장하므로 적합한 선택입니다.

---

#### **B. Elastic Load Balancer + 무제한(Unlimited) 모드 (오답)**
- **Unlimited Mode**는 EC2 인스턴스의 CPU 크레딧 사용 제한을 제거하여 CPU 성능을 높이는 기능입니다.
- **문제점**:
  1. CPU 성능에만 영향을 미치며 고가용성이나 장애 복구와는 관련이 없습니다.
  2. ELB를 사용하더라도 Auto Scaling 그룹이 없으면 장애 복구를 보장할 수 없습니다.
- **결론**: 장애 복구와 관련 없으므로 적합하지 않습니다.

---

#### **C. DB 읽기 복제본(Read Replica) 생성 (오답)**
- **읽기 복제본**은 주로 읽기 성능을 확장하고 읽기 전용 요청을 처리하기 위해 사용됩니다.
- **문제점**:
  1. 읽기 복제본은 장애 시 수동으로 승격해야 하므로 다운타임이 발생할 수 있습니다.
  2. 문제의 요구사항인 **자동 복구**와는 맞지 않습니다.
- **결론**: 장애 복구 자동화를 지원하지 않으므로 적합하지 않습니다.

---

#### **D. Multi-AZ RDS 배포 (정답)**
- **Multi-AZ**는 데이터베이스의 고가용성을 보장하기 위한 기능으로, RDS가 기본으로 장애 조치를 처리합니다.
  1. 주 DB 인스턴스가 장애를 일으키면, AWS가 자동으로 대기 인스턴스를 활성화합니다.
  2. 데이터가 가용 영역 간에 동기적으로 복제되므로 데이터 손실을 방지합니다.
- **결론**: 데이터베이스의 고가용성과 자동 장애 복구를 보장하므로 적합합니다.

---

#### **E. ElastiCache 복제 그룹 + Auto Scaling 그룹 (오답)**
- **문제점**:
  1. ElastiCache는 Auto Scaling 그룹과 직접 통합되지 않습니다.
  2. ElastiCache 복제 그룹을 사용해도 Auto Scaling 그룹을 설정하는 것은 무의미합니다.
- **결론**: ElastiCache와 Auto Scaling 그룹의 통합이 불가능하므로 적합하지 않습니다.

---

#### **F. ElastiCache Multi-AZ 활성화 (정답)**
- **ElastiCache Multi-AZ**:
  1. 복제 그룹과 함께 Multi-AZ를 활성화하면 장애 발생 시 자동으로 복구할 수 있습니다.
  2. Redis의 노드 간 비동기 복제를 통해 데이터 가용성을 보장합니다.
- **결론**: ElastiCache의 고가용성을 제공하므로 적합합니다.

---

### 최종 평가:
**A, D, F**는 각 구성 요소(EC2, RDS, ElastiCache)의 장애 복구를 자동화하여 최소한의 다운타임으로 고가용성을 제공합니다. 이 조합이 문제의 요구사항을 충족합니다.


# 10
### 정답: **A, E**

---

### **해설**  
운영 부담을 최소화하면서 사용자 정의 오류 페이지를 제공하려면 다음과 같은 솔루션이 적합합니다.

---

#### **A. Amazon S3를 사용한 사용자 정의 오류 페이지 호스팅**
- **설명**: Amazon S3 버킷을 사용하여 정적 웹페이지를 호스팅하고 사용자 정의 오류 페이지를 업로드합니다.  
- **장점**: 설정이 간단하며 비용 효율적이고 별도의 컴퓨팅 리소스가 필요 없습니다.
- **운영 부담**: 최소화됨. 정적 콘텐츠 호스팅에 이상적.

---

#### **E. CloudFront 사용자 정의 오류 응답 구성**
- **설명**: CloudFront의 사용자 정의 오류 페이지 기능을 활용하여 오류 응답을 재정의합니다.  
  - CloudFront에서 오류 응답(502)을 캐치하여 S3에서 제공하는 사용자 정의 오류 페이지로 리디렉션하도록 설정합니다.
- **장점**: ALB 뒤에 이미 CloudFront가 구성되어 있으므로 추가 변경이 간단합니다.
- **운영 부담**: 낮음. 기존 CloudFront 구성에서 간단히 확장 가능.

---

### 다른 옵션 검토

#### **B. CloudWatch 알람 및 Lambda를 사용한 ALB 포워딩 규칙 변경**
- **단점**: ALB의 포워딩 규칙을 동적으로 변경해야 하며, Lambda 함수의 트리거 및 관리가 추가적으로 필요합니다.  
- **운영 부담**: 높음. 구현 및 유지 관리가 복잡합니다.

#### **C. Route 53의 DNS 헬스 체크 구성**
- **단점**: 헬스 체크 구성과 DNS 변경은 전파 시간이 있어 실시간으로 오류를 처리하는 데 적합하지 않습니다.
- **운영 부담**: 중간. DNS 전파 지연 문제를 해결하기 어렵습니다.

#### **D. CloudWatch 알람 및 Lambda를 사용한 ALB 포워딩 규칙 변경**
- **단점**: B와 유사한 방식으로, Lambda 함수와 ALB 규칙 변경의 복잡성을 초래합니다.  
- **운영 부담**: 높음. 실시간 처리에는 적합하지만 복잡도가 높습니다.

---

### **결론**
**A와 E**는 설정이 간단하고 유지 관리 부담이 적으며, 문제 해결 동안 사용자 경험을 향상시키는 가장 효율적인 방법입니다.


# 11
### 정답:  
**A. Create a transit gateway in the infrastructure account.**  
**D. Create a resource share in AWS Resource Access Manager in the infrastructure account. Select the specific AWS Organizations OU that will use the shared network. Select each subnet to associate with the resource share.**

### 해설:
이 문제에서는 여러 AWS 계정이 공통 네트워크를 공유할 수 있도록 하는 솔루션을 설계하는 것이 목표입니다. 문제에서 제시된 조건에 따라 다음과 같은 이유로 정답을 선택해야 합니다:

1. **A. Create a transit gateway in the infrastructure account.**
   - **이유**: Transit Gateway는 여러 VPC를 연결할 수 있는 중앙 허브 역할을 하여, 여러 AWS 계정 간에 네트워크 연결을 제공할 수 있습니다. 이 방법을 사용하면 하나의 VPC에서 관리하는 네트워크를 다른 AWS 계정과 공유할 수 있습니다. 이 경우, 중앙 관리 계정(인프라 계정)을 통해 네트워크를 관리할 수 있습니다. 다른 계정들은 Transit Gateway를 통해 네트워크에 접근할 수 있습니다.

2. **D. Create a resource share in AWS Resource Access Manager in the infrastructure account. Select the specific AWS Organizations OU that will use the shared network. Select each subnet to associate with the resource share.**
   - **이유**: AWS Resource Access Manager (RAM)을 사용하면 AWS 리소스를 여러 계정에 공유할 수 있습니다. 인프라 계정에서 각 서브넷을 공유하도록 설정하면, 다른 계정들이 해당 서브넷에서 리소스를 생성할 수 있습니다. RAM을 사용하여 리소스 공유를 설정하면, 관리자는 네트워크를 중앙에서 관리할 수 있고, 다른 계정들은 이를 활용할 수 있습니다.

---

### 나머지 선택지에 대한 분석:

**B. Enable resource sharing from the AWS Organizations management account.**
   - **이유**: AWS Organizations에서 리소스 공유를 활성화하는 것은 필요하지 않습니다. AWS RAM을 사용하여 리소스를 공유하는 것이 더 적합하며, AWS Organizations의 관리 계정에서 리소스 공유를 설정하는 것은 불필요합니다.

**C. Create VPCs in each AWS account within the organization in AWS Organizations. Configure the VPCs to share the same CIDR range and subnets as the VPC in the infrastructure account. Peer the VPCs in each individual account with the VPC in the infrastructure account.**
   - **이유**: 각 계정에 VPC를 만들고 피어링하는 방식은 관리가 복잡해질 수 있습니다. VPC 피어링은 여러 계정에서 사용하는 VPC들 간의 네트워크 연결을 지원하지만, 이 방법은 각 계정에 별도로 VPC를 관리해야 하기 때문에 "개별 계정에서 네트워크를 관리하지 않도록" 요구하는 조건을 충족하지 않습니다.

**E. Create a resource share in AWS Resource Access Manager in the infrastructure account. Select the specific AWS Organizations OU that will use the shared network. Select each prefix list to associate with the resource share.**
   - **이유**: Prefix list는 VPC에서 IP 주소 범위를 정의하는 데 사용됩니다. 그러나 서브넷을 공유하는 것이 필요하므로, 서브넷을 공유하는 방법이 더 적합합니다. Prefix list를 사용하는 것보다 서브넷을 공유하는 것이 이 시나리오에서 요구하는 요구 사항에 부합합니다.

---

따라서, **A**와 **D**가 가장 적합한 조치입니다.


