# 1
- 정답: A

# 7
좋은 지적입니다! AWS Lambda는 **최대 실행 시간이 15분**으로 제한되기 때문에, 장시간 실행이 필요한 워크로드에는 적합하지 않습니다. 이를 고려하면 정답은 달라질 수 있습니다. 각 옵션을 다시 검토하고 답을 수정하겠습니다.  

---

### 수정된 분석

#### **A. Lambda + API Gateway**  
- **제약사항**: Lambda의 15분 실행 제한 때문에, 작업이 장시간 지속되거나 복잡한 연산이 포함된 경우 부적합합니다.  
- **결론**: 제한 시간으로 인해 적합하지 않음.

---

#### **B. ECS + Fargate (정답)**  
- **장점**:  
  1. ECS는 컨테이너 기반 워크로드를 안정적으로 처리할 수 있는 관리형 서비스입니다.  
  2. Fargate를 사용하면 서버를 프로비저닝하거나 관리할 필요가 없습니다.  
  3. 가변적인 부하를 처리하기 위해 **자동 확장** 기능을 활용할 수 있습니다.  
  4. ECR에서 컨테이너 이미지를 손쉽게 배포할 수 있습니다.  
  5. ECS는 Lambda의 시간 제한 없이 장시간 실행 가능한 작업에 적합합니다.  
- **단점**:  
  1. Lambda보다 기본 운영 비용이 더 높습니다.  
  2. 두 개의 로드 밸런서가 필요해 약간의 복잡성이 추가됩니다.  

- **결론**: Lambda의 시간 제한을 회피하면서 서버리스에 가까운 운영 환경을 제공하므로, 적합한 선택입니다.  

---

#### **C. EKS + Fargate**  
- **장점**:  
  1. Kubernetes 기반으로 워크로드를 세밀하게 제어할 수 있습니다.  
  2. Fargate를 활용하여 서버리스처럼 관리할 수 있습니다.  
- **단점**:  
  1. Kubernetes는 설정과 운영 관리가 ECS에 비해 더 복잡합니다.  
  2. 소규모 환경에서 Kubernetes는 과도한 솔루션일 가능성이 높습니다.  

- **결론**: EKS는 ECS보다 복잡성과 비용이 더 높아, 이 경우에는 적합하지 않습니다.  

---

#### **D. Elastic Beanstalk**  
- **장점**:  
  1. 컨테이너 기반 워크로드도 Elastic Beanstalk에서 지원 가능.  
  2. 배포 프로세스가 간단하며, 프로덕션과 테스트 환경을 별도로 설정할 수 있습니다.  
- **단점**:  
  1. 서버리스 솔루션이 아니므로 인프라를 계속 실행해야 합니다.  
  2. 비용 효율성이 Lambda나 ECS에 비해 떨어질 가능성이 큽니다.  

- **결론**: 서버리스 요구사항에는 적합하지 않습니다.  

---

### 최종 정답: **B. ECS + Fargate**  
**해설**:  
Lambda의 15분 실행 제한을 해결하면서 서버 관리 부담을 최소화하고, 가변 부하를 효율적으로 처리할 수 있는 솔루션입니다. ECS와 Fargate를 활용하면 자동 확장 및 컨테이너 중심의 아키텍처로 장시간 실행 가능한 애플리케이션을 지원할 수 있습니다.  

# 8
### 정답: **B**  

---

### 해설:  

이 문제의 핵심은 **RTO(복구 목표 시간)를 15분 미만으로 줄이고, 예산 제한에 맞춘 자동 장애 조치(failover)를 구현**하는 것입니다. 각 옵션을 분석하여 가장 적합한 솔루션을 선택해 보겠습니다.

---

#### **A. Route 53 지연 시간 기반 라우팅 + Lambda + CloudWatch**
- **장점**:
  - CloudWatch 경보를 사용해 HTTP 5XX 오류를 감지하고 Lambda 함수를 호출하여 장애 조치를 자동화할 수 있습니다.
  - Route 53의 지연 시간 기반 라우팅 정책은 두 리전 간 트래픽을 분산시킬 수 있습니다.
- **단점**:
  - **지연 시간 기반 라우팅 정책**은 주 리전이 비정상적인 상태일 경우에도 트래픽이 해당 리전으로 계속 전송될 수 있습니다. 이는 장애 조치가 제대로 작동하지 않을 가능성이 있습니다.
  - 지연 시간 기반 라우팅은 장애 조치를 위한 정책이 아니므로, 이 솔루션은 요구사항에 적합하지 않습니다.

- **결론**:
  장애 조치(failover)에 적합하지 않으므로, 정답이 될 수 없습니다.

---

#### **B. Route 53 장애 조치 정책 + Lambda + Health Check**
- **장점**:
  1. Route 53의 **장애 조치 정책(failover policy)**을 사용하면, 주 리전의 상태 확인(Health Check) 실패 시 백업 리전으로 트래픽을 자동으로 전환할 수 있습니다.
  2. 상태 확인이 실패하면 Amazon SNS를 통해 Lambda 함수가 트리거되고, 읽기 복제본을 승격 및 Auto Scaling 그룹 값을 수정하여 백업 리전을 활성화합니다.
  3. 요구사항인 **15분 이하의 RTO**를 만족합니다.
  4. 예산을 고려한 **비용 효율적인 비활성-활성(active-passive) 전략**입니다.
- **단점**:
  - 초기 설정이 약간 복잡할 수 있지만, 운영 중 복잡성은 크지 않습니다.

- **결론**:
  Route 53의 장애 조치 정책과 Lambda 기반의 자동화된 작업이 조화를 이루어 요구사항에 가장 적합합니다.  

---

#### **C. Auto Scaling + 지연 시간 기반 라우팅 + 크로스 리전 복제**
- **장점**:
  - 크로스 리전 복제를 통해 데이터 동기화를 유지할 수 있습니다.
- **단점**:
  1. **지연 시간 기반 라우팅**은 장애 조치와는 관련이 없으므로, 주 리전이 비정상이어도 트래픽이 전송될 수 있습니다.
  2. 읽기 복제본을 제거하고 독립형 RDS 인스턴스를 추가하는 것은 설정이 복잡하고 비용이 증가합니다.
  3. 크로스 리전 복제는 스냅샷과 Amazon S3를 사용하므로 실시간 데이터 복제를 보장하지 못해 **데이터 손실 가능성**이 존재합니다.

- **결론**:
  장애 조치 요구사항을 충족하지 못하며, 비용과 복잡성이 증가하므로 적합하지 않습니다.

---

#### **D. Global Accelerator + Lambda + CloudWatch**
- **장점**:
  - Global Accelerator는 두 ALB를 대상으로 트래픽을 분산할 수 있으며, ALB 비정상 상태를 감지하면 자동으로 백업 리전으로 전환합니다.
- **단점**:
  1. Global Accelerator는 **추가 비용**이 발생합니다. 예산이 제한된 상황에서는 부적합합니다.
  2. Global Accelerator는 주로 **저지연 및 고가용성 요구사항**에 사용되며, 이 문제의 장애 조치 요구사항에는 과도한 솔루션입니다.

- **결론**:
  비용이 높고, 요구사항을 충족하기 위해 반드시 필요한 서비스가 아니므로 적합하지 않습니다.

---

### 최종 평가:
**옵션 B**는 Route 53의 장애 조치 정책과 Lambda를 활용해 비용 효율적이고 신뢰성 있는 자동 장애 조치를 제공하므로, 요구사항에 가장 적합한 솔루션입니다.  

# 9
### 정답: **A, D, F**

---

### 해설:  

이 문제는 애플리케이션 인프라의 **고가용성**과 **장애 복구 능력**을 개선하기 위해 아키텍처를 설계하는 것이 핵심입니다. 주어진 조건에 따라 각 옵션을 평가해보겠습니다.

---

#### **A. Elastic Load Balancer + Auto Scaling 그룹 (정답)**
- **장점**:
  1. Elastic Load Balancer(ELB)를 사용하면 트래픽이 여러 EC2 인스턴스에 분산되어 **단일 인스턴스 장애로 인한 다운타임을 방지**할 수 있습니다.
  2. Auto Scaling 그룹을 최소 2개의 인스턴스로 설정하면 한 인스턴스가 장애를 일으키더라도 다른 인스턴스가 애플리케이션을 유지할 수 있습니다.
- **단점**: 추가 비용이 발생할 수 있지만, 고가용성을 제공하는 데 필수적입니다.
- **결론**: ELB와 Auto Scaling은 EC2 인스턴스의 장애 복구를 보장하므로 적합한 선택입니다.

---

#### **B. Elastic Load Balancer + 무제한(Unlimited) 모드 (오답)**
- **Unlimited Mode**는 EC2 인스턴스의 CPU 크레딧 사용 제한을 제거하여 CPU 성능을 높이는 기능입니다.
- **문제점**:
  1. CPU 성능에만 영향을 미치며 고가용성이나 장애 복구와는 관련이 없습니다.
  2. ELB를 사용하더라도 Auto Scaling 그룹이 없으면 장애 복구를 보장할 수 없습니다.
- **결론**: 장애 복구와 관련 없으므로 적합하지 않습니다.

---

#### **C. DB 읽기 복제본(Read Replica) 생성 (오답)**
- **읽기 복제본**은 주로 읽기 성능을 확장하고 읽기 전용 요청을 처리하기 위해 사용됩니다.
- **문제점**:
  1. 읽기 복제본은 장애 시 수동으로 승격해야 하므로 다운타임이 발생할 수 있습니다.
  2. 문제의 요구사항인 **자동 복구**와는 맞지 않습니다.
- **결론**: 장애 복구 자동화를 지원하지 않으므로 적합하지 않습니다.

---

#### **D. Multi-AZ RDS 배포 (정답)**
- **Multi-AZ**는 데이터베이스의 고가용성을 보장하기 위한 기능으로, RDS가 기본으로 장애 조치를 처리합니다.
  1. 주 DB 인스턴스가 장애를 일으키면, AWS가 자동으로 대기 인스턴스를 활성화합니다.
  2. 데이터가 가용 영역 간에 동기적으로 복제되므로 데이터 손실을 방지합니다.
- **결론**: 데이터베이스의 고가용성과 자동 장애 복구를 보장하므로 적합합니다.

---

#### **E. ElastiCache 복제 그룹 + Auto Scaling 그룹 (오답)**
- **문제점**:
  1. ElastiCache는 Auto Scaling 그룹과 직접 통합되지 않습니다.
  2. ElastiCache 복제 그룹을 사용해도 Auto Scaling 그룹을 설정하는 것은 무의미합니다.
- **결론**: ElastiCache와 Auto Scaling 그룹의 통합이 불가능하므로 적합하지 않습니다.

---

#### **F. ElastiCache Multi-AZ 활성화 (정답)**
- **ElastiCache Multi-AZ**:
  1. 복제 그룹과 함께 Multi-AZ를 활성화하면 장애 발생 시 자동으로 복구할 수 있습니다.
  2. Redis의 노드 간 비동기 복제를 통해 데이터 가용성을 보장합니다.
- **결론**: ElastiCache의 고가용성을 제공하므로 적합합니다.

---

### 최종 평가:
**A, D, F**는 각 구성 요소(EC2, RDS, ElastiCache)의 장애 복구를 자동화하여 최소한의 다운타임으로 고가용성을 제공합니다. 이 조합이 문제의 요구사항을 충족합니다.


# 10
### 정답: **A, E**

---

### **해설**  
운영 부담을 최소화하면서 사용자 정의 오류 페이지를 제공하려면 다음과 같은 솔루션이 적합합니다.

---

#### **A. Amazon S3를 사용한 사용자 정의 오류 페이지 호스팅**
- **설명**: Amazon S3 버킷을 사용하여 정적 웹페이지를 호스팅하고 사용자 정의 오류 페이지를 업로드합니다.  
- **장점**: 설정이 간단하며 비용 효율적이고 별도의 컴퓨팅 리소스가 필요 없습니다.
- **운영 부담**: 최소화됨. 정적 콘텐츠 호스팅에 이상적.

---

#### **E. CloudFront 사용자 정의 오류 응답 구성**
- **설명**: CloudFront의 사용자 정의 오류 페이지 기능을 활용하여 오류 응답을 재정의합니다.  
  - CloudFront에서 오류 응답(502)을 캐치하여 S3에서 제공하는 사용자 정의 오류 페이지로 리디렉션하도록 설정합니다.
- **장점**: ALB 뒤에 이미 CloudFront가 구성되어 있으므로 추가 변경이 간단합니다.
- **운영 부담**: 낮음. 기존 CloudFront 구성에서 간단히 확장 가능.

---

### 다른 옵션 검토

#### **B. CloudWatch 알람 및 Lambda를 사용한 ALB 포워딩 규칙 변경**
- **단점**: ALB의 포워딩 규칙을 동적으로 변경해야 하며, Lambda 함수의 트리거 및 관리가 추가적으로 필요합니다.  
- **운영 부담**: 높음. 구현 및 유지 관리가 복잡합니다.

#### **C. Route 53의 DNS 헬스 체크 구성**
- **단점**: 헬스 체크 구성과 DNS 변경은 전파 시간이 있어 실시간으로 오류를 처리하는 데 적합하지 않습니다.
- **운영 부담**: 중간. DNS 전파 지연 문제를 해결하기 어렵습니다.

#### **D. CloudWatch 알람 및 Lambda를 사용한 ALB 포워딩 규칙 변경**
- **단점**: B와 유사한 방식으로, Lambda 함수와 ALB 규칙 변경의 복잡성을 초래합니다.  
- **운영 부담**: 높음. 실시간 처리에는 적합하지만 복잡도가 높습니다.

---

### **결론**
**A와 E**는 설정이 간단하고 유지 관리 부담이 적으며, 문제 해결 동안 사용자 경험을 향상시키는 가장 효율적인 방법입니다.


# 11
### 정답:  
**A. Create a transit gateway in the infrastructure account.**  
**D. Create a resource share in AWS Resource Access Manager in the infrastructure account. Select the specific AWS Organizations OU that will use the shared network. Select each subnet to associate with the resource share.**

### 해설:
이 문제에서는 여러 AWS 계정이 공통 네트워크를 공유할 수 있도록 하는 솔루션을 설계하는 것이 목표입니다. 문제에서 제시된 조건에 따라 다음과 같은 이유로 정답을 선택해야 합니다:

1. **A. Create a transit gateway in the infrastructure account.**
   - **이유**: Transit Gateway는 여러 VPC를 연결할 수 있는 중앙 허브 역할을 하여, 여러 AWS 계정 간에 네트워크 연결을 제공할 수 있습니다. 이 방법을 사용하면 하나의 VPC에서 관리하는 네트워크를 다른 AWS 계정과 공유할 수 있습니다. 이 경우, 중앙 관리 계정(인프라 계정)을 통해 네트워크를 관리할 수 있습니다. 다른 계정들은 Transit Gateway를 통해 네트워크에 접근할 수 있습니다.

2. **D. Create a resource share in AWS Resource Access Manager in the infrastructure account. Select the specific AWS Organizations OU that will use the shared network. Select each subnet to associate with the resource share.**
   - **이유**: AWS Resource Access Manager (RAM)을 사용하면 AWS 리소스를 여러 계정에 공유할 수 있습니다. 인프라 계정에서 각 서브넷을 공유하도록 설정하면, 다른 계정들이 해당 서브넷에서 리소스를 생성할 수 있습니다. RAM을 사용하여 리소스 공유를 설정하면, 관리자는 네트워크를 중앙에서 관리할 수 있고, 다른 계정들은 이를 활용할 수 있습니다.

---

### 나머지 선택지에 대한 분석:

**B. Enable resource sharing from the AWS Organizations management account.**
   - **이유**: AWS Organizations에서 리소스 공유를 활성화하는 것은 필요하지 않습니다. AWS RAM을 사용하여 리소스를 공유하는 것이 더 적합하며, AWS Organizations의 관리 계정에서 리소스 공유를 설정하는 것은 불필요합니다.

**C. Create VPCs in each AWS account within the organization in AWS Organizations. Configure the VPCs to share the same CIDR range and subnets as the VPC in the infrastructure account. Peer the VPCs in each individual account with the VPC in the infrastructure account.**
   - **이유**: 각 계정에 VPC를 만들고 피어링하는 방식은 관리가 복잡해질 수 있습니다. VPC 피어링은 여러 계정에서 사용하는 VPC들 간의 네트워크 연결을 지원하지만, 이 방법은 각 계정에 별도로 VPC를 관리해야 하기 때문에 "개별 계정에서 네트워크를 관리하지 않도록" 요구하는 조건을 충족하지 않습니다.

**E. Create a resource share in AWS Resource Access Manager in the infrastructure account. Select the specific AWS Organizations OU that will use the shared network. Select each prefix list to associate with the resource share.**
   - **이유**: Prefix list는 VPC에서 IP 주소 범위를 정의하는 데 사용됩니다. 그러나 서브넷을 공유하는 것이 필요하므로, 서브넷을 공유하는 방법이 더 적합합니다. Prefix list를 사용하는 것보다 서브넷을 공유하는 것이 이 시나리오에서 요구하는 요구 사항에 부합합니다.

---

따라서, **A**와 **D**가 가장 적합한 조치입니다.



# 12
정답: **A. Create an AWS PrivateLink interface VPC endpoint. Connect this endpoint to the endpoint service that the third-party SaaS application provides. Create a security group to limit the access to the endpoint. Associate the security group with the endpoint.**

### 해설:

이 문제의 요구 사항은 **인터넷을 거치지 않고 사설 연결을 사용**해야 하며, **회사의 보안 정책에 맞는 최소 권한**을 준수해야 하는 것입니다. 이를 해결하는 가장 적합한 방법은 **AWS PrivateLink**를 사용하는 것입니다.

**AWS PrivateLink**는 AWS 서비스와 타사 SaaS 애플리케이션에 대한 안전한 사설 연결을 제공하며, **인터넷을 통하지 않고 연결**할 수 있습니다. 또한 **보안 그룹을 통해 액세스를 제어**할 수 있어, 최소 권한 원칙에 맞는 세밀한 접근 제어를 할 수 있습니다.

- **A**: 이 솔루션은 **AWS PrivateLink 인터페이스 VPC 엔드포인트**를 사용하여 타사 SaaS 애플리케이션의 **엔드포인트 서비스에 연결**합니다. 보안 그룹을 사용하여 엔드포인트에 대한 액세스를 제어할 수 있습니다. 이는 회사의 요구 사항을 만족시키는 최적의 방법입니다.

---

### 다른 선택지 분석:

- **B. Create an AWS Site-to-Site VPN connection**:  
  Site-to-Site VPN은 회사와 타사 SaaS 애플리케이션 사이의 연결을 제공하지만, 이 방법은 **인터넷을 거쳐야 할 가능성**이 있고, **보안 정책**을 완전히 만족시키지 않을 수 있습니다. 또한 이 방법은 **VPN을 설정하고 관리**하는 추가적인 복잡성을 초래할 수 있습니다.

- **C. Create a VPC peering connection**:  
  VPC 피어링은 두 VPC 간의 연결을 설정할 수 있지만, **타사 SaaS 애플리케이션에 대한 액세스를 관리하는 데는 적합하지 않**습니다. 또한, VPC 피어링은 인터넷을 거치지 않지만, **각각의 VPC가 같은 네트워크 범위를 공유**하기 때문에 **보안 상의 제한을 설정**하는 데 어려움이 있을 수 있습니다.

- **D. Create an AWS PrivateLink endpoint service**:  
  이 방법은 **타사 SaaS 제공자가 엔드포인트 서비스를 설정**해야 하는 방식입니다. 하지만 문제에서 요구하는 것은 **회사가 타사 SaaS 애플리케이션을 소비**하는 것이므로, **타사 제공자가 엔드포인트 서비스를 설정**해야 하는 부분이 회사의 요구 사항과 맞지 않습니다.

---

### 결론:
**A**는 회사의 요구 사항을 가장 잘 충족하는 솔루션입니다. **AWS PrivateLink**를 사용하여 **인터넷을 통하지 않고 안전하게 연결**하고, **보안 그룹을 통해 접근 제어**할 수 있기 때문입니다.

# 13
정답: **A. Use AWS Systems Manager to manage patches on the on-premises servers and EC2 instances. Use Systems Manager to generate patch compliance reports.**

---

### 해설:

1. **문제 요약:**
   - 온프레미스 서버와 Amazon EC2 인스턴스에 대한 패치 상태를 단일 보고서로 관리해야 합니다.
   - 현재 다양한 툴을 사용 중이므로 일관된 솔루션이 필요합니다.

2. **정답 분석:**
   - **AWS Systems Manager**는 EC2 인스턴스와 온프레미스 서버 모두에서 패치 관리를 지원합니다. 
   - Systems Manager의 **Patch Manager** 기능을 사용하면 패치 적용 및 컴플라이언스 상태를 쉽게 관리할 수 있습니다.
   - **Systems Manager Compliance**를 사용하면 패치 상태를 보고하는 기능도 제공됩니다.

3. **다른 선택지 분석:**
   - **B. AWS OpsWorks**:
     - OpsWorks는 애플리케이션 배포 및 관리 도구로, 패치 관리보다는 구성이 초점입니다.
     - 패치 상태를 직접적으로 보고하는 기능이 없으며 Amazon QuickSight 통합은 해당 요구에 적합하지 않습니다.
   - **C. Amazon EventBridge 및 Amazon Inspector**:
     - EventBridge는 작업 스케줄링에 적합하지만 패치 관리를 직접 수행하지 않습니다.
     - Amazon Inspector는 보안 취약성 스캔 및 보고 도구로, 패치 상태 관리 기능과는 관련이 없습니다.
   - **D. OpsWorks 및 AWS X-Ray**:
     - OpsWorks는 위와 같이 부적절하고, X-Ray는 애플리케이션 트레이싱 및 디버깅 도구로 패치 상태 보고와는 무관합니다.

4. **적합한 AWS 서비스:**
   - AWS Systems Manager는 **온프레미스 서버와 클라우드 리소스 모두를 지원**하는 통합 관리 서비스로, 패치 적용과 컴플라이언스 보고 요구를 충족시킵니다.

### 추가 참고:
- AWS Systems Manager를 사용하면 **Hybrid Activations**를 통해 온프레미스 서버를 Systems Manager와 연결할 수 있습니다.
- **Patch Baselines**를 사용해 조직의 패치 정책을 정의할 수 있고, 이를 기반으로 EC2 인스턴스 및 온프레미스 서버에 일관되게 패치를 적용할 수 있습니다.

# 14
이 문제의 정답은 **B**입니다. 아래에서 답과 해설을 제공하겠습니다.

---

### **정답: B**
**Create an AWS Systems Manager document with a script to copy log files to Amazon S3. Create an Auto Scaling lifecycle hook and an Amazon EventBridge rule to detect lifecycle events from the Auto Scaling group. Invoke an AWS Lambda function on the autoscaling:EC2_INSTANCE_TERMINATING transition to call the AWS Systems Manager API SendCommand operation to run the document to copy the log files and send CONTINUE to the Auto Scaling group to terminate the instance.**

---

### **해설**
#### 1. **문제의 핵심**
- EC2 인스턴스가 종료(terminate)될 때 로그 파일이 손실되는 문제를 해결하려면, 인스턴스가 완전히 종료되기 전에 로그를 S3로 전송해야 합니다.
- 이를 위해 Auto Scaling 그룹의 **Lifecycle Hook**를 활용하여 **EC2 종료 이벤트**에 작업을 추가할 수 있습니다.
  
---

#### 2. **옵션 분석**
**A.**
- ABANDON을 사용하여 인스턴스 종료를 방지하고 스크립트를 실행한 뒤 수동으로 종료하도록 설계했습니다.
- ABANDON은 사용된 리소스를 해제하지 않고, Auto Scaling 상태를 비정상적으로 만들 수 있으므로 적절하지 않습니다.

**B. (정답)**
- Auto Scaling **Lifecycle Hook**를 사용해 EC2 인스턴스가 종료되기 전 **Systems Manager 문서**를 실행하도록 설정합니다.
- **SendCommand**를 통해 EC2 인스턴스가 종료되기 전에 로그 파일을 S3로 복사할 수 있습니다.
- 작업이 완료되면 `CONTINUE`로 Auto Scaling 그룹의 정상적인 인스턴스 종료를 진행합니다.
- 이 방식은 AWS에서 권장하는 구조로, 확장성과 유지보수 측면에서도 효율적입니다.

**C.**
- 로그 전송 주기를 줄이는 것은 로그 손실 가능성을 줄일 수 있지만, 인스턴스 종료 직전의 로그를 완전히 보장하지는 못합니다.
- 또한 EC2 종료 시 스크립트를 실행하는 방식이 **EventBridge와 사용자 데이터**를 혼합하여 설정되어, 유지보수와 구현이 복잡해집니다.

**D.**
- ABANDON 명령을 사용하여 인스턴스를 강제로 종료시키기 전에 작업을 완료하려는 접근 방식입니다.
- 그러나 ABANDON을 사용하면 리소스가 해제되지 않아 시스템에 영향을 줄 수 있습니다.

---

#### 3. **B의 작동 방식**
1. **Lifecycle Hook 생성**:
   - `autoscaling:EC2_INSTANCE_TERMINATING` 이벤트에서 실행되도록 Lifecycle Hook을 설정합니다.
   
2. **AWS Systems Manager 사용**:
   - Systems Manager 문서(SSM Document)에 로그 파일을 S3로 복사하는 스크립트를 작성합니다.
   
3. **EventBridge와 Lambda 연동**:
   - Auto Scaling 이벤트를 EventBridge로 전달하고, Lambda를 통해 SSM의 `SendCommand` API를 호출하여 종료 전에 로그 복사를 수행합니다.
   
4. **CONTINUE 명령**:
   - Lifecycle Hook에 `CONTINUE`를 호출하여 EC2 인스턴스가 정상적으로 종료되도록 합니다.

---

#### 4. **왜 B가 적합한 해결책인가?**
- **Lifecycle Hook**: EC2 인스턴스 종료를 지연시켜 작업을 완료할 시간을 제공합니다.
- **Systems Manager**: EC2 내부에서 스크립트를 실행하는 안전하고 관리 가능한 방법을 제공합니다.
- **EventBridge + Lambda**: Auto Scaling 이벤트를 자동으로 처리하도록 구성 가능합니다.
- **CONTINUE 명령**: Auto Scaling 상태를 정상적으로 유지하며 작업을 마무리합니다.

---

### **결론**
**B**는 문제에서 요구하는 로그 손실 방지와 EC2 인스턴스 종료 과정을 모두 처리하는 가장 적합하고 확장 가능한 솔루션입니다.

# 17
### **정답: A**

---

### **해설**

이 문제는 **AWS Direct Connect 연결**을 **중복으로 추가**하고, **여러 리전**으로의 연결을 지원하는 솔루션을 요구하고 있습니다. 현재는 단일 연결이 존재하고, 확장 가능하고 중복된 연결을 제공하려는 요구 사항이 있습니다. 이를 해결하기 위한 적합한 방법을 선택해야 합니다.

### **옵션 분석**

#### **A. Provision a Direct Connect gateway. Delete the existing private virtual interface from the existing connection. Create the second Direct Connect connection. Create a new private virtual interface on each connection, and connect both private virtual interfaces to the Direct Connect gateway. Connect the Direct Connect gateway to the single VPC.**
- **Direct Connect Gateway**는 여러 AWS 리전 간 연결을 가능하게 하며, 하나의 Direct Connect 연결을 여러 리전과 연결할 수 있습니다.
- 이 솔루션은 **중복 연결을 제공**하고, **다수의 리전**과 연결을 확장할 수 있도록 합니다.
- **기존 연결**을 삭제하고 두 개의 Direct Connect 연결을 **Direct Connect Gateway**에 연결하여 **단일 VPC와 연결**합니다.
- 이 방법은 **확장성**과 **중복**을 모두 제공하는 최적의 솔루션입니다.
  
따라서 **가장 적합한 방법**입니다.

---

#### **B. Keep the existing private virtual interface. Create the second Direct Connect connection. Create a new private virtual interface on the new connection, and connect the new private virtual interface to the single VPC.**
- **두 번째 Direct Connect 연결**을 추가하지만, **Direct Connect Gateway**를 사용하지 않습니다.
- 이 방법은 **하나의 리전**에만 연결될 수 있고, 다른 리전으로의 확장성은 제공하지 않습니다. 여러 리전 간 연결이 필요하므로 이 방식은 요구 사항을 충족하지 않습니다.

---

#### **C. Keep the existing private virtual interface. Create the second Direct Connect connection. Create a new public virtual interface on the new connection, and connect the new public virtual interface to the single VPC.**
- **Public virtual interface**는 **AWS Public 서비스**와 연결되는 용도로, **VPC와의 연결**에는 적합하지 않습니다.
- 이 옵션은 요구 사항에 맞지 않으며, **VPC 연결을 위한 해결책**이 아닙니다.

---

#### **D. Provision a transit gateway. Delete the existing private virtual interface from the existing connection. Create the second Direct Connect connection. Create a new private virtual interface on each connection, and connect both private virtual interfaces to the transit gateway. Associate the transit gateway with the single VPC.**
- **Transit Gateway**는 **여러 VPC**와 연결을 처리할 수 있지만, 문제의 요구 사항은 **단일 VPC**와 연결을 설정하는 것입니다.
- Transit Gateway를 사용할 경우 **불필요한 복잡성**을 추가하게 됩니다. 또한, 이 방식은 **여러 리전**으로의 확장을 고려한 접근법이 아니라는 점에서 최적의 솔루션은 아닙니다.

---

### **결론**
옵션 **A**는 요구 사항을 충족하는 가장 **비용 효율적이고 확장 가능한** 방법으로, **Direct Connect Gateway**를 사용하여 **중복된 Direct Connect 연결**을 설정하고, **여러 리전**과의 연결을 가능하게 합니다.


# 19
**정답: B**

---

### **해설**  

**B. AWS SAM과 내장된 AWS CodeDeploy를 사용하여 새 Lambda 버전을 배포하고, 트래픽을 새 버전으로 점진적으로 전환하며, 사전 트래픽 및 사후 트래픽 테스트 기능을 사용하여 코드를 검증합니다. Amazon CloudWatch 경보가 트리거되면 롤백합니다.**

- **왜 B가 정답인가?**  
  이 옵션은 **AWS CodeDeploy**의 블루/그린 배포 전략을 활용하여 **Lambda 함수의 새 버전**으로 트래픽을 점진적으로 전환합니다.  
  1. AWS CodeDeploy는 **사전 트래픽 테스트(pre-traffic tests)**와 **사후 트래픽 테스트(post-traffic tests)**를 지원하여 배포 중 발생하는 문제를 감지할 수 있습니다.  
  2. 문제가 발생하면 자동으로 롤백할 수 있으며, 이를 위해 **Amazon CloudWatch 알람**을 사용해 오류를 모니터링합니다.  
  3. 이러한 방식은 배포 속도와 안정성을 높이고 오류로부터 복구 시간을 줄이는 데 이상적입니다.

---

### **다른 선택지 분석**

**A. AWS CloudFormation을 사용하여 중첩된 스택을 생성 및 배포**  
- 이 방법은 Lambda 함수 업데이트에 **AWS CloudFormation 변경 세트**를 사용하여 롤백할 수 있는 기능을 제공하지만, 
- 변경 세트 작성 및 배포가 상대적으로 느리고, 오류 감지 및 롤백 속도도 다른 방법보다 떨어집니다.  
- 배포 시간 단축 및 오류 복구 시간 감소라는 요구 사항을 충족하기엔 적합하지 않습니다.

**C. AWS CLI 스크립트를 리팩토링하여 자동화**  
- 단일 CLI 스크립트로 배포 프로세스를 자동화하는 것은 간단하지만,  
- 트래픽 이동 없이 배포되며 오류 감지 메커니즘이 부족합니다.  
- 수동 테스트 및 롤백에 의존해야 하므로, 복구 속도와 안정성이 제한적입니다.

**D. 새로운 API Gateway 엔드포인트를 생성 및 전환**  
- API Gateway와 CloudFront를 전환하여 새 버전을 배포하는 방법은 구현이 복잡하고,  
- 새로운 엔드포인트를 구성하는 데 시간이 소요됩니다.  
- 또한 오류 감지 및 자동 롤백 프로세스가 부족해 문제 해결 속도가 느릴 수 있습니다.

---

### **추가 설명**
- **AWS CodeDeploy**의 블루/그린 배포는 AWS Lambda 배포에서 가장 많이 사용되는 전략 중 하나입니다.  
- 이 전략은 오류 발생 시 빠르게 복구할 수 있도록 설계되어 있고, 자동화된 테스트와 모니터링을 통해 배포 안정성을 보장합니다.  
- CloudWatch 알람과 통합하면 배포 중 문제를 신속히 감지하고 대응할 수 있습니다.


# 20

### **정답: D.**  
**Amazon S3 Glacier Deep Archive를 사용하여 데이터를 저장**하는 방법이 가장 비용 효율적입니다.

---

### **해설**  

회사의 요구사항에 따라 각 선택지를 분석해보면 다음과 같습니다:

1. **저장 요건**  
   - 대량의 보관 문서를 저장해야 하며,  
   - 요청 빈도가 낮고,  
   - 데이터 가용성과 검색 속도는 중요하지 않습니다.  
   - 따라서, 장기적으로 비용이 가장 저렴한 **S3 Glacier Deep Archive**가 적합합니다.

2. **보안 요건**  
   - 데이터는 공용으로 접근할 수 없어야 하므로,  
   - **S3 인터페이스 엔드포인트**를 설정하여 VPC 내에서만 액세스하도록 제한하는 것이 필요합니다.

---

### **각 선택지 분석**

#### **A. S3 One Zone-Infrequent Access (S3 One Zone-IA)**  
- **장점**:  
  - 비용 효율적이며, 낮은 요청 빈도와 보관 데이터에 적합.  
- **단점**:  
  - S3 One Zone-IA는 장기 보관보다는 상대적으로 빈번한 데이터 액세스에 적합합니다.  
  - S3 Glacier Deep Archive에 비해 비용이 더 높습니다.  
- **적합성**: 비용 효율성 면에서 S3 Glacier Deep Archive보다 부족합니다.

---

#### **B. Amazon EFS One Zone-Infrequent Access (EFS One Zone-IA)**  
- **장점**:  
  - 파일 시스템 방식으로 데이터를 저장하며, EC2와의 통합이 쉽습니다.  
- **단점**:  
  - Amazon EFS는 데이터가 빈번히 접근될 경우 적합하며, 대량의 비활성 데이터 저장에는 비용이 비효율적입니다.  
- **적합성**: 비용이 높은 선택지입니다.

---

#### **C. Amazon EBS Cold HDD (sc1)**  
- **장점**:  
  - 저비용의 블록 스토리지로 데이터를 저장할 수 있습니다.  
- **단점**:  
  - EBS 볼륨은 EC2에 직접 연결되어야 하므로 확장성이 부족합니다.  
  - 대량의 비활성 데이터를 저장하려면 유지 비용이 더 많이 발생합니다.  
- **적합성**: S3 기반 솔루션보다 비효율적입니다.

---

#### **D. S3 Glacier Deep Archive**  
- **장점**:  
  - AWS에서 제공하는 가장 저렴한 스토리지 클래스 중 하나로, 장기 보관 데이터에 적합합니다.  
  - 요청 빈도가 낮고, 데이터 검색 속도가 중요하지 않은 상황에서 최적입니다.  
- **단점**:  
  - 데이터 검색에 시간이 더 소요됩니다(몇 시간에서 하루 정도).  
  - 그러나 이는 회사 요구사항에서 우선순위가 아닙니다.  
- **적합성**: 비용 효율적이며, 보관 데이터의 특성에 완벽히 부합합니다.

---

### **결론**  
회사의 요구사항(저비용, 낮은 요청 빈도, 데이터 가용성/검색 속도가 중요하지 않음)에 가장 적합한 솔루션은 **S3 Glacier Deep Archive**를 사용하는 것입니다.  
또한, S3 인터페이스 엔드포인트를 통해 데이터에 대한 공용 접근을 제한하여 보안 요건도 충족할 수 있습니다.


# 21
**정답: B. API Gateway 수준에서 사용 계획을 통해 API 제한(throttling)을 구현합니다. 클라이언트 애플리케이션이 코드 429 응답을 오류 없이 처리하도록 합니다.**  

### **해설**  
이 문제는 API 호출 과부하로 인해 발생하는 오류를 해결하는 방법에 초점을 맞추고 있습니다. 각 옵션을 분석하면 다음과 같습니다.  

---

**A. 클라이언트 애플리케이션에 재시도 로직 구현**  
- **장점**: 재시도 로직은 오류를 완화하는 데 유용하며, 지수적 백오프(exponential backoff)는 서버 과부하를 방지할 수 있습니다.  
- **문제점**: 이 접근 방식은 클라이언트 측 수정이 필요합니다. 그러나 문제의 원인은 특정 클라이언트의 과도한 요청이므로 API 자체에서 이를 제한하는 것이 더 적합합니다.  

---

**B. API Gateway에서 제한(throttling) 설정**  
- **장점**: 제한을 통해 특정 클라이언트가 과도한 요청을 보내는 것을 방지할 수 있습니다. 제한된 요청은 HTTP 429(Too Many Requests) 상태 코드로 응답되며, 클라이언트는 이를 기반으로 요청을 조정할 수 있습니다.  
- **적합성**: API가 비필수적이고 재시도가 가능하다는 조건에 부합하며, 고객 경험을 보호할 수 있습니다.  

---

**C. API 캐싱 활성화**  
- **문제점**: 캐싱은 주로 GET 요청과 같이 자주 액세스되는 데이터에 적합합니다. 그러나 PUT 요청은 데이터를 수정하는 작업이므로 캐싱과는 관련이 없습니다.  

---

**D. Lambda 예약된 동시성 설정**  
- **장점**: Lambda의 동시성 제어는 리소스 고갈을 방지할 수 있습니다.  
- **문제점**: 이 방법은 과도한 요청을 처리하기 위해 리소스를 추가로 할당하는 데 초점이 맞춰져 있어, 문제가 발생한 클라이언트를 제한하지 못합니다.  

---

### **결론**  
**옵션 B**는 과도한 요청을 제한하고, 다른 클라이언트에 대한 영향을 최소화하며, API의 평판을 보호할 수 있는 가장 적합한 솔루션입니다.  

추가적으로, 클라이언트가 429 응답을 적절히 처리하도록 명확한 가이드를 제공하는 것이 중요합니다.


# 23
**정답: A.**  
**기존 공유 파일 시스템 데이터를 Amazon S3 버킷으로 마이그레이션하고, S3 Intelligent-Tiering 스토리지 클래스를 사용합니다. 매달 작업 실행 전에 Amazon FSx for Lustre를 사용하여 Amazon S3에서 새로운 파일 시스템을 생성하고 지연 로딩(lazy loading)을 사용합니다. 작업 동안 새 파일 시스템을 공유 스토리지로 사용하고, 작업 완료 후 파일 시스템을 삭제합니다.**

---

### **해설**  

#### **1. 문제 요점**
- 비용을 절감해야 하며, 고성능 데이터 액세스를 제공해야 함.
- 작업은 한 달에 한 번 실행되며, 약 72시간 동안 실행됨.
- EC2 인스턴스에서 공유 스토리지를 사용해야 하며, 작업 완료 후에는 스토리지를 삭제 가능.  

---

#### **옵션 분석**  

**A. S3 + FSx for Lustre (지연 로딩)**  
- **작동 방식**:  
  - 데이터를 S3 Intelligent-Tiering으로 마이그레이션(비활성 데이터는 저렴한 스토리지 비용).  
  - 작업 실행 전 FSx for Lustre 파일 시스템을 생성하고, S3 데이터를 지연 로딩(lazy loading)하여 필요한 데이터만 로드.  
  - 작업 완료 후 FSx for Lustre 파일 시스템 삭제.  
- **비용 효과**:  
  - S3 Intelligent-Tiering은 데이터를 자주 액세스하지 않는 경우 스토리지 비용이 크게 절감됨.  
  - FSx for Lustre는 작업 기간 동안만 사용되므로 추가 비용 절감 가능.  
- **적합성**:  
  - 고성능 공유 스토리지 제공(FSx for Lustre).  
  - 필요한 데이터만 로드하여 효율적인 리소스 사용.  
  - 가장 큰 비용 절감 효과를 제공.  

---

**B. Multi-Attach EBS**  
- **작동 방식**:  
  - 데이터를 대형 EBS 볼륨으로 마이그레이션하고 Multi-Attach를 사용하여 여러 인스턴스에서 공유.  
- **문제점**:  
  - EBS는 지속적으로 실행되므로 스토리지 비용이 매우 높음.  
  - 대규모 데이터(200TB)를 저장할 때 비용이 S3보다 훨씬 비쌈.  
  - Multi-Attach는 특정 워크로드에서만 적합하며, 고성능 분산 파일 시스템 제공에 적합하지 않음.  

---

**C. S3 + FSx for Lustre (배치 로딩)**  
- **작동 방식**:  
  - 데이터를 S3 Standard로 마이그레이션(비용이 S3 Intelligent-Tiering보다 높음).  
  - FSx for Lustre 파일 시스템을 생성하고 데이터를 한꺼번에 로드(batch loading).  
- **문제점**:  
  - S3 Standard는 액세스 빈도가 낮은 데이터에 비효율적.  
  - 배치 로딩은 작업 전에 모든 데이터를 로드하므로 시간과 비용이 증가.  
  - 지연 로딩(lazy loading)보다 비효율적.  

---

**D. S3 + Storage Gateway**  
- **작동 방식**:  
  - 데이터를 S3로 마이그레이션하고, 작업 전에 Storage Gateway를 생성하여 데이터에 액세스.  
- **문제점**:  
  - Storage Gateway는 S3 데이터를 캐싱하여 사용할 수 있지만, FSx for Lustre처럼 고성능 파일 시스템 제공에는 적합하지 않음.  
  - 200TB 데이터를 처리할 때 Storage Gateway의 성능이 제한적.  

---

#### **결론**  
옵션 A는 데이터를 비용 효율적으로 저장(S3 Intelligent-Tiering)하고, 작업 기간 동안 FSx for Lustre로 고성능 공유 파일 시스템을 제공하며, 작업 완료 후 리소스를 삭제하여 추가 비용을 방지할 수 있습니다. 이로 인해 **가장 큰 비용 절감 효과**를 제공합니다.

**정답: C**  
**"Amazon EC2 인스턴스를 생성하고 가용 영역당 하나의 Elastic IP 주소를 생성하여 Network Load Balancer(NLB)에 할당합니다. NLB DNS 이름을 A(별칭) 레코드 세트에 매핑합니다."**

---

### **해설**  

#### **문제 요건 분석**
1. **고가용성 및 중복성**:  
   - 여러 가용 영역(Availability Zone)에서 서비스가 중단 없이 동작해야 함.
2. **DNS 이름을 통한 접근**:  
   - 고객이 **my.service.com**으로 서비스에 접근 가능해야 함.
3. **고정된 IP 주소**:  
   - 다른 회사가 허용 목록에 추가할 수 있도록 고정된 IP 주소를 제공해야 함.
4. **TCP 정적 포트**:  
   - 서비스가 정적 포트를 사용하며 TCP 프로토콜을 지원해야 함.

---

#### **옵션 분석**

**A. EC2 + Elastic IP + NLB**  
- **구성**:  
  - 각 EC2 인스턴스에 Elastic IP를 할당하고, 이를 DNS 이름과 직접 연결.  
- **문제점**:  
  - NLB와 EC2 인스턴스 사이에 Elastic IP를 연결하므로 고가용성과 중복성을 완벽히 보장하지 못함.  
  - 인스턴스별 Elastic IP 관리가 복잡.  
  - DNS 이름이 Elastic IP에 직접 매핑되므로 NLB가 제공하는 이점(예: 가용 영역 전환)을 활용하지 못함.  

---

**B. ECS + NLB + Public IP**  
- **구성**:  
  - ECS 클러스터와 NLB를 사용하며, ECS 클러스터의 공용 IP를 DNS 이름에 연결.  
- **문제점**:  
  - ECS의 공용 IP는 동적일 수 있어 고정된 IP 요구사항을 충족하지 못함.  
  - ECS 클러스터 이름으로 트래픽을 분배할 수 있으나, Elastic IP 주소 기반으로 허용 목록을 관리할 수 없음.  

---

**C. EC2 + Elastic IP + NLB (정답)**  
- **구성**:  
  - 각 가용 영역마다 하나의 Elastic IP를 생성하고, 이를 Network Load Balancer(NLB)에 연결.  
  - NLB가 트래픽을 EC2 인스턴스에 분배하며, NLB의 DNS 이름을 A 레코드로 설정.  
- **장점**:  
  - Elastic IP를 사용하므로 고정된 IP 주소를 제공 가능.  
  - NLB는 고가용성을 보장하며, 다중 가용 영역에 중복성을 제공.  
  - Elastic IP 주소를 허용 목록에 추가하도록 제공 가능.  

---

**D. ECS + ALB + Public IP**  
- **구성**:  
  - ECS 클러스터와 Application Load Balancer(ALB)를 사용하며, ECS 클러스터의 공용 IP를 DNS 이름에 연결.  
- **문제점**:  
  - ALB는 정적 TCP 포트를 지원하지 않음(ALB는 주로 HTTP/HTTPS 트래픽을 처리).  
  - ECS 클러스터의 공용 IP는 동적일 수 있어 고정된 IP 요구사항을 충족하지 못함.  

---

### **결론**  
옵션 C는 **고정된 IP 주소 제공, 고가용성, 중복성**을 모두 충족하며, 비용 효율적이고 관리가 용이합니다.  
- Elastic IP를 사용해 고정된 주소를 제공하며,  
- Network Load Balancer는 TCP 트래픽을 지원하고 다중 가용 영역에서 트래픽을 분배합니다.  
- DNS 이름(my.service.com)은 NLB의 DNS 이름에 매핑되므로 설정이 간단합니다.  

이로 인해 **옵션 C**가 최적의 선택입니다.


# 26
**정답: A**

**해설:**

보안 엔지니어의 요구 사항을 다시 한 번 정리해 보겠습니다:
1. **강력하고 무작위로 생성된 암호**는 **보안된 AWS 관리 서비스**에 저장되어야 합니다.
2. 애플리케이션 리소스는 **AWS CloudFormation**을 통해 배포해야 합니다.
3. 자격 증명은 **90일마다 자동으로 회전**해야 합니다.

### **옵션 분석**

**A.**  
- **장점**:
  - **AWS Secrets Manager**를 사용하여 암호를 비밀로 생성하고, 이는 강력하고 무작위로 생성된 암호를 안전하게 저장하는 데 적합합니다.
  - **Secrets Manager RotationSchedule** 리소스는 **자동으로 암호 회전**을 처리하며, 회전 주기를 설정할 수 있습니다. 이 리소스는 **CloudFormation**에서 **완전하게 지원**됩니다.
  - **Lambda 함수**는 암호 회전을 자동화하는 데 필요한 작업을 처리하며, 이는 최소한의 운영 오버헤드로 설정할 수 있습니다.
  
  **AWS Secrets Manager의 RotationSchedule**은 암호를 안전하고 자동으로 회전시키는 기능을 제공하며, **90일마다 자동으로 회전**하도록 설정할 수 있습니다. 이 방식은 요구 사항을 **가장 효율적이고 안전하게 충족**합니다.

- **운영 오버헤드**: Secrets Manager는 자동 암호 회전 기능을 기본으로 제공하므로, 추가적인 구성 요소나 외부 서비스 없이 요구 사항을 충족할 수 있어 **운영 오버헤드가 최소화**됩니다.

**B.**  
- **문제점**: AWS Systems Manager Parameter Store는 SecureString을 사용하여 자격 증명을 저장할 수 있지만, **암호 회전**을 **자동화하는 기본 기능**이 부족합니다. Lambda 함수를 사용하여 회전할 수 있지만, **회전 일정 관리**를 위해 추가적인 작업이 필요하고, CloudFormation에서 이 기능을 구현하려면 더 많은 수동 구성이 필요합니다. 이 방식은 운영 오버헤드가 증가할 수 있습니다.

**C.**  
- **문제점**: Secrets Manager를 사용하여 암호를 저장하고, Lambda 함수를 통해 암호 회전을 처리하는 것은 적절합니다. 그러나 **Amazon EventBridge**를 사용해 90일마다 암호를 회전시키는 것은 필요하지 않으며, EventBridge는 Secrets Manager의 **RotationSchedule 리소스를 대신할 수** 없습니다. Secrets Manager에서 자체적으로 회전 주기를 관리할 수 있기 때문에 EventBridge는 불필요하며, 이로 인해 복잡도가 증가할 수 있습니다.

**D.**  
- **문제점**: AWS AppSync는 주로 GraphQL API 서비스를 위한 리소스이며, 데이터베이스 자격 증명의 자동 회전과는 관련이 없습니다. 이 옵션은 요구 사항을 충족하지 않으므로 잘못된 선택입니다.

### **결론**
**옵션 A**는 AWS Secrets Manager에서 **RotationSchedule 리소스**를 사용하여 암호를 자동으로 회전시키는 기능을 제공하고, **CloudFormation 템플릿**을 통해 배포할 수 있어 가장 적합한 솔루션입니다. 이 방법은 보안 요구 사항을 충족하면서도 운영 오버헤드를 최소화할 수 있습니다.